diff --git a/crates/codex/src/auth.rs b/crates/codex/src/auth.rs
new file mode 100644
index 0000000..1aa284c
--- /dev/null
+++ b/crates/codex/src/auth.rs
@@ -0,0 +1,279 @@
+use std::path::PathBuf;
+
+use tokio::process::Command;
+
+use crate::{
+    capabilities::{guard_is_supported, log_guard_skip},
+    process::{preferred_output_channel, spawn_with_retry},
+    CodexClient, CodexError,
+};
+
+/// Current authentication state reported by `codex login status`.
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub enum CodexAuthStatus {
+    /// The CLI reports an active session.
+    LoggedIn(CodexAuthMethod),
+    /// No credentials stored locally.
+    LoggedOut,
+}
+
+/// Authentication mechanism used to sign in.
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub enum CodexAuthMethod {
+    ChatGpt,
+    ApiKey {
+        masked_key: Option<String>,
+    },
+    /// CLI reported a logged-in state but the auth method could not be parsed (e.g., new wording).
+    Unknown {
+        raw: String,
+    },
+}
+
+/// Result of invoking `codex logout`.
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub enum CodexLogoutStatus {
+    LoggedOut,
+    AlreadyLoggedOut,
+}
+
+/// Helper for checking Codex auth state and triggering login flows with an app-scoped `CODEX_HOME`.
+///
+/// All commands run with per-process env overrides; the parent process env is never mutated.
+#[derive(Clone, Debug)]
+pub struct AuthSessionHelper {
+    client: CodexClient,
+}
+
+impl AuthSessionHelper {
+    /// Creates a helper that pins `CODEX_HOME` to `app_codex_home` for every login call.
+    pub fn new(app_codex_home: impl Into<PathBuf>) -> Self {
+        let client = CodexClient::builder()
+            .codex_home(app_codex_home)
+            .create_home_dirs(true)
+            .build();
+        Self { client }
+    }
+
+    /// Wraps an existing `CodexClient` (useful when you already configured the binary path).
+    pub fn with_client(client: CodexClient) -> Self {
+        Self { client }
+    }
+
+    /// Returns the underlying `CodexClient`.
+    pub fn client(&self) -> CodexClient {
+        self.client.clone()
+    }
+
+    /// Reports the current login status under the configured `CODEX_HOME`.
+    pub async fn status(&self) -> Result<CodexAuthStatus, CodexError> {
+        self.client.login_status().await
+    }
+
+    /// Logs in with an API key when logged out; otherwise returns the current status.
+    pub async fn ensure_api_key_login(
+        &self,
+        api_key: impl AsRef<str>,
+    ) -> Result<CodexAuthStatus, CodexError> {
+        match self.status().await? {
+            logged @ CodexAuthStatus::LoggedIn(_) => Ok(logged),
+            CodexAuthStatus::LoggedOut => self.client.login_with_api_key(api_key).await,
+        }
+    }
+
+    /// Starts the ChatGPT OAuth login flow when no credentials are present.
+    ///
+    /// Returns `Ok(None)` when already logged in; otherwise returns the spawned login child so the
+    /// caller can surface output/URLs. Dropping the child kills the login helper.
+    pub async fn ensure_chatgpt_login(&self) -> Result<Option<tokio::process::Child>, CodexError> {
+        match self.status().await? {
+            CodexAuthStatus::LoggedIn(_) => Ok(None),
+            CodexAuthStatus::LoggedOut => self.client.spawn_login_process().map(Some),
+        }
+    }
+
+    /// Directly spawns the ChatGPT login process.
+    pub fn spawn_chatgpt_login(&self) -> Result<tokio::process::Child, CodexError> {
+        self.client.spawn_login_process()
+    }
+
+    /// Directly logs in with an API key without checking prior state.
+    pub async fn login_with_api_key(
+        &self,
+        api_key: impl AsRef<str>,
+    ) -> Result<CodexAuthStatus, CodexError> {
+        self.client.login_with_api_key(api_key).await
+    }
+}
+
+impl CodexClient {
+    /// Spawns a `codex login` session using the default ChatGPT OAuth flow.
+    ///
+    /// The returned child inherits `kill_on_drop` so abandoning the handle cleans up the login helper.
+    pub fn spawn_login_process(&self) -> Result<tokio::process::Child, CodexError> {
+        let mut command = Command::new(self.command_env.binary_path());
+        command
+            .arg("login")
+            .stdout(std::process::Stdio::piped())
+            .stderr(std::process::Stdio::piped())
+            .kill_on_drop(true);
+
+        self.command_env.apply(&mut command)?;
+
+        spawn_with_retry(&mut command, self.command_env.binary_path())
+    }
+
+    /// Spawns a `codex login --device-auth` session.
+    ///
+    /// The returned child inherits `kill_on_drop` so abandoning the handle cleans up the login helper.
+    pub fn spawn_device_auth_login_process(&self) -> Result<tokio::process::Child, CodexError> {
+        let mut command = Command::new(self.command_env.binary_path());
+        command
+            .arg("login")
+            .arg("--device-auth")
+            .stdout(std::process::Stdio::piped())
+            .stderr(std::process::Stdio::piped())
+            .kill_on_drop(true);
+
+        self.command_env.apply(&mut command)?;
+
+        spawn_with_retry(&mut command, self.command_env.binary_path())
+    }
+
+    /// Spawns a `codex login --with-api-key` session (interactive API-key flow).
+    ///
+    /// The returned child inherits `kill_on_drop` so abandoning the handle cleans up the login helper.
+    pub fn spawn_with_api_key_login_process(&self) -> Result<tokio::process::Child, CodexError> {
+        let mut command = Command::new(self.command_env.binary_path());
+        command
+            .arg("login")
+            .arg("--with-api-key")
+            .stdout(std::process::Stdio::piped())
+            .stderr(std::process::Stdio::piped())
+            .kill_on_drop(true);
+
+        self.command_env.apply(&mut command)?;
+
+        spawn_with_retry(&mut command, self.command_env.binary_path())
+    }
+
+    /// Spawns `codex login --mcp` when the probed binary advertises support.
+    ///
+    /// Returns `Ok(None)` when the capability is unknown or unsupported so
+    /// callers can degrade gracefully without attempting the flag.
+    pub async fn spawn_mcp_login_process(
+        &self,
+    ) -> Result<Option<tokio::process::Child>, CodexError> {
+        let capabilities = self.probe_capabilities().await;
+        let guard = capabilities.guard_mcp_login();
+        if !guard_is_supported(&guard) {
+            log_guard_skip(&guard);
+            return Ok(None);
+        }
+
+        let mut command = Command::new(self.command_env.binary_path());
+        command
+            .arg("login")
+            .arg("--mcp")
+            .stdout(std::process::Stdio::piped())
+            .stderr(std::process::Stdio::piped())
+            .kill_on_drop(true);
+
+        self.command_env.apply(&mut command)?;
+
+        let child = spawn_with_retry(&mut command, self.command_env.binary_path())?;
+
+        Ok(Some(child))
+    }
+
+    /// Logs in with a provided API key by invoking `codex login --api-key <key>`.
+    pub async fn login_with_api_key(
+        &self,
+        api_key: impl AsRef<str>,
+    ) -> Result<CodexAuthStatus, CodexError> {
+        let api_key = api_key.as_ref().trim();
+        if api_key.is_empty() {
+            return Err(CodexError::EmptyApiKey);
+        }
+
+        let output = self
+            .run_basic_command(["login", "--api-key", api_key])
+            .await?;
+        let combined = preferred_output_channel(&output);
+
+        if output.status.success() {
+            Ok(parse_login_success(&combined).unwrap_or_else(|| {
+                CodexAuthStatus::LoggedIn(CodexAuthMethod::Unknown {
+                    raw: combined.clone(),
+                })
+            }))
+        } else {
+            Err(CodexError::NonZeroExit {
+                status: output.status,
+                stderr: combined,
+            })
+        }
+    }
+
+    /// Returns the current Codex authentication state by invoking `codex login status`.
+    pub async fn login_status(&self) -> Result<CodexAuthStatus, CodexError> {
+        let output = self.run_basic_command(["login", "status"]).await?;
+        let combined = preferred_output_channel(&output);
+
+        if output.status.success() {
+            Ok(parse_login_success(&combined).unwrap_or_else(|| {
+                CodexAuthStatus::LoggedIn(CodexAuthMethod::Unknown {
+                    raw: combined.clone(),
+                })
+            }))
+        } else if combined.to_lowercase().contains("not logged in") {
+            Ok(CodexAuthStatus::LoggedOut)
+        } else {
+            Err(CodexError::NonZeroExit {
+                status: output.status,
+                stderr: combined,
+            })
+        }
+    }
+
+    /// Removes cached credentials via `codex logout`.
+    pub async fn logout(&self) -> Result<CodexLogoutStatus, CodexError> {
+        let output = self.run_basic_command(["logout"]).await?;
+        let combined = preferred_output_channel(&output);
+
+        if !output.status.success() {
+            return Err(CodexError::NonZeroExit {
+                status: output.status,
+                stderr: combined,
+            });
+        }
+
+        let normalized = combined.to_lowercase();
+        if normalized.contains("successfully logged out") {
+            Ok(CodexLogoutStatus::LoggedOut)
+        } else if normalized.contains("not logged in") {
+            Ok(CodexLogoutStatus::AlreadyLoggedOut)
+        } else {
+            Ok(CodexLogoutStatus::LoggedOut)
+        }
+    }
+}
+
+pub(crate) fn parse_login_success(output: &str) -> Option<CodexAuthStatus> {
+    let lower = output.to_lowercase();
+    if lower.contains("chatgpt") {
+        return Some(CodexAuthStatus::LoggedIn(CodexAuthMethod::ChatGpt));
+    }
+    if lower.contains("api key") || lower.contains("apikey") {
+        // Prefer everything after the first " - " so we do not chop the key itself.
+        let masked = output
+            .split_once(" - ")
+            .map(|(_, value)| value.trim().to_string())
+            .filter(|value| !value.is_empty())
+            .or_else(|| output.split_whitespace().last().map(|v| v.to_string()));
+        return Some(CodexAuthStatus::LoggedIn(CodexAuthMethod::ApiKey {
+            masked_key: masked,
+        }));
+    }
+    None
+}
diff --git a/crates/codex/src/builder/cli_overrides.rs b/crates/codex/src/builder/cli_overrides.rs
new file mode 100644
index 0000000..f1604c6
--- /dev/null
+++ b/crates/codex/src/builder/cli_overrides.rs
@@ -0,0 +1,204 @@
+use std::{ffi::OsString, path::PathBuf};
+
+use tokio::process::Command;
+
+use super::{
+    ApprovalPolicy, CliOverrides, CliOverridesPatch, ConfigOverride, FeatureToggles, FlagState,
+    LocalProvider, SafetyOverride, SandboxMode,
+};
+
+pub(super) const DEFAULT_REASONING_CONFIG_GPT5: &[(&str, &str)] = &[
+    ("model_reasoning_effort", "medium"),
+    ("model_reasoning_summary", "auto"),
+    ("model_verbosity", "low"),
+];
+
+pub(super) const DEFAULT_REASONING_CONFIG_GPT5_CODEX: &[(&str, &str)] = &[
+    ("model_reasoning_effort", "medium"),
+    ("model_reasoning_summary", "auto"),
+    ("model_verbosity", "low"),
+];
+
+pub(super) const DEFAULT_REASONING_CONFIG_GPT5_1: &[(&str, &str)] = &[
+    ("model_reasoning_effort", "medium"),
+    ("model_reasoning_summary", "auto"),
+    ("model_verbosity", "low"),
+];
+
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub(crate) struct ResolvedCliOverrides {
+    pub(crate) config_overrides: Vec<ConfigOverride>,
+    pub(crate) feature_toggles: FeatureToggles,
+    pub(crate) approval_policy: Option<ApprovalPolicy>,
+    pub(crate) sandbox_mode: Option<SandboxMode>,
+    pub(crate) safety_override: SafetyOverride,
+    pub(crate) profile: Option<String>,
+    pub(crate) cd: Option<PathBuf>,
+    pub(crate) local_provider: Option<LocalProvider>,
+    pub(crate) oss: bool,
+    pub(crate) search: FlagState,
+}
+
+impl ResolvedCliOverrides {
+    fn search_enabled(&self) -> bool {
+        matches!(self.search, FlagState::Enable)
+    }
+}
+
+pub(super) fn reasoning_config_for(
+    model: Option<&str>,
+) -> Option<&'static [(&'static str, &'static str)]> {
+    let name = model.map(|value| value.to_ascii_lowercase())?;
+    match name.as_str() {
+        name if name.starts_with("gpt-5.1-codex") => Some(DEFAULT_REASONING_CONFIG_GPT5_1),
+        name if name.starts_with("gpt-5.1") => Some(DEFAULT_REASONING_CONFIG_GPT5_1),
+        "gpt-5-codex" => Some(DEFAULT_REASONING_CONFIG_GPT5_CODEX),
+        name if name.starts_with("gpt-5") => Some(DEFAULT_REASONING_CONFIG_GPT5),
+        _ => None,
+    }
+}
+
+fn has_reasoning_config_override(overrides: &[ConfigOverride]) -> bool {
+    overrides.iter().any(ConfigOverride::is_reasoning_key)
+}
+
+pub(super) fn resolve_cli_overrides(
+    builder: &CliOverrides,
+    patch: &CliOverridesPatch,
+    model: Option<&str>,
+) -> ResolvedCliOverrides {
+    let auto_reasoning_defaults = patch
+        .auto_reasoning_defaults
+        .unwrap_or(builder.auto_reasoning_defaults);
+
+    let has_reasoning_overrides = builder.reasoning.has_overrides()
+        || patch.reasoning.has_overrides()
+        || has_reasoning_config_override(&builder.config_overrides)
+        || has_reasoning_config_override(&patch.config_overrides);
+
+    let mut config_overrides = Vec::new();
+    if auto_reasoning_defaults && !has_reasoning_overrides {
+        if let Some(defaults) = reasoning_config_for(model) {
+            for (key, value) in defaults {
+                config_overrides.push(ConfigOverride::new(*key, *value));
+            }
+        }
+    }
+
+    config_overrides.extend(builder.config_overrides.clone());
+    builder.reasoning.append_overrides(&mut config_overrides);
+    config_overrides.extend(patch.config_overrides.clone());
+    patch.reasoning.append_overrides(&mut config_overrides);
+
+    let approval_policy = patch.approval_policy.or(builder.approval_policy);
+    let sandbox_mode = patch.sandbox_mode.or(builder.sandbox_mode);
+    let safety_override = patch.safety_override.unwrap_or(builder.safety_override);
+    let profile = patch.profile.clone().or_else(|| builder.profile.clone());
+    let cd = patch.cd.clone().or_else(|| builder.cd.clone());
+    let local_provider = patch.local_provider.or(builder.local_provider);
+    let search = match patch.search {
+        FlagState::Inherit => builder.search,
+        other => other,
+    };
+    let oss = match patch.oss {
+        FlagState::Inherit => builder.oss,
+        other => other,
+    };
+    let mut feature_toggles = builder.feature_toggles.clone();
+    feature_toggles
+        .enable
+        .extend(patch.feature_toggles.enable.iter().cloned());
+    feature_toggles
+        .disable
+        .extend(patch.feature_toggles.disable.iter().cloned());
+
+    ResolvedCliOverrides {
+        config_overrides,
+        feature_toggles,
+        approval_policy,
+        sandbox_mode,
+        safety_override,
+        profile,
+        cd,
+        local_provider,
+        oss: matches!(oss, FlagState::Enable),
+        search,
+    }
+}
+
+pub(super) fn cli_override_args(
+    resolved: &ResolvedCliOverrides,
+    include_search: bool,
+) -> Vec<OsString> {
+    let mut args = Vec::new();
+    for config in &resolved.config_overrides {
+        args.push(OsString::from("--config"));
+        args.push(OsString::from(format!("{}={}", config.key, config.value)));
+    }
+
+    for feature in &resolved.feature_toggles.enable {
+        args.push(OsString::from("--enable"));
+        args.push(OsString::from(feature));
+    }
+
+    for feature in &resolved.feature_toggles.disable {
+        args.push(OsString::from("--disable"));
+        args.push(OsString::from(feature));
+    }
+
+    if let Some(profile) = &resolved.profile {
+        args.push(OsString::from("--profile"));
+        args.push(OsString::from(profile));
+    }
+
+    match resolved.safety_override {
+        SafetyOverride::DangerouslyBypass => {
+            args.push(OsString::from("--dangerously-bypass-approvals-and-sandbox"));
+        }
+        other => {
+            if let Some(policy) = resolved.approval_policy {
+                args.push(OsString::from("--ask-for-approval"));
+                args.push(OsString::from(policy.as_str()));
+            }
+
+            if let Some(mode) = resolved.sandbox_mode {
+                args.push(OsString::from("--sandbox"));
+                args.push(OsString::from(mode.as_str()));
+            } else if resolved.approval_policy.is_none()
+                && matches!(other, SafetyOverride::FullAuto)
+            {
+                args.push(OsString::from("--full-auto"));
+            }
+        }
+    }
+
+    if let Some(cd) = &resolved.cd {
+        args.push(OsString::from("--cd"));
+        args.push(cd.as_os_str().to_os_string());
+    }
+
+    if let Some(provider) = resolved.local_provider {
+        args.push(OsString::from("--local-provider"));
+        args.push(OsString::from(provider.as_str()));
+    }
+
+    if resolved.oss {
+        args.push(OsString::from("--oss"));
+    }
+
+    if include_search && resolved.search_enabled() {
+        args.push(OsString::from("--search"));
+    }
+
+    args
+}
+
+pub(super) fn apply_cli_overrides(
+    command: &mut Command,
+    resolved: &ResolvedCliOverrides,
+    include_search: bool,
+) {
+    for arg in cli_override_args(resolved, include_search) {
+        command.arg(arg);
+    }
+}
diff --git a/crates/codex/src/builder.rs b/crates/codex/src/builder/mod.rs
similarity index 51%
rename from crates/codex/src/builder.rs
rename to crates/codex/src/builder/mod.rs
index afb6530..76162a2 100644
--- a/crates/codex/src/builder.rs
+++ b/crates/codex/src/builder/mod.rs
@@ -1,26 +1,62 @@
-use std::{ffi::OsString, path::PathBuf, time::Duration};
+use std::{path::PathBuf, time::Duration};
 
-use tokio::process::Command;
+#[cfg(test)]
+use std::ffi::OsString;
 
 use crate::home::CommandEnvironment;
+use tokio::process::Command;
+
+mod cli_overrides;
+mod types;
 
-pub(super) const DEFAULT_REASONING_CONFIG_GPT5: &[(&str, &str)] = &[
-    ("model_reasoning_effort", "medium"),
-    ("model_reasoning_summary", "auto"),
-    ("model_verbosity", "low"),
-];
+pub use types::{
+    ApprovalPolicy, CliOverrides, CliOverridesPatch, ColorMode, ConfigOverride, FeatureToggles,
+    FlagState, LocalProvider, ModelVerbosity, ReasoningEffort, ReasoningOverrides,
+    ReasoningSummary, ReasoningSummaryFormat, SafetyOverride, SandboxMode,
+};
 
-pub(super) const DEFAULT_REASONING_CONFIG_GPT5_CODEX: &[(&str, &str)] = &[
-    ("model_reasoning_effort", "medium"),
-    ("model_reasoning_summary", "auto"),
-    ("model_verbosity", "low"),
-];
+pub(super) type ResolvedCliOverrides = cli_overrides::ResolvedCliOverrides;
+
+#[cfg(test)]
+pub(super) const DEFAULT_REASONING_CONFIG_GPT5: &[(&str, &str)] =
+    cli_overrides::DEFAULT_REASONING_CONFIG_GPT5;
+#[cfg(test)]
+pub(super) const DEFAULT_REASONING_CONFIG_GPT5_CODEX: &[(&str, &str)] =
+    cli_overrides::DEFAULT_REASONING_CONFIG_GPT5_CODEX;
+#[cfg(test)]
+pub(super) const DEFAULT_REASONING_CONFIG_GPT5_1: &[(&str, &str)] =
+    cli_overrides::DEFAULT_REASONING_CONFIG_GPT5_1;
+
+#[cfg(test)]
+pub(super) fn reasoning_config_for(
+    model: Option<&str>,
+) -> Option<&'static [(&'static str, &'static str)]> {
+    cli_overrides::reasoning_config_for(model)
+}
+
+pub(super) fn resolve_cli_overrides(
+    builder: &CliOverrides,
+    patch: &CliOverridesPatch,
+    model: Option<&str>,
+) -> ResolvedCliOverrides {
+    cli_overrides::resolve_cli_overrides(builder, patch, model)
+}
 
-pub(super) const DEFAULT_REASONING_CONFIG_GPT5_1: &[(&str, &str)] = &[
-    ("model_reasoning_effort", "medium"),
-    ("model_reasoning_summary", "auto"),
-    ("model_verbosity", "low"),
-];
+#[cfg(test)]
+pub(super) fn cli_override_args(
+    resolved: &ResolvedCliOverrides,
+    include_search: bool,
+) -> Vec<OsString> {
+    cli_overrides::cli_override_args(resolved, include_search)
+}
+
+pub(super) fn apply_cli_overrides(
+    command: &mut Command,
+    resolved: &ResolvedCliOverrides,
+    include_search: bool,
+) {
+    cli_overrides::apply_cli_overrides(command, resolved, include_search);
+}
 
 /// Builder for [`crate::CodexClient`].
 ///
@@ -407,11 +443,11 @@ impl CodexClientBuilder {
 impl Default for CodexClientBuilder {
     fn default() -> Self {
         Self {
-            binary: super::default_binary_path(),
+            binary: crate::defaults::default_binary_path(),
             codex_home: None,
             create_home_dirs: true,
             model: None,
-            timeout: super::DEFAULT_TIMEOUT,
+            timeout: crate::defaults::DEFAULT_TIMEOUT,
             color_mode: ColorMode::Never,
             working_dir: None,
             add_dirs: Vec::new(),
@@ -427,497 +463,3 @@ impl Default for CodexClientBuilder {
         }
     }
 }
-
-/// ANSI color behavior for `codex exec` output.
-#[derive(Clone, Copy, Debug, Eq, PartialEq)]
-pub enum ColorMode {
-    /// Match upstream defaults: use color codes when stdout/stderr look like terminals.
-    Auto,
-    /// Force colorful output even when piping.
-    Always,
-    /// Fully disable ANSI sequences for deterministic parsing/logging (default).
-    Never,
-}
-
-impl ColorMode {
-    pub(super) const fn as_str(self) -> &'static str {
-        match self {
-            ColorMode::Auto => "auto",
-            ColorMode::Always => "always",
-            ColorMode::Never => "never",
-        }
-    }
-}
-
-/// Approval policy used by `--ask-for-approval`.
-#[derive(Clone, Copy, Debug, Eq, PartialEq)]
-pub enum ApprovalPolicy {
-    Untrusted,
-    OnFailure,
-    OnRequest,
-    Never,
-}
-
-impl ApprovalPolicy {
-    const fn as_str(self) -> &'static str {
-        match self {
-            ApprovalPolicy::Untrusted => "untrusted",
-            ApprovalPolicy::OnFailure => "on-failure",
-            ApprovalPolicy::OnRequest => "on-request",
-            ApprovalPolicy::Never => "never",
-        }
-    }
-}
-
-/// Sandbox isolation level.
-#[derive(Clone, Copy, Debug, Eq, PartialEq)]
-pub enum SandboxMode {
-    ReadOnly,
-    WorkspaceWrite,
-    DangerFullAccess,
-}
-
-impl SandboxMode {
-    const fn as_str(self) -> &'static str {
-        match self {
-            SandboxMode::ReadOnly => "read-only",
-            SandboxMode::WorkspaceWrite => "workspace-write",
-            SandboxMode::DangerFullAccess => "danger-full-access",
-        }
-    }
-}
-
-/// Safety overrides that collapse approval/sandbox behavior.
-#[derive(Clone, Copy, Debug, Default, Eq, PartialEq)]
-pub enum SafetyOverride {
-    #[default]
-    Inherit,
-    FullAuto,
-    DangerouslyBypass,
-}
-
-/// Local provider selection for OSS backends.
-#[derive(Clone, Copy, Debug, Eq, PartialEq)]
-pub enum LocalProvider {
-    LmStudio,
-    Ollama,
-    Custom,
-}
-
-impl LocalProvider {
-    const fn as_str(self) -> &'static str {
-        match self {
-            LocalProvider::LmStudio => "lmstudio",
-            LocalProvider::Ollama => "ollama",
-            LocalProvider::Custom => "custom",
-        }
-    }
-}
-
-/// Three-state flag used when requests can override builder defaults.
-#[derive(Clone, Copy, Debug, Default, Eq, PartialEq)]
-pub enum FlagState {
-    #[default]
-    Inherit,
-    Enable,
-    Disable,
-}
-
-/// Feature toggles forwarded to `--enable/--disable`.
-#[derive(Clone, Debug, Default, Eq, PartialEq)]
-pub struct FeatureToggles {
-    pub enable: Vec<String>,
-    pub disable: Vec<String>,
-}
-
-/// Config values for `model_reasoning_effort`.
-#[derive(Clone, Copy, Debug, Eq, PartialEq)]
-pub enum ReasoningEffort {
-    Minimal,
-    Low,
-    Medium,
-    High,
-}
-
-impl ReasoningEffort {
-    const fn as_str(self) -> &'static str {
-        match self {
-            ReasoningEffort::Minimal => "minimal",
-            ReasoningEffort::Low => "low",
-            ReasoningEffort::Medium => "medium",
-            ReasoningEffort::High => "high",
-        }
-    }
-}
-
-/// Config values for `model_reasoning_summary`.
-#[derive(Clone, Copy, Debug, Eq, PartialEq)]
-pub enum ReasoningSummary {
-    Auto,
-    Concise,
-    Detailed,
-    None,
-}
-
-impl ReasoningSummary {
-    const fn as_str(self) -> &'static str {
-        match self {
-            ReasoningSummary::Auto => "auto",
-            ReasoningSummary::Concise => "concise",
-            ReasoningSummary::Detailed => "detailed",
-            ReasoningSummary::None => "none",
-        }
-    }
-}
-
-/// Config values for `model_verbosity`.
-#[derive(Clone, Copy, Debug, Eq, PartialEq)]
-pub enum ModelVerbosity {
-    Low,
-    Medium,
-    High,
-}
-
-impl ModelVerbosity {
-    const fn as_str(self) -> &'static str {
-        match self {
-            ModelVerbosity::Low => "low",
-            ModelVerbosity::Medium => "medium",
-            ModelVerbosity::High => "high",
-        }
-    }
-}
-
-/// Config values for `model_reasoning_summary_format`.
-#[derive(Clone, Copy, Debug, Eq, PartialEq)]
-pub enum ReasoningSummaryFormat {
-    None,
-    Experimental,
-}
-
-impl ReasoningSummaryFormat {
-    const fn as_str(self) -> &'static str {
-        match self {
-            ReasoningSummaryFormat::None => "none",
-            ReasoningSummaryFormat::Experimental => "experimental",
-        }
-    }
-}
-
-/// Represents a single `--config key=value` override.
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub struct ConfigOverride {
-    pub key: String,
-    pub value: String,
-}
-
-impl ConfigOverride {
-    pub fn new(key: impl Into<String>, value: impl Into<String>) -> Self {
-        Self {
-            key: key.into(),
-            value: value.into(),
-        }
-    }
-
-    pub fn from_raw(raw: impl Into<String>) -> Self {
-        let raw = raw.into();
-        let (key, value) = raw
-            .split_once('=')
-            .map(|(key, value)| (key.to_string(), value.to_string()))
-            .unwrap_or_else(|| (raw.clone(), String::new()));
-        ConfigOverride { key, value }
-    }
-
-    fn is_reasoning_key(&self) -> bool {
-        REASONING_CONFIG_KEYS.contains(&self.key.as_str())
-    }
-}
-
-/// Structured reasoning overrides converted into config entries.
-#[derive(Clone, Debug, Default, Eq, PartialEq)]
-pub struct ReasoningOverrides {
-    pub effort: Option<ReasoningEffort>,
-    pub summary: Option<ReasoningSummary>,
-    pub verbosity: Option<ModelVerbosity>,
-    pub summary_format: Option<ReasoningSummaryFormat>,
-    pub supports_summaries: Option<bool>,
-}
-
-impl ReasoningOverrides {
-    pub(super) fn has_overrides(&self) -> bool {
-        self.effort.is_some()
-            || self.summary.is_some()
-            || self.verbosity.is_some()
-            || self.summary_format.is_some()
-            || self.supports_summaries.is_some()
-    }
-
-    fn append_overrides(&self, configs: &mut Vec<ConfigOverride>) {
-        if let Some(value) = self.effort {
-            configs.push(ConfigOverride::new(
-                "model_reasoning_effort",
-                value.as_str(),
-            ));
-        }
-        if let Some(value) = self.summary {
-            configs.push(ConfigOverride::new(
-                "model_reasoning_summary",
-                value.as_str(),
-            ));
-        }
-        if let Some(value) = self.verbosity {
-            configs.push(ConfigOverride::new("model_verbosity", value.as_str()));
-        }
-        if let Some(value) = self.summary_format {
-            configs.push(ConfigOverride::new(
-                "model_reasoning_summary_format",
-                value.as_str(),
-            ));
-        }
-        if let Some(value) = self.supports_summaries {
-            configs.push(ConfigOverride::new(
-                "model_supports_reasoning_summaries",
-                value.to_string(),
-            ));
-        }
-    }
-}
-
-/// Builder-scoped CLI overrides.
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub struct CliOverrides {
-    pub config_overrides: Vec<ConfigOverride>,
-    pub feature_toggles: FeatureToggles,
-    pub reasoning: ReasoningOverrides,
-    pub approval_policy: Option<ApprovalPolicy>,
-    pub sandbox_mode: Option<SandboxMode>,
-    pub safety_override: SafetyOverride,
-    pub profile: Option<String>,
-    pub cd: Option<PathBuf>,
-    pub local_provider: Option<LocalProvider>,
-    pub oss: FlagState,
-    pub search: FlagState,
-    pub auto_reasoning_defaults: bool,
-}
-
-impl Default for CliOverrides {
-    fn default() -> Self {
-        Self {
-            config_overrides: Vec::new(),
-            feature_toggles: FeatureToggles::default(),
-            reasoning: ReasoningOverrides::default(),
-            approval_policy: None,
-            sandbox_mode: None,
-            safety_override: SafetyOverride::Inherit,
-            profile: None,
-            cd: None,
-            local_provider: None,
-            oss: FlagState::Inherit,
-            search: FlagState::Inherit,
-            auto_reasoning_defaults: true,
-        }
-    }
-}
-
-/// Request-level overlay of builder overrides.
-#[derive(Clone, Debug, Default, Eq, PartialEq)]
-pub struct CliOverridesPatch {
-    pub config_overrides: Vec<ConfigOverride>,
-    pub feature_toggles: FeatureToggles,
-    pub reasoning: ReasoningOverrides,
-    pub approval_policy: Option<ApprovalPolicy>,
-    pub sandbox_mode: Option<SandboxMode>,
-    pub safety_override: Option<SafetyOverride>,
-    pub profile: Option<String>,
-    pub cd: Option<PathBuf>,
-    pub local_provider: Option<LocalProvider>,
-    pub oss: FlagState,
-    pub search: FlagState,
-    pub auto_reasoning_defaults: Option<bool>,
-}
-
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub(super) struct ResolvedCliOverrides {
-    pub(super) config_overrides: Vec<ConfigOverride>,
-    pub(super) feature_toggles: FeatureToggles,
-    pub(super) approval_policy: Option<ApprovalPolicy>,
-    pub(super) sandbox_mode: Option<SandboxMode>,
-    pub(super) safety_override: SafetyOverride,
-    pub(super) profile: Option<String>,
-    pub(super) cd: Option<PathBuf>,
-    pub(super) local_provider: Option<LocalProvider>,
-    pub(super) oss: bool,
-    pub(super) search: FlagState,
-}
-
-impl ResolvedCliOverrides {
-    fn search_enabled(&self) -> bool {
-        matches!(self.search, FlagState::Enable)
-    }
-}
-
-const REASONING_CONFIG_KEYS: &[&str] = &[
-    "model_reasoning_effort",
-    "model_reasoning_summary",
-    "model_verbosity",
-    "model_reasoning_summary_format",
-    "model_supports_reasoning_summaries",
-];
-
-pub(super) fn reasoning_config_for(
-    model: Option<&str>,
-) -> Option<&'static [(&'static str, &'static str)]> {
-    let name = model.map(|value| value.to_ascii_lowercase())?;
-    match name.as_str() {
-        name if name.starts_with("gpt-5.1-codex") => Some(DEFAULT_REASONING_CONFIG_GPT5_1),
-        name if name.starts_with("gpt-5.1") => Some(DEFAULT_REASONING_CONFIG_GPT5_1),
-        "gpt-5-codex" => Some(DEFAULT_REASONING_CONFIG_GPT5_CODEX),
-        name if name.starts_with("gpt-5") => Some(DEFAULT_REASONING_CONFIG_GPT5),
-        _ => None,
-    }
-}
-
-fn has_reasoning_config_override(overrides: &[ConfigOverride]) -> bool {
-    overrides.iter().any(ConfigOverride::is_reasoning_key)
-}
-
-pub(super) fn resolve_cli_overrides(
-    builder: &CliOverrides,
-    patch: &CliOverridesPatch,
-    model: Option<&str>,
-) -> ResolvedCliOverrides {
-    let auto_reasoning_defaults = patch
-        .auto_reasoning_defaults
-        .unwrap_or(builder.auto_reasoning_defaults);
-
-    let has_reasoning_overrides = builder.reasoning.has_overrides()
-        || patch.reasoning.has_overrides()
-        || has_reasoning_config_override(&builder.config_overrides)
-        || has_reasoning_config_override(&patch.config_overrides);
-
-    let mut config_overrides = Vec::new();
-    if auto_reasoning_defaults && !has_reasoning_overrides {
-        if let Some(defaults) = reasoning_config_for(model) {
-            for (key, value) in defaults {
-                config_overrides.push(ConfigOverride::new(*key, *value));
-            }
-        }
-    }
-
-    config_overrides.extend(builder.config_overrides.clone());
-    builder.reasoning.append_overrides(&mut config_overrides);
-    config_overrides.extend(patch.config_overrides.clone());
-    patch.reasoning.append_overrides(&mut config_overrides);
-
-    let approval_policy = patch.approval_policy.or(builder.approval_policy);
-    let sandbox_mode = patch.sandbox_mode.or(builder.sandbox_mode);
-    let safety_override = patch.safety_override.unwrap_or(builder.safety_override);
-    let profile = patch.profile.clone().or_else(|| builder.profile.clone());
-    let cd = patch.cd.clone().or_else(|| builder.cd.clone());
-    let local_provider = patch.local_provider.or(builder.local_provider);
-    let search = match patch.search {
-        FlagState::Inherit => builder.search,
-        other => other,
-    };
-    let oss = match patch.oss {
-        FlagState::Inherit => builder.oss,
-        other => other,
-    };
-    let mut feature_toggles = builder.feature_toggles.clone();
-    feature_toggles
-        .enable
-        .extend(patch.feature_toggles.enable.iter().cloned());
-    feature_toggles
-        .disable
-        .extend(patch.feature_toggles.disable.iter().cloned());
-
-    ResolvedCliOverrides {
-        config_overrides,
-        feature_toggles,
-        approval_policy,
-        sandbox_mode,
-        safety_override,
-        profile,
-        cd,
-        local_provider,
-        oss: matches!(oss, FlagState::Enable),
-        search,
-    }
-}
-
-pub(super) fn cli_override_args(
-    resolved: &ResolvedCliOverrides,
-    include_search: bool,
-) -> Vec<OsString> {
-    let mut args = Vec::new();
-    for config in &resolved.config_overrides {
-        args.push(OsString::from("--config"));
-        args.push(OsString::from(format!("{}={}", config.key, config.value)));
-    }
-
-    for feature in &resolved.feature_toggles.enable {
-        args.push(OsString::from("--enable"));
-        args.push(OsString::from(feature));
-    }
-
-    for feature in &resolved.feature_toggles.disable {
-        args.push(OsString::from("--disable"));
-        args.push(OsString::from(feature));
-    }
-
-    if let Some(profile) = &resolved.profile {
-        args.push(OsString::from("--profile"));
-        args.push(OsString::from(profile));
-    }
-
-    match resolved.safety_override {
-        SafetyOverride::DangerouslyBypass => {
-            args.push(OsString::from("--dangerously-bypass-approvals-and-sandbox"));
-        }
-        other => {
-            if let Some(policy) = resolved.approval_policy {
-                args.push(OsString::from("--ask-for-approval"));
-                args.push(OsString::from(policy.as_str()));
-            }
-
-            if let Some(mode) = resolved.sandbox_mode {
-                args.push(OsString::from("--sandbox"));
-                args.push(OsString::from(mode.as_str()));
-            } else if resolved.approval_policy.is_none()
-                && matches!(other, SafetyOverride::FullAuto)
-            {
-                args.push(OsString::from("--full-auto"));
-            }
-        }
-    }
-
-    if let Some(cd) = &resolved.cd {
-        args.push(OsString::from("--cd"));
-        args.push(cd.as_os_str().to_os_string());
-    }
-
-    if let Some(provider) = resolved.local_provider {
-        args.push(OsString::from("--local-provider"));
-        args.push(OsString::from(provider.as_str()));
-    }
-
-    if resolved.oss {
-        args.push(OsString::from("--oss"));
-    }
-
-    if include_search && resolved.search_enabled() {
-        args.push(OsString::from("--search"));
-    }
-
-    args
-}
-
-pub(super) fn apply_cli_overrides(
-    command: &mut Command,
-    resolved: &ResolvedCliOverrides,
-    include_search: bool,
-) {
-    for arg in cli_override_args(resolved, include_search) {
-        command.arg(arg);
-    }
-}
diff --git a/crates/codex/src/builder/types.rs b/crates/codex/src/builder/types.rs
new file mode 100644
index 0000000..aecc3b1
--- /dev/null
+++ b/crates/codex/src/builder/types.rs
@@ -0,0 +1,317 @@
+use std::path::PathBuf;
+
+const REASONING_CONFIG_KEYS: &[&str] = &[
+    "model_reasoning_effort",
+    "model_reasoning_summary",
+    "model_verbosity",
+    "model_reasoning_summary_format",
+    "model_supports_reasoning_summaries",
+];
+
+/// ANSI color behavior for `codex exec` output.
+#[derive(Clone, Copy, Debug, Eq, PartialEq)]
+pub enum ColorMode {
+    /// Match upstream defaults: use color codes when stdout/stderr look like terminals.
+    Auto,
+    /// Force colorful output even when piping.
+    Always,
+    /// Fully disable ANSI sequences for deterministic parsing/logging (default).
+    Never,
+}
+
+impl ColorMode {
+    pub(crate) const fn as_str(self) -> &'static str {
+        match self {
+            ColorMode::Auto => "auto",
+            ColorMode::Always => "always",
+            ColorMode::Never => "never",
+        }
+    }
+}
+
+/// Approval policy used by `--ask-for-approval`.
+#[derive(Clone, Copy, Debug, Eq, PartialEq)]
+pub enum ApprovalPolicy {
+    Untrusted,
+    OnFailure,
+    OnRequest,
+    Never,
+}
+
+impl ApprovalPolicy {
+    pub(super) const fn as_str(self) -> &'static str {
+        match self {
+            ApprovalPolicy::Untrusted => "untrusted",
+            ApprovalPolicy::OnFailure => "on-failure",
+            ApprovalPolicy::OnRequest => "on-request",
+            ApprovalPolicy::Never => "never",
+        }
+    }
+}
+
+/// Sandbox isolation level.
+#[derive(Clone, Copy, Debug, Eq, PartialEq)]
+pub enum SandboxMode {
+    ReadOnly,
+    WorkspaceWrite,
+    DangerFullAccess,
+}
+
+impl SandboxMode {
+    pub(super) const fn as_str(self) -> &'static str {
+        match self {
+            SandboxMode::ReadOnly => "read-only",
+            SandboxMode::WorkspaceWrite => "workspace-write",
+            SandboxMode::DangerFullAccess => "danger-full-access",
+        }
+    }
+}
+
+/// Safety overrides that collapse approval/sandbox behavior.
+#[derive(Clone, Copy, Debug, Default, Eq, PartialEq)]
+pub enum SafetyOverride {
+    #[default]
+    Inherit,
+    FullAuto,
+    DangerouslyBypass,
+}
+
+/// Local provider selection for OSS backends.
+#[derive(Clone, Copy, Debug, Eq, PartialEq)]
+pub enum LocalProvider {
+    LmStudio,
+    Ollama,
+    Custom,
+}
+
+impl LocalProvider {
+    pub(super) const fn as_str(self) -> &'static str {
+        match self {
+            LocalProvider::LmStudio => "lmstudio",
+            LocalProvider::Ollama => "ollama",
+            LocalProvider::Custom => "custom",
+        }
+    }
+}
+
+/// Three-state flag used when requests can override builder defaults.
+#[derive(Clone, Copy, Debug, Default, Eq, PartialEq)]
+pub enum FlagState {
+    #[default]
+    Inherit,
+    Enable,
+    Disable,
+}
+
+/// Feature toggles forwarded to `--enable/--disable`.
+#[derive(Clone, Debug, Default, Eq, PartialEq)]
+pub struct FeatureToggles {
+    pub enable: Vec<String>,
+    pub disable: Vec<String>,
+}
+
+/// Config values for `model_reasoning_effort`.
+#[derive(Clone, Copy, Debug, Eq, PartialEq)]
+pub enum ReasoningEffort {
+    Minimal,
+    Low,
+    Medium,
+    High,
+}
+
+impl ReasoningEffort {
+    pub(super) const fn as_str(self) -> &'static str {
+        match self {
+            ReasoningEffort::Minimal => "minimal",
+            ReasoningEffort::Low => "low",
+            ReasoningEffort::Medium => "medium",
+            ReasoningEffort::High => "high",
+        }
+    }
+}
+
+/// Config values for `model_reasoning_summary`.
+#[derive(Clone, Copy, Debug, Eq, PartialEq)]
+pub enum ReasoningSummary {
+    Auto,
+    Concise,
+    Detailed,
+    None,
+}
+
+impl ReasoningSummary {
+    pub(super) const fn as_str(self) -> &'static str {
+        match self {
+            ReasoningSummary::Auto => "auto",
+            ReasoningSummary::Concise => "concise",
+            ReasoningSummary::Detailed => "detailed",
+            ReasoningSummary::None => "none",
+        }
+    }
+}
+
+/// Config values for `model_verbosity`.
+#[derive(Clone, Copy, Debug, Eq, PartialEq)]
+pub enum ModelVerbosity {
+    Low,
+    Medium,
+    High,
+}
+
+impl ModelVerbosity {
+    pub(super) const fn as_str(self) -> &'static str {
+        match self {
+            ModelVerbosity::Low => "low",
+            ModelVerbosity::Medium => "medium",
+            ModelVerbosity::High => "high",
+        }
+    }
+}
+
+/// Config values for `model_reasoning_summary_format`.
+#[derive(Clone, Copy, Debug, Eq, PartialEq)]
+pub enum ReasoningSummaryFormat {
+    None,
+    Experimental,
+}
+
+impl ReasoningSummaryFormat {
+    pub(super) const fn as_str(self) -> &'static str {
+        match self {
+            ReasoningSummaryFormat::None => "none",
+            ReasoningSummaryFormat::Experimental => "experimental",
+        }
+    }
+}
+
+/// Represents a single `--config key=value` override.
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub struct ConfigOverride {
+    pub key: String,
+    pub value: String,
+}
+
+impl ConfigOverride {
+    pub fn new(key: impl Into<String>, value: impl Into<String>) -> Self {
+        Self {
+            key: key.into(),
+            value: value.into(),
+        }
+    }
+
+    pub fn from_raw(raw: impl Into<String>) -> Self {
+        let raw = raw.into();
+        let (key, value) = raw
+            .split_once('=')
+            .map(|(key, value)| (key.to_string(), value.to_string()))
+            .unwrap_or_else(|| (raw.clone(), String::new()));
+        ConfigOverride { key, value }
+    }
+
+    pub(super) fn is_reasoning_key(&self) -> bool {
+        REASONING_CONFIG_KEYS.contains(&self.key.as_str())
+    }
+}
+
+/// Structured reasoning overrides converted into config entries.
+#[derive(Clone, Debug, Default, Eq, PartialEq)]
+pub struct ReasoningOverrides {
+    pub effort: Option<ReasoningEffort>,
+    pub summary: Option<ReasoningSummary>,
+    pub verbosity: Option<ModelVerbosity>,
+    pub summary_format: Option<ReasoningSummaryFormat>,
+    pub supports_summaries: Option<bool>,
+}
+
+impl ReasoningOverrides {
+    pub(crate) fn has_overrides(&self) -> bool {
+        self.effort.is_some()
+            || self.summary.is_some()
+            || self.verbosity.is_some()
+            || self.summary_format.is_some()
+            || self.supports_summaries.is_some()
+    }
+
+    pub(super) fn append_overrides(&self, configs: &mut Vec<ConfigOverride>) {
+        if let Some(value) = self.effort {
+            configs.push(ConfigOverride::new(
+                "model_reasoning_effort",
+                value.as_str(),
+            ));
+        }
+        if let Some(value) = self.summary {
+            configs.push(ConfigOverride::new(
+                "model_reasoning_summary",
+                value.as_str(),
+            ));
+        }
+        if let Some(value) = self.verbosity {
+            configs.push(ConfigOverride::new("model_verbosity", value.as_str()));
+        }
+        if let Some(value) = self.summary_format {
+            configs.push(ConfigOverride::new(
+                "model_reasoning_summary_format",
+                value.as_str(),
+            ));
+        }
+        if let Some(value) = self.supports_summaries {
+            configs.push(ConfigOverride::new(
+                "model_supports_reasoning_summaries",
+                value.to_string(),
+            ));
+        }
+    }
+}
+
+/// Builder-scoped CLI overrides.
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub struct CliOverrides {
+    pub config_overrides: Vec<ConfigOverride>,
+    pub feature_toggles: FeatureToggles,
+    pub reasoning: ReasoningOverrides,
+    pub approval_policy: Option<ApprovalPolicy>,
+    pub sandbox_mode: Option<SandboxMode>,
+    pub safety_override: SafetyOverride,
+    pub profile: Option<String>,
+    pub cd: Option<PathBuf>,
+    pub local_provider: Option<LocalProvider>,
+    pub oss: FlagState,
+    pub search: FlagState,
+    pub auto_reasoning_defaults: bool,
+}
+
+impl Default for CliOverrides {
+    fn default() -> Self {
+        Self {
+            config_overrides: Vec::new(),
+            feature_toggles: FeatureToggles::default(),
+            reasoning: ReasoningOverrides::default(),
+            approval_policy: None,
+            sandbox_mode: None,
+            safety_override: SafetyOverride::Inherit,
+            profile: None,
+            cd: None,
+            local_provider: None,
+            oss: FlagState::Inherit,
+            search: FlagState::Inherit,
+            auto_reasoning_defaults: true,
+        }
+    }
+}
+
+/// Request-level overlay of builder overrides.
+#[derive(Clone, Debug, Default, Eq, PartialEq)]
+pub struct CliOverridesPatch {
+    pub config_overrides: Vec<ConfigOverride>,
+    pub feature_toggles: FeatureToggles,
+    pub reasoning: ReasoningOverrides,
+    pub approval_policy: Option<ApprovalPolicy>,
+    pub sandbox_mode: Option<SandboxMode>,
+    pub safety_override: Option<SafetyOverride>,
+    pub profile: Option<String>,
+    pub cd: Option<PathBuf>,
+    pub local_provider: Option<LocalProvider>,
+    pub oss: FlagState,
+    pub search: FlagState,
+    pub auto_reasoning_defaults: Option<bool>,
+}
diff --git a/crates/codex/src/bundled_binary.rs b/crates/codex/src/bundled_binary.rs
new file mode 100644
index 0000000..6ff209c
--- /dev/null
+++ b/crates/codex/src/bundled_binary.rs
@@ -0,0 +1,232 @@
+use std::{
+    env, fs as std_fs,
+    path::{Path, PathBuf},
+};
+
+#[cfg(unix)]
+use std::os::unix::fs::PermissionsExt;
+
+use thiserror::Error;
+
+/// Specification for resolving an app-bundled Codex binary.
+///
+/// Callers supply a bundle root plus the pinned version they expect. Platform
+/// defaults to the current target triple label (e.g., `darwin-arm64` or
+/// `linux-x64`) but can be overridden when hosts manage their own layout.
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub struct BundledBinarySpec<'a> {
+    /// Root containing `<platform>/<version>/codex` slices managed by the host.
+    pub bundle_root: &'a Path,
+    /// Pinned Codex version directory to resolve (semantic version or channel/build id).
+    pub version: &'a str,
+    /// Optional platform label override; defaults to [`default_bundled_platform_label`].
+    pub platform: Option<&'a str>,
+}
+
+/// Resolved bundled Codex binary details.
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub struct BundledBinary {
+    /// Canonicalized path to the bundled Codex binary (`codex` or `codex.exe`).
+    pub binary_path: PathBuf,
+    /// Platform slice resolved under the bundle root.
+    pub platform: String,
+    /// Version slice resolved under the platform directory.
+    pub version: String,
+}
+
+/// Errors that may occur while resolving a bundled Codex binary.
+#[derive(Debug, Error)]
+pub enum BundledBinaryError {
+    #[error("bundled Codex version cannot be empty")]
+    EmptyVersion,
+    #[error("bundled Codex platform label cannot be empty")]
+    EmptyPlatform,
+    #[error("bundle root `{bundle_root}` does not exist or is unreadable")]
+    BundleRootUnreadable {
+        bundle_root: PathBuf,
+        #[source]
+        source: std::io::Error,
+    },
+    #[error("bundle root `{bundle_root}` is not a directory")]
+    BundleRootNotDirectory { bundle_root: PathBuf },
+    #[error("bundle platform directory `{platform_dir}` for `{platform}` does not exist or is unreadable")]
+    PlatformUnreadable {
+        platform: String,
+        platform_dir: PathBuf,
+        #[source]
+        source: std::io::Error,
+    },
+    #[error("bundle platform directory `{platform_dir}` for `{platform}` is not a directory")]
+    PlatformNotDirectory {
+        platform: String,
+        platform_dir: PathBuf,
+    },
+    #[error(
+        "bundle version directory `{version_dir}` for `{version}` does not exist or is unreadable"
+    )]
+    VersionUnreadable {
+        version: String,
+        version_dir: PathBuf,
+        #[source]
+        source: std::io::Error,
+    },
+    #[error("bundle version directory `{version_dir}` for `{version}` is not a directory")]
+    VersionNotDirectory {
+        version: String,
+        version_dir: PathBuf,
+    },
+    #[error("bundled Codex binary `{binary}` is missing or unreadable")]
+    BinaryUnreadable {
+        binary: PathBuf,
+        #[source]
+        source: std::io::Error,
+    },
+    #[error("bundled Codex binary `{binary}` is not a file")]
+    BinaryNotFile { binary: PathBuf },
+    #[error("bundled Codex binary `{binary}` is not executable")]
+    BinaryNotExecutable { binary: PathBuf },
+    #[error("failed to canonicalize bundled Codex binary `{path}`: {source}")]
+    Canonicalize {
+        path: PathBuf,
+        #[source]
+        source: std::io::Error,
+    },
+}
+
+/// Resolves a bundled Codex binary under `<bundle_root>/<platform>/<version>/`.
+///
+/// The helper never consults `PATH` or `CODEX_BINARY`; missing slices are hard
+/// errors. The resolved path is canonicalized and should be passed to
+/// [`CodexClientBuilder::binary`] to keep behavior isolated from any global
+/// Codex install.
+pub fn resolve_bundled_binary(
+    spec: BundledBinarySpec<'_>,
+) -> Result<BundledBinary, BundledBinaryError> {
+    let platform = match spec.platform {
+        Some(label) => {
+            super::normalize_non_empty(label).ok_or(BundledBinaryError::EmptyPlatform)?
+        }
+        None => default_bundled_platform_label(),
+    };
+    let version =
+        super::normalize_non_empty(spec.version).ok_or(BundledBinaryError::EmptyVersion)?;
+
+    require_directory(
+        spec.bundle_root,
+        |source| BundledBinaryError::BundleRootUnreadable {
+            bundle_root: spec.bundle_root.to_path_buf(),
+            source,
+        },
+        || BundledBinaryError::BundleRootNotDirectory {
+            bundle_root: spec.bundle_root.to_path_buf(),
+        },
+    )?;
+
+    let platform_dir = spec.bundle_root.join(&platform);
+    require_directory(
+        &platform_dir,
+        |source| BundledBinaryError::PlatformUnreadable {
+            platform: platform.clone(),
+            platform_dir: platform_dir.clone(),
+            source,
+        },
+        || BundledBinaryError::PlatformNotDirectory {
+            platform: platform.clone(),
+            platform_dir: platform_dir.clone(),
+        },
+    )?;
+
+    let version_dir = platform_dir.join(&version);
+    require_directory(
+        &version_dir,
+        |source| BundledBinaryError::VersionUnreadable {
+            version: version.clone(),
+            version_dir: version_dir.clone(),
+            source,
+        },
+        || BundledBinaryError::VersionNotDirectory {
+            version: version.clone(),
+            version_dir: version_dir.clone(),
+        },
+    )?;
+
+    let binary_path = version_dir.join(bundled_binary_filename(&platform));
+    let metadata =
+        std_fs::metadata(&binary_path).map_err(|source| BundledBinaryError::BinaryUnreadable {
+            binary: binary_path.clone(),
+            source,
+        })?;
+    if !metadata.is_file() {
+        return Err(BundledBinaryError::BinaryNotFile {
+            binary: binary_path.clone(),
+        });
+    }
+    ensure_executable(&metadata, &binary_path)?;
+
+    let canonical =
+        std_fs::canonicalize(&binary_path).map_err(|source| BundledBinaryError::Canonicalize {
+            path: binary_path.clone(),
+            source,
+        })?;
+
+    Ok(BundledBinary {
+        binary_path: canonical,
+        platform,
+        version,
+    })
+}
+
+/// Default bundled platform label for the current target (e.g., `darwin-arm64`, `linux-x64`, `windows-x64`).
+pub fn default_bundled_platform_label() -> String {
+    let os = match env::consts::OS {
+        "macos" => "darwin",
+        other => other,
+    };
+    let arch = match env::consts::ARCH {
+        "x86_64" => "x64",
+        "aarch64" => "arm64",
+        other => other,
+    };
+    format!("{os}-{arch}")
+}
+
+fn require_directory(
+    path: &Path,
+    on_read_error: impl FnOnce(std::io::Error) -> BundledBinaryError,
+    on_wrong_type: impl FnOnce() -> BundledBinaryError,
+) -> Result<(), BundledBinaryError> {
+    let metadata = std_fs::metadata(path).map_err(on_read_error)?;
+    if !metadata.is_dir() {
+        return Err(on_wrong_type());
+    }
+    Ok(())
+}
+
+fn ensure_executable(metadata: &std_fs::Metadata, binary: &Path) -> Result<(), BundledBinaryError> {
+    if binary_is_executable(metadata) {
+        return Ok(());
+    }
+    Err(BundledBinaryError::BinaryNotExecutable {
+        binary: binary.to_path_buf(),
+    })
+}
+
+fn binary_is_executable(metadata: &std_fs::Metadata) -> bool {
+    #[cfg(unix)]
+    {
+        metadata.permissions().mode() & 0o111 != 0
+    }
+    #[cfg(not(unix))]
+    {
+        // Windows does not use executable bits; existence is sufficient.
+        true
+    }
+}
+
+pub(super) fn bundled_binary_filename(platform: &str) -> &'static str {
+    if platform.to_ascii_lowercase().contains("windows") {
+        "codex.exe"
+    } else {
+        "codex"
+    }
+}
diff --git a/crates/codex/src/cli/app_server.rs b/crates/codex/src/cli/app_server.rs
new file mode 100644
index 0000000..f0c2ff0
--- /dev/null
+++ b/crates/codex/src/cli/app_server.rs
@@ -0,0 +1,140 @@
+use crate::{CliOverridesPatch, ConfigOverride, FlagState};
+use std::{path::PathBuf, process::ExitStatus};
+
+/// Target for app-server code generation.
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub enum AppServerCodegenTarget {
+    /// Emits TypeScript bindings for the app-server protocol. Optionally formats the output with Prettier.
+    TypeScript { prettier: Option<PathBuf> },
+    /// Emits a JSON schema bundle for the app-server protocol.
+    JsonSchema,
+}
+
+impl AppServerCodegenTarget {
+    pub(crate) fn subcommand(&self) -> &'static str {
+        match self {
+            AppServerCodegenTarget::TypeScript { .. } => "generate-ts",
+            AppServerCodegenTarget::JsonSchema => "generate-json-schema",
+        }
+    }
+
+    pub(crate) fn prettier(&self) -> Option<&PathBuf> {
+        match self {
+            AppServerCodegenTarget::TypeScript { prettier } => prettier.as_ref(),
+            AppServerCodegenTarget::JsonSchema => None,
+        }
+    }
+}
+
+/// Request for `codex app-server generate-ts` or `generate-json-schema`.
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub struct AppServerCodegenRequest {
+    /// Codegen target and optional Prettier path (TypeScript only).
+    pub target: AppServerCodegenTarget,
+    /// Output directory passed to `--out`; created if missing.
+    pub out_dir: PathBuf,
+    /// Per-call CLI overrides layered on top of the builder.
+    pub overrides: CliOverridesPatch,
+}
+
+impl AppServerCodegenRequest {
+    /// Generates TypeScript bindings into `out_dir`.
+    pub fn typescript(out_dir: impl Into<PathBuf>) -> Self {
+        Self {
+            target: AppServerCodegenTarget::TypeScript { prettier: None },
+            out_dir: out_dir.into(),
+            overrides: CliOverridesPatch::default(),
+        }
+    }
+
+    /// Generates a JSON schema bundle into `out_dir`.
+    pub fn json_schema(out_dir: impl Into<PathBuf>) -> Self {
+        Self {
+            target: AppServerCodegenTarget::JsonSchema,
+            out_dir: out_dir.into(),
+            overrides: CliOverridesPatch::default(),
+        }
+    }
+
+    /// Formats TypeScript output with the provided Prettier executable (no-op for JSON schema).
+    pub fn prettier(mut self, prettier: impl Into<PathBuf>) -> Self {
+        if let AppServerCodegenTarget::TypeScript { prettier: slot } = &mut self.target {
+            *slot = Some(prettier.into());
+        }
+        self
+    }
+
+    /// Replaces the default CLI overrides for this request.
+    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
+        self.overrides = overrides;
+        self
+    }
+
+    /// Adds a `--config key=value` override for this request.
+    pub fn config_override(mut self, key: impl Into<String>, value: impl Into<String>) -> Self {
+        self.overrides
+            .config_overrides
+            .push(ConfigOverride::new(key, value));
+        self
+    }
+
+    /// Adds a raw `--config key=value` override without validation.
+    pub fn config_override_raw(mut self, raw: impl Into<String>) -> Self {
+        self.overrides
+            .config_overrides
+            .push(ConfigOverride::from_raw(raw));
+        self
+    }
+
+    /// Sets the config profile (`--profile`) for this request.
+    pub fn profile(mut self, profile: impl Into<String>) -> Self {
+        let profile = profile.into();
+        self.overrides.profile = (!profile.trim().is_empty()).then_some(profile);
+        self
+    }
+
+    /// Requests the CLI `--oss` flag for this codegen call.
+    pub fn oss(mut self, enable: bool) -> Self {
+        self.overrides.oss = if enable {
+            FlagState::Enable
+        } else {
+            FlagState::Disable
+        };
+        self
+    }
+
+    /// Adds a `--enable <feature>` toggle for this codegen call.
+    pub fn enable_feature(mut self, name: impl Into<String>) -> Self {
+        self.overrides.feature_toggles.enable.push(name.into());
+        self
+    }
+
+    /// Adds a `--disable <feature>` toggle for this codegen call.
+    pub fn disable_feature(mut self, name: impl Into<String>) -> Self {
+        self.overrides.feature_toggles.disable.push(name.into());
+        self
+    }
+
+    /// Controls whether `--search` is passed through to Codex.
+    pub fn search(mut self, enable: bool) -> Self {
+        self.overrides.search = if enable {
+            FlagState::Enable
+        } else {
+            FlagState::Disable
+        };
+        self
+    }
+}
+
+/// Captured output from app-server codegen commands.
+#[derive(Clone, Debug)]
+pub struct AppServerCodegenOutput {
+    /// Exit status returned by the subcommand.
+    pub status: ExitStatus,
+    /// Captured stdout (mirrored to the console when `mirror_stdout` is true).
+    pub stdout: String,
+    /// Captured stderr (mirrored unless `quiet` is set).
+    pub stderr: String,
+    /// Output directory passed to `--out`.
+    pub out_dir: PathBuf,
+}
diff --git a/crates/codex/src/cli/cloud.rs b/crates/codex/src/cli/cloud.rs
new file mode 100644
index 0000000..cb51168
--- /dev/null
+++ b/crates/codex/src/cli/cloud.rs
@@ -0,0 +1,158 @@
+use crate::CliOverridesPatch;
+use serde_json::Value;
+use std::process::ExitStatus;
+
+/// Request for `codex cloud` (overview/help).
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub struct CloudOverviewRequest {
+    pub overrides: CliOverridesPatch,
+}
+
+impl CloudOverviewRequest {
+    pub fn new() -> Self {
+        Self {
+            overrides: CliOverridesPatch::default(),
+        }
+    }
+
+    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
+        self.overrides = overrides;
+        self
+    }
+}
+
+impl Default for CloudOverviewRequest {
+    fn default() -> Self {
+        Self::new()
+    }
+}
+
+/// Request for `codex cloud list`.
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub struct CloudListRequest {
+    pub json: bool,
+    pub env_id: Option<String>,
+    pub limit: Option<u32>,
+    pub cursor: Option<String>,
+    pub overrides: CliOverridesPatch,
+}
+
+impl CloudListRequest {
+    pub fn new() -> Self {
+        Self {
+            json: false,
+            env_id: None,
+            limit: None,
+            cursor: None,
+            overrides: CliOverridesPatch::default(),
+        }
+    }
+
+    pub fn json(mut self, enable: bool) -> Self {
+        self.json = enable;
+        self
+    }
+
+    pub fn env_id(mut self, env_id: impl Into<String>) -> Self {
+        let env_id = env_id.into();
+        self.env_id = (!env_id.trim().is_empty()).then_some(env_id);
+        self
+    }
+
+    pub fn limit(mut self, limit: u32) -> Self {
+        self.limit = Some(limit);
+        self
+    }
+
+    pub fn cursor(mut self, cursor: impl Into<String>) -> Self {
+        let cursor = cursor.into();
+        self.cursor = (!cursor.trim().is_empty()).then_some(cursor);
+        self
+    }
+
+    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
+        self.overrides = overrides;
+        self
+    }
+}
+
+impl Default for CloudListRequest {
+    fn default() -> Self {
+        Self::new()
+    }
+}
+
+/// Output from `codex cloud list`.
+#[derive(Clone, Debug, PartialEq)]
+pub struct CloudListOutput {
+    pub status: ExitStatus,
+    pub stdout: String,
+    pub stderr: String,
+    /// Parsed JSON output when `--json` was requested.
+    pub json: Option<Value>,
+}
+
+/// Request for `codex cloud status <TASK_ID>`.
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub struct CloudStatusRequest {
+    pub task_id: String,
+    pub overrides: CliOverridesPatch,
+}
+
+impl CloudStatusRequest {
+    pub fn new(task_id: impl Into<String>) -> Self {
+        Self {
+            task_id: task_id.into(),
+            overrides: CliOverridesPatch::default(),
+        }
+    }
+
+    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
+        self.overrides = overrides;
+        self
+    }
+}
+
+/// Request for `codex cloud exec`.
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub struct CloudExecRequest {
+    pub env_id: String,
+    pub query: Option<String>,
+    pub attempts: Option<u32>,
+    pub branch: Option<String>,
+    pub overrides: CliOverridesPatch,
+}
+
+impl CloudExecRequest {
+    pub fn new(env_id: impl Into<String>) -> Self {
+        Self {
+            env_id: env_id.into(),
+            query: None,
+            attempts: None,
+            branch: None,
+            overrides: CliOverridesPatch::default(),
+        }
+    }
+
+    pub fn query(mut self, query: impl Into<String>) -> Self {
+        let query = query.into();
+        self.query = (!query.trim().is_empty()).then_some(query);
+        self
+    }
+
+    pub fn attempts(mut self, attempts: u32) -> Self {
+        self.attempts = Some(attempts);
+        self
+    }
+
+    pub fn branch(mut self, branch: impl Into<String>) -> Self {
+        let branch = branch.into();
+        self.branch = (!branch.trim().is_empty()).then_some(branch);
+        self
+    }
+
+    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
+        self.overrides = overrides;
+        self
+    }
+}
diff --git a/crates/codex/src/cli/exec.rs b/crates/codex/src/cli/exec.rs
new file mode 100644
index 0000000..00c9049
--- /dev/null
+++ b/crates/codex/src/cli/exec.rs
@@ -0,0 +1,70 @@
+use crate::{CliOverridesPatch, ConfigOverride, FlagState};
+
+/// Options configuring a single exec request.
+#[derive(Clone, Debug)]
+pub struct ExecRequest {
+    pub prompt: String,
+    pub overrides: CliOverridesPatch,
+}
+
+impl ExecRequest {
+    pub fn new(prompt: impl Into<String>) -> Self {
+        Self {
+            prompt: prompt.into(),
+            overrides: CliOverridesPatch::default(),
+        }
+    }
+
+    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
+        self.overrides = overrides;
+        self
+    }
+
+    pub fn config_override(mut self, key: impl Into<String>, value: impl Into<String>) -> Self {
+        self.overrides
+            .config_overrides
+            .push(ConfigOverride::new(key, value));
+        self
+    }
+
+    pub fn config_override_raw(mut self, raw: impl Into<String>) -> Self {
+        self.overrides
+            .config_overrides
+            .push(ConfigOverride::from_raw(raw));
+        self
+    }
+
+    pub fn profile(mut self, profile: impl Into<String>) -> Self {
+        let profile = profile.into();
+        self.overrides.profile = (!profile.trim().is_empty()).then_some(profile);
+        self
+    }
+
+    pub fn oss(mut self, enable: bool) -> Self {
+        self.overrides.oss = if enable {
+            FlagState::Enable
+        } else {
+            FlagState::Disable
+        };
+        self
+    }
+
+    pub fn enable_feature(mut self, name: impl Into<String>) -> Self {
+        self.overrides.feature_toggles.enable.push(name.into());
+        self
+    }
+
+    pub fn disable_feature(mut self, name: impl Into<String>) -> Self {
+        self.overrides.feature_toggles.disable.push(name.into());
+        self
+    }
+
+    pub fn search(mut self, enable: bool) -> Self {
+        self.overrides.search = if enable {
+            FlagState::Enable
+        } else {
+            FlagState::Disable
+        };
+        self
+    }
+}
diff --git a/crates/codex/src/cli/features.rs b/crates/codex/src/cli/features.rs
new file mode 100644
index 0000000..fdb1a55
--- /dev/null
+++ b/crates/codex/src/cli/features.rs
@@ -0,0 +1,223 @@
+use crate::{CliOverridesPatch, ConfigOverride, FlagState};
+use serde::{Deserialize, Serialize};
+use serde_json::Value;
+use std::{collections::BTreeMap, process::ExitStatus};
+
+/// Stage labels reported by `codex features list`.
+#[derive(Clone, Debug, Eq, PartialEq, Serialize, Deserialize)]
+#[serde(from = "String", into = "String")]
+pub enum CodexFeatureStage {
+    Experimental,
+    Beta,
+    Stable,
+    Deprecated,
+    Removed,
+    Unknown(String),
+}
+
+impl CodexFeatureStage {
+    pub(crate) fn parse(raw: &str) -> Self {
+        let normalized = raw.trim();
+        match normalized.to_ascii_lowercase().as_str() {
+            "experimental" => CodexFeatureStage::Experimental,
+            "beta" => CodexFeatureStage::Beta,
+            "stable" => CodexFeatureStage::Stable,
+            "deprecated" => CodexFeatureStage::Deprecated,
+            "removed" => CodexFeatureStage::Removed,
+            _ => CodexFeatureStage::Unknown(normalized.to_string()),
+        }
+    }
+
+    /// Returns the normalized label for this stage.
+    pub fn as_str(&self) -> &str {
+        match self {
+            CodexFeatureStage::Experimental => "experimental",
+            CodexFeatureStage::Beta => "beta",
+            CodexFeatureStage::Stable => "stable",
+            CodexFeatureStage::Deprecated => "deprecated",
+            CodexFeatureStage::Removed => "removed",
+            CodexFeatureStage::Unknown(label) => label.as_str(),
+        }
+    }
+}
+
+impl From<String> for CodexFeatureStage {
+    fn from(value: String) -> Self {
+        CodexFeatureStage::parse(&value)
+    }
+}
+
+impl From<CodexFeatureStage> for String {
+    fn from(stage: CodexFeatureStage) -> Self {
+        String::from(&stage)
+    }
+}
+
+impl From<&CodexFeatureStage> for String {
+    fn from(stage: &CodexFeatureStage) -> Self {
+        stage.as_str().to_string()
+    }
+}
+
+/// Single feature entry reported by `codex features list`.
+#[derive(Clone, Debug, Eq, PartialEq, Serialize, Deserialize)]
+pub struct CodexFeature {
+    /// Feature name as reported by the CLI.
+    pub name: String,
+    /// Feature stage (experimental/beta/stable/deprecated/removed) when provided.
+    #[serde(default, skip_serializing_if = "Option::is_none")]
+    pub stage: Option<CodexFeatureStage>,
+    /// Whether the feature is enabled for the current config/profile.
+    pub enabled: bool,
+    /// Unrecognized fields from JSON output are preserved here.
+    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
+    pub extra: BTreeMap<String, Value>,
+}
+
+impl CodexFeature {
+    /// Convenience helper mirroring the `enabled` flag.
+    pub const fn is_enabled(&self) -> bool {
+        self.enabled
+    }
+}
+
+/// Format used to parse `codex features list` output.
+#[derive(Clone, Copy, Debug, Eq, PartialEq)]
+pub enum FeaturesListFormat {
+    Json,
+    Text,
+}
+
+/// Parsed output from `codex features list`.
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub struct FeaturesListOutput {
+    /// Exit status returned by the subcommand.
+    pub status: ExitStatus,
+    /// Captured stdout (mirrored to the console when `mirror_stdout` is true).
+    pub stdout: String,
+    /// Captured stderr (mirrored unless `quiet` is set).
+    pub stderr: String,
+    /// Parsed feature entries.
+    pub features: Vec<CodexFeature>,
+    /// Indicates whether JSON or text parsing was used.
+    pub format: FeaturesListFormat,
+}
+
+/// Request for `codex features list`.
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub struct FeaturesListRequest {
+    /// Request JSON output via `--json` (falls back to text parsing when JSON is absent).
+    pub json: bool,
+    /// Per-call CLI overrides layered on top of the builder.
+    pub overrides: CliOverridesPatch,
+}
+
+impl FeaturesListRequest {
+    /// Creates a request with JSON disabled by default for compatibility with older binaries.
+    pub fn new() -> Self {
+        Self {
+            json: false,
+            overrides: CliOverridesPatch::default(),
+        }
+    }
+
+    /// Controls whether `--json` is passed to `codex features list`.
+    pub fn json(mut self, enable: bool) -> Self {
+        self.json = enable;
+        self
+    }
+
+    /// Replaces the default CLI overrides for this request.
+    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
+        self.overrides = overrides;
+        self
+    }
+
+    /// Adds a `--config key=value` override for this request.
+    pub fn config_override(mut self, key: impl Into<String>, value: impl Into<String>) -> Self {
+        self.overrides
+            .config_overrides
+            .push(ConfigOverride::new(key, value));
+        self
+    }
+
+    /// Adds a raw `--config key=value` override without validation.
+    pub fn config_override_raw(mut self, raw: impl Into<String>) -> Self {
+        self.overrides
+            .config_overrides
+            .push(ConfigOverride::from_raw(raw));
+        self
+    }
+
+    /// Sets the config profile (`--profile`) for this request.
+    pub fn profile(mut self, profile: impl Into<String>) -> Self {
+        let profile = profile.into();
+        self.overrides.profile = (!profile.trim().is_empty()).then_some(profile);
+        self
+    }
+
+    /// Requests the CLI `--oss` flag for this call.
+    pub fn oss(mut self, enable: bool) -> Self {
+        self.overrides.oss = if enable {
+            FlagState::Enable
+        } else {
+            FlagState::Disable
+        };
+        self
+    }
+
+    /// Adds a `--enable <feature>` toggle for this call.
+    pub fn enable_feature(mut self, name: impl Into<String>) -> Self {
+        self.overrides.feature_toggles.enable.push(name.into());
+        self
+    }
+
+    /// Adds a `--disable <feature>` toggle for this call.
+    pub fn disable_feature(mut self, name: impl Into<String>) -> Self {
+        self.overrides.feature_toggles.disable.push(name.into());
+        self
+    }
+
+    /// Controls whether `--search` is passed through to Codex.
+    pub fn search(mut self, enable: bool) -> Self {
+        self.overrides.search = if enable {
+            FlagState::Enable
+        } else {
+            FlagState::Disable
+        };
+        self
+    }
+}
+
+impl Default for FeaturesListRequest {
+    fn default() -> Self {
+        Self::new()
+    }
+}
+
+/// Request for `codex features`.
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub struct FeaturesCommandRequest {
+    /// Per-call CLI overrides layered on top of the builder.
+    pub overrides: CliOverridesPatch,
+}
+
+impl FeaturesCommandRequest {
+    pub fn new() -> Self {
+        Self {
+            overrides: CliOverridesPatch::default(),
+        }
+    }
+
+    /// Replaces the default CLI overrides for this request.
+    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
+        self.overrides = overrides;
+        self
+    }
+}
+
+impl Default for FeaturesCommandRequest {
+    fn default() -> Self {
+        Self::new()
+    }
+}
diff --git a/crates/codex/src/cli/help.rs b/crates/codex/src/cli/help.rs
new file mode 100644
index 0000000..87e6f91
--- /dev/null
+++ b/crates/codex/src/cli/help.rs
@@ -0,0 +1,65 @@
+use crate::CliOverridesPatch;
+
+/// Selector for `codex help`-style command families.
+#[derive(Clone, Copy, Debug, Eq, PartialEq)]
+pub enum HelpScope {
+    Root,
+    Exec,
+    Features,
+    Login,
+    AppServer,
+    Sandbox,
+    Cloud,
+    Mcp,
+}
+
+impl HelpScope {
+    pub(crate) fn argv_prefix(&self) -> &'static [&'static str] {
+        match self {
+            HelpScope::Root => &["help"],
+            HelpScope::Exec => &["exec", "help"],
+            HelpScope::Features => &["features", "help"],
+            HelpScope::Login => &["login", "help"],
+            HelpScope::AppServer => &["app-server", "help"],
+            HelpScope::Sandbox => &["sandbox", "help"],
+            HelpScope::Cloud => &["cloud", "help"],
+            HelpScope::Mcp => &["mcp", "help"],
+        }
+    }
+}
+
+/// Request for `codex <scope> help [COMMAND]...`.
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub struct HelpCommandRequest {
+    pub scope: HelpScope,
+    /// Optional command path components appended after `help` (variadic upstream).
+    pub command: Vec<String>,
+    /// Per-call CLI overrides layered on top of the builder.
+    pub overrides: CliOverridesPatch,
+}
+
+impl HelpCommandRequest {
+    pub fn new(scope: HelpScope) -> Self {
+        Self {
+            scope,
+            command: Vec::new(),
+            overrides: CliOverridesPatch::default(),
+        }
+    }
+
+    /// Appends one or more command tokens to the help invocation.
+    pub fn command<I, S>(mut self, tokens: I) -> Self
+    where
+        I: IntoIterator<Item = S>,
+        S: Into<String>,
+    {
+        self.command.extend(tokens.into_iter().map(Into::into));
+        self
+    }
+
+    /// Replaces the default CLI overrides for this request.
+    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
+        self.overrides = overrides;
+        self
+    }
+}
diff --git a/crates/codex/src/cli/mcp.rs b/crates/codex/src/cli/mcp.rs
new file mode 100644
index 0000000..20e120a
--- /dev/null
+++ b/crates/codex/src/cli/mcp.rs
@@ -0,0 +1,245 @@
+use crate::CliOverridesPatch;
+use serde_json::Value;
+use std::{ffi::OsString, process::ExitStatus};
+
+/// Request for `codex mcp` (overview/help).
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub struct McpOverviewRequest {
+    pub overrides: CliOverridesPatch,
+}
+
+impl McpOverviewRequest {
+    pub fn new() -> Self {
+        Self {
+            overrides: CliOverridesPatch::default(),
+        }
+    }
+
+    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
+        self.overrides = overrides;
+        self
+    }
+}
+
+impl Default for McpOverviewRequest {
+    fn default() -> Self {
+        Self::new()
+    }
+}
+
+/// Request for `codex mcp list`.
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub struct McpListRequest {
+    pub json: bool,
+    pub overrides: CliOverridesPatch,
+}
+
+impl McpListRequest {
+    pub fn new() -> Self {
+        Self {
+            json: false,
+            overrides: CliOverridesPatch::default(),
+        }
+    }
+
+    pub fn json(mut self, enable: bool) -> Self {
+        self.json = enable;
+        self
+    }
+
+    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
+        self.overrides = overrides;
+        self
+    }
+}
+
+impl Default for McpListRequest {
+    fn default() -> Self {
+        Self::new()
+    }
+}
+
+/// Output from `codex mcp list`.
+#[derive(Clone, Debug, PartialEq)]
+pub struct McpListOutput {
+    pub status: ExitStatus,
+    pub stdout: String,
+    pub stderr: String,
+    pub json: Option<Value>,
+}
+
+/// Request for `codex mcp get <NAME>`.
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub struct McpGetRequest {
+    pub name: String,
+    pub json: bool,
+    pub overrides: CliOverridesPatch,
+}
+
+impl McpGetRequest {
+    pub fn new(name: impl Into<String>) -> Self {
+        Self {
+            name: name.into(),
+            json: false,
+            overrides: CliOverridesPatch::default(),
+        }
+    }
+
+    pub fn json(mut self, enable: bool) -> Self {
+        self.json = enable;
+        self
+    }
+
+    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
+        self.overrides = overrides;
+        self
+    }
+}
+
+/// Transport for `codex mcp add`.
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub enum McpAddTransport {
+    Stdio {
+        env: Vec<(String, String)>,
+        command: Vec<OsString>,
+    },
+    StreamableHttp {
+        url: String,
+        bearer_token_env_var: Option<String>,
+    },
+}
+
+/// Request for `codex mcp add`.
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub struct McpAddRequest {
+    pub name: String,
+    pub transport: McpAddTransport,
+    pub overrides: CliOverridesPatch,
+}
+
+impl McpAddRequest {
+    pub fn stdio(name: impl Into<String>, command: Vec<OsString>) -> Self {
+        Self {
+            name: name.into(),
+            transport: McpAddTransport::Stdio {
+                env: Vec::new(),
+                command,
+            },
+            overrides: CliOverridesPatch::default(),
+        }
+    }
+
+    pub fn streamable_http(name: impl Into<String>, url: impl Into<String>) -> Self {
+        Self {
+            name: name.into(),
+            transport: McpAddTransport::StreamableHttp {
+                url: url.into(),
+                bearer_token_env_var: None,
+            },
+            overrides: CliOverridesPatch::default(),
+        }
+    }
+
+    pub fn env(mut self, key: impl Into<String>, value: impl Into<String>) -> Self {
+        if let McpAddTransport::Stdio { env, .. } = &mut self.transport {
+            env.push((key.into(), value.into()));
+        }
+        self
+    }
+
+    pub fn bearer_token_env_var(mut self, env_var: impl Into<String>) -> Self {
+        if let McpAddTransport::StreamableHttp {
+            bearer_token_env_var,
+            ..
+        } = &mut self.transport
+        {
+            let env_var = env_var.into();
+            *bearer_token_env_var = (!env_var.trim().is_empty()).then_some(env_var);
+        }
+        self
+    }
+
+    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
+        self.overrides = overrides;
+        self
+    }
+}
+
+/// Request for `codex mcp remove <NAME>`.
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub struct McpRemoveRequest {
+    pub name: String,
+    pub overrides: CliOverridesPatch,
+}
+
+impl McpRemoveRequest {
+    pub fn new(name: impl Into<String>) -> Self {
+        Self {
+            name: name.into(),
+            overrides: CliOverridesPatch::default(),
+        }
+    }
+
+    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
+        self.overrides = overrides;
+        self
+    }
+}
+
+/// Request for `codex mcp logout <NAME>`.
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub struct McpLogoutRequest {
+    pub name: String,
+    pub overrides: CliOverridesPatch,
+}
+
+impl McpLogoutRequest {
+    pub fn new(name: impl Into<String>) -> Self {
+        Self {
+            name: name.into(),
+            overrides: CliOverridesPatch::default(),
+        }
+    }
+
+    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
+        self.overrides = overrides;
+        self
+    }
+}
+
+/// Request for `codex mcp login <NAME>` (OAuth).
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub struct McpOauthLoginRequest {
+    pub name: String,
+    pub scopes: Vec<String>,
+    pub overrides: CliOverridesPatch,
+}
+
+impl McpOauthLoginRequest {
+    pub fn new(name: impl Into<String>) -> Self {
+        Self {
+            name: name.into(),
+            scopes: Vec::new(),
+            overrides: CliOverridesPatch::default(),
+        }
+    }
+
+    pub fn scopes<I, S>(mut self, scopes: I) -> Self
+    where
+        I: IntoIterator<Item = S>,
+        S: Into<String>,
+    {
+        self.scopes.extend(
+            scopes
+                .into_iter()
+                .map(|s| s.into())
+                .filter(|s| !s.trim().is_empty()),
+        );
+        self
+    }
+
+    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
+        self.overrides = overrides;
+        self
+    }
+}
diff --git a/crates/codex/src/cli/mod.rs b/crates/codex/src/cli/mod.rs
new file mode 100644
index 0000000..252b76d
--- /dev/null
+++ b/crates/codex/src/cli/mod.rs
@@ -0,0 +1,33 @@
+mod app_server;
+mod cloud;
+mod exec;
+mod features;
+mod help;
+mod mcp;
+mod responses_api_proxy;
+mod review;
+mod sandbox;
+mod session;
+mod stdio_to_uds;
+
+pub use app_server::{AppServerCodegenOutput, AppServerCodegenRequest, AppServerCodegenTarget};
+pub use cloud::{
+    CloudExecRequest, CloudListOutput, CloudListRequest, CloudOverviewRequest, CloudStatusRequest,
+};
+pub use exec::ExecRequest;
+pub use features::{
+    CodexFeature, CodexFeatureStage, FeaturesCommandRequest, FeaturesListFormat,
+    FeaturesListOutput, FeaturesListRequest,
+};
+pub use help::{HelpCommandRequest, HelpScope};
+pub use mcp::{
+    McpAddRequest, McpAddTransport, McpGetRequest, McpListOutput, McpListRequest, McpLogoutRequest,
+    McpOauthLoginRequest, McpOverviewRequest, McpRemoveRequest,
+};
+pub use responses_api_proxy::{
+    ResponsesApiProxyHandle, ResponsesApiProxyInfo, ResponsesApiProxyRequest,
+};
+pub use review::{ExecReviewCommandRequest, ReviewCommandRequest};
+pub use sandbox::{SandboxCommandRequest, SandboxPlatform, SandboxRun};
+pub use session::{ForkSessionRequest, ResumeSessionRequest};
+pub use stdio_to_uds::StdioToUdsRequest;
diff --git a/crates/codex/src/cli/responses_api_proxy.rs b/crates/codex/src/cli/responses_api_proxy.rs
new file mode 100644
index 0000000..32c6d82
--- /dev/null
+++ b/crates/codex/src/cli/responses_api_proxy.rs
@@ -0,0 +1,119 @@
+use crate::CodexError;
+use serde::{Deserialize, Serialize};
+use serde_json::Value;
+use std::{collections::BTreeMap, path::PathBuf};
+use tokio::fs;
+
+/// Request for `codex responses-api-proxy`.
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub struct ResponsesApiProxyRequest {
+    /// API key to write to stdin on startup.
+    pub api_key: String,
+    /// Optional port to bind; falls back to an OS-assigned ephemeral port when omitted.
+    pub port: Option<u16>,
+    /// Optional path passed to `--server-info` for `{port,pid}` JSON output.
+    pub server_info_path: Option<PathBuf>,
+    /// Enables the HTTP shutdown endpoint (`GET /shutdown`).
+    pub http_shutdown: bool,
+    /// Optional upstream URL passed to `--upstream-url` (defaults to `https://api.openai.com/v1/responses`).
+    pub upstream_url: Option<String>,
+}
+
+impl ResponsesApiProxyRequest {
+    /// Creates a request with the API key provided via stdin.
+    pub fn new(api_key: impl Into<String>) -> Self {
+        Self {
+            api_key: api_key.into(),
+            port: None,
+            server_info_path: None,
+            http_shutdown: false,
+            upstream_url: None,
+        }
+    }
+
+    /// Sets the listening port (`--port`).
+    pub fn port(mut self, port: u16) -> Self {
+        self.port = Some(port);
+        self
+    }
+
+    /// Writes `{port,pid}` JSON to the provided path via `--server-info`.
+    pub fn server_info(mut self, path: impl Into<PathBuf>) -> Self {
+        self.server_info_path = Some(path.into());
+        self
+    }
+
+    /// Enables the `--http-shutdown` flag (GET /shutdown).
+    pub fn http_shutdown(mut self, enable: bool) -> Self {
+        self.http_shutdown = enable;
+        self
+    }
+
+    /// Overrides the upstream responses endpoint URL.
+    pub fn upstream_url(mut self, url: impl Into<String>) -> Self {
+        let url = url.into();
+        self.upstream_url = (!url.trim().is_empty()).then_some(url);
+        self
+    }
+}
+
+/// Running responses proxy process and metadata.
+#[derive(Debug)]
+pub struct ResponsesApiProxyHandle {
+    /// Spawned `codex responses-api-proxy` child (inherits kill-on-drop).
+    pub child: tokio::process::Child,
+    /// Optional `--server-info` path that may contain `{port,pid}` JSON.
+    pub server_info_path: Option<PathBuf>,
+}
+
+impl ResponsesApiProxyHandle {
+    /// Reads and parses the `{port,pid}` JSON written by `--server-info`.
+    ///
+    /// Returns `Ok(None)` when no server info path was configured.
+    pub async fn read_server_info(&self) -> Result<Option<ResponsesApiProxyInfo>, CodexError> {
+        let Some(path) = &self.server_info_path else {
+            return Ok(None);
+        };
+
+        const MAX_ATTEMPTS: usize = 10;
+        const BACKOFF_MS: u64 = 25;
+
+        for attempt in 0..MAX_ATTEMPTS {
+            match fs::read_to_string(path).await {
+                Ok(contents) => match serde_json::from_str::<ResponsesApiProxyInfo>(&contents) {
+                    Ok(info) => return Ok(Some(info)),
+                    Err(source) => {
+                        if attempt + 1 == MAX_ATTEMPTS {
+                            return Err(CodexError::ResponsesApiProxyInfoParse {
+                                path: path.clone(),
+                                source,
+                            });
+                        }
+                    }
+                },
+                Err(source) => {
+                    let is_missing = source.kind() == std::io::ErrorKind::NotFound;
+                    if !is_missing || attempt + 1 == MAX_ATTEMPTS {
+                        return Err(CodexError::ResponsesApiProxyInfoRead {
+                            path: path.clone(),
+                            source,
+                        });
+                    }
+                }
+            }
+
+            tokio::time::sleep(std::time::Duration::from_millis(BACKOFF_MS)).await;
+        }
+
+        unreachable!("read_server_info loop must return by MAX_ATTEMPTS")
+    }
+}
+
+/// Parsed `{port,pid}` emitted by `codex responses-api-proxy --server-info`.
+#[derive(Clone, Debug, Eq, PartialEq, Serialize, Deserialize)]
+pub struct ResponsesApiProxyInfo {
+    pub port: u16,
+    pub pid: u32,
+    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
+    pub extra: BTreeMap<String, Value>,
+}
diff --git a/crates/codex/src/cli/review.rs b/crates/codex/src/cli/review.rs
new file mode 100644
index 0000000..55ec539
--- /dev/null
+++ b/crates/codex/src/cli/review.rs
@@ -0,0 +1,145 @@
+use crate::CliOverridesPatch;
+
+/// Request for `codex review [OPTIONS] [PROMPT]`.
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub struct ReviewCommandRequest {
+    pub prompt: Option<String>,
+    pub base: Option<String>,
+    pub commit: Option<String>,
+    pub title: Option<String>,
+    pub uncommitted: bool,
+    /// Per-call CLI overrides layered on top of the builder.
+    pub overrides: CliOverridesPatch,
+}
+
+impl ReviewCommandRequest {
+    pub fn new() -> Self {
+        Self {
+            prompt: None,
+            base: None,
+            commit: None,
+            title: None,
+            uncommitted: false,
+            overrides: CliOverridesPatch::default(),
+        }
+    }
+
+    pub fn prompt(mut self, prompt: impl Into<String>) -> Self {
+        let prompt = prompt.into();
+        self.prompt = (!prompt.trim().is_empty()).then_some(prompt);
+        self
+    }
+
+    pub fn base(mut self, branch: impl Into<String>) -> Self {
+        let branch = branch.into();
+        self.base = (!branch.trim().is_empty()).then_some(branch);
+        self
+    }
+
+    pub fn commit(mut self, sha: impl Into<String>) -> Self {
+        let sha = sha.into();
+        self.commit = (!sha.trim().is_empty()).then_some(sha);
+        self
+    }
+
+    pub fn title(mut self, title: impl Into<String>) -> Self {
+        let title = title.into();
+        self.title = (!title.trim().is_empty()).then_some(title);
+        self
+    }
+
+    pub fn uncommitted(mut self, enable: bool) -> Self {
+        self.uncommitted = enable;
+        self
+    }
+
+    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
+        self.overrides = overrides;
+        self
+    }
+}
+
+impl Default for ReviewCommandRequest {
+    fn default() -> Self {
+        Self::new()
+    }
+}
+
+/// Request for `codex exec review [OPTIONS] [PROMPT]`.
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub struct ExecReviewCommandRequest {
+    pub prompt: Option<String>,
+    pub base: Option<String>,
+    pub commit: Option<String>,
+    pub title: Option<String>,
+    pub uncommitted: bool,
+    pub json: bool,
+    pub skip_git_repo_check: bool,
+    /// Per-call CLI overrides layered on top of the builder.
+    pub overrides: CliOverridesPatch,
+}
+
+impl ExecReviewCommandRequest {
+    pub fn new() -> Self {
+        Self {
+            prompt: None,
+            base: None,
+            commit: None,
+            title: None,
+            uncommitted: false,
+            json: false,
+            skip_git_repo_check: true,
+            overrides: CliOverridesPatch::default(),
+        }
+    }
+
+    pub fn prompt(mut self, prompt: impl Into<String>) -> Self {
+        let prompt = prompt.into();
+        self.prompt = (!prompt.trim().is_empty()).then_some(prompt);
+        self
+    }
+
+    pub fn base(mut self, branch: impl Into<String>) -> Self {
+        let branch = branch.into();
+        self.base = (!branch.trim().is_empty()).then_some(branch);
+        self
+    }
+
+    pub fn commit(mut self, sha: impl Into<String>) -> Self {
+        let sha = sha.into();
+        self.commit = (!sha.trim().is_empty()).then_some(sha);
+        self
+    }
+
+    pub fn title(mut self, title: impl Into<String>) -> Self {
+        let title = title.into();
+        self.title = (!title.trim().is_empty()).then_some(title);
+        self
+    }
+
+    pub fn uncommitted(mut self, enable: bool) -> Self {
+        self.uncommitted = enable;
+        self
+    }
+
+    pub fn json(mut self, enable: bool) -> Self {
+        self.json = enable;
+        self
+    }
+
+    pub fn skip_git_repo_check(mut self, enable: bool) -> Self {
+        self.skip_git_repo_check = enable;
+        self
+    }
+
+    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
+        self.overrides = overrides;
+        self
+    }
+}
+
+impl Default for ExecReviewCommandRequest {
+    fn default() -> Self {
+        Self::new()
+    }
+}
diff --git a/crates/codex/src/cli/sandbox.rs b/crates/codex/src/cli/sandbox.rs
new file mode 100644
index 0000000..f23ab1a
--- /dev/null
+++ b/crates/codex/src/cli/sandbox.rs
@@ -0,0 +1,103 @@
+use crate::{ConfigOverride, FeatureToggles};
+use std::{ffi::OsString, path::PathBuf, process::ExitStatus};
+
+/// Sandbox platform variant; maps to platform subcommands of `codex sandbox`.
+#[derive(Clone, Copy, Debug, Eq, PartialEq)]
+pub enum SandboxPlatform {
+    Macos,
+    Linux,
+    Windows,
+}
+
+impl SandboxPlatform {
+    pub(crate) fn subcommand(self) -> &'static str {
+        match self {
+            SandboxPlatform::Macos => "macos",
+            SandboxPlatform::Linux => "linux",
+            SandboxPlatform::Windows => "windows",
+        }
+    }
+}
+
+/// Request to run an arbitrary command inside a Codex-provided sandbox.
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub struct SandboxCommandRequest {
+    /// Target platform subcommand; maps to `macos` (alias `seatbelt`), `linux` (alias `landlock`), or `windows`.
+    pub platform: SandboxPlatform,
+    /// Trailing command arguments to execute. Must be non-empty to avoid the upstream CLI panic.
+    pub command: Vec<OsString>,
+    /// Request the workspace-write sandbox preset (`--full-auto`).
+    pub full_auto: bool,
+    /// Stream macOS sandbox denials after the child process exits (no-op on other platforms).
+    pub log_denials: bool,
+    /// Additional `--config key=value` overrides to pass through.
+    pub config_overrides: Vec<ConfigOverride>,
+    /// Feature toggles forwarded to `--enable`/`--disable`.
+    pub feature_toggles: FeatureToggles,
+    /// Working directory for the spawned command; falls back to the builder value, then the current process directory.
+    pub working_dir: Option<PathBuf>,
+}
+
+impl SandboxCommandRequest {
+    pub fn new<I, S>(platform: SandboxPlatform, command: I) -> Self
+    where
+        I: IntoIterator<Item = S>,
+        S: Into<OsString>,
+    {
+        Self {
+            platform,
+            command: command.into_iter().map(Into::into).collect(),
+            full_auto: false,
+            log_denials: false,
+            config_overrides: Vec::new(),
+            feature_toggles: FeatureToggles::default(),
+            working_dir: None,
+        }
+    }
+
+    pub fn full_auto(mut self, enable: bool) -> Self {
+        self.full_auto = enable;
+        self
+    }
+
+    pub fn log_denials(mut self, enable: bool) -> Self {
+        self.log_denials = enable;
+        self
+    }
+
+    pub fn config_override(mut self, key: impl Into<String>, value: impl Into<String>) -> Self {
+        self.config_overrides.push(ConfigOverride::new(key, value));
+        self
+    }
+
+    pub fn config_override_raw(mut self, raw: impl Into<String>) -> Self {
+        self.config_overrides.push(ConfigOverride::from_raw(raw));
+        self
+    }
+
+    pub fn enable_feature(mut self, name: impl Into<String>) -> Self {
+        self.feature_toggles.enable.push(name.into());
+        self
+    }
+
+    pub fn disable_feature(mut self, name: impl Into<String>) -> Self {
+        self.feature_toggles.disable.push(name.into());
+        self
+    }
+
+    pub fn working_dir(mut self, dir: impl Into<PathBuf>) -> Self {
+        self.working_dir = Some(dir.into());
+        self
+    }
+}
+
+/// Captured output from `codex sandbox <platform>`.
+#[derive(Clone, Debug)]
+pub struct SandboxRun {
+    /// Exit status returned by the inner command (mirrors the sandbox helper).
+    pub status: ExitStatus,
+    /// Captured stdout (mirrored to the console when `mirror_stdout` is true).
+    pub stdout: String,
+    /// Captured stderr (mirrored unless `quiet` is set).
+    pub stderr: String,
+}
diff --git a/crates/codex/src/cli/session.rs b/crates/codex/src/cli/session.rs
new file mode 100644
index 0000000..fcef5e0
--- /dev/null
+++ b/crates/codex/src/cli/session.rs
@@ -0,0 +1,113 @@
+use crate::CliOverridesPatch;
+
+/// Request for `codex resume [OPTIONS] [SESSION_ID] [PROMPT]`.
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub struct ResumeSessionRequest {
+    pub session_id: Option<String>,
+    pub prompt: Option<String>,
+    pub all: bool,
+    pub last: bool,
+    /// Per-call CLI overrides layered on top of the builder.
+    pub overrides: CliOverridesPatch,
+}
+
+impl ResumeSessionRequest {
+    pub fn new() -> Self {
+        Self {
+            session_id: None,
+            prompt: None,
+            all: false,
+            last: false,
+            overrides: CliOverridesPatch::default(),
+        }
+    }
+
+    pub fn session_id(mut self, session_id: impl Into<String>) -> Self {
+        let session_id = session_id.into();
+        self.session_id = (!session_id.trim().is_empty()).then_some(session_id);
+        self
+    }
+
+    pub fn prompt(mut self, prompt: impl Into<String>) -> Self {
+        let prompt = prompt.into();
+        self.prompt = (!prompt.trim().is_empty()).then_some(prompt);
+        self
+    }
+
+    pub fn all(mut self, enable: bool) -> Self {
+        self.all = enable;
+        self
+    }
+
+    pub fn last(mut self, enable: bool) -> Self {
+        self.last = enable;
+        self
+    }
+
+    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
+        self.overrides = overrides;
+        self
+    }
+}
+
+impl Default for ResumeSessionRequest {
+    fn default() -> Self {
+        Self::new()
+    }
+}
+
+/// Request for `codex fork [OPTIONS] [SESSION_ID] [PROMPT]`.
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub struct ForkSessionRequest {
+    pub session_id: Option<String>,
+    pub prompt: Option<String>,
+    pub all: bool,
+    pub last: bool,
+    /// Per-call CLI overrides layered on top of the builder.
+    pub overrides: CliOverridesPatch,
+}
+
+impl ForkSessionRequest {
+    pub fn new() -> Self {
+        Self {
+            session_id: None,
+            prompt: None,
+            all: false,
+            last: false,
+            overrides: CliOverridesPatch::default(),
+        }
+    }
+
+    pub fn session_id(mut self, session_id: impl Into<String>) -> Self {
+        let session_id = session_id.into();
+        self.session_id = (!session_id.trim().is_empty()).then_some(session_id);
+        self
+    }
+
+    pub fn prompt(mut self, prompt: impl Into<String>) -> Self {
+        let prompt = prompt.into();
+        self.prompt = (!prompt.trim().is_empty()).then_some(prompt);
+        self
+    }
+
+    pub fn all(mut self, enable: bool) -> Self {
+        self.all = enable;
+        self
+    }
+
+    pub fn last(mut self, enable: bool) -> Self {
+        self.last = enable;
+        self
+    }
+
+    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
+        self.overrides = overrides;
+        self
+    }
+}
+
+impl Default for ForkSessionRequest {
+    fn default() -> Self {
+        Self::new()
+    }
+}
diff --git a/crates/codex/src/cli/stdio_to_uds.rs b/crates/codex/src/cli/stdio_to_uds.rs
new file mode 100644
index 0000000..31c9b84
--- /dev/null
+++ b/crates/codex/src/cli/stdio_to_uds.rs
@@ -0,0 +1,25 @@
+use std::path::PathBuf;
+
+/// Request for `codex stdio-to-uds <SOCKET_PATH>`.
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub struct StdioToUdsRequest {
+    /// Path to the Unix domain socket to connect to.
+    pub socket_path: PathBuf,
+    /// Optional working directory override for the spawned process.
+    pub working_dir: Option<PathBuf>,
+}
+
+impl StdioToUdsRequest {
+    pub fn new(socket_path: impl Into<PathBuf>) -> Self {
+        Self {
+            socket_path: socket_path.into(),
+            working_dir: None,
+        }
+    }
+
+    /// Sets the working directory used to resolve the socket path.
+    pub fn working_dir(mut self, dir: impl Into<PathBuf>) -> Self {
+        self.working_dir = Some(dir.into());
+        self
+    }
+}
diff --git a/crates/codex/src/client_core.rs b/crates/codex/src/client_core.rs
new file mode 100644
index 0000000..47947cc
--- /dev/null
+++ b/crates/codex/src/client_core.rs
@@ -0,0 +1,188 @@
+use std::{
+    env,
+    ffi::{OsStr, OsString},
+    path::{Path, PathBuf},
+};
+
+use crate::{
+    apply_diff::ApplyDiffArtifacts,
+    builder::{apply_cli_overrides, resolve_cli_overrides, CliOverridesPatch},
+    process::{spawn_with_retry, tee_stream, CommandOutput, ConsoleTarget},
+    CodexClient, CodexError,
+};
+use tempfile::TempDir;
+use tokio::{process::Command, time};
+
+impl CodexClient {
+    pub(crate) fn directory_context(&self) -> Result<DirectoryContext, CodexError> {
+        if let Some(dir) = &self.working_dir {
+            return Ok(DirectoryContext::Fixed(dir.clone()));
+        }
+
+        let temp = tempfile::tempdir().map_err(CodexError::TempDir)?;
+        Ok(DirectoryContext::Ephemeral(temp))
+    }
+
+    pub(crate) fn sandbox_working_dir(
+        &self,
+        request_dir: Option<PathBuf>,
+    ) -> Result<PathBuf, CodexError> {
+        if let Some(dir) = request_dir {
+            return Ok(dir);
+        }
+
+        if let Some(dir) = &self.working_dir {
+            return Ok(dir.clone());
+        }
+
+        env::current_dir().map_err(|source| CodexError::WorkingDirectory { source })
+    }
+
+    pub(crate) async fn run_simple_command_with_overrides(
+        &self,
+        args: Vec<OsString>,
+        overrides: CliOverridesPatch,
+    ) -> Result<ApplyDiffArtifacts, CodexError> {
+        let dir_ctx = self.directory_context()?;
+        let resolved_overrides =
+            resolve_cli_overrides(&self.cli_overrides, &overrides, self.model.as_deref());
+
+        let mut command = Command::new(self.command_env.binary_path());
+        command
+            .args(args)
+            .stdout(std::process::Stdio::piped())
+            .stderr(std::process::Stdio::piped())
+            .kill_on_drop(true)
+            .current_dir(dir_ctx.path());
+
+        apply_cli_overrides(&mut command, &resolved_overrides, true);
+
+        self.command_env.apply(&mut command)?;
+
+        let mut child = spawn_with_retry(&mut command, self.command_env.binary_path())?;
+
+        let stdout = child.stdout.take().ok_or(CodexError::StdoutUnavailable)?;
+        let stderr = child.stderr.take().ok_or(CodexError::StderrUnavailable)?;
+
+        let stdout_task = tokio::spawn(tee_stream(
+            stdout,
+            ConsoleTarget::Stdout,
+            self.mirror_stdout,
+        ));
+        let stderr_task = tokio::spawn(tee_stream(stderr, ConsoleTarget::Stderr, !self.quiet));
+
+        let timeout = self.timeout;
+        let wait_task = async move {
+            let _dir_ctx = dir_ctx;
+            let status = child
+                .wait()
+                .await
+                .map_err(|source| CodexError::Wait { source })?;
+            let stdout_bytes = stdout_task
+                .await
+                .map_err(CodexError::Join)?
+                .map_err(CodexError::CaptureIo)?;
+            let stderr_bytes = stderr_task
+                .await
+                .map_err(CodexError::Join)?
+                .map_err(CodexError::CaptureIo)?;
+            Ok::<_, CodexError>((status, stdout_bytes, stderr_bytes))
+        };
+
+        let (status, stdout_bytes, stderr_bytes) = if timeout.is_zero() {
+            wait_task.await?
+        } else {
+            match time::timeout(timeout, wait_task).await {
+                Ok(result) => result?,
+                Err(_) => {
+                    return Err(CodexError::Timeout { timeout });
+                }
+            }
+        };
+
+        if !status.success() {
+            return Err(CodexError::NonZeroExit {
+                status,
+                stderr: String::from_utf8(stderr_bytes)?,
+            });
+        }
+
+        Ok(ApplyDiffArtifacts {
+            status,
+            stdout: String::from_utf8(stdout_bytes)?,
+            stderr: String::from_utf8(stderr_bytes)?,
+        })
+    }
+
+    pub(crate) async fn run_basic_command<S, I>(&self, args: I) -> Result<CommandOutput, CodexError>
+    where
+        S: AsRef<OsStr>,
+        I: IntoIterator<Item = S>,
+    {
+        let mut command = Command::new(self.command_env.binary_path());
+        command
+            .args(args)
+            .stdout(std::process::Stdio::piped())
+            .stderr(std::process::Stdio::piped())
+            .kill_on_drop(true);
+
+        self.command_env.apply(&mut command)?;
+
+        let mut child = spawn_with_retry(&mut command, self.command_env.binary_path())?;
+
+        let stdout = child.stdout.take().ok_or(CodexError::StdoutUnavailable)?;
+        let stderr = child.stderr.take().ok_or(CodexError::StderrUnavailable)?;
+
+        let stdout_task = tokio::spawn(tee_stream(stdout, ConsoleTarget::Stdout, false));
+        let stderr_task = tokio::spawn(tee_stream(stderr, ConsoleTarget::Stderr, false));
+
+        let wait_task = async move {
+            let status = child
+                .wait()
+                .await
+                .map_err(|source| CodexError::Wait { source })?;
+            let stdout_bytes = stdout_task
+                .await
+                .map_err(CodexError::Join)?
+                .map_err(CodexError::CaptureIo)?;
+            let stderr_bytes = stderr_task
+                .await
+                .map_err(CodexError::Join)?
+                .map_err(CodexError::CaptureIo)?;
+            Ok::<_, CodexError>((status, stdout_bytes, stderr_bytes))
+        };
+
+        let (status, stdout_bytes, stderr_bytes) = if self.timeout.is_zero() {
+            wait_task.await?
+        } else {
+            match time::timeout(self.timeout, wait_task).await {
+                Ok(result) => result?,
+                Err(_) => {
+                    return Err(CodexError::Timeout {
+                        timeout: self.timeout,
+                    });
+                }
+            }
+        };
+
+        Ok(CommandOutput {
+            status,
+            stdout: stdout_bytes,
+            stderr: stderr_bytes,
+        })
+    }
+}
+
+pub(crate) enum DirectoryContext {
+    Fixed(PathBuf),
+    Ephemeral(TempDir),
+}
+
+impl DirectoryContext {
+    pub(crate) fn path(&self) -> &Path {
+        match self {
+            DirectoryContext::Fixed(path) => path.as_path(),
+            DirectoryContext::Ephemeral(dir) => dir.path(),
+        }
+    }
+}
diff --git a/crates/codex/src/commands/app_server.rs b/crates/codex/src/commands/app_server.rs
new file mode 100644
index 0000000..95a09f6
--- /dev/null
+++ b/crates/codex/src/commands/app_server.rs
@@ -0,0 +1,112 @@
+use std::fs as std_fs;
+
+use tokio::{process::Command, time};
+
+use crate::{
+    builder::{apply_cli_overrides, resolve_cli_overrides},
+    process::{spawn_with_retry, tee_stream, ConsoleTarget},
+    AppServerCodegenOutput, AppServerCodegenRequest, CodexClient, CodexError,
+};
+
+impl CodexClient {
+    /// Generates app-server bindings via `codex app-server generate-ts` or `generate-json-schema`.
+    ///
+    /// Ensures the output directory exists, mirrors stdout/stderr according to the builder
+    /// (`mirror_stdout` / `quiet`), and returns captured output plus the exit status. Non-zero
+    /// exits bubble up as [`CodexError::NonZeroExit`] with stderr attached. Use
+    /// [`AppServerCodegenRequest::prettier`] to format TypeScript output with a specific
+    /// Prettier binary and request-level overrides for config/profile toggles.
+    pub async fn generate_app_server_bindings(
+        &self,
+        request: AppServerCodegenRequest,
+    ) -> Result<AppServerCodegenOutput, CodexError> {
+        let AppServerCodegenRequest {
+            target,
+            out_dir,
+            overrides,
+        } = request;
+
+        std_fs::create_dir_all(&out_dir).map_err(|source| CodexError::PrepareOutputDirectory {
+            path: out_dir.clone(),
+            source,
+        })?;
+
+        let dir_ctx = self.directory_context()?;
+        let resolved_overrides =
+            resolve_cli_overrides(&self.cli_overrides, &overrides, self.model.as_deref());
+
+        let mut command = Command::new(self.command_env.binary_path());
+        command
+            .arg("app-server")
+            .arg(target.subcommand())
+            .arg("--out")
+            .arg(&out_dir)
+            .stdout(std::process::Stdio::piped())
+            .stderr(std::process::Stdio::piped())
+            .kill_on_drop(true)
+            .current_dir(dir_ctx.path());
+
+        apply_cli_overrides(&mut command, &resolved_overrides, true);
+
+        if let Some(prettier) = target.prettier() {
+            command.arg("--prettier").arg(prettier);
+        }
+
+        self.command_env.apply(&mut command)?;
+
+        let mut child = spawn_with_retry(&mut command, self.command_env.binary_path())?;
+
+        let stdout = child.stdout.take().ok_or(CodexError::StdoutUnavailable)?;
+        let stderr = child.stderr.take().ok_or(CodexError::StderrUnavailable)?;
+
+        let stdout_task = tokio::spawn(tee_stream(
+            stdout,
+            ConsoleTarget::Stdout,
+            self.mirror_stdout,
+        ));
+        let stderr_task = tokio::spawn(tee_stream(stderr, ConsoleTarget::Stderr, !self.quiet));
+
+        let wait_task = async move {
+            let status = child
+                .wait()
+                .await
+                .map_err(|source| CodexError::Wait { source })?;
+            let stdout_bytes = stdout_task
+                .await
+                .map_err(CodexError::Join)?
+                .map_err(CodexError::CaptureIo)?;
+            let stderr_bytes = stderr_task
+                .await
+                .map_err(CodexError::Join)?
+                .map_err(CodexError::CaptureIo)?;
+            Ok::<_, CodexError>((status, stdout_bytes, stderr_bytes))
+        };
+
+        let (status, stdout_bytes, stderr_bytes) = if self.timeout.is_zero() {
+            wait_task.await?
+        } else {
+            match time::timeout(self.timeout, wait_task).await {
+                Ok(result) => result?,
+                Err(_) => {
+                    return Err(CodexError::Timeout {
+                        timeout: self.timeout,
+                    });
+                }
+            }
+        };
+
+        if !status.success() {
+            return Err(CodexError::NonZeroExit {
+                status,
+                stderr: String::from_utf8(stderr_bytes)?,
+            });
+        }
+
+        Ok(AppServerCodegenOutput {
+            status,
+            stdout: String::from_utf8(stdout_bytes)?,
+            stderr: String::from_utf8(stderr_bytes)?,
+            out_dir,
+        })
+    }
+}
diff --git a/crates/codex/src/commands/apply_diff.rs b/crates/codex/src/commands/apply_diff.rs
new file mode 100644
index 0000000..21ff5fb
--- /dev/null
+++ b/crates/codex/src/commands/apply_diff.rs
@@ -0,0 +1,159 @@
+use std::{env, ffi::OsString};
+
+use tokio::{process::Command, time};
+
+use crate::{
+    builder::{apply_cli_overrides, resolve_cli_overrides},
+    process::{spawn_with_retry, tee_stream, ConsoleTarget},
+    ApplyDiffArtifacts, CliOverridesPatch, CodexClient, CodexError,
+};
+
+impl CodexClient {
+    /// Applies a Codex diff by invoking `codex apply <TASK_ID>`.
+    ///
+    /// Stdout mirrors to the console when `mirror_stdout` is enabled; stderr mirrors unless `quiet`
+    /// is set. Output and exit status are always captured and returned, and `RUST_LOG=error` is
+    /// injected for the child process when the environment variable is unset.
+    ///
+    /// Convenience behavior: if `CODEX_TASK_ID` is set, it is appended as `<TASK_ID>`. When the
+    /// environment variable is missing, the subprocess is still spawned and will typically exit
+    /// non-zero with a "missing TASK_ID" error from the CLI.
+    pub async fn apply(&self) -> Result<ApplyDiffArtifacts, CodexError> {
+        let task_id = env::var_os("CODEX_TASK_ID")
+            .and_then(|v| crate::normalize_non_empty(&v.to_string_lossy()).map(OsString::from));
+        self.apply_task_inner(task_id).await
+    }
+
+    /// Applies a Codex diff by task id via `codex apply <TASK_ID>`.
+    pub async fn apply_task(
+        &self,
+        task_id: impl AsRef<str>,
+    ) -> Result<ApplyDiffArtifacts, CodexError> {
+        let task_id = task_id.as_ref().trim();
+        if task_id.is_empty() {
+            return Err(CodexError::EmptyTaskId);
+        }
+        self.apply_task_inner(Some(OsString::from(task_id))).await
+    }
+
+    /// Shows a Codex Cloud task diff by invoking `codex cloud diff <TASK_ID>`.
+    ///
+    /// Mirrors stdout/stderr using the same `mirror_stdout`/`quiet` defaults as `apply`, but always
+    /// returns the captured output alongside the child exit status. Applies the same `RUST_LOG`
+    /// defaulting behavior when the variable is unset.
+    ///
+    /// Convenience behavior: if `CODEX_TASK_ID` is set, it is appended as `<TASK_ID>`. When the
+    /// environment variable is missing, the subprocess is still spawned and will typically exit
+    /// non-zero with a "missing TASK_ID" error from the CLI.
+    pub async fn diff(&self) -> Result<ApplyDiffArtifacts, CodexError> {
+        let task_id = env::var_os("CODEX_TASK_ID")
+            .and_then(|v| crate::normalize_non_empty(&v.to_string_lossy()).map(OsString::from));
+        self.cloud_diff_task_inner(task_id).await
+    }
+
+    /// Shows a Codex Cloud task diff by task id via `codex cloud diff <TASK_ID>`.
+    pub async fn cloud_diff_task(
+        &self,
+        task_id: impl AsRef<str>,
+    ) -> Result<ApplyDiffArtifacts, CodexError> {
+        let task_id = task_id.as_ref().trim();
+        if task_id.is_empty() {
+            return Err(CodexError::EmptyTaskId);
+        }
+        self.cloud_diff_task_inner(Some(OsString::from(task_id)))
+            .await
+    }
+
+    async fn apply_task_inner(
+        &self,
+        task_id: Option<OsString>,
+    ) -> Result<ApplyDiffArtifacts, CodexError> {
+        let mut args = vec![OsString::from("apply")];
+        if let Some(task_id) = task_id {
+            args.push(task_id);
+        }
+        self.capture_codex_command(args, false).await
+    }
+
+    async fn cloud_diff_task_inner(
+        &self,
+        task_id: Option<OsString>,
+    ) -> Result<ApplyDiffArtifacts, CodexError> {
+        let mut args = vec![OsString::from("cloud"), OsString::from("diff")];
+        if let Some(task_id) = task_id {
+            args.push(task_id);
+        }
+        self.capture_codex_command(args, false).await
+    }
+
+    async fn capture_codex_command(
+        &self,
+        args: Vec<OsString>,
+        include_search: bool,
+    ) -> Result<ApplyDiffArtifacts, CodexError> {
+        let dir_ctx = self.directory_context()?;
+        let resolved_overrides = resolve_cli_overrides(
+            &self.cli_overrides,
+            &CliOverridesPatch::default(),
+            self.model.as_deref(),
+        );
+
+        let mut command = Command::new(self.command_env.binary_path());
+        command
+            .args(&args)
+            .stdout(std::process::Stdio::piped())
+            .stderr(std::process::Stdio::piped())
+            .kill_on_drop(true)
+            .current_dir(dir_ctx.path());
+
+        apply_cli_overrides(&mut command, &resolved_overrides, include_search);
+        self.command_env.apply(&mut command)?;
+
+        let mut child = spawn_with_retry(&mut command, self.command_env.binary_path())?;
+
+        let stdout = child.stdout.take().ok_or(CodexError::StdoutUnavailable)?;
+        let stderr = child.stderr.take().ok_or(CodexError::StderrUnavailable)?;
+
+        let stdout_task = tokio::spawn(tee_stream(
+            stdout,
+            ConsoleTarget::Stdout,
+            self.mirror_stdout,
+        ));
+        let stderr_task = tokio::spawn(tee_stream(stderr, ConsoleTarget::Stderr, !self.quiet));
+
+        let wait_task = async move {
+            let status = child
+                .wait()
+                .await
+                .map_err(|source| CodexError::Wait { source })?;
+            let stdout_bytes = stdout_task
+                .await
+                .map_err(CodexError::Join)?
+                .map_err(CodexError::CaptureIo)?;
+            let stderr_bytes = stderr_task
+                .await
+                .map_err(CodexError::Join)?
+                .map_err(CodexError::CaptureIo)?;
+            Ok::<_, CodexError>((status, stdout_bytes, stderr_bytes))
+        };
+
+        let (status, stdout_bytes, stderr_bytes) = if self.timeout.is_zero() {
+            wait_task.await?
+        } else {
+            match time::timeout(self.timeout, wait_task).await {
+                Ok(result) => result?,
+                Err(_) => {
+                    return Err(CodexError::Timeout {
+                        timeout: self.timeout,
+                    });
+                }
+            }
+        };
+
+        Ok(ApplyDiffArtifacts {
+            status,
+            stdout: String::from_utf8(stdout_bytes)?,
+            stderr: String::from_utf8(stderr_bytes)?,
+        })
+    }
+}
diff --git a/crates/codex/src/commands/cloud.rs b/crates/codex/src/commands/cloud.rs
new file mode 100644
index 0000000..1544a1c
--- /dev/null
+++ b/crates/codex/src/commands/cloud.rs
@@ -0,0 +1,163 @@
+use std::ffi::OsString;
+
+use crate::{
+    ApplyDiffArtifacts, CloudApplyRequest, CloudDiffRequest, CloudExecRequest, CloudListOutput,
+    CloudListRequest, CloudOverviewRequest, CloudStatusRequest, CodexClient, CodexError,
+};
+
+impl CodexClient {
+    /// Runs `codex cloud --help` and returns captured output.
+    pub async fn cloud_overview(
+        &self,
+        request: CloudOverviewRequest,
+    ) -> Result<ApplyDiffArtifacts, CodexError> {
+        self.run_simple_command_with_overrides(
+            vec![OsString::from("cloud"), OsString::from("--help")],
+            request.overrides,
+        )
+        .await
+    }
+
+    /// Lists Codex Cloud tasks via `codex cloud list`.
+    pub async fn cloud_list(
+        &self,
+        request: CloudListRequest,
+    ) -> Result<CloudListOutput, CodexError> {
+        let CloudListRequest {
+            json,
+            env_id,
+            limit,
+            cursor,
+            overrides,
+        } = request;
+
+        let mut args = vec![OsString::from("cloud"), OsString::from("list")];
+        if let Some(env_id) = env_id {
+            args.push(OsString::from("--env"));
+            args.push(OsString::from(env_id));
+        }
+        if let Some(limit) = limit {
+            args.push(OsString::from("--limit"));
+            args.push(OsString::from(limit.to_string()));
+        }
+        if let Some(cursor) = cursor {
+            args.push(OsString::from("--cursor"));
+            args.push(OsString::from(cursor));
+        }
+        if json {
+            args.push(OsString::from("--json"));
+        }
+
+        let artifacts = self
+            .run_simple_command_with_overrides(args, overrides)
+            .await?;
+        let parsed = if json {
+            Some(serde_json::from_str(&artifacts.stdout).map_err(|source| {
+                CodexError::JsonParse {
+                    context: "cloud list",
+                    stdout: artifacts.stdout.clone(),
+                    source,
+                }
+            })?)
+        } else {
+            None
+        };
+
+        Ok(CloudListOutput {
+            status: artifacts.status,
+            stdout: artifacts.stdout,
+            stderr: artifacts.stderr,
+            json: parsed,
+        })
+    }
+
+    /// Shows the status of a Codex Cloud task via `codex cloud status <TASK_ID>`.
+    pub async fn cloud_status(
+        &self,
+        request: CloudStatusRequest,
+    ) -> Result<ApplyDiffArtifacts, CodexError> {
+        let task_id = request.task_id.trim();
+        if task_id.is_empty() {
+            return Err(CodexError::EmptyTaskId);
+        }
+
+        self.run_simple_command_with_overrides(
+            vec![
+                OsString::from("cloud"),
+                OsString::from("status"),
+                OsString::from(task_id),
+            ],
+            request.overrides,
+        )
+        .await
+    }
+
+    /// Shows the unified diff for a Codex Cloud task via `codex cloud diff [--attempt N] <TASK_ID>`.
+    pub async fn cloud_diff(
+        &self,
+        request: CloudDiffRequest,
+    ) -> Result<ApplyDiffArtifacts, CodexError> {
+        let task_id = request.task_id.trim();
+        if task_id.is_empty() {
+            return Err(CodexError::EmptyTaskId);
+        }
+
+        let mut args = vec![OsString::from("cloud"), OsString::from("diff")];
+        if let Some(attempt) = request.attempt {
+            args.push(OsString::from("--attempt"));
+            args.push(OsString::from(attempt.to_string()));
+        }
+        args.push(OsString::from(task_id));
+        self.run_simple_command_with_overrides(args, request.overrides)
+            .await
+    }
+
+    /// Applies the diff for a Codex Cloud task locally via `codex cloud apply [--attempt N] <TASK_ID>`.
+    pub async fn cloud_apply(
+        &self,
+        request: CloudApplyRequest,
+    ) -> Result<ApplyDiffArtifacts, CodexError> {
+        let task_id = request.task_id.trim();
+        if task_id.is_empty() {
+            return Err(CodexError::EmptyTaskId);
+        }
+
+        let mut args = vec![OsString::from("cloud"), OsString::from("apply")];
+        if let Some(attempt) = request.attempt {
+            args.push(OsString::from("--attempt"));
+            args.push(OsString::from(attempt.to_string()));
+        }
+        args.push(OsString::from(task_id));
+        self.run_simple_command_with_overrides(args, request.overrides)
+            .await
+    }
+
+    /// Submits a new Codex Cloud task via `codex cloud exec`.
+    pub async fn cloud_exec(
+        &self,
+        request: CloudExecRequest,
+    ) -> Result<ApplyDiffArtifacts, CodexError> {
+        let env_id = request.env_id.trim();
+        if env_id.is_empty() {
+            return Err(CodexError::EmptyEnvId);
+        }
+
+        let mut args = vec![OsString::from("cloud"), OsString::from("exec")];
+        args.push(OsString::from("--env"));
+        args.push(OsString::from(env_id));
+        if let Some(attempts) = request.attempts {
+            args.push(OsString::from("--attempts"));
+            args.push(OsString::from(attempts.to_string()));
+        }
+        if let Some(branch) = request.branch {
+            args.push(OsString::from("--branch"));
+            args.push(OsString::from(branch));
+        }
+        if let Some(query) = request.query {
+            args.push(OsString::from(query));
+        }
+
+        self.run_simple_command_with_overrides(args, request.overrides)
+            .await
+    }
+}
diff --git a/crates/codex/src/commands/features.rs b/crates/codex/src/commands/features.rs
new file mode 100644
index 0000000..09bc2a7
--- /dev/null
+++ b/crates/codex/src/commands/features.rs
@@ -0,0 +1,119 @@
+use std::ffi::OsString;
+
+use tokio::{process::Command, time};
+
+use crate::{
+    builder::{apply_cli_overrides, resolve_cli_overrides},
+    process::{spawn_with_retry, tee_stream, ConsoleTarget},
+    ApplyDiffArtifacts, CodexClient, CodexError, FeaturesCommandRequest, FeaturesListOutput,
+    FeaturesListRequest,
+};
+
+impl CodexClient {
+    /// Runs `codex features` and returns captured output.
+    pub async fn features(
+        &self,
+        request: FeaturesCommandRequest,
+    ) -> Result<ApplyDiffArtifacts, CodexError> {
+        self.run_simple_command_with_overrides(vec![OsString::from("features")], request.overrides)
+            .await
+    }
+
+    /// Lists CLI features via `codex features list`.
+    ///
+    /// Requests JSON output when `json(true)` is set and falls back to parsing the text table when
+    /// JSON is unavailable. Shared config/profile/search/approval overrides flow through via the
+    /// request/builder, stdout/stderr are mirrored according to the builder, and non-zero exits
+    /// surface as [`CodexError::NonZeroExit`].
+    pub async fn list_features(
+        &self,
+        request: FeaturesListRequest,
+    ) -> Result<FeaturesListOutput, CodexError> {
+        let FeaturesListRequest { json, overrides } = request;
+
+        let dir_ctx = self.directory_context()?;
+        let resolved_overrides =
+            resolve_cli_overrides(&self.cli_overrides, &overrides, self.model.as_deref());
+
+        let mut command = Command::new(self.command_env.binary_path());
+        command
+            .arg("features")
+            .arg("list")
+            .stdout(std::process::Stdio::piped())
+            .stderr(std::process::Stdio::piped())
+            .kill_on_drop(true)
+            .current_dir(dir_ctx.path());
+
+        apply_cli_overrides(&mut command, &resolved_overrides, true);
+
+        if json {
+            command.arg("--json");
+        }
+
+        self.command_env.apply(&mut command)?;
+
+        let mut child = spawn_with_retry(&mut command, self.command_env.binary_path())?;
+
+        let stdout = child.stdout.take().ok_or(CodexError::StdoutUnavailable)?;
+        let stderr = child.stderr.take().ok_or(CodexError::StderrUnavailable)?;
+
+        let stdout_task = tokio::spawn(tee_stream(
+            stdout,
+            ConsoleTarget::Stdout,
+            self.mirror_stdout,
+        ));
+        let stderr_task = tokio::spawn(tee_stream(stderr, ConsoleTarget::Stderr, !self.quiet));
+
+        let wait_task = async move {
+            let status = child
+                .wait()
+                .await
+                .map_err(|source| CodexError::Wait { source })?;
+            let stdout_bytes = stdout_task
+                .await
+                .map_err(CodexError::Join)?
+                .map_err(CodexError::CaptureIo)?;
+            let stderr_bytes = stderr_task
+                .await
+                .map_err(CodexError::Join)?
+                .map_err(CodexError::CaptureIo)?;
+            Ok::<_, CodexError>((status, stdout_bytes, stderr_bytes))
+        };
+
+        let (status, stdout_bytes, stderr_bytes) = if self.timeout.is_zero() {
+            wait_task.await?
+        } else {
+            match time::timeout(self.timeout, wait_task).await {
+                Ok(result) => result?,
+                Err(_) => {
+                    return Err(CodexError::Timeout {
+                        timeout: self.timeout,
+                    });
+                }
+            }
+        };
+
+        if !status.success() {
+            return Err(CodexError::NonZeroExit {
+                status,
+                stderr: String::from_utf8(stderr_bytes)?,
+            });
+        }
+
+        let stdout_string = String::from_utf8(stdout_bytes)?;
+        let stderr_string = String::from_utf8(stderr_bytes)?;
+        let (features, format) = crate::version::parse_feature_list_output(&stdout_string, json)
+            .map_err(|reason| CodexError::FeatureListParse {
+                reason,
+                stdout: stdout_string.clone(),
+            })?;
+
+        Ok(FeaturesListOutput {
+            status,
+            stdout: stdout_string,
+            stderr: stderr_string,
+            features,
+            format,
+        })
+    }
+}
diff --git a/crates/codex/src/commands/fork.rs b/crates/codex/src/commands/fork.rs
new file mode 100644
index 0000000..2daddad
--- /dev/null
+++ b/crates/codex/src/commands/fork.rs
@@ -0,0 +1,36 @@
+use std::ffi::OsString;
+
+use crate::{ApplyDiffArtifacts, CodexClient, CodexError, ForkSessionRequest};
+
+impl CodexClient {
+    /// Runs `codex fork [OPTIONS] [SESSION_ID] [PROMPT]` and returns captured output.
+    pub async fn fork_session(
+        &self,
+        request: ForkSessionRequest,
+    ) -> Result<ApplyDiffArtifacts, CodexError> {
+        if matches!(request.prompt.as_deref(), Some(prompt) if prompt.trim().is_empty()) {
+            return Err(CodexError::EmptyPrompt);
+        }
+
+        let mut args = vec![OsString::from("fork")];
+        if request.all {
+            args.push(OsString::from("--all"));
+        }
+        if request.last {
+            args.push(OsString::from("--last"));
+        }
+        if let Some(session_id) = request.session_id {
+            if !session_id.trim().is_empty() {
+                args.push(OsString::from(session_id));
+            }
+        }
+        if let Some(prompt) = request.prompt {
+            if !prompt.trim().is_empty() {
+                args.push(OsString::from(prompt));
+            }
+        }
+
+        self.run_simple_command_with_overrides(args, request.overrides)
+            .await
+    }
+}
diff --git a/crates/codex/src/commands/help.rs b/crates/codex/src/commands/help.rs
new file mode 100644
index 0000000..bcca57f
--- /dev/null
+++ b/crates/codex/src/commands/help.rs
@@ -0,0 +1,21 @@
+use std::ffi::OsString;
+
+use crate::{ApplyDiffArtifacts, CodexClient, CodexError, HelpCommandRequest};
+
+impl CodexClient {
+    /// Runs `codex <scope> help [COMMAND]...` and returns captured output.
+    pub async fn help(
+        &self,
+        request: HelpCommandRequest,
+    ) -> Result<ApplyDiffArtifacts, CodexError> {
+        let mut args: Vec<OsString> = request
+            .scope
+            .argv_prefix()
+            .iter()
+            .map(|value| OsString::from(*value))
+            .collect();
+        args.extend(request.command.into_iter().map(OsString::from));
+        self.run_simple_command_with_overrides(args, request.overrides)
+            .await
+    }
+}
diff --git a/crates/codex/src/commands/mcp.rs b/crates/codex/src/commands/mcp.rs
new file mode 100644
index 0000000..81b9238
--- /dev/null
+++ b/crates/codex/src/commands/mcp.rs
@@ -0,0 +1,220 @@
+use std::ffi::OsString;
+
+use tokio::process::Command;
+
+use crate::{
+    builder::{apply_cli_overrides, resolve_cli_overrides},
+    process::spawn_with_retry,
+    ApplyDiffArtifacts, CodexClient, CodexError, McpAddRequest, McpAddTransport, McpGetRequest,
+    McpListOutput, McpListRequest, McpLogoutRequest, McpOauthLoginRequest, McpOverviewRequest,
+    McpRemoveRequest,
+};
+
+impl CodexClient {
+    /// Runs `codex mcp --help` and returns captured output.
+    pub async fn mcp_overview(
+        &self,
+        request: McpOverviewRequest,
+    ) -> Result<ApplyDiffArtifacts, CodexError> {
+        self.run_simple_command_with_overrides(
+            vec![OsString::from("mcp"), OsString::from("--help")],
+            request.overrides,
+        )
+        .await
+    }
+
+    /// Lists configured MCP servers via `codex mcp list`.
+    pub async fn mcp_list(&self, request: McpListRequest) -> Result<McpListOutput, CodexError> {
+        let McpListRequest { json, overrides } = request;
+        let mut args = vec![OsString::from("mcp"), OsString::from("list")];
+        if json {
+            args.push(OsString::from("--json"));
+        }
+
+        let artifacts = self
+            .run_simple_command_with_overrides(args, overrides)
+            .await?;
+        let parsed = if json {
+            Some(serde_json::from_str(&artifacts.stdout).map_err(|source| {
+                CodexError::JsonParse {
+                    context: "mcp list",
+                    stdout: artifacts.stdout.clone(),
+                    source,
+                }
+            })?)
+        } else {
+            None
+        };
+
+        Ok(McpListOutput {
+            status: artifacts.status,
+            stdout: artifacts.stdout,
+            stderr: artifacts.stderr,
+            json: parsed,
+        })
+    }
+
+    /// Gets a configured MCP server entry via `codex mcp get <NAME>`.
+    pub async fn mcp_get(&self, request: McpGetRequest) -> Result<McpListOutput, CodexError> {
+        let name = request.name.trim();
+        if name.is_empty() {
+            return Err(CodexError::EmptyMcpServerName);
+        }
+
+        let mut args = vec![OsString::from("mcp"), OsString::from("get")];
+        if request.json {
+            args.push(OsString::from("--json"));
+        }
+        args.push(OsString::from(name));
+
+        let artifacts = self
+            .run_simple_command_with_overrides(args, request.overrides)
+            .await?;
+        let parsed = if request.json {
+            Some(serde_json::from_str(&artifacts.stdout).map_err(|source| {
+                CodexError::JsonParse {
+                    context: "mcp get",
+                    stdout: artifacts.stdout.clone(),
+                    source,
+                }
+            })?)
+        } else {
+            None
+        };
+
+        Ok(McpListOutput {
+            status: artifacts.status,
+            stdout: artifacts.stdout,
+            stderr: artifacts.stderr,
+            json: parsed,
+        })
+    }
+
+    /// Adds an MCP server configuration entry via `codex mcp add`.
+    pub async fn mcp_add(&self, request: McpAddRequest) -> Result<ApplyDiffArtifacts, CodexError> {
+        let name = request.name.trim();
+        if name.is_empty() {
+            return Err(CodexError::EmptyMcpServerName);
+        }
+
+        let mut args = vec![
+            OsString::from("mcp"),
+            OsString::from("add"),
+            OsString::from(name),
+        ];
+        match request.transport {
+            McpAddTransport::StreamableHttp {
+                url,
+                bearer_token_env_var,
+            } => {
+                let url = url.trim();
+                if url.is_empty() {
+                    return Err(CodexError::EmptyMcpUrl);
+                }
+                args.push(OsString::from("--url"));
+                args.push(OsString::from(url));
+                if let Some(env_var) = bearer_token_env_var {
+                    if !env_var.trim().is_empty() {
+                        args.push(OsString::from("--bearer-token-env-var"));
+                        args.push(OsString::from(env_var));
+                    }
+                }
+            }
+            McpAddTransport::Stdio { env, command } => {
+                if command.is_empty() {
+                    return Err(CodexError::EmptyMcpCommand);
+                }
+                for (key, value) in env {
+                    let key = key.trim();
+                    if key.is_empty() {
+                        continue;
+                    }
+                    args.push(OsString::from("--env"));
+                    args.push(OsString::from(format!("{key}={value}")));
+                }
+                args.push(OsString::from("--"));
+                args.extend(command);
+            }
+        }
+
+        self.run_simple_command_with_overrides(args, request.overrides)
+            .await
+    }
+
+    /// Removes an MCP server configuration entry via `codex mcp remove <NAME>`.
+    pub async fn mcp_remove(
+        &self,
+        request: McpRemoveRequest,
+    ) -> Result<ApplyDiffArtifacts, CodexError> {
+        let name = request.name.trim();
+        if name.is_empty() {
+            return Err(CodexError::EmptyMcpServerName);
+        }
+
+        self.run_simple_command_with_overrides(
+            vec![
+                OsString::from("mcp"),
+                OsString::from("remove"),
+                OsString::from(name),
+            ],
+            request.overrides,
+        )
+        .await
+    }
+
+    /// Deauthenticates from an MCP server via `codex mcp logout <NAME>`.
+    pub async fn mcp_logout(
+        &self,
+        request: McpLogoutRequest,
+    ) -> Result<ApplyDiffArtifacts, CodexError> {
+        let name = request.name.trim();
+        if name.is_empty() {
+            return Err(CodexError::EmptyMcpServerName);
+        }
+
+        self.run_simple_command_with_overrides(
+            vec![
+                OsString::from("mcp"),
+                OsString::from("logout"),
+                OsString::from(name),
+            ],
+            request.overrides,
+        )
+        .await
+    }
+
+    /// Spawns `codex mcp login <NAME> [--scopes ...]`.
+    pub fn spawn_mcp_oauth_login_process(
+        &self,
+        request: McpOauthLoginRequest,
+    ) -> Result<tokio::process::Child, CodexError> {
+        let name = request.name.trim();
+        if name.is_empty() {
+            return Err(CodexError::EmptyMcpServerName);
+        }
+
+        let resolved_overrides = resolve_cli_overrides(
+            &self.cli_overrides,
+            &request.overrides,
+            self.model.as_deref(),
+        );
+
+        let mut command = Command::new(self.command_env.binary_path());
+        command
+            .arg("mcp")
+            .arg("login")
+            .arg(name)
+            .stdout(std::process::Stdio::piped())
+            .stderr(std::process::Stdio::piped())
+            .kill_on_drop(true);
+
+        if !request.scopes.is_empty() {
+            command.arg("--scopes").arg(request.scopes.join(","));
+        }
+
+        apply_cli_overrides(&mut command, &resolved_overrides, true);
+        self.command_env.apply(&mut command)?;
+
+        spawn_with_retry(&mut command, self.command_env.binary_path())
+    }
+}
diff --git a/crates/codex/src/commands/mod.rs b/crates/codex/src/commands/mod.rs
new file mode 100644
index 0000000..bd9d738
--- /dev/null
+++ b/crates/codex/src/commands/mod.rs
@@ -0,0 +1,10 @@
+mod app_server;
+mod apply_diff;
+mod cloud;
+mod features;
+mod fork;
+mod help;
+mod mcp;
+mod proxy;
+mod review;
+mod sandbox;
diff --git a/crates/codex/src/commands/proxy.rs b/crates/codex/src/commands/proxy.rs
new file mode 100644
index 0000000..478fe11
--- /dev/null
+++ b/crates/codex/src/commands/proxy.rs
@@ -0,0 +1,80 @@
+use tokio::{io::AsyncWriteExt, process::Command};
+
+use crate::{
+    process::spawn_with_retry, CodexClient, CodexError, ResponsesApiProxyHandle,
+    ResponsesApiProxyRequest,
+};
+
+impl CodexClient {
+    /// Starts the `codex responses-api-proxy` helper with a supplied API key.
+    ///
+    /// Forwards optional `--port`, `--server-info`, `--http-shutdown`, and `--upstream-url` flags.
+    /// The API key is written to stdin immediately after spawn, stdout/stderr remain piped for callers
+    /// to drain, and the returned handle owns the child process plus any `--server-info` path used.
+    pub async fn start_responses_api_proxy(
+        &self,
+        request: ResponsesApiProxyRequest,
+    ) -> Result<ResponsesApiProxyHandle, CodexError> {
+        let ResponsesApiProxyRequest {
+            api_key,
+            port,
+            server_info_path,
+            http_shutdown,
+            upstream_url,
+        } = request;
+
+        let api_key = api_key.trim().to_string();
+        if api_key.is_empty() {
+            return Err(CodexError::EmptyApiKey);
+        }
+
+        let working_dir = self.sandbox_working_dir(None)?;
+
+        let mut command = Command::new(self.command_env.binary_path());
+        command
+            .arg("responses-api-proxy")
+            .stdin(std::process::Stdio::piped())
+            .stdout(std::process::Stdio::piped())
+            .stderr(std::process::Stdio::piped())
+            .kill_on_drop(true)
+            .current_dir(&working_dir);
+
+        if let Some(port) = port {
+            command.arg("--port").arg(port.to_string());
+        }
+
+        if let Some(path) = server_info_path.as_ref() {
+            command.arg("--server-info").arg(path);
+        }
+
+        if http_shutdown {
+            command.arg("--http-shutdown");
+        }
+
+        if let Some(url) = upstream_url.as_ref() {
+            if !url.trim().is_empty() {
+                command.arg("--upstream-url").arg(url);
+            }
+        }
+
+        self.command_env.apply(&mut command)?;
+
+        let mut child = spawn_with_retry(&mut command, self.command_env.binary_path())?;
+
+        let mut stdin = child.stdin.take().ok_or(CodexError::StdinUnavailable)?;
+        stdin
+            .write_all(api_key.as_bytes())
+            .await
+            .map_err(CodexError::StdinWrite)?;
+        stdin
+            .write_all(b"\n")
+            .await
+            .map_err(CodexError::StdinWrite)?;
+        stdin.shutdown().await.map_err(CodexError::StdinWrite)?;
+
+        Ok(ResponsesApiProxyHandle {
+            child,
+            server_info_path,
+        })
+    }
+}
diff --git a/crates/codex/src/commands/review.rs b/crates/codex/src/commands/review.rs
new file mode 100644
index 0000000..2602c27
--- /dev/null
+++ b/crates/codex/src/commands/review.rs
@@ -0,0 +1,95 @@
+use std::ffi::OsString;
+
+use crate::{
+    ApplyDiffArtifacts, CodexClient, CodexError, ExecReviewCommandRequest, ReviewCommandRequest,
+};
+
+impl CodexClient {
+    /// Runs `codex review [OPTIONS] [PROMPT]` and returns captured output.
+    pub async fn review(
+        &self,
+        request: ReviewCommandRequest,
+    ) -> Result<ApplyDiffArtifacts, CodexError> {
+        if matches!(request.prompt.as_deref(), Some(prompt) if prompt.trim().is_empty()) {
+            return Err(CodexError::EmptyPrompt);
+        }
+
+        let mut args = vec![OsString::from("review")];
+        if let Some(base) = request.base {
+            if !base.trim().is_empty() {
+                args.push(OsString::from("--base"));
+                args.push(OsString::from(base));
+            }
+        }
+        if let Some(commit) = request.commit {
+            if !commit.trim().is_empty() {
+                args.push(OsString::from("--commit"));
+                args.push(OsString::from(commit));
+            }
+        }
+        if let Some(title) = request.title {
+            if !title.trim().is_empty() {
+                args.push(OsString::from("--title"));
+                args.push(OsString::from(title));
+            }
+        }
+        if request.uncommitted {
+            args.push(OsString::from("--uncommitted"));
+        }
+        if let Some(prompt) = request.prompt {
+            if !prompt.trim().is_empty() {
+                args.push(OsString::from(prompt));
+            }
+        }
+
+        self.run_simple_command_with_overrides(args, request.overrides)
+            .await
+    }
+
+    /// Runs `codex exec review [OPTIONS] [PROMPT]` and returns captured output.
+    pub async fn exec_review(
+        &self,
+        request: ExecReviewCommandRequest,
+    ) -> Result<ApplyDiffArtifacts, CodexError> {
+        if matches!(request.prompt.as_deref(), Some(prompt) if prompt.trim().is_empty()) {
+            return Err(CodexError::EmptyPrompt);
+        }
+
+        let mut args = vec![OsString::from("exec"), OsString::from("review")];
+        if let Some(base) = request.base {
+            if !base.trim().is_empty() {
+                args.push(OsString::from("--base"));
+                args.push(OsString::from(base));
+            }
+        }
+        if let Some(commit) = request.commit {
+            if !commit.trim().is_empty() {
+                args.push(OsString::from("--commit"));
+                args.push(OsString::from(commit));
+            }
+        }
+        if request.json {
+            args.push(OsString::from("--json"));
+        }
+        if request.skip_git_repo_check {
+            args.push(OsString::from("--skip-git-repo-check"));
+        }
+        if let Some(title) = request.title {
+            if !title.trim().is_empty() {
+                args.push(OsString::from("--title"));
+                args.push(OsString::from(title));
+            }
+        }
+        if request.uncommitted {
+            args.push(OsString::from("--uncommitted"));
+        }
+        if let Some(prompt) = request.prompt {
+            if !prompt.trim().is_empty() {
+                args.push(OsString::from(prompt));
+            }
+        }
+
+        self.run_simple_command_with_overrides(args, request.overrides)
+            .await
+    }
+}
diff --git a/crates/codex/src/commands/sandbox.rs b/crates/codex/src/commands/sandbox.rs
new file mode 100644
index 0000000..c1a9dd9
--- /dev/null
+++ b/crates/codex/src/commands/sandbox.rs
@@ -0,0 +1,154 @@
+use tokio::{process::Command, time};
+
+use crate::{
+    process::{spawn_with_retry, tee_stream, ConsoleTarget},
+    CodexClient, CodexError, SandboxCommandRequest, SandboxPlatform, SandboxRun, StdioToUdsRequest,
+};
+
+impl CodexClient {
+    /// Spawns `codex stdio-to-uds <SOCKET_PATH>` with piped stdio for manual relays.
+    ///
+    /// Returns the child process so callers can write to stdin/read from stdout (e.g., to bridge a
+    /// JSON-RPC transport over a Unix domain socket). Fails fast on empty socket paths and inherits
+    /// the builder working directory when none is provided on the request.
+    pub fn stdio_to_uds(
+        &self,
+        request: StdioToUdsRequest,
+    ) -> Result<tokio::process::Child, CodexError> {
+        let StdioToUdsRequest {
+            socket_path,
+            working_dir,
+        } = request;
+
+        if socket_path.as_os_str().is_empty() {
+            return Err(CodexError::EmptySocketPath);
+        }
+
+        let mut command = Command::new(self.command_env.binary_path());
+        command
+            .arg("stdio-to-uds")
+            .arg(&socket_path)
+            .stdin(std::process::Stdio::piped())
+            .stdout(std::process::Stdio::piped())
+            .stderr(std::process::Stdio::piped())
+            .kill_on_drop(true)
+            .current_dir(self.sandbox_working_dir(working_dir)?);
+
+        self.command_env.apply(&mut command)?;
+
+        spawn_with_retry(&mut command, self.command_env.binary_path())
+    }
+
+    /// Runs `codex sandbox <platform> [--full-auto|--log-denials] [--config/--enable/--disable] -- <COMMAND...>`.
+    ///
+    /// Captures stdout/stderr and mirrors them according to the builder (`mirror_stdout` / `quiet`). Unlike
+    /// `apply`/`diff`, non-zero exit codes are returned in [`SandboxRun::status`] without being wrapped in
+    /// [`CodexError::NonZeroExit`]. macOS denial logging is enabled via [`SandboxCommandRequest::log_denials`]
+    /// and ignored on other platforms. Linux uses the bundled `codex-linux-sandbox` helper; Windows sandboxing
+    /// is experimental and relies on the upstream helper. The wrapper does not gate availabilityunsupported
+    /// installs will surface as non-zero statuses.
+    pub async fn run_sandbox(
+        &self,
+        request: SandboxCommandRequest,
+    ) -> Result<SandboxRun, CodexError> {
+        if request.command.is_empty() {
+            return Err(CodexError::EmptySandboxCommand);
+        }
+
+        let SandboxCommandRequest {
+            platform,
+            command,
+            full_auto,
+            log_denials,
+            config_overrides,
+            feature_toggles,
+            working_dir,
+        } = request;
+
+        let working_dir = self.sandbox_working_dir(working_dir)?;
+
+        let mut process = Command::new(self.command_env.binary_path());
+        process
+            .arg("sandbox")
+            .arg(platform.subcommand())
+            .stdout(std::process::Stdio::piped())
+            .stderr(std::process::Stdio::piped())
+            .kill_on_drop(true)
+            .current_dir(&working_dir);
+
+        if full_auto {
+            process.arg("--full-auto");
+        }
+
+        if log_denials && matches!(platform, SandboxPlatform::Macos) {
+            process.arg("--log-denials");
+        }
+
+        for override_ in config_overrides {
+            process.arg("--config");
+            process.arg(format!("{}={}", override_.key, override_.value));
+        }
+
+        for feature in feature_toggles.enable {
+            process.arg("--enable");
+            process.arg(feature);
+        }
+
+        for feature in feature_toggles.disable {
+            process.arg("--disable");
+            process.arg(feature);
+        }
+
+        process.arg("--");
+        process.args(&command);
+
+        self.command_env.apply(&mut process)?;
+
+        let mut child = spawn_with_retry(&mut process, self.command_env.binary_path())?;
+
+        let stdout = child.stdout.take().ok_or(CodexError::StdoutUnavailable)?;
+        let stderr = child.stderr.take().ok_or(CodexError::StderrUnavailable)?;
+
+        let stdout_task = tokio::spawn(tee_stream(
+            stdout,
+            ConsoleTarget::Stdout,
+            self.mirror_stdout,
+        ));
+        let stderr_task = tokio::spawn(tee_stream(stderr, ConsoleTarget::Stderr, !self.quiet));
+
+        let wait_task = async move {
+            let status = child
+                .wait()
+                .await
+                .map_err(|source| CodexError::Wait { source })?;
+            let stdout_bytes = stdout_task
+                .await
+                .map_err(CodexError::Join)?
+                .map_err(CodexError::CaptureIo)?;
+            let stderr_bytes = stderr_task
+                .await
+                .map_err(CodexError::Join)?
+                .map_err(CodexError::CaptureIo)?;
+            Ok::<_, CodexError>((status, stdout_bytes, stderr_bytes))
+        };
+
+        let (status, stdout_bytes, stderr_bytes) = if self.timeout.is_zero() {
+            wait_task.await?
+        } else {
+            match time::timeout(self.timeout, wait_task).await {
+                Ok(result) => result?,
+                Err(_) => {
+                    return Err(CodexError::Timeout {
+                        timeout: self.timeout,
+                    });
+                }
+            }
+        };
+
+        Ok(SandboxRun {
+            status,
+            stdout: String::from_utf8(stdout_bytes)?,
+            stderr: String::from_utf8(stderr_bytes)?,
+        })
+    }
+}
diff --git a/crates/codex/src/defaults.rs b/crates/codex/src/defaults.rs
new file mode 100644
index 0000000..97d0580
--- /dev/null
+++ b/crates/codex/src/defaults.rs
@@ -0,0 +1,19 @@
+use std::{env, path::PathBuf, time::Duration};
+
+pub(crate) const DEFAULT_TIMEOUT: Duration = Duration::from_secs(120);
+pub(crate) const CODEX_BINARY_ENV: &str = "CODEX_BINARY";
+pub(crate) const CODEX_HOME_ENV: &str = "CODEX_HOME";
+pub(crate) const RUST_LOG_ENV: &str = "RUST_LOG";
+pub(crate) const DEFAULT_RUST_LOG: &str = "error";
+
+pub(crate) fn default_rust_log_value() -> Option<&'static str> {
+    env::var_os(RUST_LOG_ENV)
+        .is_none()
+        .then_some(DEFAULT_RUST_LOG)
+}
+
+pub(crate) fn default_binary_path() -> PathBuf {
+    env::var_os(CODEX_BINARY_ENV)
+        .map(PathBuf::from)
+        .unwrap_or_else(|| PathBuf::from("codex"))
+}
diff --git a/crates/codex/src/error.rs b/crates/codex/src/error.rs
new file mode 100644
index 0000000..09f2dce
--- /dev/null
+++ b/crates/codex/src/error.rs
@@ -0,0 +1,103 @@
+use std::{path::PathBuf, process::ExitStatus, time::Duration};
+
+use thiserror::Error;
+
+/// Errors that may occur while invoking the Codex CLI.
+#[derive(Debug, Error)]
+pub enum CodexError {
+    #[error("codex binary `{binary}` could not be spawned: {source}")]
+    Spawn {
+        binary: PathBuf,
+        #[source]
+        source: std::io::Error,
+    },
+    #[error("failed to wait for codex process: {source}")]
+    Wait {
+        #[source]
+        source: std::io::Error,
+    },
+    #[error("codex exceeded timeout of {timeout:?}")]
+    Timeout { timeout: Duration },
+    #[error("codex exited with {status:?}: {stderr}")]
+    NonZeroExit { status: ExitStatus, stderr: String },
+    #[error("codex output was not valid UTF-8: {0}")]
+    InvalidUtf8(#[from] std::string::FromUtf8Error),
+    #[error("failed to parse {context} JSON output: {source}")]
+    JsonParse {
+        context: &'static str,
+        stdout: String,
+        #[source]
+        source: serde_json::Error,
+    },
+    #[error("failed to parse execpolicy JSON output: {source}")]
+    ExecPolicyParse {
+        stdout: String,
+        #[source]
+        source: serde_json::Error,
+    },
+    #[error("failed to parse features list output: {reason}")]
+    FeatureListParse { reason: String, stdout: String },
+    #[error("failed to read responses-api-proxy server info from `{path}`: {source}")]
+    ResponsesApiProxyInfoRead {
+        path: PathBuf,
+        #[source]
+        source: std::io::Error,
+    },
+    #[error("failed to parse responses-api-proxy server info from `{path}`: {source}")]
+    ResponsesApiProxyInfoParse {
+        path: PathBuf,
+        #[source]
+        source: serde_json::Error,
+    },
+    #[error("prompt must not be empty")]
+    EmptyPrompt,
+    #[error("sandbox command must not be empty")]
+    EmptySandboxCommand,
+    #[error("execpolicy command must not be empty")]
+    EmptyExecPolicyCommand,
+    #[error("API key must not be empty")]
+    EmptyApiKey,
+    #[error("task id must not be empty")]
+    EmptyTaskId,
+    #[error("environment id must not be empty")]
+    EmptyEnvId,
+    #[error("MCP server name must not be empty")]
+    EmptyMcpServerName,
+    #[error("MCP server command must not be empty")]
+    EmptyMcpCommand,
+    #[error("MCP server URL must not be empty")]
+    EmptyMcpUrl,
+    #[error("socket path must not be empty")]
+    EmptySocketPath,
+    #[error("failed to create temporary working directory: {0}")]
+    TempDir(#[source] std::io::Error),
+    #[error("failed to resolve working directory: {source}")]
+    WorkingDirectory {
+        #[source]
+        source: std::io::Error,
+    },
+    #[error("failed to prepare app-server output directory `{path}`: {source}")]
+    PrepareOutputDirectory {
+        path: PathBuf,
+        #[source]
+        source: std::io::Error,
+    },
+    #[error("failed to prepare CODEX_HOME at `{path}`: {source}")]
+    PrepareCodexHome {
+        path: PathBuf,
+        #[source]
+        source: std::io::Error,
+    },
+    #[error("codex stdout unavailable")]
+    StdoutUnavailable,
+    #[error("codex stderr unavailable")]
+    StderrUnavailable,
+    #[error("codex stdin unavailable")]
+    StdinUnavailable,
+    #[error("failed to capture codex output: {0}")]
+    CaptureIo(#[from] std::io::Error),
+    #[error("failed to write prompt to codex stdin: {0}")]
+    StdinWrite(#[source] std::io::Error),
+    #[error("failed to join codex output task: {0}")]
+    Join(#[from] tokio::task::JoinError),
+}
diff --git a/crates/codex/src/events.rs b/crates/codex/src/events.rs
new file mode 100644
index 0000000..4c6f08c
--- /dev/null
+++ b/crates/codex/src/events.rs
@@ -0,0 +1,414 @@
+use serde::{Deserialize, Serialize};
+use serde_json::Value;
+use std::collections::BTreeMap;
+use std::path::PathBuf;
+
+/// Single JSONL event emitted by `codex exec --json`.
+///
+/// Each line on stdout maps to a [`ThreadEvent`] with lifecycle edges:
+/// - `thread.started` is emitted once per invocation.
+/// - `turn.started` begins the turn associated with the provided prompt.
+/// - one or more `item.*` events stream output and tool activity.
+/// - `turn.completed` or `turn.failed` closes the stream; `error` captures transport-level failures.
+///
+/// Item variants mirror the upstream `item_type` field: `agent_message`, `reasoning`,
+/// `command_execution`, `file_change`, `mcp_tool_call`, `web_search`, `todo_list`, and `error`.
+/// Unknown or future fields are preserved in `extra` maps to keep the parser forward-compatible.
+#[derive(Clone, Debug, Deserialize, Serialize)]
+#[serde(tag = "type")]
+pub enum ThreadEvent {
+    #[serde(rename = "thread.started", alias = "thread.resumed")]
+    ThreadStarted(ThreadStarted),
+    #[serde(rename = "turn.started")]
+    TurnStarted(TurnStarted),
+    #[serde(rename = "turn.completed")]
+    TurnCompleted(TurnCompleted),
+    #[serde(rename = "turn.failed")]
+    TurnFailed(TurnFailed),
+    #[serde(rename = "item.started", alias = "item.created")]
+    ItemStarted(ItemEnvelope<ItemSnapshot>),
+    #[serde(rename = "item.delta", alias = "item.updated")]
+    ItemDelta(ItemDelta),
+    #[serde(rename = "item.completed")]
+    ItemCompleted(ItemEnvelope<ItemSnapshot>),
+    #[serde(rename = "item.failed")]
+    ItemFailed(ItemEnvelope<ItemFailure>),
+    #[serde(rename = "error")]
+    Error(EventError),
+}
+
+/// Marks the start of a new thread.
+#[derive(Clone, Debug, Deserialize, Serialize)]
+pub struct ThreadStarted {
+    pub thread_id: String,
+    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
+    pub extra: BTreeMap<String, Value>,
+}
+
+/// Indicates the CLI accepted a new turn within a thread.
+#[derive(Clone, Debug, Deserialize, Serialize)]
+pub struct TurnStarted {
+    pub thread_id: String,
+    pub turn_id: String,
+    /// Original input text when upstream echoes it; may be omitted for security reasons.
+    #[serde(default, skip_serializing_if = "Option::is_none")]
+    pub input_text: Option<String>,
+    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
+    pub extra: BTreeMap<String, Value>,
+}
+
+/// Reports a completed turn.
+#[derive(Clone, Debug, Deserialize, Serialize)]
+pub struct TurnCompleted {
+    pub thread_id: String,
+    pub turn_id: String,
+    /// Identifier of the last output item when provided by the CLI.
+    #[serde(default, skip_serializing_if = "Option::is_none")]
+    pub last_item_id: Option<String>,
+    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
+    pub extra: BTreeMap<String, Value>,
+}
+
+/// Indicates a turn-level failure.
+#[derive(Clone, Debug, Deserialize, Serialize)]
+pub struct TurnFailed {
+    pub thread_id: String,
+    pub turn_id: String,
+    pub error: EventError,
+    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
+    pub extra: BTreeMap<String, Value>,
+}
+
+/// Shared wrapper for item events that always include thread/turn context.
+#[derive(Clone, Debug, Deserialize, Serialize)]
+pub struct ItemEnvelope<T> {
+    pub thread_id: String,
+    pub turn_id: String,
+    #[serde(flatten)]
+    pub item: T,
+}
+
+/// Snapshot of an item at start/completion time.
+#[derive(Clone, Debug, Deserialize, Serialize)]
+pub struct ItemSnapshot {
+    #[serde(rename = "item_id", alias = "id")]
+    pub item_id: String,
+    #[serde(default, skip_serializing_if = "Option::is_none")]
+    pub index: Option<u32>,
+    #[serde(default)]
+    pub status: ItemStatus,
+    #[serde(flatten)]
+    pub payload: ItemPayload,
+    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
+    pub extra: BTreeMap<String, Value>,
+}
+
+/// Streaming delta describing the next piece of an item.
+#[derive(Clone, Debug, Deserialize, Serialize)]
+pub struct ItemDelta {
+    pub thread_id: String,
+    pub turn_id: String,
+    #[serde(rename = "item_id", alias = "id")]
+    pub item_id: String,
+    #[serde(default, skip_serializing_if = "Option::is_none")]
+    pub index: Option<u32>,
+    #[serde(flatten)]
+    pub delta: ItemDeltaPayload,
+    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
+    pub extra: BTreeMap<String, Value>,
+}
+
+/// Terminal item failure event.
+#[derive(Clone, Debug, Deserialize, Serialize)]
+pub struct ItemFailure {
+    #[serde(rename = "item_id", alias = "id")]
+    pub item_id: String,
+    #[serde(default, skip_serializing_if = "Option::is_none")]
+    pub index: Option<u32>,
+    pub error: EventError,
+    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
+    pub extra: BTreeMap<String, Value>,
+}
+
+/// Fully-typed item payload for start/completed events.
+#[derive(Clone, Debug, Deserialize, Serialize)]
+#[serde(tag = "item_type", content = "content", rename_all = "snake_case")]
+pub enum ItemPayload {
+    AgentMessage(TextContent),
+    Reasoning(TextContent),
+    CommandExecution(CommandExecutionState),
+    FileChange(FileChangeState),
+    McpToolCall(McpToolCallState),
+    WebSearch(WebSearchState),
+    TodoList(TodoListState),
+    Error(EventError),
+}
+
+/// Delta form of an item payload. Each delta should be applied in order to reconstruct the item.
+#[derive(Clone, Debug, Deserialize, Serialize)]
+#[serde(tag = "item_type", content = "delta", rename_all = "snake_case")]
+pub enum ItemDeltaPayload {
+    AgentMessage(TextDelta),
+    Reasoning(TextDelta),
+    CommandExecution(CommandExecutionDelta),
+    FileChange(FileChangeDelta),
+    McpToolCall(McpToolCallDelta),
+    WebSearch(WebSearchDelta),
+    TodoList(TodoListDelta),
+    Error(EventError),
+}
+
+/// Item status supplied by the CLI for bookkeeping.
+#[derive(Clone, Debug, Default, Deserialize, Serialize, Eq, PartialEq)]
+#[serde(rename_all = "snake_case")]
+pub enum ItemStatus {
+    #[default]
+    InProgress,
+    Completed,
+    Failed,
+    #[serde(other)]
+    Unknown,
+}
+
+/// Human-readable content emitted by the agent.
+#[derive(Clone, Debug, Deserialize, Serialize)]
+pub struct TextContent {
+    pub text: String,
+    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
+    pub extra: BTreeMap<String, Value>,
+}
+
+/// Incremental content fragment for streaming items.
+#[derive(Clone, Debug, Deserialize, Serialize)]
+pub struct TextDelta {
+    #[serde(rename = "text_delta", alias = "text")]
+    pub text_delta: String,
+    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
+    pub extra: BTreeMap<String, Value>,
+}
+
+/// Snapshot of a command execution, including accumulated stdout/stderr.
+#[derive(Clone, Debug, Deserialize, Serialize)]
+pub struct CommandExecutionState {
+    pub command: String,
+    #[serde(default, skip_serializing_if = "Option::is_none")]
+    pub exit_code: Option<i32>,
+    #[serde(
+        default,
+        skip_serializing_if = "String::is_empty",
+        alias = "aggregated_output",
+        alias = "output"
+    )]
+    pub stdout: String,
+    #[serde(
+        default,
+        skip_serializing_if = "String::is_empty",
+        alias = "error_output",
+        alias = "err"
+    )]
+    pub stderr: String,
+    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
+    pub extra: BTreeMap<String, Value>,
+}
+
+/// Streaming delta for command execution.
+#[derive(Clone, Debug, Deserialize, Serialize)]
+pub struct CommandExecutionDelta {
+    #[serde(
+        default,
+        skip_serializing_if = "String::is_empty",
+        alias = "aggregated_output",
+        alias = "output"
+    )]
+    pub stdout: String,
+    #[serde(
+        default,
+        skip_serializing_if = "String::is_empty",
+        alias = "error_output",
+        alias = "err"
+    )]
+    pub stderr: String,
+    #[serde(default, skip_serializing_if = "Option::is_none")]
+    pub exit_code: Option<i32>,
+    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
+    pub extra: BTreeMap<String, Value>,
+}
+
+/// File change or diff applied by the agent.
+#[derive(Clone, Debug, Deserialize, Serialize)]
+pub struct FileChangeState {
+    #[serde(alias = "file_path")]
+    pub path: PathBuf,
+    #[serde(default, skip_serializing_if = "Option::is_none")]
+    pub change: Option<FileChangeKind>,
+    #[serde(default, skip_serializing_if = "Option::is_none", alias = "patch")]
+    pub diff: Option<String>,
+    #[serde(default, skip_serializing_if = "Option::is_none")]
+    pub exit_code: Option<i32>,
+    #[serde(
+        default,
+        skip_serializing_if = "String::is_empty",
+        alias = "aggregated_output",
+        alias = "output"
+    )]
+    pub stdout: String,
+    #[serde(
+        default,
+        skip_serializing_if = "String::is_empty",
+        alias = "error_output",
+        alias = "err"
+    )]
+    pub stderr: String,
+    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
+    pub extra: BTreeMap<String, Value>,
+}
+
+/// Streaming delta describing a file change.
+#[derive(Clone, Debug, Deserialize, Serialize)]
+pub struct FileChangeDelta {
+    #[serde(default, skip_serializing_if = "Option::is_none", alias = "patch")]
+    pub diff: Option<String>,
+    #[serde(
+        default,
+        skip_serializing_if = "String::is_empty",
+        alias = "aggregated_output",
+        alias = "output"
+    )]
+    pub stdout: String,
+    #[serde(
+        default,
+        skip_serializing_if = "String::is_empty",
+        alias = "error_output",
+        alias = "err"
+    )]
+    pub stderr: String,
+    #[serde(default, skip_serializing_if = "Option::is_none")]
+    pub exit_code: Option<i32>,
+    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
+    pub extra: BTreeMap<String, Value>,
+}
+
+/// Type of file operation being reported.
+#[derive(Clone, Copy, Debug, Deserialize, Serialize, Eq, PartialEq)]
+#[serde(rename_all = "snake_case")]
+pub enum FileChangeKind {
+    Apply,
+    Diff,
+    #[serde(other)]
+    Unknown,
+}
+
+/// State of an MCP tool call.
+#[derive(Clone, Debug, Deserialize, Serialize)]
+pub struct McpToolCallState {
+    #[serde(alias = "server")]
+    pub server_name: String,
+    #[serde(alias = "tool")]
+    pub tool_name: String,
+    #[serde(default, skip_serializing_if = "Option::is_none")]
+    pub arguments: Option<Value>,
+    #[serde(default, skip_serializing_if = "Option::is_none")]
+    pub result: Option<Value>,
+    #[serde(default)]
+    pub status: ToolCallStatus,
+    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
+    pub extra: BTreeMap<String, Value>,
+}
+
+/// Streaming delta for MCP tool call output.
+#[derive(Clone, Debug, Deserialize, Serialize)]
+pub struct McpToolCallDelta {
+    #[serde(default, skip_serializing_if = "Option::is_none")]
+    pub result: Option<Value>,
+    #[serde(default)]
+    pub status: ToolCallStatus,
+    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
+    pub extra: BTreeMap<String, Value>,
+}
+
+/// Lifecycle state for a tool call.
+#[derive(Clone, Debug, Default, Deserialize, Serialize, Eq, PartialEq)]
+#[serde(rename_all = "snake_case")]
+pub enum ToolCallStatus {
+    #[default]
+    Pending,
+    Running,
+    Completed,
+    Failed,
+    #[serde(other)]
+    Unknown,
+}
+
+/// Details of a web search step.
+#[derive(Clone, Debug, Deserialize, Serialize)]
+pub struct WebSearchState {
+    pub query: String,
+    #[serde(default, skip_serializing_if = "Option::is_none")]
+    pub results: Option<Value>,
+    #[serde(default)]
+    pub status: WebSearchStatus,
+    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
+    pub extra: BTreeMap<String, Value>,
+}
+
+/// Streaming delta for search results.
+#[derive(Clone, Debug, Deserialize, Serialize)]
+pub struct WebSearchDelta {
+    #[serde(default, skip_serializing_if = "Option::is_none")]
+    pub results: Option<Value>,
+    #[serde(default)]
+    pub status: WebSearchStatus,
+    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
+    pub extra: BTreeMap<String, Value>,
+}
+
+/// Search progress indicator.
+#[derive(Clone, Debug, Default, Deserialize, Serialize, Eq, PartialEq)]
+#[serde(rename_all = "snake_case")]
+pub enum WebSearchStatus {
+    #[default]
+    Pending,
+    Running,
+    Completed,
+    Failed,
+    #[serde(other)]
+    Unknown,
+}
+
+/// Checklist maintained by the agent.
+#[derive(Clone, Debug, Deserialize, Serialize)]
+pub struct TodoListState {
+    #[serde(default, skip_serializing_if = "Vec::is_empty")]
+    pub items: Vec<TodoItem>,
+    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
+    pub extra: BTreeMap<String, Value>,
+}
+
+/// Streaming delta for todo list mutations.
+#[derive(Clone, Debug, Deserialize, Serialize)]
+pub struct TodoListDelta {
+    #[serde(default, skip_serializing_if = "Vec::is_empty")]
+    pub items: Vec<TodoItem>,
+    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
+    pub extra: BTreeMap<String, Value>,
+}
+
+/// Single todo item.
+#[derive(Clone, Debug, Deserialize, Serialize)]
+pub struct TodoItem {
+    pub title: String,
+    #[serde(default)]
+    pub completed: bool,
+    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
+    pub extra: BTreeMap<String, Value>,
+}
+
+/// Error payload shared by turn/item failures.
+#[derive(Clone, Debug, Deserialize, Serialize)]
+pub struct EventError {
+    pub message: String,
+    #[serde(default, skip_serializing_if = "Option::is_none")]
+    pub code: Option<String>,
+    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
+    pub extra: BTreeMap<String, Value>,
+}
diff --git a/crates/codex/src/exec.rs b/crates/codex/src/exec.rs
new file mode 100644
index 0000000..bf520c0
--- /dev/null
+++ b/crates/codex/src/exec.rs
@@ -0,0 +1,817 @@
+use std::{
+    env,
+    ffi::OsString,
+    future::Future,
+    path::{Path, PathBuf},
+    pin::Pin,
+    process::ExitStatus,
+    time::{Duration, SystemTime, UNIX_EPOCH},
+};
+
+use futures_core::Stream;
+use thiserror::Error;
+use tokio::{fs, io::AsyncWriteExt, process::Command, sync::mpsc, time};
+use tracing::debug;
+
+use crate::{
+    builder::{apply_cli_overrides, resolve_cli_overrides},
+    capabilities::{guard_is_supported, log_guard_skip},
+    jsonl,
+    process::{spawn_with_retry, tee_stream, ConsoleTarget},
+    ApplyDiffArtifacts, CliOverridesPatch, CodexClient, CodexError, ConfigOverride, ExecRequest,
+    FlagState, ResumeSessionRequest, ThreadEvent,
+};
+
+impl CodexClient {
+    /// Sends `prompt` to `codex exec` and returns its stdout (the final agent message) on success.
+    ///
+    /// When `.json(true)` is enabled the CLI emits JSONL events (`thread.started` or
+    /// `thread.resumed`, `turn.started`/`turn.completed`/`turn.failed`,
+    /// `item.created`/`item.updated`, or `error`). The stream is mirrored to stdout unless
+    /// `.mirror_stdout(false)`; the returned string contains the buffered lines for offline
+    /// parsing. For per-event handling, see `crates/codex/examples/stream_events.rs`.
+    ///
+    /// ```rust,no_run
+    /// use codex::CodexClient;
+    /// # #[tokio::main]
+    /// # async fn main() -> Result<(), Box<dyn std::error::Error>> {
+    /// let client = CodexClient::builder().json(true).mirror_stdout(false).build();
+    /// let jsonl = client.send_prompt("Stream repo status").await?;
+    /// println!("{jsonl}");
+    /// # Ok(()) }
+    /// ```
+    pub async fn send_prompt(&self, prompt: impl AsRef<str>) -> Result<String, CodexError> {
+        self.send_prompt_with(ExecRequest::new(prompt.as_ref()))
+            .await
+    }
+
+    /// Sends an exec request with per-call CLI overrides.
+    pub async fn send_prompt_with(&self, request: ExecRequest) -> Result<String, CodexError> {
+        if request.prompt.trim().is_empty() {
+            return Err(CodexError::EmptyPrompt);
+        }
+
+        self.invoke_codex_exec(request).await
+    }
+
+    /// Streams structured JSONL events from `codex exec --json`.
+    ///
+    /// Respects `mirror_stdout` (raw JSON echoing) and tees raw lines to `json_event_log` when
+    /// configured on the builder or request. Returns an [`ExecStream`] with both the parsed event
+    /// stream and a completion future that reports `--output-last-message`/schema paths.
+    pub async fn stream_exec(
+        &self,
+        request: ExecStreamRequest,
+    ) -> Result<ExecStream, ExecStreamError> {
+        self.stream_exec_with_overrides(request, CliOverridesPatch::default())
+            .await
+    }
+
+    /// Streams JSONL events with per-request CLI overrides.
+    pub async fn stream_exec_with_overrides(
+        &self,
+        request: ExecStreamRequest,
+        overrides: CliOverridesPatch,
+    ) -> Result<ExecStream, ExecStreamError> {
+        if request.prompt.trim().is_empty() {
+            return Err(CodexError::EmptyPrompt.into());
+        }
+
+        let ExecStreamRequest {
+            prompt,
+            idle_timeout,
+            output_last_message,
+            output_schema,
+            json_event_log,
+        } = request;
+
+        let dir_ctx = self.directory_context()?;
+        let dir_path = dir_ctx.path().to_path_buf();
+        let last_message_path =
+            output_last_message.unwrap_or_else(|| unique_temp_path("codex_last_message_", "txt"));
+        let needs_capabilities = output_schema.is_some() || !self.add_dirs.is_empty();
+        let capabilities = if needs_capabilities {
+            Some(self.probe_capabilities().await)
+        } else {
+            None
+        };
+        let resolved_overrides =
+            resolve_cli_overrides(&self.cli_overrides, &overrides, self.model.as_deref());
+
+        let mut command = Command::new(self.command_env.binary_path());
+        command
+            .arg("exec")
+            .arg("--color")
+            .arg(self.color_mode.as_str())
+            .arg("--skip-git-repo-check")
+            .arg("--json")
+            .stdout(std::process::Stdio::piped())
+            .stderr(std::process::Stdio::piped())
+            .stdin(std::process::Stdio::piped())
+            .kill_on_drop(true)
+            .current_dir(&dir_path);
+
+        apply_cli_overrides(&mut command, &resolved_overrides, true);
+
+        if let Some(model) = &self.model {
+            command.arg("--model").arg(model);
+        }
+
+        if let Some(capabilities) = &capabilities {
+            if !self.add_dirs.is_empty() {
+                let guard = capabilities.guard_add_dir();
+                if guard_is_supported(&guard) {
+                    for dir in &self.add_dirs {
+                        command.arg("--add-dir").arg(dir);
+                    }
+                } else {
+                    log_guard_skip(&guard);
+                }
+            }
+        }
+
+        for image in &self.images {
+            command.arg("--image").arg(image);
+        }
+
+        command.arg("--output-last-message").arg(&last_message_path);
+
+        if let Some(schema_path) = &output_schema {
+            if let Some(capabilities) = &capabilities {
+                let guard = capabilities.guard_output_schema();
+                if guard_is_supported(&guard) {
+                    command.arg("--output-schema").arg(schema_path);
+                } else {
+                    log_guard_skip(&guard);
+                }
+            } else {
+                command.arg("--output-schema").arg(schema_path);
+            }
+        }
+
+        self.command_env.apply(&mut command)?;
+
+        let mut child = spawn_with_retry(&mut command, self.command_env.binary_path())?;
+
+        {
+            let mut stdin = child.stdin.take().ok_or(CodexError::StdinUnavailable)?;
+            if let Err(source) = stdin.write_all(prompt.as_bytes()).await {
+                if source.kind() != std::io::ErrorKind::BrokenPipe {
+                    return Err(CodexError::StdinWrite(source).into());
+                }
+            }
+            if let Err(source) = stdin.write_all(b"\n").await {
+                if source.kind() != std::io::ErrorKind::BrokenPipe {
+                    return Err(CodexError::StdinWrite(source).into());
+                }
+            }
+            if let Err(source) = stdin.shutdown().await {
+                if source.kind() != std::io::ErrorKind::BrokenPipe {
+                    return Err(CodexError::StdinWrite(source).into());
+                }
+            }
+        }
+
+        let stdout = child.stdout.take().ok_or(CodexError::StdoutUnavailable)?;
+        let stderr = child.stderr.take().ok_or(CodexError::StderrUnavailable)?;
+
+        let (tx, rx) = mpsc::channel(32);
+        let json_log = jsonl::prepare_json_log(
+            json_event_log
+                .or_else(|| self.json_event_log.clone())
+                .filter(|path| !path.as_os_str().is_empty()),
+        )
+        .await?;
+        let stdout_task = tokio::spawn(jsonl::forward_json_events(
+            stdout,
+            tx,
+            self.mirror_stdout,
+            json_log,
+        ));
+        let stderr_task = tokio::spawn(tee_stream(stderr, ConsoleTarget::Stderr, !self.quiet));
+
+        let events = jsonl::EventChannelStream::new(rx, idle_timeout);
+        let timeout = self.timeout;
+        let schema_path = output_schema.clone();
+        let completion = Box::pin(async move {
+            let _dir_ctx = dir_ctx;
+            let wait_task = async move {
+                let status = child
+                    .wait()
+                    .await
+                    .map_err(|source| CodexError::Wait { source })?;
+                let stdout_result = stdout_task.await.map_err(CodexError::Join)?;
+                stdout_result?;
+                let stderr_bytes = stderr_task
+                    .await
+                    .map_err(CodexError::Join)?
+                    .map_err(CodexError::CaptureIo)?;
+                if !status.success() {
+                    return Err(CodexError::NonZeroExit {
+                        status,
+                        stderr: String::from_utf8(stderr_bytes).unwrap_or_default(),
+                    }
+                    .into());
+                }
+                let last_message = read_last_message(&last_message_path).await;
+                Ok(ExecCompletion {
+                    status,
+                    last_message_path: Some(last_message_path),
+                    last_message,
+                    schema_path,
+                })
+            };
+
+            if timeout.is_zero() {
+                wait_task.await
+            } else {
+                match time::timeout(timeout, wait_task).await {
+                    Ok(result) => result,
+                    Err(_) => Err(CodexError::Timeout { timeout }.into()),
+                }
+            }
+        });
+
+        Ok(ExecStream {
+            events: Box::pin(events),
+            completion,
+        })
+    }
+
+    /// Streams structured events from `codex exec --json resume ...`.
+    pub async fn stream_resume(
+        &self,
+        request: ResumeRequest,
+    ) -> Result<ExecStream, ExecStreamError> {
+        if let Some(prompt) = &request.prompt {
+            if prompt.trim().is_empty() {
+                return Err(CodexError::EmptyPrompt.into());
+            }
+        }
+
+        let ResumeRequest {
+            selector,
+            prompt,
+            idle_timeout,
+            output_last_message,
+            output_schema,
+            json_event_log,
+            overrides,
+        } = request;
+
+        let dir_ctx = self.directory_context()?;
+        let dir_path = dir_ctx.path().to_path_buf();
+        let last_message_path =
+            output_last_message.unwrap_or_else(|| unique_temp_path("codex_last_message_", "txt"));
+        let needs_capabilities = output_schema.is_some() || !self.add_dirs.is_empty();
+        let capabilities = if needs_capabilities {
+            Some(self.probe_capabilities().await)
+        } else {
+            None
+        };
+        let resolved_overrides =
+            resolve_cli_overrides(&self.cli_overrides, &overrides, self.model.as_deref());
+
+        let mut command = Command::new(self.command_env.binary_path());
+        command
+            .arg("exec")
+            .arg("--color")
+            .arg(self.color_mode.as_str())
+            .arg("--skip-git-repo-check")
+            .arg("--json")
+            .stdout(std::process::Stdio::piped())
+            .stderr(std::process::Stdio::piped())
+            .stdin(std::process::Stdio::piped())
+            .kill_on_drop(true)
+            .current_dir(&dir_path);
+
+        apply_cli_overrides(&mut command, &resolved_overrides, true);
+
+        if let Some(model) = &self.model {
+            command.arg("--model").arg(model);
+        }
+
+        if let Some(capabilities) = &capabilities {
+            if !self.add_dirs.is_empty() {
+                let guard = capabilities.guard_add_dir();
+                if guard_is_supported(&guard) {
+                    for dir in &self.add_dirs {
+                        command.arg("--add-dir").arg(dir);
+                    }
+                } else {
+                    log_guard_skip(&guard);
+                }
+            }
+        }
+
+        for image in &self.images {
+            command.arg("--image").arg(image);
+        }
+
+        command.arg("--output-last-message").arg(&last_message_path);
+
+        if let Some(schema_path) = &output_schema {
+            if let Some(capabilities) = &capabilities {
+                let guard = capabilities.guard_output_schema();
+                if guard_is_supported(&guard) {
+                    command.arg("--output-schema").arg(schema_path);
+                } else {
+                    log_guard_skip(&guard);
+                }
+            } else {
+                command.arg("--output-schema").arg(schema_path);
+            }
+        }
+
+        command.arg("resume");
+
+        match selector {
+            ResumeSelector::Id(id) => {
+                command.arg(id);
+            }
+            ResumeSelector::Last => {
+                command.arg("--last");
+            }
+            ResumeSelector::All => {
+                command.arg("--all");
+            }
+        }
+
+        if prompt.is_some() {
+            // `codex exec resume` reads the follow-up prompt from stdin when `-` is supplied.
+            command.arg("-");
+        }
+
+        self.command_env.apply(&mut command)?;
+
+        let mut child = spawn_with_retry(&mut command, self.command_env.binary_path())?;
+
+        if let Some(prompt) = &prompt {
+            let mut stdin = child.stdin.take().ok_or(CodexError::StdinUnavailable)?;
+            if let Err(source) = stdin.write_all(prompt.as_bytes()).await {
+                if source.kind() != std::io::ErrorKind::BrokenPipe {
+                    return Err(CodexError::StdinWrite(source).into());
+                }
+            }
+            if let Err(source) = stdin.write_all(b"\n").await {
+                if source.kind() != std::io::ErrorKind::BrokenPipe {
+                    return Err(CodexError::StdinWrite(source).into());
+                }
+            }
+            if let Err(source) = stdin.shutdown().await {
+                if source.kind() != std::io::ErrorKind::BrokenPipe {
+                    return Err(CodexError::StdinWrite(source).into());
+                }
+            }
+        } else {
+            let _ = child.stdin.take();
+        }
+
+        let stdout = child.stdout.take().ok_or(CodexError::StdoutUnavailable)?;
+        let stderr = child.stderr.take().ok_or(CodexError::StderrUnavailable)?;
+
+        let (tx, rx) = mpsc::channel(32);
+        let json_log = jsonl::prepare_json_log(
+            json_event_log
+                .or_else(|| self.json_event_log.clone())
+                .filter(|path| !path.as_os_str().is_empty()),
+        )
+        .await?;
+        let stdout_task = tokio::spawn(jsonl::forward_json_events(
+            stdout,
+            tx,
+            self.mirror_stdout,
+            json_log,
+        ));
+        let stderr_task = tokio::spawn(tee_stream(stderr, ConsoleTarget::Stderr, !self.quiet));
+
+        let events = jsonl::EventChannelStream::new(rx, idle_timeout);
+        let timeout = self.timeout;
+        let schema_path = output_schema.clone();
+        let completion = Box::pin(async move {
+            let _dir_ctx = dir_ctx;
+            let wait_task = async move {
+                let status = child
+                    .wait()
+                    .await
+                    .map_err(|source| CodexError::Wait { source })?;
+                let stdout_result = stdout_task.await.map_err(CodexError::Join)?;
+                stdout_result?;
+                let stderr_bytes = stderr_task
+                    .await
+                    .map_err(CodexError::Join)?
+                    .map_err(CodexError::CaptureIo)?;
+                if !status.success() {
+                    return Err(CodexError::NonZeroExit {
+                        status,
+                        stderr: String::from_utf8(stderr_bytes).unwrap_or_default(),
+                    }
+                    .into());
+                }
+                let last_message = read_last_message(&last_message_path).await;
+                Ok(ExecCompletion {
+                    status,
+                    last_message_path: Some(last_message_path),
+                    last_message,
+                    schema_path,
+                })
+            };
+
+            if timeout.is_zero() {
+                wait_task.await
+            } else {
+                match time::timeout(timeout, wait_task).await {
+                    Ok(result) => result,
+                    Err(_) => Err(CodexError::Timeout { timeout }.into()),
+                }
+            }
+        });
+
+        Ok(ExecStream {
+            events: Box::pin(events),
+            completion,
+        })
+    }
+
+    /// Runs `codex resume [OPTIONS] [SESSION_ID] [PROMPT]` and returns captured output.
+    pub async fn resume_session(
+        &self,
+        request: ResumeSessionRequest,
+    ) -> Result<ApplyDiffArtifacts, CodexError> {
+        if matches!(request.prompt.as_deref(), Some(prompt) if prompt.trim().is_empty()) {
+            return Err(CodexError::EmptyPrompt);
+        }
+
+        let mut args = vec![OsString::from("resume")];
+        if request.all {
+            args.push(OsString::from("--all"));
+        }
+        if request.last {
+            args.push(OsString::from("--last"));
+        }
+        if let Some(session_id) = request.session_id {
+            if !session_id.trim().is_empty() {
+                args.push(OsString::from(session_id));
+            }
+        }
+        if let Some(prompt) = request.prompt {
+            if !prompt.trim().is_empty() {
+                args.push(OsString::from(prompt));
+            }
+        }
+
+        self.run_simple_command_with_overrides(args, request.overrides)
+            .await
+    }
+
+    async fn invoke_codex_exec(&self, request: ExecRequest) -> Result<String, CodexError> {
+        let ExecRequest { prompt, overrides } = request;
+        let dir_ctx = self.directory_context()?;
+        let needs_capabilities = self.output_schema || !self.add_dirs.is_empty();
+        let capabilities = if needs_capabilities {
+            Some(self.probe_capabilities().await)
+        } else {
+            None
+        };
+
+        let resolved_overrides =
+            resolve_cli_overrides(&self.cli_overrides, &overrides, self.model.as_deref());
+        let mut command = Command::new(self.command_env.binary_path());
+        command
+            .arg("exec")
+            .arg("--color")
+            .arg(self.color_mode.as_str())
+            .arg("--skip-git-repo-check")
+            .stdout(std::process::Stdio::piped())
+            .stderr(std::process::Stdio::piped())
+            .kill_on_drop(true)
+            .current_dir(dir_ctx.path());
+
+        apply_cli_overrides(&mut command, &resolved_overrides, true);
+
+        let send_prompt_via_stdin = self.json_output;
+        if !send_prompt_via_stdin {
+            command.arg(&prompt);
+        }
+        let stdin_mode = if send_prompt_via_stdin {
+            std::process::Stdio::piped()
+        } else {
+            std::process::Stdio::null()
+        };
+        command.stdin(stdin_mode);
+
+        if let Some(model) = &self.model {
+            command.arg("--model").arg(model);
+        }
+
+        if let Some(capabilities) = &capabilities {
+            if self.output_schema {
+                let guard = capabilities.guard_output_schema();
+                if guard_is_supported(&guard) {
+                    command.arg("--output-schema");
+                } else {
+                    log_guard_skip(&guard);
+                }
+            }
+
+            if !self.add_dirs.is_empty() {
+                let guard = capabilities.guard_add_dir();
+                if guard_is_supported(&guard) {
+                    for dir in &self.add_dirs {
+                        command.arg("--add-dir").arg(dir);
+                    }
+                } else {
+                    log_guard_skip(&guard);
+                }
+            }
+        }
+
+        for image in &self.images {
+            command.arg("--image").arg(image);
+        }
+
+        if self.json_output {
+            command.arg("--json");
+        }
+
+        self.command_env.apply(&mut command)?;
+
+        let mut child = spawn_with_retry(&mut command, self.command_env.binary_path())?;
+
+        if send_prompt_via_stdin {
+            let mut stdin = child.stdin.take().ok_or(CodexError::StdinUnavailable)?;
+            if let Err(source) = stdin.write_all(prompt.as_bytes()).await {
+                if source.kind() != std::io::ErrorKind::BrokenPipe {
+                    return Err(CodexError::StdinWrite(source));
+                }
+            }
+            if let Err(source) = stdin.write_all(b"\n").await {
+                if source.kind() != std::io::ErrorKind::BrokenPipe {
+                    return Err(CodexError::StdinWrite(source));
+                }
+            }
+            if let Err(source) = stdin.shutdown().await {
+                if source.kind() != std::io::ErrorKind::BrokenPipe {
+                    return Err(CodexError::StdinWrite(source));
+                }
+            }
+        } else {
+            let _ = child.stdin.take();
+        }
+
+        let stdout = child.stdout.take().ok_or(CodexError::StdoutUnavailable)?;
+        let stderr = child.stderr.take().ok_or(CodexError::StderrUnavailable)?;
+
+        let stdout_task = tokio::spawn(tee_stream(
+            stdout,
+            ConsoleTarget::Stdout,
+            self.mirror_stdout,
+        ));
+        let stderr_task = tokio::spawn(tee_stream(stderr, ConsoleTarget::Stderr, !self.quiet));
+
+        let wait_task = async move {
+            let status = child
+                .wait()
+                .await
+                .map_err(|source| CodexError::Wait { source })?;
+            let stdout_bytes = stdout_task
+                .await
+                .map_err(CodexError::Join)?
+                .map_err(CodexError::CaptureIo)?;
+            let stderr_bytes = stderr_task
+                .await
+                .map_err(CodexError::Join)?
+                .map_err(CodexError::CaptureIo)?;
+            Ok::<_, CodexError>((status, stdout_bytes, stderr_bytes))
+        };
+
+        let (status, stdout_bytes, stderr_bytes) = if self.timeout.is_zero() {
+            wait_task.await?
+        } else {
+            match time::timeout(self.timeout, wait_task).await {
+                Ok(result) => result?,
+                Err(_) => {
+                    return Err(CodexError::Timeout {
+                        timeout: self.timeout,
+                    });
+                }
+            }
+        };
+
+        let stderr_string = String::from_utf8(stderr_bytes).unwrap_or_default();
+        if !status.success() {
+            return Err(CodexError::NonZeroExit {
+                status,
+                stderr: stderr_string,
+            });
+        }
+
+        let primary_output = if self.json_output && stdout_bytes.is_empty() {
+            stderr_string
+        } else {
+            String::from_utf8(stdout_bytes)?
+        };
+        let trimmed = if self.json_output {
+            primary_output
+        } else {
+            primary_output.trim().to_string()
+        };
+        debug!(
+            binary = ?self.command_env.binary_path(),
+            bytes = trimmed.len(),
+            "received Codex output"
+        );
+        Ok(trimmed)
+    }
+}
+
+/// Options configuring a streaming exec invocation.
+#[derive(Clone, Debug)]
+pub struct ExecStreamRequest {
+    /// User prompt that will be forwarded to `codex exec`.
+    pub prompt: String,
+    /// Per-event idle timeout. If no JSON lines arrive before the duration elapses,
+    /// [`ExecStreamError::IdleTimeout`] is returned.
+    pub idle_timeout: Option<Duration>,
+    /// Optional file path passed through to `--output-last-message`. When unset, the wrapper
+    /// will request a temporary path and return it in [`ExecCompletion::last_message_path`].
+    pub output_last_message: Option<PathBuf>,
+    /// Optional file path passed through to `--output-schema` so clients can persist the schema
+    /// describing the item envelope structure seen during the run.
+    pub output_schema: Option<PathBuf>,
+    /// Optional file path that receives a tee of every raw JSONL event line as it streams in.
+    /// Appends to existing files, flushes each line, and creates parent directories. Overrides
+    /// [`CodexClientBuilder::json_event_log`] for this request when provided.
+    pub json_event_log: Option<PathBuf>,
+}
+
+/// Selector for `codex resume` targets.
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub enum ResumeSelector {
+    Id(String),
+    Last,
+    All,
+}
+
+/// Options configuring a streaming resume invocation.
+#[derive(Clone, Debug)]
+pub struct ResumeRequest {
+    pub selector: ResumeSelector,
+    pub prompt: Option<String>,
+    pub idle_timeout: Option<Duration>,
+    pub output_last_message: Option<PathBuf>,
+    pub output_schema: Option<PathBuf>,
+    pub json_event_log: Option<PathBuf>,
+    pub overrides: CliOverridesPatch,
+}
+
+impl ResumeRequest {
+    pub fn new(selector: ResumeSelector) -> Self {
+        Self {
+            selector,
+            prompt: None,
+            idle_timeout: None,
+            output_last_message: None,
+            output_schema: None,
+            json_event_log: None,
+            overrides: CliOverridesPatch::default(),
+        }
+    }
+
+    pub fn with_id(id: impl Into<String>) -> Self {
+        Self::new(ResumeSelector::Id(id.into()))
+    }
+
+    pub fn last() -> Self {
+        Self::new(ResumeSelector::Last)
+    }
+
+    pub fn all() -> Self {
+        Self::new(ResumeSelector::All)
+    }
+
+    pub fn prompt(mut self, prompt: impl Into<String>) -> Self {
+        self.prompt = Some(prompt.into());
+        self
+    }
+
+    pub fn idle_timeout(mut self, idle_timeout: Duration) -> Self {
+        self.idle_timeout = Some(idle_timeout);
+        self
+    }
+
+    pub fn config_override(mut self, key: impl Into<String>, value: impl Into<String>) -> Self {
+        self.overrides
+            .config_overrides
+            .push(ConfigOverride::new(key, value));
+        self
+    }
+
+    pub fn config_override_raw(mut self, raw: impl Into<String>) -> Self {
+        self.overrides
+            .config_overrides
+            .push(ConfigOverride::from_raw(raw));
+        self
+    }
+
+    pub fn profile(mut self, profile: impl Into<String>) -> Self {
+        let profile = profile.into();
+        self.overrides.profile = (!profile.trim().is_empty()).then_some(profile);
+        self
+    }
+
+    pub fn oss(mut self, enable: bool) -> Self {
+        self.overrides.oss = if enable {
+            FlagState::Enable
+        } else {
+            FlagState::Disable
+        };
+        self
+    }
+
+    pub fn enable_feature(mut self, name: impl Into<String>) -> Self {
+        self.overrides.feature_toggles.enable.push(name.into());
+        self
+    }
+
+    pub fn disable_feature(mut self, name: impl Into<String>) -> Self {
+        self.overrides.feature_toggles.disable.push(name.into());
+        self
+    }
+
+    pub fn search(mut self, enable: bool) -> Self {
+        self.overrides.search = if enable {
+            FlagState::Enable
+        } else {
+            FlagState::Disable
+        };
+        self
+    }
+}
+
+/// Ergonomic container for the streaming surface; produced by `stream_exec` (implemented in D2).
+///
+/// `events` yields parsed [`ThreadEvent`] values as soon as each JSONL line arrives from the CLI.
+/// `completion` resolves once the Codex process exits and is the place to surface `--output-last-message`
+/// and `--output-schema` paths after streaming finishes.
+pub struct ExecStream {
+    pub events: DynThreadEventStream,
+    pub completion: DynExecCompletion,
+}
+
+/// Type-erased stream of events from the Codex CLI.
+pub type DynThreadEventStream =
+    Pin<Box<dyn Stream<Item = Result<ThreadEvent, ExecStreamError>> + Send>>;
+
+/// Type-erased completion future that resolves when streaming stops.
+pub type DynExecCompletion =
+    Pin<Box<dyn Future<Output = Result<ExecCompletion, ExecStreamError>> + Send>>;
+
+/// Summary returned when the codex child process exits.
+#[derive(Clone, Debug)]
+pub struct ExecCompletion {
+    pub status: ExitStatus,
+    /// Path that codex wrote when `--output-last-message` was enabled. The wrapper may eagerly
+    /// read the file and populate `last_message` when feasible.
+    pub last_message_path: Option<PathBuf>,
+    pub last_message: Option<String>,
+    /// Path to the JSON schema requested via `--output-schema`, if provided by the caller.
+    pub schema_path: Option<PathBuf>,
+}
+
+/// Errors that may occur while consuming the JSONL stream.
+#[derive(Debug, Error)]
+pub enum ExecStreamError {
+    #[error(transparent)]
+    Codex(#[from] CodexError),
+    #[error("failed to parse codex JSONL event: {source}: `{line}`")]
+    Parse {
+        line: String,
+        #[source]
+        source: serde_json::Error,
+    },
+    #[error("codex JSONL event missing required context: {message}: `{line}`")]
+    Normalize { line: String, message: String },
+    #[error("codex JSON stream idle for {idle_for:?}")]
+    IdleTimeout { idle_for: Duration },
+    #[error("codex JSON stream closed unexpectedly")]
+    ChannelClosed,
+}
+
+async fn read_last_message(path: &Path) -> Option<String> {
+    (fs::read_to_string(path).await).ok()
+}
+
+fn unique_temp_path(prefix: &str, extension: &str) -> PathBuf {
+    let mut path = env::temp_dir();
+    let timestamp = SystemTime::now()
+        .duration_since(UNIX_EPOCH)
+        .unwrap_or_else(|_| Duration::from_secs(0))
+        .as_nanos();
+    path.push(format!(
+        "{prefix}{timestamp}_{}.{}",
+        std::process::id(),
+        extension
+    ));
+    path
+}
diff --git a/crates/codex/src/home.rs b/crates/codex/src/home.rs
index 18e7567..de46f08 100644
--- a/crates/codex/src/home.rs
+++ b/crates/codex/src/home.rs
@@ -7,7 +7,8 @@ use std::{
 use thiserror::Error;
 use tokio::process::Command;
 
-use super::{default_rust_log_value, CodexError, CODEX_BINARY_ENV, CODEX_HOME_ENV, RUST_LOG_ENV};
+use crate::defaults::{default_rust_log_value, CODEX_BINARY_ENV, CODEX_HOME_ENV, RUST_LOG_ENV};
+use crate::CodexError;
 
 #[derive(Clone, Debug)]
 pub(super) struct CommandEnvironment {
diff --git a/crates/codex/src/lib.rs b/crates/codex/src/lib.rs
index 08e80ed..e790397 100644
--- a/crates/codex/src/lib.rs
+++ b/crates/codex/src/lib.rs
@@ -68,19 +68,56 @@
 //! - Overrides + persistence: `capability_snapshot`, `capability_overrides`, `write_capabilities_snapshot`, `read_capabilities_snapshot`, and `capability_snapshot_matches_binary` let hosts reuse snapshots across processes and fall back to probes when fingerprints diverge.
 
 mod apply_diff;
+mod auth;
 mod builder;
+mod bundled_binary;
+mod cli;
+mod client_core;
+mod commands;
+mod defaults;
+mod error;
+mod events;
+mod exec;
 mod execpolicy;
 mod home;
 pub mod jsonl;
 pub mod mcp;
+mod process;
 pub mod wrapper_coverage_manifest;
 
+pub use crate::error::CodexError;
 pub use apply_diff::{ApplyDiffArtifacts, CloudApplyRequest, CloudDiffRequest};
+pub use auth::{AuthSessionHelper, CodexAuthMethod, CodexAuthStatus, CodexLogoutStatus};
 pub use builder::{
     ApprovalPolicy, CliOverrides, CliOverridesPatch, CodexClientBuilder, ColorMode, ConfigOverride,
     FeatureToggles, FlagState, LocalProvider, ModelVerbosity, ReasoningEffort, ReasoningOverrides,
     ReasoningSummary, ReasoningSummaryFormat, SafetyOverride, SandboxMode,
 };
+pub use bundled_binary::{
+    default_bundled_platform_label, resolve_bundled_binary, BundledBinary, BundledBinaryError,
+    BundledBinarySpec,
+};
+pub use cli::{
+    AppServerCodegenOutput, AppServerCodegenRequest, AppServerCodegenTarget, CloudExecRequest,
+    CloudListOutput, CloudListRequest, CloudOverviewRequest, CloudStatusRequest, CodexFeature,
+    CodexFeatureStage, ExecRequest, ExecReviewCommandRequest, FeaturesCommandRequest,
+    FeaturesListFormat, FeaturesListOutput, FeaturesListRequest, ForkSessionRequest,
+    HelpCommandRequest, HelpScope, McpAddRequest, McpAddTransport, McpGetRequest, McpListOutput,
+    McpListRequest, McpLogoutRequest, McpOauthLoginRequest, McpOverviewRequest, McpRemoveRequest,
+    ResponsesApiProxyHandle, ResponsesApiProxyInfo, ResponsesApiProxyRequest, ResumeSessionRequest,
+    ReviewCommandRequest, SandboxCommandRequest, SandboxPlatform, SandboxRun, StdioToUdsRequest,
+};
+pub use events::{
+    CommandExecutionDelta, CommandExecutionState, EventError, FileChangeDelta, FileChangeKind,
+    FileChangeState, ItemDelta, ItemDeltaPayload, ItemEnvelope, ItemFailure, ItemPayload,
+    ItemSnapshot, ItemStatus, McpToolCallDelta, McpToolCallState, TextContent, TextDelta,
+    ThreadEvent, ThreadStarted, TodoItem, TodoListDelta, TodoListState, ToolCallStatus,
+    TurnCompleted, TurnFailed, TurnStarted, WebSearchDelta, WebSearchState, WebSearchStatus,
+};
+pub use exec::{
+    DynExecCompletion, DynThreadEventStream, ExecCompletion, ExecStream, ExecStreamError,
+    ExecStreamRequest, ResumeRequest, ResumeSelector,
+};
 pub use execpolicy::{
     ExecPolicyCheckRequest, ExecPolicyCheckResult, ExecPolicyDecision, ExecPolicyEvaluation,
     ExecPolicyMatch, ExecPolicyNoMatch, ExecPolicyRuleMatch,
@@ -92,42 +129,22 @@ pub use jsonl::{
 };
 
 use std::{
-    collections::{BTreeMap, HashSet},
-    env,
-    ffi::{OsStr, OsString},
-    fs as std_fs,
-    future::Future,
-    io::{self as stdio, Write},
-    path::{Path, PathBuf},
-    pin::Pin,
-    process::ExitStatus,
-    time::{Duration, SystemTime, UNIX_EPOCH},
+    path::PathBuf,
+    time::{Duration, SystemTime},
 };
 
-use builder::{apply_cli_overrides, resolve_cli_overrides};
-use futures_core::Stream;
 use home::CommandEnvironment;
-use semver::{Prerelease, Version};
-use serde::{Deserialize, Serialize};
-use serde_json::Value;
-#[cfg(unix)]
-use std::os::unix::fs::PermissionsExt;
-use tempfile::TempDir;
-use thiserror::Error;
-use tokio::{
-    fs,
-    io::{AsyncRead, AsyncReadExt, AsyncWriteExt},
-    process::Command,
-    sync::mpsc,
-    task, time,
-};
-use tracing::{debug, warn};
+use process::command_output_text;
+use tracing::warn;
+
+#[cfg(test)]
+use std::path::Path;
+
+#[cfg(test)]
+use tokio::time;
 
-const DEFAULT_TIMEOUT: Duration = Duration::from_secs(120);
-const CODEX_BINARY_ENV: &str = "CODEX_BINARY";
-const CODEX_HOME_ENV: &str = "CODEX_HOME";
-const RUST_LOG_ENV: &str = "RUST_LOG";
-const DEFAULT_RUST_LOG: &str = "error";
+#[cfg(test)]
+use tokio::sync::mpsc;
 
 #[cfg(test)]
 use builder::{
@@ -135,233 +152,60 @@ use builder::{
     DEFAULT_REASONING_CONFIG_GPT5_1, DEFAULT_REASONING_CONFIG_GPT5_CODEX,
 };
 
-/// Specification for resolving an app-bundled Codex binary.
-///
-/// Callers supply a bundle root plus the pinned version they expect. Platform
-/// defaults to the current target triple label (e.g., `darwin-arm64` or
-/// `linux-x64`) but can be overridden when hosts manage their own layout.
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub struct BundledBinarySpec<'a> {
-    /// Root containing `<platform>/<version>/codex` slices managed by the host.
-    pub bundle_root: &'a Path,
-    /// Pinned Codex version directory to resolve (semantic version or channel/build id).
-    pub version: &'a str,
-    /// Optional platform label override; defaults to [`default_bundled_platform_label`].
-    pub platform: Option<&'a str>,
-}
-
-/// Resolved bundled Codex binary details.
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub struct BundledBinary {
-    /// Canonicalized path to the bundled Codex binary (`codex` or `codex.exe`).
-    pub binary_path: PathBuf,
-    /// Platform slice resolved under the bundle root.
-    pub platform: String,
-    /// Version slice resolved under the platform directory.
-    pub version: String,
-}
-
-/// Errors that may occur while resolving a bundled Codex binary.
-#[derive(Debug, Error)]
-pub enum BundledBinaryError {
-    #[error("bundled Codex version cannot be empty")]
-    EmptyVersion,
-    #[error("bundled Codex platform label cannot be empty")]
-    EmptyPlatform,
-    #[error("bundle root `{bundle_root}` does not exist or is unreadable")]
-    BundleRootUnreadable {
-        bundle_root: PathBuf,
-        #[source]
-        source: std::io::Error,
-    },
-    #[error("bundle root `{bundle_root}` is not a directory")]
-    BundleRootNotDirectory { bundle_root: PathBuf },
-    #[error("bundle platform directory `{platform_dir}` for `{platform}` does not exist or is unreadable")]
-    PlatformUnreadable {
-        platform: String,
-        platform_dir: PathBuf,
-        #[source]
-        source: std::io::Error,
-    },
-    #[error("bundle platform directory `{platform_dir}` for `{platform}` is not a directory")]
-    PlatformNotDirectory {
-        platform: String,
-        platform_dir: PathBuf,
-    },
-    #[error(
-        "bundle version directory `{version_dir}` for `{version}` does not exist or is unreadable"
-    )]
-    VersionUnreadable {
-        version: String,
-        version_dir: PathBuf,
-        #[source]
-        source: std::io::Error,
-    },
-    #[error("bundle version directory `{version_dir}` for `{version}` is not a directory")]
-    VersionNotDirectory {
-        version: String,
-        version_dir: PathBuf,
-    },
-    #[error("bundled Codex binary `{binary}` is missing or unreadable")]
-    BinaryUnreadable {
-        binary: PathBuf,
-        #[source]
-        source: std::io::Error,
-    },
-    #[error("bundled Codex binary `{binary}` is not a file")]
-    BinaryNotFile { binary: PathBuf },
-    #[error("bundled Codex binary `{binary}` is not executable")]
-    BinaryNotExecutable { binary: PathBuf },
-    #[error("failed to canonicalize bundled Codex binary `{path}`: {source}")]
-    Canonicalize {
-        path: PathBuf,
-        #[source]
-        source: std::io::Error,
-    },
+fn normalize_non_empty(value: &str) -> Option<String> {
+    let trimmed = value.trim();
+    (!trimmed.is_empty()).then_some(trimmed.to_string())
 }
 
-/// Resolves a bundled Codex binary under `<bundle_root>/<platform>/<version>/`.
-///
-/// The helper never consults `PATH` or `CODEX_BINARY`; missing slices are hard
-/// errors. The resolved path is canonicalized and should be passed to
-/// [`CodexClientBuilder::binary`] to keep behavior isolated from any global
-/// Codex install.
-pub fn resolve_bundled_binary(
-    spec: BundledBinarySpec<'_>,
-) -> Result<BundledBinary, BundledBinaryError> {
-    let platform = match spec.platform {
-        Some(label) => normalize_non_empty(label).ok_or(BundledBinaryError::EmptyPlatform)?,
-        None => default_bundled_platform_label(),
-    };
-    let version = normalize_non_empty(spec.version).ok_or(BundledBinaryError::EmptyVersion)?;
-
-    require_directory(
-        spec.bundle_root,
-        |source| BundledBinaryError::BundleRootUnreadable {
-            bundle_root: spec.bundle_root.to_path_buf(),
-            source,
-        },
-        || BundledBinaryError::BundleRootNotDirectory {
-            bundle_root: spec.bundle_root.to_path_buf(),
-        },
-    )?;
-
-    let platform_dir = spec.bundle_root.join(&platform);
-    require_directory(
-        &platform_dir,
-        |source| BundledBinaryError::PlatformUnreadable {
-            platform: platform.clone(),
-            platform_dir: platform_dir.clone(),
-            source,
-        },
-        || BundledBinaryError::PlatformNotDirectory {
-            platform: platform.clone(),
-            platform_dir: platform_dir.clone(),
-        },
-    )?;
-
-    let version_dir = platform_dir.join(&version);
-    require_directory(
-        &version_dir,
-        |source| BundledBinaryError::VersionUnreadable {
-            version: version.clone(),
-            version_dir: version_dir.clone(),
-            source,
-        },
-        || BundledBinaryError::VersionNotDirectory {
-            version: version.clone(),
-            version_dir: version_dir.clone(),
-        },
-    )?;
-
-    let binary_path = version_dir.join(bundled_binary_filename(&platform));
-    let metadata =
-        std_fs::metadata(&binary_path).map_err(|source| BundledBinaryError::BinaryUnreadable {
-            binary: binary_path.clone(),
-            source,
-        })?;
-    if !metadata.is_file() {
-        return Err(BundledBinaryError::BinaryNotFile {
-            binary: binary_path.clone(),
-        });
-    }
-    ensure_executable(&metadata, &binary_path)?;
-
-    let canonical =
-        std_fs::canonicalize(&binary_path).map_err(|source| BundledBinaryError::Canonicalize {
-            path: binary_path.clone(),
-            source,
-        })?;
+type Command = tokio::process::Command;
+type ConsoleTarget = crate::process::ConsoleTarget;
 
-    Ok(BundledBinary {
-        binary_path: canonical,
-        platform,
-        version,
-    })
-}
+#[cfg(test)]
+type OsString = std::ffi::OsString;
 
-/// Default bundled platform label for the current target (e.g., `darwin-arm64`, `linux-x64`, `windows-x64`).
-pub fn default_bundled_platform_label() -> String {
-    let os = match env::consts::OS {
-        "macos" => "darwin",
-        other => other,
-    };
-    let arch = match env::consts::ARCH {
-        "x86_64" => "x64",
-        "aarch64" => "arm64",
-        other => other,
-    };
-    format!("{os}-{arch}")
+async fn tee_stream<R>(
+    reader: R,
+    target: ConsoleTarget,
+    mirror_console: bool,
+) -> Result<Vec<u8>, std::io::Error>
+where
+    R: tokio::io::AsyncRead + Unpin,
+{
+    crate::process::tee_stream(reader, target, mirror_console).await
 }
 
-fn require_directory(
-    path: &Path,
-    on_read_error: impl FnOnce(std::io::Error) -> BundledBinaryError,
-    on_wrong_type: impl FnOnce() -> BundledBinaryError,
-) -> Result<(), BundledBinaryError> {
-    let metadata = std_fs::metadata(path).map_err(on_read_error)?;
-    if !metadata.is_dir() {
-        return Err(on_wrong_type());
-    }
-    Ok(())
+fn spawn_with_retry(
+    command: &mut Command,
+    binary: &std::path::Path,
+) -> Result<tokio::process::Child, CodexError> {
+    crate::process::spawn_with_retry(command, binary)
 }
 
-fn ensure_executable(metadata: &std_fs::Metadata, binary: &Path) -> Result<(), BundledBinaryError> {
-    if binary_is_executable(metadata) {
-        return Ok(());
-    }
-    Err(BundledBinaryError::BinaryNotExecutable {
-        binary: binary.to_path_buf(),
-    })
+fn resolve_cli_overrides(
+    builder: &CliOverrides,
+    patch: &CliOverridesPatch,
+    model: Option<&str>,
+) -> builder::ResolvedCliOverrides {
+    builder::resolve_cli_overrides(builder, patch, model)
 }
 
-fn binary_is_executable(metadata: &std_fs::Metadata) -> bool {
-    #[cfg(unix)]
-    {
-        metadata.permissions().mode() & 0o111 != 0
-    }
-    #[cfg(not(unix))]
-    {
-        // Windows does not use executable bits; existence is sufficient.
-        true
-    }
+fn apply_cli_overrides(
+    command: &mut Command,
+    resolved: &builder::ResolvedCliOverrides,
+    include_search: bool,
+) {
+    builder::apply_cli_overrides(command, resolved, include_search);
 }
 
+#[cfg(test)]
 fn bundled_binary_filename(platform: &str) -> &'static str {
-    if platform.to_ascii_lowercase().contains("windows") {
-        "codex.exe"
-    } else {
-        "codex"
-    }
-}
-
-fn normalize_non_empty(value: &str) -> Option<String> {
-    let trimmed = value.trim();
-    (!trimmed.is_empty()).then_some(trimmed.to_string())
+    bundled_binary::bundled_binary_filename(platform)
 }
 
 mod capabilities;
+mod version;
 pub use capabilities::*;
+pub use version::update_advisory_from_capabilities;
 
 /// High-level client for interacting with `codex exec`.
 ///
@@ -388,104 +232,6 @@ pub struct CodexClient {
     capability_cache_policy: CapabilityCachePolicy,
 }
 
-/// Current authentication state reported by `codex login status`.
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub enum CodexAuthStatus {
-    /// The CLI reports an active session.
-    LoggedIn(CodexAuthMethod),
-    /// No credentials stored locally.
-    LoggedOut,
-}
-
-/// Authentication mechanism used to sign in.
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub enum CodexAuthMethod {
-    ChatGpt,
-    ApiKey {
-        masked_key: Option<String>,
-    },
-    /// CLI reported a logged-in state but the auth method could not be parsed (e.g., new wording).
-    Unknown {
-        raw: String,
-    },
-}
-
-/// Result of invoking `codex logout`.
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub enum CodexLogoutStatus {
-    LoggedOut,
-    AlreadyLoggedOut,
-}
-
-/// Helper for checking Codex auth state and triggering login flows with an app-scoped `CODEX_HOME`.
-///
-/// All commands run with per-process env overrides; the parent process env is never mutated.
-#[derive(Clone, Debug)]
-pub struct AuthSessionHelper {
-    client: CodexClient,
-}
-
-impl AuthSessionHelper {
-    /// Creates a helper that pins `CODEX_HOME` to `app_codex_home` for every login call.
-    pub fn new(app_codex_home: impl Into<PathBuf>) -> Self {
-        let client = CodexClient::builder()
-            .codex_home(app_codex_home)
-            .create_home_dirs(true)
-            .build();
-        Self { client }
-    }
-
-    /// Wraps an existing `CodexClient` (useful when you already configured the binary path).
-    pub fn with_client(client: CodexClient) -> Self {
-        Self { client }
-    }
-
-    /// Returns the underlying `CodexClient`.
-    pub fn client(&self) -> CodexClient {
-        self.client.clone()
-    }
-
-    /// Reports the current login status under the configured `CODEX_HOME`.
-    pub async fn status(&self) -> Result<CodexAuthStatus, CodexError> {
-        self.client.login_status().await
-    }
-
-    /// Logs in with an API key when logged out; otherwise returns the current status.
-    pub async fn ensure_api_key_login(
-        &self,
-        api_key: impl AsRef<str>,
-    ) -> Result<CodexAuthStatus, CodexError> {
-        match self.status().await? {
-            logged @ CodexAuthStatus::LoggedIn(_) => Ok(logged),
-            CodexAuthStatus::LoggedOut => self.client.login_with_api_key(api_key).await,
-        }
-    }
-
-    /// Starts the ChatGPT OAuth login flow when no credentials are present.
-    ///
-    /// Returns `Ok(None)` when already logged in; otherwise returns the spawned login child so the
-    /// caller can surface output/URLs. Dropping the child kills the login helper.
-    pub async fn ensure_chatgpt_login(&self) -> Result<Option<tokio::process::Child>, CodexError> {
-        match self.status().await? {
-            CodexAuthStatus::LoggedIn(_) => Ok(None),
-            CodexAuthStatus::LoggedOut => self.client.spawn_login_process().map(Some),
-        }
-    }
-
-    /// Directly spawns the ChatGPT login process.
-    pub fn spawn_chatgpt_login(&self) -> Result<tokio::process::Child, CodexError> {
-        self.client.spawn_login_process()
-    }
-
-    /// Directly logs in with an API key without checking prior state.
-    pub async fn login_with_api_key(
-        &self,
-        api_key: impl AsRef<str>,
-    ) -> Result<CodexAuthStatus, CodexError> {
-        self.client.login_with_api_key(api_key).await
-    }
-}
-
 impl CodexClient {
     /// Returns a [`CodexClientBuilder`] preloaded with safe defaults.
     pub fn builder() -> CodexClientBuilder {
@@ -499,8548 +245,226 @@ impl CodexClient {
         self.command_env.codex_home_layout()
     }
 
-    /// Sends `prompt` to `codex exec` and returns its stdout (the final agent message) on success.
-    ///
-    /// When `.json(true)` is enabled the CLI emits JSONL events (`thread.started` or
-    /// `thread.resumed`, `turn.started`/`turn.completed`/`turn.failed`,
-    /// `item.created`/`item.updated`, or `error`). The stream is mirrored to stdout unless
-    /// `.mirror_stdout(false)`; the returned string contains the buffered lines for offline
-    /// parsing. For per-event handling, see `crates/codex/examples/stream_events.rs`.
-    ///
-    /// ```rust,no_run
-    /// use codex::CodexClient;
-    /// # #[tokio::main]
-    /// # async fn main() -> Result<(), Box<dyn std::error::Error>> {
-    /// let client = CodexClient::builder().json(true).mirror_stdout(false).build();
-    /// let jsonl = client.send_prompt("Stream repo status").await?;
-    /// println!("{jsonl}");
-    /// # Ok(()) }
-    /// ```
-    pub async fn send_prompt(&self, prompt: impl AsRef<str>) -> Result<String, CodexError> {
-        self.send_prompt_with(ExecRequest::new(prompt.as_ref()))
-            .await
-    }
-
-    /// Sends an exec request with per-call CLI overrides.
-    pub async fn send_prompt_with(&self, request: ExecRequest) -> Result<String, CodexError> {
-        if request.prompt.trim().is_empty() {
-            return Err(CodexError::EmptyPrompt);
-        }
-
-        self.invoke_codex_exec(request).await
-    }
-
-    /// Streams structured JSONL events from `codex exec --json`.
+    /// Probes the configured binary for version/build metadata and supported feature flags.
     ///
-    /// Respects `mirror_stdout` (raw JSON echoing) and tees raw lines to `json_event_log` when
-    /// configured on the builder or request. Returns an [`ExecStream`] with both the parsed event
-    /// stream and a completion future that reports `--output-last-message`/schema paths.
-    pub async fn stream_exec(
-        &self,
-        request: ExecStreamRequest,
-    ) -> Result<ExecStream, ExecStreamError> {
-        self.stream_exec_with_overrides(request, CliOverridesPatch::default())
+    /// Results are cached per canonical binary path and invalidated when file metadata changes.
+    /// Caller-supplied overrides (see [`CodexClientBuilder::capability_overrides`]) can
+    /// short-circuit probes or layer hints; snapshots are still cached against the current
+    /// binary fingerprint so changes on disk trigger revalidation. Missing fingerprints skip
+    /// cache reuse to force a re-probe. Cache interaction follows the policy configured on
+    /// the builder (see [`CodexClientBuilder::capability_cache_policy`]).
+    /// Failures are logged and return conservative defaults so callers can gate optional flags.
+    pub async fn probe_capabilities(&self) -> CodexCapabilities {
+        self.probe_capabilities_with_policy(self.capability_cache_policy)
             .await
     }
 
-    /// Streams JSONL events with per-request CLI overrides.
-    pub async fn stream_exec_with_overrides(
+    /// Probes capabilities with an explicit cache policy.
+    pub async fn probe_capabilities_with_policy(
         &self,
-        request: ExecStreamRequest,
-        overrides: CliOverridesPatch,
-    ) -> Result<ExecStream, ExecStreamError> {
-        if request.prompt.trim().is_empty() {
-            return Err(CodexError::EmptyPrompt.into());
-        }
-
-        let ExecStreamRequest {
-            prompt,
-            idle_timeout,
-            output_last_message,
-            output_schema,
-            json_event_log,
-        } = request;
-
-        let dir_ctx = self.directory_context()?;
-        let dir_path = dir_ctx.path().to_path_buf();
-        let last_message_path =
-            output_last_message.unwrap_or_else(|| unique_temp_path("codex_last_message_", "txt"));
-        let needs_capabilities = output_schema.is_some() || !self.add_dirs.is_empty();
-        let capabilities = if needs_capabilities {
-            Some(self.probe_capabilities().await)
-        } else {
-            None
-        };
-        let resolved_overrides =
-            resolve_cli_overrides(&self.cli_overrides, &overrides, self.model.as_deref());
-
-        let mut command = Command::new(self.command_env.binary_path());
-        command
-            .arg("exec")
-            .arg("--color")
-            .arg(self.color_mode.as_str())
-            .arg("--skip-git-repo-check")
-            .arg("--json")
-            .stdout(std::process::Stdio::piped())
-            .stderr(std::process::Stdio::piped())
-            .stdin(std::process::Stdio::piped())
-            .kill_on_drop(true)
-            .current_dir(&dir_path);
+        cache_policy: CapabilityCachePolicy,
+    ) -> CodexCapabilities {
+        let cache_key = capability_cache_key(self.command_env.binary_path());
+        let fingerprint = current_fingerprint(&cache_key);
+        let overrides = &self.capability_overrides;
 
-        apply_cli_overrides(&mut command, &resolved_overrides, true);
+        let cache_reads_enabled = matches!(cache_policy, CapabilityCachePolicy::PreferCache)
+            && has_fingerprint_metadata(&fingerprint);
+        let cache_writes_enabled = !matches!(cache_policy, CapabilityCachePolicy::Bypass)
+            && has_fingerprint_metadata(&fingerprint);
 
-        if let Some(model) = &self.model {
-            command.arg("--model").arg(model);
+        if let Some(snapshot) = overrides.snapshot.clone() {
+            let capabilities = finalize_capabilities_with_overrides(
+                snapshot,
+                overrides,
+                cache_key.clone(),
+                fingerprint.clone(),
+                true,
+            );
+            if cache_writes_enabled {
+                update_capability_cache(capabilities.clone());
+            }
+            return capabilities;
         }
 
-        if let Some(capabilities) = &capabilities {
-            if !self.add_dirs.is_empty() {
-                let guard = capabilities.guard_add_dir();
-                if guard_is_supported(&guard) {
-                    for dir in &self.add_dirs {
-                        command.arg("--add-dir").arg(dir);
-                    }
-                } else {
-                    log_guard_skip(&guard);
+        if cache_reads_enabled {
+            if let Some(cached) = cached_capabilities(&cache_key, &fingerprint) {
+                if overrides.is_empty() {
+                    return cached;
+                }
+                let merged = finalize_capabilities_with_overrides(
+                    cached,
+                    overrides,
+                    cache_key.clone(),
+                    fingerprint.clone(),
+                    false,
+                );
+                if cache_writes_enabled {
+                    update_capability_cache(merged.clone());
                 }
+                return merged;
             }
         }
 
-        for image in &self.images {
-            command.arg("--image").arg(image);
-        }
+        let probed = self
+            .probe_capabilities_uncached(&cache_key, fingerprint.clone())
+            .await;
 
-        command.arg("--output-last-message").arg(&last_message_path);
+        let capabilities =
+            finalize_capabilities_with_overrides(probed, overrides, cache_key, fingerprint, false);
 
-        if let Some(schema_path) = &output_schema {
-            if let Some(capabilities) = &capabilities {
-                let guard = capabilities.guard_output_schema();
-                if guard_is_supported(&guard) {
-                    command.arg("--output-schema").arg(schema_path);
-                } else {
-                    log_guard_skip(&guard);
-                }
-            } else {
-                command.arg("--output-schema").arg(schema_path);
-            }
+        if cache_writes_enabled {
+            update_capability_cache(capabilities.clone());
         }
 
-        self.command_env.apply(&mut command)?;
+        capabilities
+    }
 
-        let mut child = spawn_with_retry(&mut command, self.command_env.binary_path())?;
+    async fn probe_capabilities_uncached(
+        &self,
+        cache_key: &CapabilityCacheKey,
+        fingerprint: Option<BinaryFingerprint>,
+    ) -> CodexCapabilities {
+        let mut plan = CapabilityProbePlan::default();
+        let mut features = CodexFeatureFlags::default();
+        let mut version = None;
 
-        {
-            let mut stdin = child.stdin.take().ok_or(CodexError::StdinUnavailable)?;
-            if let Err(source) = stdin.write_all(prompt.as_bytes()).await {
-                if source.kind() != std::io::ErrorKind::BrokenPipe {
-                    return Err(CodexError::StdinWrite(source).into());
-                }
-            }
-            if let Err(source) = stdin.write_all(b"\n").await {
-                if source.kind() != std::io::ErrorKind::BrokenPipe {
-                    return Err(CodexError::StdinWrite(source).into());
+        plan.steps.push(CapabilityProbeStep::VersionFlag);
+        match self.run_basic_command(["--version"]).await {
+            Ok(output) => {
+                if !output.status.success() {
+                    warn!(
+                        status = ?output.status,
+                        binary = ?cache_key.binary_path,
+                        "codex --version exited non-zero"
+                    );
                 }
-            }
-            if let Err(source) = stdin.shutdown().await {
-                if source.kind() != std::io::ErrorKind::BrokenPipe {
-                    return Err(CodexError::StdinWrite(source).into());
+                let text = command_output_text(&output);
+                if !text.trim().is_empty() {
+                    version = Some(version::parse_version_output(&text));
                 }
             }
+            Err(error) => warn!(
+                ?error,
+                binary = ?cache_key.binary_path,
+                "codex --version probe failed"
+            ),
         }
 
-        let stdout = child.stdout.take().ok_or(CodexError::StdoutUnavailable)?;
-        let stderr = child.stderr.take().ok_or(CodexError::StderrUnavailable)?;
-
-        let (tx, rx) = mpsc::channel(32);
-        let json_log = jsonl::prepare_json_log(
-            json_event_log
-                .or_else(|| self.json_event_log.clone())
-                .filter(|path| !path.as_os_str().is_empty()),
-        )
-        .await?;
-        let stdout_task = tokio::spawn(jsonl::forward_json_events(
-            stdout,
-            tx,
-            self.mirror_stdout,
-            json_log,
-        ));
-        let stderr_task = tokio::spawn(tee_stream(stderr, ConsoleTarget::Stderr, !self.quiet));
+        let mut parsed_features = false;
 
-        let events = jsonl::EventChannelStream::new(rx, idle_timeout);
-        let timeout = self.timeout;
-        let schema_path = output_schema.clone();
-        let completion = Box::pin(async move {
-            let _dir_ctx = dir_ctx;
-            let wait_task = async move {
-                let status = child
-                    .wait()
-                    .await
-                    .map_err(|source| CodexError::Wait { source })?;
-                let stdout_result = stdout_task.await.map_err(CodexError::Join)?;
-                stdout_result?;
-                let stderr_bytes = stderr_task
-                    .await
-                    .map_err(CodexError::Join)?
-                    .map_err(CodexError::CaptureIo)?;
-                if !status.success() {
-                    return Err(CodexError::NonZeroExit {
-                        status,
-                        stderr: String::from_utf8(stderr_bytes).unwrap_or_default(),
-                    }
-                    .into());
+        plan.steps.push(CapabilityProbeStep::FeaturesListJson);
+        match self.run_basic_command(["features", "list", "--json"]).await {
+            Ok(output) => {
+                if !output.status.success() {
+                    warn!(
+                        status = ?output.status,
+                        binary = ?cache_key.binary_path,
+                        "codex features list --json exited non-zero"
+                    );
                 }
-                let last_message = read_last_message(&last_message_path).await;
-                Ok(ExecCompletion {
-                    status,
-                    last_message_path: Some(last_message_path),
-                    last_message,
-                    schema_path,
-                })
-            };
-
-            if timeout.is_zero() {
-                wait_task.await
-            } else {
-                match time::timeout(timeout, wait_task).await {
-                    Ok(result) => result,
-                    Err(_) => Err(CodexError::Timeout { timeout }.into()),
+                if output.status.success() {
+                    features.supports_features_list = true;
+                }
+                let text = command_output_text(&output);
+                if let Some(parsed) = version::parse_features_from_json(&text) {
+                    version::merge_feature_flags(&mut features, parsed);
+                    parsed_features = version::detected_feature_flags(&features);
+                } else if !text.is_empty() {
+                    let parsed = version::parse_features_from_text(&text);
+                    version::merge_feature_flags(&mut features, parsed);
+                    parsed_features = version::detected_feature_flags(&features);
                 }
             }
-        });
-
-        Ok(ExecStream {
-            events: Box::pin(events),
-            completion,
-        })
-    }
-
-    /// Streams structured events from `codex exec --json resume ...`.
-    pub async fn stream_resume(
-        &self,
-        request: ResumeRequest,
-    ) -> Result<ExecStream, ExecStreamError> {
-        if let Some(prompt) = &request.prompt {
-            if prompt.trim().is_empty() {
-                return Err(CodexError::EmptyPrompt.into());
-            }
-        }
-
-        let ResumeRequest {
-            selector,
-            prompt,
-            idle_timeout,
-            output_last_message,
-            output_schema,
-            json_event_log,
-            overrides,
-        } = request;
-
-        let dir_ctx = self.directory_context()?;
-        let dir_path = dir_ctx.path().to_path_buf();
-        let last_message_path =
-            output_last_message.unwrap_or_else(|| unique_temp_path("codex_last_message_", "txt"));
-        let needs_capabilities = output_schema.is_some() || !self.add_dirs.is_empty();
-        let capabilities = if needs_capabilities {
-            Some(self.probe_capabilities().await)
-        } else {
-            None
-        };
-        let resolved_overrides =
-            resolve_cli_overrides(&self.cli_overrides, &overrides, self.model.as_deref());
-
-        let mut command = Command::new(self.command_env.binary_path());
-        command
-            .arg("exec")
-            .arg("--color")
-            .arg(self.color_mode.as_str())
-            .arg("--skip-git-repo-check")
-            .arg("--json")
-            .stdout(std::process::Stdio::piped())
-            .stderr(std::process::Stdio::piped())
-            .stdin(std::process::Stdio::piped())
-            .kill_on_drop(true)
-            .current_dir(&dir_path);
-
-        apply_cli_overrides(&mut command, &resolved_overrides, true);
-
-        if let Some(model) = &self.model {
-            command.arg("--model").arg(model);
+            Err(error) => warn!(
+                ?error,
+                binary = ?cache_key.binary_path,
+                "codex features list --json probe failed"
+            ),
         }
 
-        if let Some(capabilities) = &capabilities {
-            if !self.add_dirs.is_empty() {
-                let guard = capabilities.guard_add_dir();
-                if guard_is_supported(&guard) {
-                    for dir in &self.add_dirs {
-                        command.arg("--add-dir").arg(dir);
+        if !parsed_features {
+            plan.steps.push(CapabilityProbeStep::FeaturesListText);
+            match self.run_basic_command(["features", "list"]).await {
+                Ok(output) => {
+                    if !output.status.success() {
+                        warn!(
+                            status = ?output.status,
+                            binary = ?cache_key.binary_path,
+                            "codex features list exited non-zero"
+                        );
+                    }
+                    if output.status.success() {
+                        features.supports_features_list = true;
                     }
-                } else {
-                    log_guard_skip(&guard);
+                    let text = command_output_text(&output);
+                    let parsed = version::parse_features_from_text(&text);
+                    version::merge_feature_flags(&mut features, parsed);
                 }
+                Err(error) => warn!(
+                    ?error,
+                    binary = ?cache_key.binary_path,
+                    "codex features list probe failed"
+                ),
             }
         }
 
-        for image in &self.images {
-            command.arg("--image").arg(image);
-        }
-
-        command.arg("--output-last-message").arg(&last_message_path);
-
-        if let Some(schema_path) = &output_schema {
-            if let Some(capabilities) = &capabilities {
-                let guard = capabilities.guard_output_schema();
-                if guard_is_supported(&guard) {
-                    command.arg("--output-schema").arg(schema_path);
-                } else {
-                    log_guard_skip(&guard);
+        if version::should_run_help_fallback(&features) {
+            plan.steps.push(CapabilityProbeStep::HelpFallback);
+            match self.run_basic_command(["--help"]).await {
+                Ok(output) => {
+                    if !output.status.success() {
+                        warn!(
+                            status = ?output.status,
+                            binary = ?cache_key.binary_path,
+                            "codex --help exited non-zero"
+                        );
+                    }
+                    let text = command_output_text(&output);
+                    let parsed = version::parse_help_output(&text);
+                    version::merge_feature_flags(&mut features, parsed);
                 }
-            } else {
-                command.arg("--output-schema").arg(schema_path);
+                Err(error) => warn!(
+                    ?error,
+                    binary = ?cache_key.binary_path,
+                    "codex --help probe failed"
+                ),
             }
         }
 
-        command.arg("resume");
-
-        match selector {
-            ResumeSelector::Id(id) => {
-                command.arg(id);
-            }
-            ResumeSelector::Last => {
-                command.arg("--last");
-            }
-            ResumeSelector::All => {
-                command.arg("--all");
-            }
-        }
-
-        if prompt.is_some() {
-            // `codex exec resume` reads the follow-up prompt from stdin when `-` is supplied.
-            command.arg("-");
-        }
-
-        self.command_env.apply(&mut command)?;
-
-        let mut child = spawn_with_retry(&mut command, self.command_env.binary_path())?;
-
-        if let Some(prompt) = &prompt {
-            let mut stdin = child.stdin.take().ok_or(CodexError::StdinUnavailable)?;
-            if let Err(source) = stdin.write_all(prompt.as_bytes()).await {
-                if source.kind() != std::io::ErrorKind::BrokenPipe {
-                    return Err(CodexError::StdinWrite(source).into());
-                }
-            }
-            if let Err(source) = stdin.write_all(b"\n").await {
-                if source.kind() != std::io::ErrorKind::BrokenPipe {
-                    return Err(CodexError::StdinWrite(source).into());
-                }
-            }
-            if let Err(source) = stdin.shutdown().await {
-                if source.kind() != std::io::ErrorKind::BrokenPipe {
-                    return Err(CodexError::StdinWrite(source).into());
-                }
-            }
-        } else {
-            let _ = child.stdin.take();
-        }
-
-        let stdout = child.stdout.take().ok_or(CodexError::StdoutUnavailable)?;
-        let stderr = child.stderr.take().ok_or(CodexError::StderrUnavailable)?;
-
-        let (tx, rx) = mpsc::channel(32);
-        let json_log = jsonl::prepare_json_log(
-            json_event_log
-                .or_else(|| self.json_event_log.clone())
-                .filter(|path| !path.as_os_str().is_empty()),
-        )
-        .await?;
-        let stdout_task = tokio::spawn(jsonl::forward_json_events(
-            stdout,
-            tx,
-            self.mirror_stdout,
-            json_log,
-        ));
-        let stderr_task = tokio::spawn(tee_stream(stderr, ConsoleTarget::Stderr, !self.quiet));
-
-        let events = jsonl::EventChannelStream::new(rx, idle_timeout);
-        let timeout = self.timeout;
-        let schema_path = output_schema.clone();
-        let completion = Box::pin(async move {
-            let _dir_ctx = dir_ctx;
-            let wait_task = async move {
-                let status = child
-                    .wait()
-                    .await
-                    .map_err(|source| CodexError::Wait { source })?;
-                let stdout_result = stdout_task.await.map_err(CodexError::Join)?;
-                stdout_result?;
-                let stderr_bytes = stderr_task
-                    .await
-                    .map_err(CodexError::Join)?
-                    .map_err(CodexError::CaptureIo)?;
-                if !status.success() {
-                    return Err(CodexError::NonZeroExit {
-                        status,
-                        stderr: String::from_utf8(stderr_bytes).unwrap_or_default(),
-                    }
-                    .into());
-                }
-                let last_message = read_last_message(&last_message_path).await;
-                Ok(ExecCompletion {
-                    status,
-                    last_message_path: Some(last_message_path),
-                    last_message,
-                    schema_path,
-                })
-            };
-
-            if timeout.is_zero() {
-                wait_task.await
-            } else {
-                match time::timeout(timeout, wait_task).await {
-                    Ok(result) => result,
-                    Err(_) => Err(CodexError::Timeout { timeout }.into()),
-                }
-            }
-        });
-
-        Ok(ExecStream {
-            events: Box::pin(events),
-            completion,
-        })
-    }
-
-    /// Spawns a `codex login` session using the default ChatGPT OAuth flow.
-    ///
-    /// The returned child inherits `kill_on_drop` so abandoning the handle cleans up the login helper.
-    pub fn spawn_login_process(&self) -> Result<tokio::process::Child, CodexError> {
-        let mut command = Command::new(self.command_env.binary_path());
-        command
-            .arg("login")
-            .stdout(std::process::Stdio::piped())
-            .stderr(std::process::Stdio::piped())
-            .kill_on_drop(true);
-
-        self.command_env.apply(&mut command)?;
-
-        spawn_with_retry(&mut command, self.command_env.binary_path())
-    }
-
-    /// Spawns a `codex login --device-auth` session.
-    ///
-    /// The returned child inherits `kill_on_drop` so abandoning the handle cleans up the login helper.
-    pub fn spawn_device_auth_login_process(&self) -> Result<tokio::process::Child, CodexError> {
-        let mut command = Command::new(self.command_env.binary_path());
-        command
-            .arg("login")
-            .arg("--device-auth")
-            .stdout(std::process::Stdio::piped())
-            .stderr(std::process::Stdio::piped())
-            .kill_on_drop(true);
-
-        self.command_env.apply(&mut command)?;
-
-        spawn_with_retry(&mut command, self.command_env.binary_path())
-    }
-
-    /// Spawns a `codex login --with-api-key` session (interactive API-key flow).
-    ///
-    /// The returned child inherits `kill_on_drop` so abandoning the handle cleans up the login helper.
-    pub fn spawn_with_api_key_login_process(&self) -> Result<tokio::process::Child, CodexError> {
-        let mut command = Command::new(self.command_env.binary_path());
-        command
-            .arg("login")
-            .arg("--with-api-key")
-            .stdout(std::process::Stdio::piped())
-            .stderr(std::process::Stdio::piped())
-            .kill_on_drop(true);
-
-        self.command_env.apply(&mut command)?;
-
-        spawn_with_retry(&mut command, self.command_env.binary_path())
-    }
-
-    /// Spawns `codex login --mcp` when the probed binary advertises support.
-    ///
-    /// Returns `Ok(None)` when the capability is unknown or unsupported so
-    /// callers can degrade gracefully without attempting the flag.
-    pub async fn spawn_mcp_login_process(
-        &self,
-    ) -> Result<Option<tokio::process::Child>, CodexError> {
-        let capabilities = self.probe_capabilities().await;
-        let guard = capabilities.guard_mcp_login();
-        if !guard_is_supported(&guard) {
-            log_guard_skip(&guard);
-            return Ok(None);
-        }
-
-        let mut command = Command::new(self.command_env.binary_path());
-        command
-            .arg("login")
-            .arg("--mcp")
-            .stdout(std::process::Stdio::piped())
-            .stderr(std::process::Stdio::piped())
-            .kill_on_drop(true);
-
-        self.command_env.apply(&mut command)?;
-
-        let child = spawn_with_retry(&mut command, self.command_env.binary_path())?;
-
-        Ok(Some(child))
-    }
-
-    /// Logs in with a provided API key by invoking `codex login --api-key <key>`.
-    pub async fn login_with_api_key(
-        &self,
-        api_key: impl AsRef<str>,
-    ) -> Result<CodexAuthStatus, CodexError> {
-        let api_key = api_key.as_ref().trim();
-        if api_key.is_empty() {
-            return Err(CodexError::EmptyApiKey);
-        }
-
-        let output = self
-            .run_basic_command(["login", "--api-key", api_key])
-            .await?;
-        let combined = preferred_output_channel(&output);
-
-        if output.status.success() {
-            Ok(parse_login_success(&combined).unwrap_or_else(|| {
-                CodexAuthStatus::LoggedIn(CodexAuthMethod::Unknown {
-                    raw: combined.clone(),
-                })
-            }))
-        } else {
-            Err(CodexError::NonZeroExit {
-                status: output.status,
-                stderr: combined,
-            })
-        }
-    }
-
-    /// Returns the current Codex authentication state by invoking `codex login status`.
-    pub async fn login_status(&self) -> Result<CodexAuthStatus, CodexError> {
-        let output = self.run_basic_command(["login", "status"]).await?;
-        let combined = preferred_output_channel(&output);
-
-        if output.status.success() {
-            Ok(parse_login_success(&combined).unwrap_or_else(|| {
-                CodexAuthStatus::LoggedIn(CodexAuthMethod::Unknown {
-                    raw: combined.clone(),
-                })
-            }))
-        } else if combined.to_lowercase().contains("not logged in") {
-            Ok(CodexAuthStatus::LoggedOut)
-        } else {
-            Err(CodexError::NonZeroExit {
-                status: output.status,
-                stderr: combined,
-            })
-        }
-    }
-
-    /// Removes cached credentials via `codex logout`.
-    pub async fn logout(&self) -> Result<CodexLogoutStatus, CodexError> {
-        let output = self.run_basic_command(["logout"]).await?;
-        let combined = preferred_output_channel(&output);
-
-        if !output.status.success() {
-            return Err(CodexError::NonZeroExit {
-                status: output.status,
-                stderr: combined,
-            });
-        }
-
-        let normalized = combined.to_lowercase();
-        if normalized.contains("successfully logged out") {
-            Ok(CodexLogoutStatus::LoggedOut)
-        } else if normalized.contains("not logged in") {
-            Ok(CodexLogoutStatus::AlreadyLoggedOut)
-        } else {
-            Ok(CodexLogoutStatus::LoggedOut)
-        }
-    }
-
-    /// Applies a Codex diff by invoking `codex apply <TASK_ID>`.
-    ///
-    /// Stdout mirrors to the console when `mirror_stdout` is enabled; stderr mirrors unless `quiet`
-    /// is set. Output and exit status are always captured and returned, and `RUST_LOG=error` is
-    /// injected for the child process when the environment variable is unset.
-    ///
-    /// Convenience behavior: if `CODEX_TASK_ID` is set, it is appended as `<TASK_ID>`. When the
-    /// environment variable is missing, the subprocess is still spawned and will typically exit
-    /// non-zero with a "missing TASK_ID" error from the CLI.
-    pub async fn apply(&self) -> Result<ApplyDiffArtifacts, CodexError> {
-        let task_id = env::var_os("CODEX_TASK_ID")
-            .and_then(|v| normalize_non_empty(&v.to_string_lossy()).map(OsString::from));
-        self.apply_task_inner(task_id).await
-    }
-
-    /// Applies a Codex diff by task id via `codex apply <TASK_ID>`.
-    pub async fn apply_task(
-        &self,
-        task_id: impl AsRef<str>,
-    ) -> Result<ApplyDiffArtifacts, CodexError> {
-        let task_id = task_id.as_ref().trim();
-        if task_id.is_empty() {
-            return Err(CodexError::EmptyTaskId);
-        }
-        self.apply_task_inner(Some(OsString::from(task_id))).await
-    }
-
-    /// Shows a Codex Cloud task diff by invoking `codex cloud diff <TASK_ID>`.
-    ///
-    /// Mirrors stdout/stderr using the same `mirror_stdout`/`quiet` defaults as `apply`, but always
-    /// returns the captured output alongside the child exit status. Applies the same `RUST_LOG`
-    /// defaulting behavior when the variable is unset.
-    ///
-    /// Convenience behavior: if `CODEX_TASK_ID` is set, it is appended as `<TASK_ID>`. When the
-    /// environment variable is missing, the subprocess is still spawned and will typically exit
-    /// non-zero with a "missing TASK_ID" error from the CLI.
-    pub async fn diff(&self) -> Result<ApplyDiffArtifacts, CodexError> {
-        let task_id = env::var_os("CODEX_TASK_ID")
-            .and_then(|v| normalize_non_empty(&v.to_string_lossy()).map(OsString::from));
-        self.cloud_diff_task_inner(task_id).await
-    }
-
-    /// Shows a Codex Cloud task diff by task id via `codex cloud diff <TASK_ID>`.
-    pub async fn cloud_diff_task(
-        &self,
-        task_id: impl AsRef<str>,
-    ) -> Result<ApplyDiffArtifacts, CodexError> {
-        let task_id = task_id.as_ref().trim();
-        if task_id.is_empty() {
-            return Err(CodexError::EmptyTaskId);
-        }
-        self.cloud_diff_task_inner(Some(OsString::from(task_id)))
-            .await
-    }
-
-    async fn apply_task_inner(
-        &self,
-        task_id: Option<OsString>,
-    ) -> Result<ApplyDiffArtifacts, CodexError> {
-        let mut args = vec![OsString::from("apply")];
-        if let Some(task_id) = task_id {
-            args.push(task_id);
-        }
-        self.capture_codex_command(args, false).await
-    }
-
-    async fn cloud_diff_task_inner(
-        &self,
-        task_id: Option<OsString>,
-    ) -> Result<ApplyDiffArtifacts, CodexError> {
-        let mut args = vec![OsString::from("cloud"), OsString::from("diff")];
-        if let Some(task_id) = task_id {
-            args.push(task_id);
-        }
-        self.capture_codex_command(args, false).await
-    }
-
-    async fn capture_codex_command(
-        &self,
-        args: Vec<OsString>,
-        include_search: bool,
-    ) -> Result<ApplyDiffArtifacts, CodexError> {
-        let dir_ctx = self.directory_context()?;
-        let resolved_overrides = resolve_cli_overrides(
-            &self.cli_overrides,
-            &CliOverridesPatch::default(),
-            self.model.as_deref(),
-        );
-
-        let mut command = Command::new(self.command_env.binary_path());
-        command
-            .args(&args)
-            .stdout(std::process::Stdio::piped())
-            .stderr(std::process::Stdio::piped())
-            .kill_on_drop(true)
-            .current_dir(dir_ctx.path());
-
-        apply_cli_overrides(&mut command, &resolved_overrides, include_search);
-        self.command_env.apply(&mut command)?;
-
-        let mut child = spawn_with_retry(&mut command, self.command_env.binary_path())?;
-
-        let stdout = child.stdout.take().ok_or(CodexError::StdoutUnavailable)?;
-        let stderr = child.stderr.take().ok_or(CodexError::StderrUnavailable)?;
-
-        let stdout_task = tokio::spawn(tee_stream(
-            stdout,
-            ConsoleTarget::Stdout,
-            self.mirror_stdout,
-        ));
-        let stderr_task = tokio::spawn(tee_stream(stderr, ConsoleTarget::Stderr, !self.quiet));
-
-        let wait_task = async move {
-            let status = child
-                .wait()
-                .await
-                .map_err(|source| CodexError::Wait { source })?;
-            let stdout_bytes = stdout_task
-                .await
-                .map_err(CodexError::Join)?
-                .map_err(CodexError::CaptureIo)?;
-            let stderr_bytes = stderr_task
-                .await
-                .map_err(CodexError::Join)?
-                .map_err(CodexError::CaptureIo)?;
-            Ok::<_, CodexError>((status, stdout_bytes, stderr_bytes))
-        };
-
-        let (status, stdout_bytes, stderr_bytes) = if self.timeout.is_zero() {
-            wait_task.await?
-        } else {
-            match time::timeout(self.timeout, wait_task).await {
-                Ok(result) => result?,
-                Err(_) => {
-                    return Err(CodexError::Timeout {
-                        timeout: self.timeout,
-                    });
-                }
-            }
-        };
-
-        Ok(ApplyDiffArtifacts {
-            status,
-            stdout: String::from_utf8(stdout_bytes)?,
-            stderr: String::from_utf8(stderr_bytes)?,
-        })
-    }
-
-    /// Generates app-server bindings via `codex app-server generate-ts` or `generate-json-schema`.
-    ///
-    /// Ensures the output directory exists, mirrors stdout/stderr according to the builder
-    /// (`mirror_stdout` / `quiet`), and returns captured output plus the exit status. Non-zero
-    /// exits bubble up as [`CodexError::NonZeroExit`] with stderr attached. Use
-    /// [`AppServerCodegenRequest::prettier`] to format TypeScript output with a specific
-    /// Prettier binary and request-level overrides for config/profile toggles.
-    pub async fn generate_app_server_bindings(
-        &self,
-        request: AppServerCodegenRequest,
-    ) -> Result<AppServerCodegenOutput, CodexError> {
-        let AppServerCodegenRequest {
-            target,
-            out_dir,
-            overrides,
-        } = request;
-
-        std_fs::create_dir_all(&out_dir).map_err(|source| CodexError::PrepareOutputDirectory {
-            path: out_dir.clone(),
-            source,
-        })?;
-
-        let dir_ctx = self.directory_context()?;
-        let resolved_overrides =
-            resolve_cli_overrides(&self.cli_overrides, &overrides, self.model.as_deref());
-
-        let mut command = Command::new(self.command_env.binary_path());
-        command
-            .arg("app-server")
-            .arg(target.subcommand())
-            .arg("--out")
-            .arg(&out_dir)
-            .stdout(std::process::Stdio::piped())
-            .stderr(std::process::Stdio::piped())
-            .kill_on_drop(true)
-            .current_dir(dir_ctx.path());
-
-        apply_cli_overrides(&mut command, &resolved_overrides, true);
-
-        if let Some(prettier) = target.prettier() {
-            command.arg("--prettier").arg(prettier);
-        }
-
-        self.command_env.apply(&mut command)?;
-
-        let mut child = spawn_with_retry(&mut command, self.command_env.binary_path())?;
-
-        let stdout = child.stdout.take().ok_or(CodexError::StdoutUnavailable)?;
-        let stderr = child.stderr.take().ok_or(CodexError::StderrUnavailable)?;
-
-        let stdout_task = tokio::spawn(tee_stream(
-            stdout,
-            ConsoleTarget::Stdout,
-            self.mirror_stdout,
-        ));
-        let stderr_task = tokio::spawn(tee_stream(stderr, ConsoleTarget::Stderr, !self.quiet));
-
-        let wait_task = async move {
-            let status = child
-                .wait()
-                .await
-                .map_err(|source| CodexError::Wait { source })?;
-            let stdout_bytes = stdout_task
-                .await
-                .map_err(CodexError::Join)?
-                .map_err(CodexError::CaptureIo)?;
-            let stderr_bytes = stderr_task
-                .await
-                .map_err(CodexError::Join)?
-                .map_err(CodexError::CaptureIo)?;
-            Ok::<_, CodexError>((status, stdout_bytes, stderr_bytes))
-        };
-
-        let (status, stdout_bytes, stderr_bytes) = if self.timeout.is_zero() {
-            wait_task.await?
-        } else {
-            match time::timeout(self.timeout, wait_task).await {
-                Ok(result) => result?,
-                Err(_) => {
-                    return Err(CodexError::Timeout {
-                        timeout: self.timeout,
-                    });
-                }
-            }
-        };
-
-        if !status.success() {
-            return Err(CodexError::NonZeroExit {
-                status,
-                stderr: String::from_utf8(stderr_bytes)?,
-            });
-        }
-
-        Ok(AppServerCodegenOutput {
-            status,
-            stdout: String::from_utf8(stdout_bytes)?,
-            stderr: String::from_utf8(stderr_bytes)?,
-            out_dir,
-        })
-    }
-
-    /// Lists CLI features via `codex features list`.
-    ///
-    /// Requests JSON output when `json(true)` is set and falls back to parsing the text table when
-    /// JSON is unavailable. Shared config/profile/search/approval overrides flow through via the
-    /// request/builder, stdout/stderr are mirrored according to the builder, and non-zero exits
-    /// surface as [`CodexError::NonZeroExit`].
-    pub async fn list_features(
-        &self,
-        request: FeaturesListRequest,
-    ) -> Result<FeaturesListOutput, CodexError> {
-        let FeaturesListRequest { json, overrides } = request;
-
-        let dir_ctx = self.directory_context()?;
-        let resolved_overrides =
-            resolve_cli_overrides(&self.cli_overrides, &overrides, self.model.as_deref());
-
-        let mut command = Command::new(self.command_env.binary_path());
-        command
-            .arg("features")
-            .arg("list")
-            .stdout(std::process::Stdio::piped())
-            .stderr(std::process::Stdio::piped())
-            .kill_on_drop(true)
-            .current_dir(dir_ctx.path());
-
-        apply_cli_overrides(&mut command, &resolved_overrides, true);
-
-        if json {
-            command.arg("--json");
-        }
-
-        self.command_env.apply(&mut command)?;
-
-        let mut child = spawn_with_retry(&mut command, self.command_env.binary_path())?;
-
-        let stdout = child.stdout.take().ok_or(CodexError::StdoutUnavailable)?;
-        let stderr = child.stderr.take().ok_or(CodexError::StderrUnavailable)?;
-
-        let stdout_task = tokio::spawn(tee_stream(
-            stdout,
-            ConsoleTarget::Stdout,
-            self.mirror_stdout,
-        ));
-        let stderr_task = tokio::spawn(tee_stream(stderr, ConsoleTarget::Stderr, !self.quiet));
-
-        let wait_task = async move {
-            let status = child
-                .wait()
-                .await
-                .map_err(|source| CodexError::Wait { source })?;
-            let stdout_bytes = stdout_task
-                .await
-                .map_err(CodexError::Join)?
-                .map_err(CodexError::CaptureIo)?;
-            let stderr_bytes = stderr_task
-                .await
-                .map_err(CodexError::Join)?
-                .map_err(CodexError::CaptureIo)?;
-            Ok::<_, CodexError>((status, stdout_bytes, stderr_bytes))
-        };
-
-        let (status, stdout_bytes, stderr_bytes) = if self.timeout.is_zero() {
-            wait_task.await?
-        } else {
-            match time::timeout(self.timeout, wait_task).await {
-                Ok(result) => result?,
-                Err(_) => {
-                    return Err(CodexError::Timeout {
-                        timeout: self.timeout,
-                    });
-                }
-            }
-        };
-
-        if !status.success() {
-            return Err(CodexError::NonZeroExit {
-                status,
-                stderr: String::from_utf8(stderr_bytes)?,
-            });
-        }
-
-        let stdout_string = String::from_utf8(stdout_bytes)?;
-        let stderr_string = String::from_utf8(stderr_bytes)?;
-        let (features, format) =
-            parse_feature_list_output(&stdout_string, json).map_err(|reason| {
-                CodexError::FeatureListParse {
-                    reason,
-                    stdout: stdout_string.clone(),
-                }
-            })?;
-
-        Ok(FeaturesListOutput {
-            status,
-            stdout: stdout_string,
-            stderr: stderr_string,
-            features,
-            format,
-        })
-    }
-
-    /// Runs `codex features` and returns captured output.
-    pub async fn features(
-        &self,
-        request: FeaturesCommandRequest,
-    ) -> Result<ApplyDiffArtifacts, CodexError> {
-        self.run_simple_command_with_overrides(vec![OsString::from("features")], request.overrides)
-            .await
-    }
-
-    /// Runs `codex <scope> help [COMMAND]...` and returns captured output.
-    pub async fn help(
-        &self,
-        request: HelpCommandRequest,
-    ) -> Result<ApplyDiffArtifacts, CodexError> {
-        let mut args: Vec<OsString> = request
-            .scope
-            .argv_prefix()
-            .iter()
-            .map(|value| OsString::from(*value))
-            .collect();
-        args.extend(request.command.into_iter().map(OsString::from));
-        self.run_simple_command_with_overrides(args, request.overrides)
-            .await
-    }
-
-    /// Runs `codex review [OPTIONS] [PROMPT]` and returns captured output.
-    pub async fn review(
-        &self,
-        request: ReviewCommandRequest,
-    ) -> Result<ApplyDiffArtifacts, CodexError> {
-        if matches!(request.prompt.as_deref(), Some(prompt) if prompt.trim().is_empty()) {
-            return Err(CodexError::EmptyPrompt);
-        }
-
-        let mut args = vec![OsString::from("review")];
-        if let Some(base) = request.base {
-            if !base.trim().is_empty() {
-                args.push(OsString::from("--base"));
-                args.push(OsString::from(base));
-            }
-        }
-        if let Some(commit) = request.commit {
-            if !commit.trim().is_empty() {
-                args.push(OsString::from("--commit"));
-                args.push(OsString::from(commit));
-            }
-        }
-        if let Some(title) = request.title {
-            if !title.trim().is_empty() {
-                args.push(OsString::from("--title"));
-                args.push(OsString::from(title));
-            }
-        }
-        if request.uncommitted {
-            args.push(OsString::from("--uncommitted"));
-        }
-        if let Some(prompt) = request.prompt {
-            if !prompt.trim().is_empty() {
-                args.push(OsString::from(prompt));
-            }
-        }
-
-        self.run_simple_command_with_overrides(args, request.overrides)
-            .await
-    }
-
-    /// Runs `codex exec review [OPTIONS] [PROMPT]` and returns captured output.
-    pub async fn exec_review(
-        &self,
-        request: ExecReviewCommandRequest,
-    ) -> Result<ApplyDiffArtifacts, CodexError> {
-        if matches!(request.prompt.as_deref(), Some(prompt) if prompt.trim().is_empty()) {
-            return Err(CodexError::EmptyPrompt);
-        }
-
-        let mut args = vec![OsString::from("exec"), OsString::from("review")];
-        if let Some(base) = request.base {
-            if !base.trim().is_empty() {
-                args.push(OsString::from("--base"));
-                args.push(OsString::from(base));
-            }
-        }
-        if let Some(commit) = request.commit {
-            if !commit.trim().is_empty() {
-                args.push(OsString::from("--commit"));
-                args.push(OsString::from(commit));
-            }
-        }
-        if request.json {
-            args.push(OsString::from("--json"));
-        }
-        if request.skip_git_repo_check {
-            args.push(OsString::from("--skip-git-repo-check"));
-        }
-        if let Some(title) = request.title {
-            if !title.trim().is_empty() {
-                args.push(OsString::from("--title"));
-                args.push(OsString::from(title));
-            }
-        }
-        if request.uncommitted {
-            args.push(OsString::from("--uncommitted"));
-        }
-        if let Some(prompt) = request.prompt {
-            if !prompt.trim().is_empty() {
-                args.push(OsString::from(prompt));
-            }
-        }
-
-        self.run_simple_command_with_overrides(args, request.overrides)
-            .await
-    }
-
-    /// Runs `codex resume [OPTIONS] [SESSION_ID] [PROMPT]` and returns captured output.
-    pub async fn resume_session(
-        &self,
-        request: ResumeSessionRequest,
-    ) -> Result<ApplyDiffArtifacts, CodexError> {
-        if matches!(request.prompt.as_deref(), Some(prompt) if prompt.trim().is_empty()) {
-            return Err(CodexError::EmptyPrompt);
-        }
-
-        let mut args = vec![OsString::from("resume")];
-        if request.all {
-            args.push(OsString::from("--all"));
-        }
-        if request.last {
-            args.push(OsString::from("--last"));
-        }
-        if let Some(session_id) = request.session_id {
-            if !session_id.trim().is_empty() {
-                args.push(OsString::from(session_id));
-            }
-        }
-        if let Some(prompt) = request.prompt {
-            if !prompt.trim().is_empty() {
-                args.push(OsString::from(prompt));
-            }
-        }
-
-        self.run_simple_command_with_overrides(args, request.overrides)
-            .await
-    }
-
-    /// Runs `codex fork [OPTIONS] [SESSION_ID] [PROMPT]` and returns captured output.
-    pub async fn fork_session(
-        &self,
-        request: ForkSessionRequest,
-    ) -> Result<ApplyDiffArtifacts, CodexError> {
-        if matches!(request.prompt.as_deref(), Some(prompt) if prompt.trim().is_empty()) {
-            return Err(CodexError::EmptyPrompt);
-        }
-
-        let mut args = vec![OsString::from("fork")];
-        if request.all {
-            args.push(OsString::from("--all"));
-        }
-        if request.last {
-            args.push(OsString::from("--last"));
-        }
-        if let Some(session_id) = request.session_id {
-            if !session_id.trim().is_empty() {
-                args.push(OsString::from(session_id));
-            }
-        }
-        if let Some(prompt) = request.prompt {
-            if !prompt.trim().is_empty() {
-                args.push(OsString::from(prompt));
-            }
-        }
-
-        self.run_simple_command_with_overrides(args, request.overrides)
-            .await
-    }
-
-    /// Runs `codex cloud --help` and returns captured output.
-    pub async fn cloud_overview(
-        &self,
-        request: CloudOverviewRequest,
-    ) -> Result<ApplyDiffArtifacts, CodexError> {
-        self.run_simple_command_with_overrides(
-            vec![OsString::from("cloud"), OsString::from("--help")],
-            request.overrides,
-        )
-        .await
-    }
-
-    /// Lists Codex Cloud tasks via `codex cloud list`.
-    pub async fn cloud_list(
-        &self,
-        request: CloudListRequest,
-    ) -> Result<CloudListOutput, CodexError> {
-        let CloudListRequest {
-            json,
-            env_id,
-            limit,
-            cursor,
-            overrides,
-        } = request;
-
-        let mut args = vec![OsString::from("cloud"), OsString::from("list")];
-        if let Some(env_id) = env_id {
-            args.push(OsString::from("--env"));
-            args.push(OsString::from(env_id));
-        }
-        if let Some(limit) = limit {
-            args.push(OsString::from("--limit"));
-            args.push(OsString::from(limit.to_string()));
-        }
-        if let Some(cursor) = cursor {
-            args.push(OsString::from("--cursor"));
-            args.push(OsString::from(cursor));
-        }
-        if json {
-            args.push(OsString::from("--json"));
-        }
-
-        let artifacts = self
-            .run_simple_command_with_overrides(args, overrides)
-            .await?;
-        let parsed = if json {
-            Some(serde_json::from_str(&artifacts.stdout).map_err(|source| {
-                CodexError::JsonParse {
-                    context: "cloud list",
-                    stdout: artifacts.stdout.clone(),
-                    source,
-                }
-            })?)
-        } else {
-            None
-        };
-
-        Ok(CloudListOutput {
-            status: artifacts.status,
-            stdout: artifacts.stdout,
-            stderr: artifacts.stderr,
-            json: parsed,
-        })
-    }
-
-    /// Shows the status of a Codex Cloud task via `codex cloud status <TASK_ID>`.
-    pub async fn cloud_status(
-        &self,
-        request: CloudStatusRequest,
-    ) -> Result<ApplyDiffArtifacts, CodexError> {
-        let task_id = request.task_id.trim();
-        if task_id.is_empty() {
-            return Err(CodexError::EmptyTaskId);
-        }
-
-        self.run_simple_command_with_overrides(
-            vec![
-                OsString::from("cloud"),
-                OsString::from("status"),
-                OsString::from(task_id),
-            ],
-            request.overrides,
-        )
-        .await
-    }
-
-    /// Shows the unified diff for a Codex Cloud task via `codex cloud diff [--attempt N] <TASK_ID>`.
-    pub async fn cloud_diff(
-        &self,
-        request: CloudDiffRequest,
-    ) -> Result<ApplyDiffArtifacts, CodexError> {
-        let task_id = request.task_id.trim();
-        if task_id.is_empty() {
-            return Err(CodexError::EmptyTaskId);
-        }
-
-        let mut args = vec![OsString::from("cloud"), OsString::from("diff")];
-        if let Some(attempt) = request.attempt {
-            args.push(OsString::from("--attempt"));
-            args.push(OsString::from(attempt.to_string()));
-        }
-        args.push(OsString::from(task_id));
-        self.run_simple_command_with_overrides(args, request.overrides)
-            .await
-    }
-
-    /// Applies the diff for a Codex Cloud task locally via `codex cloud apply [--attempt N] <TASK_ID>`.
-    pub async fn cloud_apply(
-        &self,
-        request: CloudApplyRequest,
-    ) -> Result<ApplyDiffArtifacts, CodexError> {
-        let task_id = request.task_id.trim();
-        if task_id.is_empty() {
-            return Err(CodexError::EmptyTaskId);
-        }
-
-        let mut args = vec![OsString::from("cloud"), OsString::from("apply")];
-        if let Some(attempt) = request.attempt {
-            args.push(OsString::from("--attempt"));
-            args.push(OsString::from(attempt.to_string()));
-        }
-        args.push(OsString::from(task_id));
-        self.run_simple_command_with_overrides(args, request.overrides)
-            .await
-    }
-
-    /// Submits a new Codex Cloud task via `codex cloud exec`.
-    pub async fn cloud_exec(
-        &self,
-        request: CloudExecRequest,
-    ) -> Result<ApplyDiffArtifacts, CodexError> {
-        let env_id = request.env_id.trim();
-        if env_id.is_empty() {
-            return Err(CodexError::EmptyEnvId);
-        }
-
-        let mut args = vec![OsString::from("cloud"), OsString::from("exec")];
-        args.push(OsString::from("--env"));
-        args.push(OsString::from(env_id));
-        if let Some(attempts) = request.attempts {
-            args.push(OsString::from("--attempts"));
-            args.push(OsString::from(attempts.to_string()));
-        }
-        if let Some(branch) = request.branch {
-            args.push(OsString::from("--branch"));
-            args.push(OsString::from(branch));
-        }
-        if let Some(query) = request.query {
-            args.push(OsString::from(query));
-        }
-
-        self.run_simple_command_with_overrides(args, request.overrides)
-            .await
-    }
-
-    /// Runs `codex mcp --help` and returns captured output.
-    pub async fn mcp_overview(
-        &self,
-        request: McpOverviewRequest,
-    ) -> Result<ApplyDiffArtifacts, CodexError> {
-        self.run_simple_command_with_overrides(
-            vec![OsString::from("mcp"), OsString::from("--help")],
-            request.overrides,
-        )
-        .await
-    }
-
-    /// Lists configured MCP servers via `codex mcp list`.
-    pub async fn mcp_list(&self, request: McpListRequest) -> Result<McpListOutput, CodexError> {
-        let McpListRequest { json, overrides } = request;
-        let mut args = vec![OsString::from("mcp"), OsString::from("list")];
-        if json {
-            args.push(OsString::from("--json"));
-        }
-
-        let artifacts = self
-            .run_simple_command_with_overrides(args, overrides)
-            .await?;
-        let parsed = if json {
-            Some(serde_json::from_str(&artifacts.stdout).map_err(|source| {
-                CodexError::JsonParse {
-                    context: "mcp list",
-                    stdout: artifacts.stdout.clone(),
-                    source,
-                }
-            })?)
-        } else {
-            None
-        };
-
-        Ok(McpListOutput {
-            status: artifacts.status,
-            stdout: artifacts.stdout,
-            stderr: artifacts.stderr,
-            json: parsed,
-        })
-    }
-
-    /// Gets a configured MCP server entry via `codex mcp get <NAME>`.
-    pub async fn mcp_get(&self, request: McpGetRequest) -> Result<McpListOutput, CodexError> {
-        let name = request.name.trim();
-        if name.is_empty() {
-            return Err(CodexError::EmptyMcpServerName);
-        }
-
-        let mut args = vec![OsString::from("mcp"), OsString::from("get")];
-        if request.json {
-            args.push(OsString::from("--json"));
-        }
-        args.push(OsString::from(name));
-
-        let artifacts = self
-            .run_simple_command_with_overrides(args, request.overrides)
-            .await?;
-        let parsed = if request.json {
-            Some(serde_json::from_str(&artifacts.stdout).map_err(|source| {
-                CodexError::JsonParse {
-                    context: "mcp get",
-                    stdout: artifacts.stdout.clone(),
-                    source,
-                }
-            })?)
-        } else {
-            None
-        };
-
-        Ok(McpListOutput {
-            status: artifacts.status,
-            stdout: artifacts.stdout,
-            stderr: artifacts.stderr,
-            json: parsed,
-        })
-    }
-
-    /// Adds an MCP server configuration entry via `codex mcp add`.
-    pub async fn mcp_add(&self, request: McpAddRequest) -> Result<ApplyDiffArtifacts, CodexError> {
-        let name = request.name.trim();
-        if name.is_empty() {
-            return Err(CodexError::EmptyMcpServerName);
-        }
-
-        let mut args = vec![
-            OsString::from("mcp"),
-            OsString::from("add"),
-            OsString::from(name),
-        ];
-        match request.transport {
-            McpAddTransport::StreamableHttp {
-                url,
-                bearer_token_env_var,
-            } => {
-                let url = url.trim();
-                if url.is_empty() {
-                    return Err(CodexError::EmptyMcpUrl);
-                }
-                args.push(OsString::from("--url"));
-                args.push(OsString::from(url));
-                if let Some(env_var) = bearer_token_env_var {
-                    if !env_var.trim().is_empty() {
-                        args.push(OsString::from("--bearer-token-env-var"));
-                        args.push(OsString::from(env_var));
-                    }
-                }
-            }
-            McpAddTransport::Stdio { env, command } => {
-                if command.is_empty() {
-                    return Err(CodexError::EmptyMcpCommand);
-                }
-                for (key, value) in env {
-                    let key = key.trim();
-                    if key.is_empty() {
-                        continue;
-                    }
-                    args.push(OsString::from("--env"));
-                    args.push(OsString::from(format!("{key}={value}")));
-                }
-                args.push(OsString::from("--"));
-                args.extend(command);
-            }
-        }
-
-        self.run_simple_command_with_overrides(args, request.overrides)
-            .await
-    }
-
-    /// Removes an MCP server configuration entry via `codex mcp remove <NAME>`.
-    pub async fn mcp_remove(
-        &self,
-        request: McpRemoveRequest,
-    ) -> Result<ApplyDiffArtifacts, CodexError> {
-        let name = request.name.trim();
-        if name.is_empty() {
-            return Err(CodexError::EmptyMcpServerName);
-        }
-
-        self.run_simple_command_with_overrides(
-            vec![
-                OsString::from("mcp"),
-                OsString::from("remove"),
-                OsString::from(name),
-            ],
-            request.overrides,
-        )
-        .await
-    }
-
-    /// Deauthenticates from an MCP server via `codex mcp logout <NAME>`.
-    pub async fn mcp_logout(
-        &self,
-        request: McpLogoutRequest,
-    ) -> Result<ApplyDiffArtifacts, CodexError> {
-        let name = request.name.trim();
-        if name.is_empty() {
-            return Err(CodexError::EmptyMcpServerName);
-        }
-
-        self.run_simple_command_with_overrides(
-            vec![
-                OsString::from("mcp"),
-                OsString::from("logout"),
-                OsString::from(name),
-            ],
-            request.overrides,
-        )
-        .await
-    }
-
-    /// Spawns `codex mcp login <NAME> [--scopes ...]`.
-    pub fn spawn_mcp_oauth_login_process(
-        &self,
-        request: McpOauthLoginRequest,
-    ) -> Result<tokio::process::Child, CodexError> {
-        let name = request.name.trim();
-        if name.is_empty() {
-            return Err(CodexError::EmptyMcpServerName);
-        }
-
-        let resolved_overrides = resolve_cli_overrides(
-            &self.cli_overrides,
-            &request.overrides,
-            self.model.as_deref(),
-        );
-
-        let mut command = Command::new(self.command_env.binary_path());
-        command
-            .arg("mcp")
-            .arg("login")
-            .arg(name)
-            .stdout(std::process::Stdio::piped())
-            .stderr(std::process::Stdio::piped())
-            .kill_on_drop(true);
-
-        if !request.scopes.is_empty() {
-            command.arg("--scopes").arg(request.scopes.join(","));
-        }
-
-        apply_cli_overrides(&mut command, &resolved_overrides, true);
-        self.command_env.apply(&mut command)?;
-
-        spawn_with_retry(&mut command, self.command_env.binary_path())
-    }
-
-    /// Starts the `codex responses-api-proxy` helper with a supplied API key.
-    ///
-    /// Forwards optional `--port`, `--server-info`, `--http-shutdown`, and `--upstream-url` flags.
-    /// The API key is written to stdin immediately after spawn, stdout/stderr remain piped for callers
-    /// to drain, and the returned handle owns the child process plus any `--server-info` path used.
-    pub async fn start_responses_api_proxy(
-        &self,
-        request: ResponsesApiProxyRequest,
-    ) -> Result<ResponsesApiProxyHandle, CodexError> {
-        let ResponsesApiProxyRequest {
-            api_key,
-            port,
-            server_info_path,
-            http_shutdown,
-            upstream_url,
-        } = request;
-
-        let api_key = api_key.trim().to_string();
-        if api_key.is_empty() {
-            return Err(CodexError::EmptyApiKey);
-        }
-
-        let working_dir = self.sandbox_working_dir(None)?;
-
-        let mut command = Command::new(self.command_env.binary_path());
-        command
-            .arg("responses-api-proxy")
-            .stdin(std::process::Stdio::piped())
-            .stdout(std::process::Stdio::piped())
-            .stderr(std::process::Stdio::piped())
-            .kill_on_drop(true)
-            .current_dir(&working_dir);
-
-        if let Some(port) = port {
-            command.arg("--port").arg(port.to_string());
-        }
-
-        if let Some(path) = server_info_path.as_ref() {
-            command.arg("--server-info").arg(path);
-        }
-
-        if http_shutdown {
-            command.arg("--http-shutdown");
-        }
-
-        if let Some(url) = upstream_url.as_ref() {
-            if !url.trim().is_empty() {
-                command.arg("--upstream-url").arg(url);
-            }
-        }
-
-        self.command_env.apply(&mut command)?;
-
-        let mut child = spawn_with_retry(&mut command, self.command_env.binary_path())?;
-
-        let mut stdin = child.stdin.take().ok_or(CodexError::StdinUnavailable)?;
-        stdin
-            .write_all(api_key.as_bytes())
-            .await
-            .map_err(CodexError::StdinWrite)?;
-        stdin
-            .write_all(b"\n")
-            .await
-            .map_err(CodexError::StdinWrite)?;
-        stdin.shutdown().await.map_err(CodexError::StdinWrite)?;
-
-        Ok(ResponsesApiProxyHandle {
-            child,
-            server_info_path,
-        })
-    }
-
-    /// Spawns `codex stdio-to-uds <SOCKET_PATH>` with piped stdio for manual relays.
-    ///
-    /// Returns the child process so callers can write to stdin/read from stdout (e.g., to bridge a
-    /// JSON-RPC transport over a Unix domain socket). Fails fast on empty socket paths and inherits
-    /// the builder working directory when none is provided on the request.
-    pub fn stdio_to_uds(
-        &self,
-        request: StdioToUdsRequest,
-    ) -> Result<tokio::process::Child, CodexError> {
-        let StdioToUdsRequest {
-            socket_path,
-            working_dir,
-        } = request;
-
-        if socket_path.as_os_str().is_empty() {
-            return Err(CodexError::EmptySocketPath);
-        }
-
-        let mut command = Command::new(self.command_env.binary_path());
-        command
-            .arg("stdio-to-uds")
-            .arg(&socket_path)
-            .stdin(std::process::Stdio::piped())
-            .stdout(std::process::Stdio::piped())
-            .stderr(std::process::Stdio::piped())
-            .kill_on_drop(true)
-            .current_dir(self.sandbox_working_dir(working_dir)?);
-
-        self.command_env.apply(&mut command)?;
-
-        spawn_with_retry(&mut command, self.command_env.binary_path())
-    }
-
-    /// Runs `codex sandbox <platform> [--full-auto|--log-denials] [--config/--enable/--disable] -- <COMMAND...>`.
-    ///
-    /// Captures stdout/stderr and mirrors them according to the builder (`mirror_stdout` / `quiet`). Unlike
-    /// `apply`/`diff`, non-zero exit codes are returned in [`SandboxRun::status`] without being wrapped in
-    /// [`CodexError::NonZeroExit`]. macOS denial logging is enabled via [`SandboxCommandRequest::log_denials`]
-    /// and ignored on other platforms. Linux uses the bundled `codex-linux-sandbox` helper; Windows sandboxing
-    /// is experimental and relies on the upstream helper. The wrapper does not gate availabilityunsupported
-    /// installs will surface as non-zero statuses.
-    pub async fn run_sandbox(
-        &self,
-        request: SandboxCommandRequest,
-    ) -> Result<SandboxRun, CodexError> {
-        if request.command.is_empty() {
-            return Err(CodexError::EmptySandboxCommand);
-        }
-
-        let SandboxCommandRequest {
-            platform,
-            command,
-            full_auto,
-            log_denials,
-            config_overrides,
-            feature_toggles,
-            working_dir,
-        } = request;
-
-        let working_dir = self.sandbox_working_dir(working_dir)?;
-
-        let mut process = Command::new(self.command_env.binary_path());
-        process
-            .arg("sandbox")
-            .arg(platform.subcommand())
-            .stdout(std::process::Stdio::piped())
-            .stderr(std::process::Stdio::piped())
-            .kill_on_drop(true)
-            .current_dir(&working_dir);
-
-        if full_auto {
-            process.arg("--full-auto");
-        }
-
-        if log_denials && matches!(platform, SandboxPlatform::Macos) {
-            process.arg("--log-denials");
-        }
-
-        for override_ in config_overrides {
-            process.arg("--config");
-            process.arg(format!("{}={}", override_.key, override_.value));
-        }
-
-        for feature in feature_toggles.enable {
-            process.arg("--enable");
-            process.arg(feature);
-        }
-
-        for feature in feature_toggles.disable {
-            process.arg("--disable");
-            process.arg(feature);
-        }
-
-        process.arg("--");
-        process.args(&command);
-
-        self.command_env.apply(&mut process)?;
-
-        let mut child = spawn_with_retry(&mut process, self.command_env.binary_path())?;
-
-        let stdout = child.stdout.take().ok_or(CodexError::StdoutUnavailable)?;
-        let stderr = child.stderr.take().ok_or(CodexError::StderrUnavailable)?;
-
-        let stdout_task = tokio::spawn(tee_stream(
-            stdout,
-            ConsoleTarget::Stdout,
-            self.mirror_stdout,
-        ));
-        let stderr_task = tokio::spawn(tee_stream(stderr, ConsoleTarget::Stderr, !self.quiet));
-
-        let wait_task = async move {
-            let status = child
-                .wait()
-                .await
-                .map_err(|source| CodexError::Wait { source })?;
-            let stdout_bytes = stdout_task
-                .await
-                .map_err(CodexError::Join)?
-                .map_err(CodexError::CaptureIo)?;
-            let stderr_bytes = stderr_task
-                .await
-                .map_err(CodexError::Join)?
-                .map_err(CodexError::CaptureIo)?;
-            Ok::<_, CodexError>((status, stdout_bytes, stderr_bytes))
-        };
-
-        let (status, stdout_bytes, stderr_bytes) = if self.timeout.is_zero() {
-            wait_task.await?
-        } else {
-            match time::timeout(self.timeout, wait_task).await {
-                Ok(result) => result?,
-                Err(_) => {
-                    return Err(CodexError::Timeout {
-                        timeout: self.timeout,
-                    });
-                }
-            }
-        };
-
-        Ok(SandboxRun {
-            status,
-            stdout: String::from_utf8(stdout_bytes)?,
-            stderr: String::from_utf8(stderr_bytes)?,
-        })
-    }
-
-    /// Probes the configured binary for version/build metadata and supported feature flags.
-    ///
-    /// Results are cached per canonical binary path and invalidated when file metadata changes.
-    /// Caller-supplied overrides (see [`CodexClientBuilder::capability_overrides`]) can
-    /// short-circuit probes or layer hints; snapshots are still cached against the current
-    /// binary fingerprint so changes on disk trigger revalidation. Missing fingerprints skip
-    /// cache reuse to force a re-probe. Cache interaction follows the policy configured on
-    /// the builder (see [`CodexClientBuilder::capability_cache_policy`]).
-    /// Failures are logged and return conservative defaults so callers can gate optional flags.
-    pub async fn probe_capabilities(&self) -> CodexCapabilities {
-        self.probe_capabilities_with_policy(self.capability_cache_policy)
-            .await
-    }
-
-    /// Probes capabilities with an explicit cache policy.
-    pub async fn probe_capabilities_with_policy(
-        &self,
-        cache_policy: CapabilityCachePolicy,
-    ) -> CodexCapabilities {
-        let cache_key = capability_cache_key(self.command_env.binary_path());
-        let fingerprint = current_fingerprint(&cache_key);
-        let overrides = &self.capability_overrides;
-
-        let cache_reads_enabled = matches!(cache_policy, CapabilityCachePolicy::PreferCache)
-            && has_fingerprint_metadata(&fingerprint);
-        let cache_writes_enabled = !matches!(cache_policy, CapabilityCachePolicy::Bypass)
-            && has_fingerprint_metadata(&fingerprint);
-
-        if let Some(snapshot) = overrides.snapshot.clone() {
-            let capabilities = finalize_capabilities_with_overrides(
-                snapshot,
-                overrides,
-                cache_key.clone(),
-                fingerprint.clone(),
-                true,
-            );
-            if cache_writes_enabled {
-                update_capability_cache(capabilities.clone());
-            }
-            return capabilities;
-        }
-
-        if cache_reads_enabled {
-            if let Some(cached) = cached_capabilities(&cache_key, &fingerprint) {
-                if overrides.is_empty() {
-                    return cached;
-                }
-                let merged = finalize_capabilities_with_overrides(
-                    cached,
-                    overrides,
-                    cache_key.clone(),
-                    fingerprint.clone(),
-                    false,
-                );
-                if cache_writes_enabled {
-                    update_capability_cache(merged.clone());
-                }
-                return merged;
-            }
-        }
-
-        let probed = self
-            .probe_capabilities_uncached(&cache_key, fingerprint.clone())
-            .await;
-
-        let capabilities =
-            finalize_capabilities_with_overrides(probed, overrides, cache_key, fingerprint, false);
-
-        if cache_writes_enabled {
-            update_capability_cache(capabilities.clone());
-        }
-
-        capabilities
-    }
-
-    async fn probe_capabilities_uncached(
-        &self,
-        cache_key: &CapabilityCacheKey,
-        fingerprint: Option<BinaryFingerprint>,
-    ) -> CodexCapabilities {
-        let mut plan = CapabilityProbePlan::default();
-        let mut features = CodexFeatureFlags::default();
-        let mut version = None;
-
-        plan.steps.push(CapabilityProbeStep::VersionFlag);
-        match self.run_basic_command(["--version"]).await {
-            Ok(output) => {
-                if !output.status.success() {
-                    warn!(
-                        status = ?output.status,
-                        binary = ?cache_key.binary_path,
-                        "codex --version exited non-zero"
-                    );
-                }
-                let text = command_output_text(&output);
-                if !text.trim().is_empty() {
-                    version = Some(parse_version_output(&text));
-                }
-            }
-            Err(error) => warn!(
-                ?error,
-                binary = ?cache_key.binary_path,
-                "codex --version probe failed"
-            ),
-        }
-
-        let mut parsed_features = false;
-
-        plan.steps.push(CapabilityProbeStep::FeaturesListJson);
-        match self.run_basic_command(["features", "list", "--json"]).await {
-            Ok(output) => {
-                if !output.status.success() {
-                    warn!(
-                        status = ?output.status,
-                        binary = ?cache_key.binary_path,
-                        "codex features list --json exited non-zero"
-                    );
-                }
-                if output.status.success() {
-                    features.supports_features_list = true;
-                }
-                let text = command_output_text(&output);
-                if let Some(parsed) = parse_features_from_json(&text) {
-                    merge_feature_flags(&mut features, parsed);
-                    parsed_features = detected_feature_flags(&features);
-                } else if !text.is_empty() {
-                    let parsed = parse_features_from_text(&text);
-                    merge_feature_flags(&mut features, parsed);
-                    parsed_features = detected_feature_flags(&features);
-                }
-            }
-            Err(error) => warn!(
-                ?error,
-                binary = ?cache_key.binary_path,
-                "codex features list --json probe failed"
-            ),
-        }
-
-        if !parsed_features {
-            plan.steps.push(CapabilityProbeStep::FeaturesListText);
-            match self.run_basic_command(["features", "list"]).await {
-                Ok(output) => {
-                    if !output.status.success() {
-                        warn!(
-                            status = ?output.status,
-                            binary = ?cache_key.binary_path,
-                            "codex features list exited non-zero"
-                        );
-                    }
-                    if output.status.success() {
-                        features.supports_features_list = true;
-                    }
-                    let text = command_output_text(&output);
-                    let parsed = parse_features_from_text(&text);
-                    merge_feature_flags(&mut features, parsed);
-                }
-                Err(error) => warn!(
-                    ?error,
-                    binary = ?cache_key.binary_path,
-                    "codex features list probe failed"
-                ),
-            }
-        }
-
-        if should_run_help_fallback(&features) {
-            plan.steps.push(CapabilityProbeStep::HelpFallback);
-            match self.run_basic_command(["--help"]).await {
-                Ok(output) => {
-                    if !output.status.success() {
-                        warn!(
-                            status = ?output.status,
-                            binary = ?cache_key.binary_path,
-                            "codex --help exited non-zero"
-                        );
-                    }
-                    let text = command_output_text(&output);
-                    let parsed = parse_help_output(&text);
-                    merge_feature_flags(&mut features, parsed);
-                }
-                Err(error) => warn!(
-                    ?error,
-                    binary = ?cache_key.binary_path,
-                    "codex --help probe failed"
-                ),
-            }
-        }
-
-        CodexCapabilities {
-            cache_key: cache_key.clone(),
-            fingerprint,
-            version,
-            features,
-            probe_plan: plan,
-            collected_at: SystemTime::now(),
-        }
-    }
-
-    /// Computes an update advisory by comparing the probed Codex version against
-    /// caller-supplied latest releases.
-    ///
-    /// The crate does not fetch release metadata itself; hosts should populate
-    /// [`CodexLatestReleases`] using their preferred update channel (npm,
-    /// Homebrew, GitHub releases) and then call this helper. Results leverage
-    /// the capability probe cache; callers with an existing
-    /// [`CodexCapabilities`] snapshot can skip the probe by invoking
-    /// [`update_advisory_from_capabilities`].
-    pub async fn update_advisory(
-        &self,
-        latest_releases: &CodexLatestReleases,
-    ) -> CodexUpdateAdvisory {
-        let capabilities = self.probe_capabilities().await;
-        update_advisory_from_capabilities(&capabilities, latest_releases)
-    }
-
-    async fn invoke_codex_exec(&self, request: ExecRequest) -> Result<String, CodexError> {
-        let ExecRequest { prompt, overrides } = request;
-        let dir_ctx = self.directory_context()?;
-        let needs_capabilities = self.output_schema || !self.add_dirs.is_empty();
-        let capabilities = if needs_capabilities {
-            Some(self.probe_capabilities().await)
-        } else {
-            None
-        };
-
-        let resolved_overrides =
-            resolve_cli_overrides(&self.cli_overrides, &overrides, self.model.as_deref());
-        let mut command = Command::new(self.command_env.binary_path());
-        command
-            .arg("exec")
-            .arg("--color")
-            .arg(self.color_mode.as_str())
-            .arg("--skip-git-repo-check")
-            .stdout(std::process::Stdio::piped())
-            .stderr(std::process::Stdio::piped())
-            .kill_on_drop(true)
-            .current_dir(dir_ctx.path());
-
-        apply_cli_overrides(&mut command, &resolved_overrides, true);
-
-        let send_prompt_via_stdin = self.json_output;
-        if !send_prompt_via_stdin {
-            command.arg(&prompt);
-        }
-        let stdin_mode = if send_prompt_via_stdin {
-            std::process::Stdio::piped()
-        } else {
-            std::process::Stdio::null()
-        };
-        command.stdin(stdin_mode);
-
-        if let Some(model) = &self.model {
-            command.arg("--model").arg(model);
-        }
-
-        if let Some(capabilities) = &capabilities {
-            if self.output_schema {
-                let guard = capabilities.guard_output_schema();
-                if guard_is_supported(&guard) {
-                    command.arg("--output-schema");
-                } else {
-                    log_guard_skip(&guard);
-                }
-            }
-
-            if !self.add_dirs.is_empty() {
-                let guard = capabilities.guard_add_dir();
-                if guard_is_supported(&guard) {
-                    for dir in &self.add_dirs {
-                        command.arg("--add-dir").arg(dir);
-                    }
-                } else {
-                    log_guard_skip(&guard);
-                }
-            }
-        }
-
-        for image in &self.images {
-            command.arg("--image").arg(image);
-        }
-
-        if self.json_output {
-            command.arg("--json");
-        }
-
-        self.command_env.apply(&mut command)?;
-
-        let mut child = spawn_with_retry(&mut command, self.command_env.binary_path())?;
-
-        if send_prompt_via_stdin {
-            let mut stdin = child.stdin.take().ok_or(CodexError::StdinUnavailable)?;
-            if let Err(source) = stdin.write_all(prompt.as_bytes()).await {
-                if source.kind() != std::io::ErrorKind::BrokenPipe {
-                    return Err(CodexError::StdinWrite(source));
-                }
-            }
-            if let Err(source) = stdin.write_all(b"\n").await {
-                if source.kind() != std::io::ErrorKind::BrokenPipe {
-                    return Err(CodexError::StdinWrite(source));
-                }
-            }
-            if let Err(source) = stdin.shutdown().await {
-                if source.kind() != std::io::ErrorKind::BrokenPipe {
-                    return Err(CodexError::StdinWrite(source));
-                }
-            }
-        } else {
-            let _ = child.stdin.take();
-        }
-
-        let stdout = child.stdout.take().ok_or(CodexError::StdoutUnavailable)?;
-        let stderr = child.stderr.take().ok_or(CodexError::StderrUnavailable)?;
-
-        let stdout_task = tokio::spawn(tee_stream(
-            stdout,
-            ConsoleTarget::Stdout,
-            self.mirror_stdout,
-        ));
-        let stderr_task = tokio::spawn(tee_stream(stderr, ConsoleTarget::Stderr, !self.quiet));
-
-        let wait_task = async move {
-            let status = child
-                .wait()
-                .await
-                .map_err(|source| CodexError::Wait { source })?;
-            let stdout_bytes = stdout_task
-                .await
-                .map_err(CodexError::Join)?
-                .map_err(CodexError::CaptureIo)?;
-            let stderr_bytes = stderr_task
-                .await
-                .map_err(CodexError::Join)?
-                .map_err(CodexError::CaptureIo)?;
-            Ok::<_, CodexError>((status, stdout_bytes, stderr_bytes))
-        };
-
-        let (status, stdout_bytes, stderr_bytes) = if self.timeout.is_zero() {
-            wait_task.await?
-        } else {
-            match time::timeout(self.timeout, wait_task).await {
-                Ok(result) => result?,
-                Err(_) => {
-                    return Err(CodexError::Timeout {
-                        timeout: self.timeout,
-                    });
-                }
-            }
-        };
-
-        let stderr_string = String::from_utf8(stderr_bytes).unwrap_or_default();
-        if !status.success() {
-            return Err(CodexError::NonZeroExit {
-                status,
-                stderr: stderr_string,
-            });
-        }
-
-        let primary_output = if self.json_output && stdout_bytes.is_empty() {
-            stderr_string
-        } else {
-            String::from_utf8(stdout_bytes)?
-        };
-        let trimmed = if self.json_output {
-            primary_output
-        } else {
-            primary_output.trim().to_string()
-        };
-        debug!(
-            binary = ?self.command_env.binary_path(),
-            bytes = trimmed.len(),
-            "received Codex output"
-        );
-        Ok(trimmed)
-    }
-
-    fn directory_context(&self) -> Result<DirectoryContext, CodexError> {
-        if let Some(dir) = &self.working_dir {
-            return Ok(DirectoryContext::Fixed(dir.clone()));
-        }
-
-        let temp = tempfile::tempdir().map_err(CodexError::TempDir)?;
-        Ok(DirectoryContext::Ephemeral(temp))
-    }
-
-    fn sandbox_working_dir(&self, request_dir: Option<PathBuf>) -> Result<PathBuf, CodexError> {
-        if let Some(dir) = request_dir {
-            return Ok(dir);
-        }
-
-        if let Some(dir) = &self.working_dir {
-            return Ok(dir.clone());
-        }
-
-        env::current_dir().map_err(|source| CodexError::WorkingDirectory { source })
-    }
-
-    async fn run_simple_command_with_overrides(
-        &self,
-        args: Vec<OsString>,
-        overrides: CliOverridesPatch,
-    ) -> Result<ApplyDiffArtifacts, CodexError> {
-        let dir_ctx = self.directory_context()?;
-        let resolved_overrides =
-            resolve_cli_overrides(&self.cli_overrides, &overrides, self.model.as_deref());
-
-        let mut command = Command::new(self.command_env.binary_path());
-        command
-            .args(args)
-            .stdout(std::process::Stdio::piped())
-            .stderr(std::process::Stdio::piped())
-            .kill_on_drop(true)
-            .current_dir(dir_ctx.path());
-
-        apply_cli_overrides(&mut command, &resolved_overrides, true);
-
-        self.command_env.apply(&mut command)?;
-
-        let mut child = spawn_with_retry(&mut command, self.command_env.binary_path())?;
-
-        let stdout = child.stdout.take().ok_or(CodexError::StdoutUnavailable)?;
-        let stderr = child.stderr.take().ok_or(CodexError::StderrUnavailable)?;
-
-        let stdout_task = tokio::spawn(tee_stream(
-            stdout,
-            ConsoleTarget::Stdout,
-            self.mirror_stdout,
-        ));
-        let stderr_task = tokio::spawn(tee_stream(stderr, ConsoleTarget::Stderr, !self.quiet));
-
-        let timeout = self.timeout;
-        let wait_task = async move {
-            let _dir_ctx = dir_ctx;
-            let status = child
-                .wait()
-                .await
-                .map_err(|source| CodexError::Wait { source })?;
-            let stdout_bytes = stdout_task
-                .await
-                .map_err(CodexError::Join)?
-                .map_err(CodexError::CaptureIo)?;
-            let stderr_bytes = stderr_task
-                .await
-                .map_err(CodexError::Join)?
-                .map_err(CodexError::CaptureIo)?;
-            Ok::<_, CodexError>((status, stdout_bytes, stderr_bytes))
-        };
-
-        let (status, stdout_bytes, stderr_bytes) = if timeout.is_zero() {
-            wait_task.await?
-        } else {
-            match time::timeout(timeout, wait_task).await {
-                Ok(result) => result?,
-                Err(_) => {
-                    return Err(CodexError::Timeout { timeout });
-                }
-            }
-        };
-
-        if !status.success() {
-            return Err(CodexError::NonZeroExit {
-                status,
-                stderr: String::from_utf8(stderr_bytes)?,
-            });
-        }
-
-        Ok(ApplyDiffArtifacts {
-            status,
-            stdout: String::from_utf8(stdout_bytes)?,
-            stderr: String::from_utf8(stderr_bytes)?,
-        })
-    }
-
-    async fn run_basic_command<S, I>(&self, args: I) -> Result<CommandOutput, CodexError>
-    where
-        S: AsRef<OsStr>,
-        I: IntoIterator<Item = S>,
-    {
-        let mut command = Command::new(self.command_env.binary_path());
-        command
-            .args(args)
-            .stdout(std::process::Stdio::piped())
-            .stderr(std::process::Stdio::piped())
-            .kill_on_drop(true);
-
-        self.command_env.apply(&mut command)?;
-
-        let mut child = spawn_with_retry(&mut command, self.command_env.binary_path())?;
-
-        let stdout = child.stdout.take().ok_or(CodexError::StdoutUnavailable)?;
-        let stderr = child.stderr.take().ok_or(CodexError::StderrUnavailable)?;
-
-        let stdout_task = tokio::spawn(tee_stream(stdout, ConsoleTarget::Stdout, false));
-        let stderr_task = tokio::spawn(tee_stream(stderr, ConsoleTarget::Stderr, false));
-
-        let wait_task = async move {
-            let status = child
-                .wait()
-                .await
-                .map_err(|source| CodexError::Wait { source })?;
-            let stdout_bytes = stdout_task
-                .await
-                .map_err(CodexError::Join)?
-                .map_err(CodexError::CaptureIo)?;
-            let stderr_bytes = stderr_task
-                .await
-                .map_err(CodexError::Join)?
-                .map_err(CodexError::CaptureIo)?;
-            Ok::<_, CodexError>((status, stdout_bytes, stderr_bytes))
-        };
-
-        let (status, stdout_bytes, stderr_bytes) = if self.timeout.is_zero() {
-            wait_task.await?
-        } else {
-            match time::timeout(self.timeout, wait_task).await {
-                Ok(result) => result?,
-                Err(_) => {
-                    return Err(CodexError::Timeout {
-                        timeout: self.timeout,
-                    });
-                }
-            }
-        };
-
-        Ok(CommandOutput {
-            status,
-            stdout: stdout_bytes,
-            stderr: stderr_bytes,
-        })
-    }
-}
-
-impl Default for CodexClient {
-    fn default() -> Self {
-        CodexClient::builder().build()
-    }
-}
-
-fn spawn_with_retry(
-    command: &mut Command,
-    binary: &Path,
-) -> Result<tokio::process::Child, CodexError> {
-    let mut backoff = Duration::from_millis(2);
-    for attempt in 0..5 {
-        match command.spawn() {
-            Ok(child) => return Ok(child),
-            Err(source) => {
-                let is_busy = matches!(source.kind(), std::io::ErrorKind::ExecutableFileBusy)
-                    || source.raw_os_error() == Some(26);
-                if is_busy && attempt < 4 {
-                    std::thread::sleep(backoff);
-                    backoff = std::cmp::min(backoff * 2, Duration::from_millis(50));
-                    continue;
-                }
-                return Err(CodexError::Spawn {
-                    binary: binary.to_path_buf(),
-                    source,
-                });
-            }
-        }
-    }
-
-    unreachable!("spawn_with_retry should return before exhausting retries")
-}
-
-/// Errors that may occur while invoking the Codex CLI.
-#[derive(Debug, Error)]
-pub enum CodexError {
-    #[error("codex binary `{binary}` could not be spawned: {source}")]
-    Spawn {
-        binary: PathBuf,
-        #[source]
-        source: std::io::Error,
-    },
-    #[error("failed to wait for codex process: {source}")]
-    Wait {
-        #[source]
-        source: std::io::Error,
-    },
-    #[error("codex exceeded timeout of {timeout:?}")]
-    Timeout { timeout: Duration },
-    #[error("codex exited with {status:?}: {stderr}")]
-    NonZeroExit { status: ExitStatus, stderr: String },
-    #[error("codex output was not valid UTF-8: {0}")]
-    InvalidUtf8(#[from] std::string::FromUtf8Error),
-    #[error("failed to parse {context} JSON output: {source}")]
-    JsonParse {
-        context: &'static str,
-        stdout: String,
-        #[source]
-        source: serde_json::Error,
-    },
-    #[error("failed to parse execpolicy JSON output: {source}")]
-    ExecPolicyParse {
-        stdout: String,
-        #[source]
-        source: serde_json::Error,
-    },
-    #[error("failed to parse features list output: {reason}")]
-    FeatureListParse { reason: String, stdout: String },
-    #[error("failed to read responses-api-proxy server info from `{path}`: {source}")]
-    ResponsesApiProxyInfoRead {
-        path: PathBuf,
-        #[source]
-        source: std::io::Error,
-    },
-    #[error("failed to parse responses-api-proxy server info from `{path}`: {source}")]
-    ResponsesApiProxyInfoParse {
-        path: PathBuf,
-        #[source]
-        source: serde_json::Error,
-    },
-    #[error("prompt must not be empty")]
-    EmptyPrompt,
-    #[error("sandbox command must not be empty")]
-    EmptySandboxCommand,
-    #[error("execpolicy command must not be empty")]
-    EmptyExecPolicyCommand,
-    #[error("API key must not be empty")]
-    EmptyApiKey,
-    #[error("task id must not be empty")]
-    EmptyTaskId,
-    #[error("environment id must not be empty")]
-    EmptyEnvId,
-    #[error("MCP server name must not be empty")]
-    EmptyMcpServerName,
-    #[error("MCP server command must not be empty")]
-    EmptyMcpCommand,
-    #[error("MCP server URL must not be empty")]
-    EmptyMcpUrl,
-    #[error("socket path must not be empty")]
-    EmptySocketPath,
-    #[error("failed to create temporary working directory: {0}")]
-    TempDir(#[source] std::io::Error),
-    #[error("failed to resolve working directory: {source}")]
-    WorkingDirectory {
-        #[source]
-        source: std::io::Error,
-    },
-    #[error("failed to prepare app-server output directory `{path}`: {source}")]
-    PrepareOutputDirectory {
-        path: PathBuf,
-        #[source]
-        source: std::io::Error,
-    },
-    #[error("failed to prepare CODEX_HOME at `{path}`: {source}")]
-    PrepareCodexHome {
-        path: PathBuf,
-        #[source]
-        source: std::io::Error,
-    },
-    #[error("codex stdout unavailable")]
-    StdoutUnavailable,
-    #[error("codex stderr unavailable")]
-    StderrUnavailable,
-    #[error("codex stdin unavailable")]
-    StdinUnavailable,
-    #[error("failed to capture codex output: {0}")]
-    CaptureIo(#[from] std::io::Error),
-    #[error("failed to write prompt to codex stdin: {0}")]
-    StdinWrite(#[source] std::io::Error),
-    #[error("failed to join codex output task: {0}")]
-    Join(#[from] tokio::task::JoinError),
-}
-
-/// Single JSONL event emitted by `codex exec --json`.
-///
-/// Each line on stdout maps to a [`ThreadEvent`] with lifecycle edges:
-/// - `thread.started` is emitted once per invocation.
-/// - `turn.started` begins the turn associated with the provided prompt.
-/// - one or more `item.*` events stream output and tool activity.
-/// - `turn.completed` or `turn.failed` closes the stream; `error` captures transport-level failures.
-///
-/// Item variants mirror the upstream `item_type` field: `agent_message`, `reasoning`,
-/// `command_execution`, `file_change`, `mcp_tool_call`, `web_search`, `todo_list`, and `error`.
-/// Unknown or future fields are preserved in `extra` maps to keep the parser forward-compatible.
-#[derive(Clone, Debug, Deserialize, Serialize)]
-#[serde(tag = "type")]
-pub enum ThreadEvent {
-    #[serde(rename = "thread.started", alias = "thread.resumed")]
-    ThreadStarted(ThreadStarted),
-    #[serde(rename = "turn.started")]
-    TurnStarted(TurnStarted),
-    #[serde(rename = "turn.completed")]
-    TurnCompleted(TurnCompleted),
-    #[serde(rename = "turn.failed")]
-    TurnFailed(TurnFailed),
-    #[serde(rename = "item.started", alias = "item.created")]
-    ItemStarted(ItemEnvelope<ItemSnapshot>),
-    #[serde(rename = "item.delta", alias = "item.updated")]
-    ItemDelta(ItemDelta),
-    #[serde(rename = "item.completed")]
-    ItemCompleted(ItemEnvelope<ItemSnapshot>),
-    #[serde(rename = "item.failed")]
-    ItemFailed(ItemEnvelope<ItemFailure>),
-    #[serde(rename = "error")]
-    Error(EventError),
-}
-
-/// Marks the start of a new thread.
-#[derive(Clone, Debug, Deserialize, Serialize)]
-pub struct ThreadStarted {
-    pub thread_id: String,
-    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
-    pub extra: BTreeMap<String, Value>,
-}
-
-/// Indicates the CLI accepted a new turn within a thread.
-#[derive(Clone, Debug, Deserialize, Serialize)]
-pub struct TurnStarted {
-    pub thread_id: String,
-    pub turn_id: String,
-    /// Original input text when upstream echoes it; may be omitted for security reasons.
-    #[serde(default, skip_serializing_if = "Option::is_none")]
-    pub input_text: Option<String>,
-    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
-    pub extra: BTreeMap<String, Value>,
-}
-
-/// Reports a completed turn.
-#[derive(Clone, Debug, Deserialize, Serialize)]
-pub struct TurnCompleted {
-    pub thread_id: String,
-    pub turn_id: String,
-    /// Identifier of the last output item when provided by the CLI.
-    #[serde(default, skip_serializing_if = "Option::is_none")]
-    pub last_item_id: Option<String>,
-    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
-    pub extra: BTreeMap<String, Value>,
-}
-
-/// Indicates a turn-level failure.
-#[derive(Clone, Debug, Deserialize, Serialize)]
-pub struct TurnFailed {
-    pub thread_id: String,
-    pub turn_id: String,
-    pub error: EventError,
-    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
-    pub extra: BTreeMap<String, Value>,
-}
-
-/// Shared wrapper for item events that always include thread/turn context.
-#[derive(Clone, Debug, Deserialize, Serialize)]
-pub struct ItemEnvelope<T> {
-    pub thread_id: String,
-    pub turn_id: String,
-    #[serde(flatten)]
-    pub item: T,
-}
-
-/// Snapshot of an item at start/completion time.
-#[derive(Clone, Debug, Deserialize, Serialize)]
-pub struct ItemSnapshot {
-    #[serde(rename = "item_id", alias = "id")]
-    pub item_id: String,
-    #[serde(default, skip_serializing_if = "Option::is_none")]
-    pub index: Option<u32>,
-    #[serde(default)]
-    pub status: ItemStatus,
-    #[serde(flatten)]
-    pub payload: ItemPayload,
-    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
-    pub extra: BTreeMap<String, Value>,
-}
-
-/// Streaming delta describing the next piece of an item.
-#[derive(Clone, Debug, Deserialize, Serialize)]
-pub struct ItemDelta {
-    pub thread_id: String,
-    pub turn_id: String,
-    #[serde(rename = "item_id", alias = "id")]
-    pub item_id: String,
-    #[serde(default, skip_serializing_if = "Option::is_none")]
-    pub index: Option<u32>,
-    #[serde(flatten)]
-    pub delta: ItemDeltaPayload,
-    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
-    pub extra: BTreeMap<String, Value>,
-}
-
-/// Terminal item failure event.
-#[derive(Clone, Debug, Deserialize, Serialize)]
-pub struct ItemFailure {
-    #[serde(rename = "item_id", alias = "id")]
-    pub item_id: String,
-    #[serde(default, skip_serializing_if = "Option::is_none")]
-    pub index: Option<u32>,
-    pub error: EventError,
-    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
-    pub extra: BTreeMap<String, Value>,
-}
-
-/// Fully-typed item payload for start/completed events.
-#[derive(Clone, Debug, Deserialize, Serialize)]
-#[serde(tag = "item_type", content = "content", rename_all = "snake_case")]
-pub enum ItemPayload {
-    AgentMessage(TextContent),
-    Reasoning(TextContent),
-    CommandExecution(CommandExecutionState),
-    FileChange(FileChangeState),
-    McpToolCall(McpToolCallState),
-    WebSearch(WebSearchState),
-    TodoList(TodoListState),
-    Error(EventError),
-}
-
-/// Delta form of an item payload. Each delta should be applied in order to reconstruct the item.
-#[derive(Clone, Debug, Deserialize, Serialize)]
-#[serde(tag = "item_type", content = "delta", rename_all = "snake_case")]
-pub enum ItemDeltaPayload {
-    AgentMessage(TextDelta),
-    Reasoning(TextDelta),
-    CommandExecution(CommandExecutionDelta),
-    FileChange(FileChangeDelta),
-    McpToolCall(McpToolCallDelta),
-    WebSearch(WebSearchDelta),
-    TodoList(TodoListDelta),
-    Error(EventError),
-}
-
-/// Item status supplied by the CLI for bookkeeping.
-#[derive(Clone, Debug, Default, Deserialize, Serialize, Eq, PartialEq)]
-#[serde(rename_all = "snake_case")]
-pub enum ItemStatus {
-    #[default]
-    InProgress,
-    Completed,
-    Failed,
-    #[serde(other)]
-    Unknown,
-}
-
-/// Human-readable content emitted by the agent.
-#[derive(Clone, Debug, Deserialize, Serialize)]
-pub struct TextContent {
-    pub text: String,
-    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
-    pub extra: BTreeMap<String, Value>,
-}
-
-/// Incremental content fragment for streaming items.
-#[derive(Clone, Debug, Deserialize, Serialize)]
-pub struct TextDelta {
-    #[serde(rename = "text_delta", alias = "text")]
-    pub text_delta: String,
-    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
-    pub extra: BTreeMap<String, Value>,
-}
-
-/// Snapshot of a command execution, including accumulated stdout/stderr.
-#[derive(Clone, Debug, Deserialize, Serialize)]
-pub struct CommandExecutionState {
-    pub command: String,
-    #[serde(default, skip_serializing_if = "Option::is_none")]
-    pub exit_code: Option<i32>,
-    #[serde(
-        default,
-        skip_serializing_if = "String::is_empty",
-        alias = "aggregated_output",
-        alias = "output"
-    )]
-    pub stdout: String,
-    #[serde(
-        default,
-        skip_serializing_if = "String::is_empty",
-        alias = "error_output",
-        alias = "err"
-    )]
-    pub stderr: String,
-    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
-    pub extra: BTreeMap<String, Value>,
-}
-
-/// Streaming delta for command execution.
-#[derive(Clone, Debug, Deserialize, Serialize)]
-pub struct CommandExecutionDelta {
-    #[serde(
-        default,
-        skip_serializing_if = "String::is_empty",
-        alias = "aggregated_output",
-        alias = "output"
-    )]
-    pub stdout: String,
-    #[serde(
-        default,
-        skip_serializing_if = "String::is_empty",
-        alias = "error_output",
-        alias = "err"
-    )]
-    pub stderr: String,
-    #[serde(default, skip_serializing_if = "Option::is_none")]
-    pub exit_code: Option<i32>,
-    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
-    pub extra: BTreeMap<String, Value>,
-}
-
-/// File change or diff applied by the agent.
-#[derive(Clone, Debug, Deserialize, Serialize)]
-pub struct FileChangeState {
-    #[serde(alias = "file_path")]
-    pub path: PathBuf,
-    #[serde(default, skip_serializing_if = "Option::is_none")]
-    pub change: Option<FileChangeKind>,
-    #[serde(default, skip_serializing_if = "Option::is_none", alias = "patch")]
-    pub diff: Option<String>,
-    #[serde(default, skip_serializing_if = "Option::is_none")]
-    pub exit_code: Option<i32>,
-    #[serde(
-        default,
-        skip_serializing_if = "String::is_empty",
-        alias = "aggregated_output",
-        alias = "output"
-    )]
-    pub stdout: String,
-    #[serde(
-        default,
-        skip_serializing_if = "String::is_empty",
-        alias = "error_output",
-        alias = "err"
-    )]
-    pub stderr: String,
-    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
-    pub extra: BTreeMap<String, Value>,
-}
-
-/// Streaming delta describing a file change.
-#[derive(Clone, Debug, Deserialize, Serialize)]
-pub struct FileChangeDelta {
-    #[serde(default, skip_serializing_if = "Option::is_none", alias = "patch")]
-    pub diff: Option<String>,
-    #[serde(
-        default,
-        skip_serializing_if = "String::is_empty",
-        alias = "aggregated_output",
-        alias = "output"
-    )]
-    pub stdout: String,
-    #[serde(
-        default,
-        skip_serializing_if = "String::is_empty",
-        alias = "error_output",
-        alias = "err"
-    )]
-    pub stderr: String,
-    #[serde(default, skip_serializing_if = "Option::is_none")]
-    pub exit_code: Option<i32>,
-    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
-    pub extra: BTreeMap<String, Value>,
-}
-
-/// Type of file operation being reported.
-#[derive(Clone, Copy, Debug, Deserialize, Serialize, Eq, PartialEq)]
-#[serde(rename_all = "snake_case")]
-pub enum FileChangeKind {
-    Apply,
-    Diff,
-    #[serde(other)]
-    Unknown,
-}
-
-/// State of an MCP tool call.
-#[derive(Clone, Debug, Deserialize, Serialize)]
-pub struct McpToolCallState {
-    #[serde(alias = "server")]
-    pub server_name: String,
-    #[serde(alias = "tool")]
-    pub tool_name: String,
-    #[serde(default, skip_serializing_if = "Option::is_none")]
-    pub arguments: Option<Value>,
-    #[serde(default, skip_serializing_if = "Option::is_none")]
-    pub result: Option<Value>,
-    #[serde(default)]
-    pub status: ToolCallStatus,
-    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
-    pub extra: BTreeMap<String, Value>,
-}
-
-/// Streaming delta for MCP tool call output.
-#[derive(Clone, Debug, Deserialize, Serialize)]
-pub struct McpToolCallDelta {
-    #[serde(default, skip_serializing_if = "Option::is_none")]
-    pub result: Option<Value>,
-    #[serde(default)]
-    pub status: ToolCallStatus,
-    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
-    pub extra: BTreeMap<String, Value>,
-}
-
-/// Lifecycle state for a tool call.
-#[derive(Clone, Debug, Default, Deserialize, Serialize, Eq, PartialEq)]
-#[serde(rename_all = "snake_case")]
-pub enum ToolCallStatus {
-    #[default]
-    Pending,
-    Running,
-    Completed,
-    Failed,
-    #[serde(other)]
-    Unknown,
-}
-
-/// Details of a web search step.
-#[derive(Clone, Debug, Deserialize, Serialize)]
-pub struct WebSearchState {
-    pub query: String,
-    #[serde(default, skip_serializing_if = "Option::is_none")]
-    pub results: Option<Value>,
-    #[serde(default)]
-    pub status: WebSearchStatus,
-    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
-    pub extra: BTreeMap<String, Value>,
-}
-
-/// Streaming delta for search results.
-#[derive(Clone, Debug, Deserialize, Serialize)]
-pub struct WebSearchDelta {
-    #[serde(default, skip_serializing_if = "Option::is_none")]
-    pub results: Option<Value>,
-    #[serde(default)]
-    pub status: WebSearchStatus,
-    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
-    pub extra: BTreeMap<String, Value>,
-}
-
-/// Search progress indicator.
-#[derive(Clone, Debug, Default, Deserialize, Serialize, Eq, PartialEq)]
-#[serde(rename_all = "snake_case")]
-pub enum WebSearchStatus {
-    #[default]
-    Pending,
-    Running,
-    Completed,
-    Failed,
-    #[serde(other)]
-    Unknown,
-}
-
-/// Checklist maintained by the agent.
-#[derive(Clone, Debug, Deserialize, Serialize)]
-pub struct TodoListState {
-    #[serde(default, skip_serializing_if = "Vec::is_empty")]
-    pub items: Vec<TodoItem>,
-    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
-    pub extra: BTreeMap<String, Value>,
-}
-
-/// Streaming delta for todo list mutations.
-#[derive(Clone, Debug, Deserialize, Serialize)]
-pub struct TodoListDelta {
-    #[serde(default, skip_serializing_if = "Vec::is_empty")]
-    pub items: Vec<TodoItem>,
-    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
-    pub extra: BTreeMap<String, Value>,
-}
-
-/// Single todo item.
-#[derive(Clone, Debug, Deserialize, Serialize)]
-pub struct TodoItem {
-    pub title: String,
-    #[serde(default)]
-    pub completed: bool,
-    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
-    pub extra: BTreeMap<String, Value>,
-}
-
-/// Error payload shared by turn/item failures.
-#[derive(Clone, Debug, Deserialize, Serialize)]
-pub struct EventError {
-    pub message: String,
-    #[serde(default, skip_serializing_if = "Option::is_none")]
-    pub code: Option<String>,
-    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
-    pub extra: BTreeMap<String, Value>,
-}
-
-/// Options configuring a single exec request.
-#[derive(Clone, Debug)]
-pub struct ExecRequest {
-    pub prompt: String,
-    pub overrides: CliOverridesPatch,
-}
-
-impl ExecRequest {
-    pub fn new(prompt: impl Into<String>) -> Self {
-        Self {
-            prompt: prompt.into(),
-            overrides: CliOverridesPatch::default(),
-        }
-    }
-
-    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
-        self.overrides = overrides;
-        self
-    }
-
-    pub fn config_override(mut self, key: impl Into<String>, value: impl Into<String>) -> Self {
-        self.overrides
-            .config_overrides
-            .push(ConfigOverride::new(key, value));
-        self
-    }
-
-    pub fn config_override_raw(mut self, raw: impl Into<String>) -> Self {
-        self.overrides
-            .config_overrides
-            .push(ConfigOverride::from_raw(raw));
-        self
-    }
-
-    pub fn profile(mut self, profile: impl Into<String>) -> Self {
-        let profile = profile.into();
-        self.overrides.profile = (!profile.trim().is_empty()).then_some(profile);
-        self
-    }
-
-    pub fn oss(mut self, enable: bool) -> Self {
-        self.overrides.oss = if enable {
-            FlagState::Enable
-        } else {
-            FlagState::Disable
-        };
-        self
-    }
-
-    pub fn enable_feature(mut self, name: impl Into<String>) -> Self {
-        self.overrides.feature_toggles.enable.push(name.into());
-        self
-    }
-
-    pub fn disable_feature(mut self, name: impl Into<String>) -> Self {
-        self.overrides.feature_toggles.disable.push(name.into());
-        self
-    }
-
-    pub fn search(mut self, enable: bool) -> Self {
-        self.overrides.search = if enable {
-            FlagState::Enable
-        } else {
-            FlagState::Disable
-        };
-        self
-    }
-}
-
-/// Options configuring a streaming exec invocation.
-#[derive(Clone, Debug)]
-pub struct ExecStreamRequest {
-    /// User prompt that will be forwarded to `codex exec`.
-    pub prompt: String,
-    /// Per-event idle timeout. If no JSON lines arrive before the duration elapses,
-    /// [`ExecStreamError::IdleTimeout`] is returned.
-    pub idle_timeout: Option<Duration>,
-    /// Optional file path passed through to `--output-last-message`. When unset, the wrapper
-    /// will request a temporary path and return it in [`ExecCompletion::last_message_path`].
-    pub output_last_message: Option<PathBuf>,
-    /// Optional file path passed through to `--output-schema` so clients can persist the schema
-    /// describing the item envelope structure seen during the run.
-    pub output_schema: Option<PathBuf>,
-    /// Optional file path that receives a tee of every raw JSONL event line as it streams in.
-    /// Appends to existing files, flushes each line, and creates parent directories. Overrides
-    /// [`CodexClientBuilder::json_event_log`] for this request when provided.
-    pub json_event_log: Option<PathBuf>,
-}
-
-/// Selector for `codex resume` targets.
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub enum ResumeSelector {
-    Id(String),
-    Last,
-    All,
-}
-
-/// Options configuring a streaming resume invocation.
-#[derive(Clone, Debug)]
-pub struct ResumeRequest {
-    pub selector: ResumeSelector,
-    pub prompt: Option<String>,
-    pub idle_timeout: Option<Duration>,
-    pub output_last_message: Option<PathBuf>,
-    pub output_schema: Option<PathBuf>,
-    pub json_event_log: Option<PathBuf>,
-    pub overrides: CliOverridesPatch,
-}
-
-impl ResumeRequest {
-    pub fn new(selector: ResumeSelector) -> Self {
-        Self {
-            selector,
-            prompt: None,
-            idle_timeout: None,
-            output_last_message: None,
-            output_schema: None,
-            json_event_log: None,
-            overrides: CliOverridesPatch::default(),
-        }
-    }
-
-    pub fn with_id(id: impl Into<String>) -> Self {
-        Self::new(ResumeSelector::Id(id.into()))
-    }
-
-    pub fn last() -> Self {
-        Self::new(ResumeSelector::Last)
-    }
-
-    pub fn all() -> Self {
-        Self::new(ResumeSelector::All)
-    }
-
-    pub fn prompt(mut self, prompt: impl Into<String>) -> Self {
-        self.prompt = Some(prompt.into());
-        self
-    }
-
-    pub fn idle_timeout(mut self, idle_timeout: Duration) -> Self {
-        self.idle_timeout = Some(idle_timeout);
-        self
-    }
-
-    pub fn config_override(mut self, key: impl Into<String>, value: impl Into<String>) -> Self {
-        self.overrides
-            .config_overrides
-            .push(ConfigOverride::new(key, value));
-        self
-    }
-
-    pub fn config_override_raw(mut self, raw: impl Into<String>) -> Self {
-        self.overrides
-            .config_overrides
-            .push(ConfigOverride::from_raw(raw));
-        self
-    }
-
-    pub fn profile(mut self, profile: impl Into<String>) -> Self {
-        let profile = profile.into();
-        self.overrides.profile = (!profile.trim().is_empty()).then_some(profile);
-        self
-    }
-
-    pub fn oss(mut self, enable: bool) -> Self {
-        self.overrides.oss = if enable {
-            FlagState::Enable
-        } else {
-            FlagState::Disable
-        };
-        self
-    }
-
-    pub fn enable_feature(mut self, name: impl Into<String>) -> Self {
-        self.overrides.feature_toggles.enable.push(name.into());
-        self
-    }
-
-    pub fn disable_feature(mut self, name: impl Into<String>) -> Self {
-        self.overrides.feature_toggles.disable.push(name.into());
-        self
-    }
-
-    pub fn search(mut self, enable: bool) -> Self {
-        self.overrides.search = if enable {
-            FlagState::Enable
-        } else {
-            FlagState::Disable
-        };
-        self
-    }
-}
-
-/// Sandbox platform variant; maps to platform subcommands of `codex sandbox`.
-#[derive(Clone, Copy, Debug, Eq, PartialEq)]
-pub enum SandboxPlatform {
-    Macos,
-    Linux,
-    Windows,
-}
-
-impl SandboxPlatform {
-    fn subcommand(self) -> &'static str {
-        match self {
-            SandboxPlatform::Macos => "macos",
-            SandboxPlatform::Linux => "linux",
-            SandboxPlatform::Windows => "windows",
-        }
-    }
-}
-
-/// Request to run an arbitrary command inside a Codex-provided sandbox.
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub struct SandboxCommandRequest {
-    /// Target platform subcommand; maps to `macos` (alias `seatbelt`), `linux` (alias `landlock`), or `windows`.
-    pub platform: SandboxPlatform,
-    /// Trailing command arguments to execute. Must be non-empty to avoid the upstream CLI panic.
-    pub command: Vec<OsString>,
-    /// Request the workspace-write sandbox preset (`--full-auto`).
-    pub full_auto: bool,
-    /// Stream macOS sandbox denials after the child process exits (no-op on other platforms).
-    pub log_denials: bool,
-    /// Additional `--config key=value` overrides to pass through.
-    pub config_overrides: Vec<ConfigOverride>,
-    /// Feature toggles forwarded to `--enable`/`--disable`.
-    pub feature_toggles: FeatureToggles,
-    /// Working directory for the spawned command; falls back to the builder value, then the current process directory.
-    pub working_dir: Option<PathBuf>,
-}
-
-impl SandboxCommandRequest {
-    pub fn new<I, S>(platform: SandboxPlatform, command: I) -> Self
-    where
-        I: IntoIterator<Item = S>,
-        S: Into<OsString>,
-    {
-        Self {
-            platform,
-            command: command.into_iter().map(Into::into).collect(),
-            full_auto: false,
-            log_denials: false,
-            config_overrides: Vec::new(),
-            feature_toggles: FeatureToggles::default(),
-            working_dir: None,
-        }
-    }
-
-    pub fn full_auto(mut self, enable: bool) -> Self {
-        self.full_auto = enable;
-        self
-    }
-
-    pub fn log_denials(mut self, enable: bool) -> Self {
-        self.log_denials = enable;
-        self
-    }
-
-    pub fn config_override(mut self, key: impl Into<String>, value: impl Into<String>) -> Self {
-        self.config_overrides.push(ConfigOverride::new(key, value));
-        self
-    }
-
-    pub fn config_override_raw(mut self, raw: impl Into<String>) -> Self {
-        self.config_overrides.push(ConfigOverride::from_raw(raw));
-        self
-    }
-
-    pub fn enable_feature(mut self, name: impl Into<String>) -> Self {
-        self.feature_toggles.enable.push(name.into());
-        self
-    }
-
-    pub fn disable_feature(mut self, name: impl Into<String>) -> Self {
-        self.feature_toggles.disable.push(name.into());
-        self
-    }
-
-    pub fn working_dir(mut self, dir: impl Into<PathBuf>) -> Self {
-        self.working_dir = Some(dir.into());
-        self
-    }
-}
-
-/// Captured output from `codex sandbox <platform>`.
-#[derive(Clone, Debug)]
-pub struct SandboxRun {
-    /// Exit status returned by the inner command (mirrors the sandbox helper).
-    pub status: ExitStatus,
-    /// Captured stdout (mirrored to the console when `mirror_stdout` is true).
-    pub stdout: String,
-    /// Captured stderr (mirrored unless `quiet` is set).
-    pub stderr: String,
-}
-
-/// Request for `codex responses-api-proxy`.
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub struct ResponsesApiProxyRequest {
-    /// API key to write to stdin on startup.
-    pub api_key: String,
-    /// Optional port to bind; falls back to an OS-assigned ephemeral port when omitted.
-    pub port: Option<u16>,
-    /// Optional path passed to `--server-info` for `{port,pid}` JSON output.
-    pub server_info_path: Option<PathBuf>,
-    /// Enables the HTTP shutdown endpoint (`GET /shutdown`).
-    pub http_shutdown: bool,
-    /// Optional upstream URL passed to `--upstream-url` (defaults to `https://api.openai.com/v1/responses`).
-    pub upstream_url: Option<String>,
-}
-
-impl ResponsesApiProxyRequest {
-    /// Creates a request with the API key provided via stdin.
-    pub fn new(api_key: impl Into<String>) -> Self {
-        Self {
-            api_key: api_key.into(),
-            port: None,
-            server_info_path: None,
-            http_shutdown: false,
-            upstream_url: None,
-        }
-    }
-
-    /// Sets the listening port (`--port`).
-    pub fn port(mut self, port: u16) -> Self {
-        self.port = Some(port);
-        self
-    }
-
-    /// Writes `{port,pid}` JSON to the provided path via `--server-info`.
-    pub fn server_info(mut self, path: impl Into<PathBuf>) -> Self {
-        self.server_info_path = Some(path.into());
-        self
-    }
-
-    /// Enables the `--http-shutdown` flag (GET /shutdown).
-    pub fn http_shutdown(mut self, enable: bool) -> Self {
-        self.http_shutdown = enable;
-        self
-    }
-
-    /// Overrides the upstream responses endpoint URL.
-    pub fn upstream_url(mut self, url: impl Into<String>) -> Self {
-        let url = url.into();
-        self.upstream_url = (!url.trim().is_empty()).then_some(url);
-        self
-    }
-}
-
-/// Running responses proxy process and metadata.
-#[derive(Debug)]
-pub struct ResponsesApiProxyHandle {
-    /// Spawned `codex responses-api-proxy` child (inherits kill-on-drop).
-    pub child: tokio::process::Child,
-    /// Optional `--server-info` path that may contain `{port,pid}` JSON.
-    pub server_info_path: Option<PathBuf>,
-}
-
-impl ResponsesApiProxyHandle {
-    /// Reads and parses the `{port,pid}` JSON written by `--server-info`.
-    ///
-    /// Returns `Ok(None)` when no server info path was configured.
-    pub async fn read_server_info(&self) -> Result<Option<ResponsesApiProxyInfo>, CodexError> {
-        let Some(path) = &self.server_info_path else {
-            return Ok(None);
-        };
-
-        const MAX_ATTEMPTS: usize = 10;
-        const BACKOFF_MS: u64 = 25;
-
-        for attempt in 0..MAX_ATTEMPTS {
-            match fs::read_to_string(path).await {
-                Ok(contents) => match serde_json::from_str::<ResponsesApiProxyInfo>(&contents) {
-                    Ok(info) => return Ok(Some(info)),
-                    Err(source) => {
-                        if attempt + 1 == MAX_ATTEMPTS {
-                            return Err(CodexError::ResponsesApiProxyInfoParse {
-                                path: path.clone(),
-                                source,
-                            });
-                        }
-                    }
-                },
-                Err(source) => {
-                    let is_missing = source.kind() == std::io::ErrorKind::NotFound;
-                    if !is_missing || attempt + 1 == MAX_ATTEMPTS {
-                        return Err(CodexError::ResponsesApiProxyInfoRead {
-                            path: path.clone(),
-                            source,
-                        });
-                    }
-                }
-            }
-
-            tokio::time::sleep(std::time::Duration::from_millis(BACKOFF_MS)).await;
-        }
-
-        unreachable!("read_server_info loop must return by MAX_ATTEMPTS")
-    }
-}
-
-/// Parsed `{port,pid}` emitted by `codex responses-api-proxy --server-info`.
-#[derive(Clone, Debug, Eq, PartialEq, Serialize, Deserialize)]
-pub struct ResponsesApiProxyInfo {
-    pub port: u16,
-    pub pid: u32,
-    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
-    pub extra: BTreeMap<String, Value>,
-}
-
-/// Request for `codex stdio-to-uds <SOCKET_PATH>`.
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub struct StdioToUdsRequest {
-    /// Path to the Unix domain socket to connect to.
-    pub socket_path: PathBuf,
-    /// Optional working directory override for the spawned process.
-    pub working_dir: Option<PathBuf>,
-}
-
-impl StdioToUdsRequest {
-    pub fn new(socket_path: impl Into<PathBuf>) -> Self {
-        Self {
-            socket_path: socket_path.into(),
-            working_dir: None,
-        }
-    }
-
-    /// Sets the working directory used to resolve the socket path.
-    pub fn working_dir(mut self, dir: impl Into<PathBuf>) -> Self {
-        self.working_dir = Some(dir.into());
-        self
-    }
-}
-
-/// Stage labels reported by `codex features list`.
-#[derive(Clone, Debug, Eq, PartialEq, Serialize, Deserialize)]
-#[serde(from = "String", into = "String")]
-pub enum CodexFeatureStage {
-    Experimental,
-    Beta,
-    Stable,
-    Deprecated,
-    Removed,
-    Unknown(String),
-}
-
-impl CodexFeatureStage {
-    fn parse(raw: &str) -> Self {
-        let normalized = raw.trim();
-        match normalized.to_ascii_lowercase().as_str() {
-            "experimental" => CodexFeatureStage::Experimental,
-            "beta" => CodexFeatureStage::Beta,
-            "stable" => CodexFeatureStage::Stable,
-            "deprecated" => CodexFeatureStage::Deprecated,
-            "removed" => CodexFeatureStage::Removed,
-            _ => CodexFeatureStage::Unknown(normalized.to_string()),
-        }
-    }
-
-    /// Returns the normalized label for this stage.
-    pub fn as_str(&self) -> &str {
-        match self {
-            CodexFeatureStage::Experimental => "experimental",
-            CodexFeatureStage::Beta => "beta",
-            CodexFeatureStage::Stable => "stable",
-            CodexFeatureStage::Deprecated => "deprecated",
-            CodexFeatureStage::Removed => "removed",
-            CodexFeatureStage::Unknown(label) => label.as_str(),
-        }
-    }
-}
-
-impl From<String> for CodexFeatureStage {
-    fn from(value: String) -> Self {
-        CodexFeatureStage::parse(&value)
-    }
-}
-
-impl From<CodexFeatureStage> for String {
-    fn from(stage: CodexFeatureStage) -> Self {
-        String::from(&stage)
-    }
-}
-
-impl From<&CodexFeatureStage> for String {
-    fn from(stage: &CodexFeatureStage) -> Self {
-        stage.as_str().to_string()
-    }
-}
-
-/// Single feature entry reported by `codex features list`.
-#[derive(Clone, Debug, Eq, PartialEq, Serialize, Deserialize)]
-pub struct CodexFeature {
-    /// Feature name as reported by the CLI.
-    pub name: String,
-    /// Feature stage (experimental/beta/stable/deprecated/removed) when provided.
-    #[serde(default, skip_serializing_if = "Option::is_none")]
-    pub stage: Option<CodexFeatureStage>,
-    /// Whether the feature is enabled for the current config/profile.
-    pub enabled: bool,
-    /// Unrecognized fields from JSON output are preserved here.
-    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
-    pub extra: BTreeMap<String, Value>,
-}
-
-impl CodexFeature {
-    /// Convenience helper mirroring the `enabled` flag.
-    pub const fn is_enabled(&self) -> bool {
-        self.enabled
-    }
-}
-
-/// Format used to parse `codex features list` output.
-#[derive(Clone, Copy, Debug, Eq, PartialEq)]
-pub enum FeaturesListFormat {
-    Json,
-    Text,
-}
-
-/// Parsed output from `codex features list`.
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub struct FeaturesListOutput {
-    /// Exit status returned by the subcommand.
-    pub status: ExitStatus,
-    /// Captured stdout (mirrored to the console when `mirror_stdout` is true).
-    pub stdout: String,
-    /// Captured stderr (mirrored unless `quiet` is set).
-    pub stderr: String,
-    /// Parsed feature entries.
-    pub features: Vec<CodexFeature>,
-    /// Indicates whether JSON or text parsing was used.
-    pub format: FeaturesListFormat,
-}
-
-/// Request for `codex features list`.
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub struct FeaturesListRequest {
-    /// Request JSON output via `--json` (falls back to text parsing when JSON is absent).
-    pub json: bool,
-    /// Per-call CLI overrides layered on top of the builder.
-    pub overrides: CliOverridesPatch,
-}
-
-impl FeaturesListRequest {
-    /// Creates a request with JSON disabled by default for compatibility with older binaries.
-    pub fn new() -> Self {
-        Self {
-            json: false,
-            overrides: CliOverridesPatch::default(),
-        }
-    }
-
-    /// Controls whether `--json` is passed to `codex features list`.
-    pub fn json(mut self, enable: bool) -> Self {
-        self.json = enable;
-        self
-    }
-
-    /// Replaces the default CLI overrides for this request.
-    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
-        self.overrides = overrides;
-        self
-    }
-
-    /// Adds a `--config key=value` override for this request.
-    pub fn config_override(mut self, key: impl Into<String>, value: impl Into<String>) -> Self {
-        self.overrides
-            .config_overrides
-            .push(ConfigOverride::new(key, value));
-        self
-    }
-
-    /// Adds a raw `--config key=value` override without validation.
-    pub fn config_override_raw(mut self, raw: impl Into<String>) -> Self {
-        self.overrides
-            .config_overrides
-            .push(ConfigOverride::from_raw(raw));
-        self
-    }
-
-    /// Sets the config profile (`--profile`) for this request.
-    pub fn profile(mut self, profile: impl Into<String>) -> Self {
-        let profile = profile.into();
-        self.overrides.profile = (!profile.trim().is_empty()).then_some(profile);
-        self
-    }
-
-    /// Requests the CLI `--oss` flag for this call.
-    pub fn oss(mut self, enable: bool) -> Self {
-        self.overrides.oss = if enable {
-            FlagState::Enable
-        } else {
-            FlagState::Disable
-        };
-        self
-    }
-
-    /// Adds a `--enable <feature>` toggle for this call.
-    pub fn enable_feature(mut self, name: impl Into<String>) -> Self {
-        self.overrides.feature_toggles.enable.push(name.into());
-        self
-    }
-
-    /// Adds a `--disable <feature>` toggle for this call.
-    pub fn disable_feature(mut self, name: impl Into<String>) -> Self {
-        self.overrides.feature_toggles.disable.push(name.into());
-        self
-    }
-
-    /// Controls whether `--search` is passed through to Codex.
-    pub fn search(mut self, enable: bool) -> Self {
-        self.overrides.search = if enable {
-            FlagState::Enable
-        } else {
-            FlagState::Disable
-        };
-        self
-    }
-}
-
-impl Default for FeaturesListRequest {
-    fn default() -> Self {
-        Self::new()
-    }
-}
-
-/// Request for `codex features`.
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub struct FeaturesCommandRequest {
-    /// Per-call CLI overrides layered on top of the builder.
-    pub overrides: CliOverridesPatch,
-}
-
-impl FeaturesCommandRequest {
-    pub fn new() -> Self {
-        Self {
-            overrides: CliOverridesPatch::default(),
-        }
-    }
-
-    /// Replaces the default CLI overrides for this request.
-    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
-        self.overrides = overrides;
-        self
-    }
-}
-
-impl Default for FeaturesCommandRequest {
-    fn default() -> Self {
-        Self::new()
-    }
-}
-
-/// Selector for `codex help`-style command families.
-#[derive(Clone, Copy, Debug, Eq, PartialEq)]
-pub enum HelpScope {
-    Root,
-    Exec,
-    Features,
-    Login,
-    AppServer,
-    Sandbox,
-    Cloud,
-    Mcp,
-}
-
-impl HelpScope {
-    fn argv_prefix(&self) -> &'static [&'static str] {
-        match self {
-            HelpScope::Root => &["help"],
-            HelpScope::Exec => &["exec", "help"],
-            HelpScope::Features => &["features", "help"],
-            HelpScope::Login => &["login", "help"],
-            HelpScope::AppServer => &["app-server", "help"],
-            HelpScope::Sandbox => &["sandbox", "help"],
-            HelpScope::Cloud => &["cloud", "help"],
-            HelpScope::Mcp => &["mcp", "help"],
-        }
-    }
-}
-
-/// Request for `codex <scope> help [COMMAND]...`.
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub struct HelpCommandRequest {
-    pub scope: HelpScope,
-    /// Optional command path components appended after `help` (variadic upstream).
-    pub command: Vec<String>,
-    /// Per-call CLI overrides layered on top of the builder.
-    pub overrides: CliOverridesPatch,
-}
-
-impl HelpCommandRequest {
-    pub fn new(scope: HelpScope) -> Self {
-        Self {
-            scope,
-            command: Vec::new(),
-            overrides: CliOverridesPatch::default(),
-        }
-    }
-
-    /// Appends one or more command tokens to the help invocation.
-    pub fn command<I, S>(mut self, tokens: I) -> Self
-    where
-        I: IntoIterator<Item = S>,
-        S: Into<String>,
-    {
-        self.command.extend(tokens.into_iter().map(Into::into));
-        self
-    }
-
-    /// Replaces the default CLI overrides for this request.
-    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
-        self.overrides = overrides;
-        self
-    }
-}
-
-/// Request for `codex review [OPTIONS] [PROMPT]`.
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub struct ReviewCommandRequest {
-    pub prompt: Option<String>,
-    pub base: Option<String>,
-    pub commit: Option<String>,
-    pub title: Option<String>,
-    pub uncommitted: bool,
-    /// Per-call CLI overrides layered on top of the builder.
-    pub overrides: CliOverridesPatch,
-}
-
-impl ReviewCommandRequest {
-    pub fn new() -> Self {
-        Self {
-            prompt: None,
-            base: None,
-            commit: None,
-            title: None,
-            uncommitted: false,
-            overrides: CliOverridesPatch::default(),
-        }
-    }
-
-    pub fn prompt(mut self, prompt: impl Into<String>) -> Self {
-        let prompt = prompt.into();
-        self.prompt = (!prompt.trim().is_empty()).then_some(prompt);
-        self
-    }
-
-    pub fn base(mut self, branch: impl Into<String>) -> Self {
-        let branch = branch.into();
-        self.base = (!branch.trim().is_empty()).then_some(branch);
-        self
-    }
-
-    pub fn commit(mut self, sha: impl Into<String>) -> Self {
-        let sha = sha.into();
-        self.commit = (!sha.trim().is_empty()).then_some(sha);
-        self
-    }
-
-    pub fn title(mut self, title: impl Into<String>) -> Self {
-        let title = title.into();
-        self.title = (!title.trim().is_empty()).then_some(title);
-        self
-    }
-
-    pub fn uncommitted(mut self, enable: bool) -> Self {
-        self.uncommitted = enable;
-        self
-    }
-
-    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
-        self.overrides = overrides;
-        self
-    }
-}
-
-impl Default for ReviewCommandRequest {
-    fn default() -> Self {
-        Self::new()
-    }
-}
-
-/// Request for `codex exec review [OPTIONS] [PROMPT]`.
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub struct ExecReviewCommandRequest {
-    pub prompt: Option<String>,
-    pub base: Option<String>,
-    pub commit: Option<String>,
-    pub title: Option<String>,
-    pub uncommitted: bool,
-    pub json: bool,
-    pub skip_git_repo_check: bool,
-    /// Per-call CLI overrides layered on top of the builder.
-    pub overrides: CliOverridesPatch,
-}
-
-impl ExecReviewCommandRequest {
-    pub fn new() -> Self {
-        Self {
-            prompt: None,
-            base: None,
-            commit: None,
-            title: None,
-            uncommitted: false,
-            json: false,
-            skip_git_repo_check: true,
-            overrides: CliOverridesPatch::default(),
-        }
-    }
-
-    pub fn prompt(mut self, prompt: impl Into<String>) -> Self {
-        let prompt = prompt.into();
-        self.prompt = (!prompt.trim().is_empty()).then_some(prompt);
-        self
-    }
-
-    pub fn base(mut self, branch: impl Into<String>) -> Self {
-        let branch = branch.into();
-        self.base = (!branch.trim().is_empty()).then_some(branch);
-        self
-    }
-
-    pub fn commit(mut self, sha: impl Into<String>) -> Self {
-        let sha = sha.into();
-        self.commit = (!sha.trim().is_empty()).then_some(sha);
-        self
-    }
-
-    pub fn title(mut self, title: impl Into<String>) -> Self {
-        let title = title.into();
-        self.title = (!title.trim().is_empty()).then_some(title);
-        self
-    }
-
-    pub fn uncommitted(mut self, enable: bool) -> Self {
-        self.uncommitted = enable;
-        self
-    }
-
-    pub fn json(mut self, enable: bool) -> Self {
-        self.json = enable;
-        self
-    }
-
-    pub fn skip_git_repo_check(mut self, enable: bool) -> Self {
-        self.skip_git_repo_check = enable;
-        self
-    }
-
-    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
-        self.overrides = overrides;
-        self
-    }
-}
-
-impl Default for ExecReviewCommandRequest {
-    fn default() -> Self {
-        Self::new()
-    }
-}
-
-/// Request for `codex resume [OPTIONS] [SESSION_ID] [PROMPT]`.
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub struct ResumeSessionRequest {
-    pub session_id: Option<String>,
-    pub prompt: Option<String>,
-    pub all: bool,
-    pub last: bool,
-    /// Per-call CLI overrides layered on top of the builder.
-    pub overrides: CliOverridesPatch,
-}
-
-impl ResumeSessionRequest {
-    pub fn new() -> Self {
-        Self {
-            session_id: None,
-            prompt: None,
-            all: false,
-            last: false,
-            overrides: CliOverridesPatch::default(),
-        }
-    }
-
-    pub fn session_id(mut self, session_id: impl Into<String>) -> Self {
-        let session_id = session_id.into();
-        self.session_id = (!session_id.trim().is_empty()).then_some(session_id);
-        self
-    }
-
-    pub fn prompt(mut self, prompt: impl Into<String>) -> Self {
-        let prompt = prompt.into();
-        self.prompt = (!prompt.trim().is_empty()).then_some(prompt);
-        self
-    }
-
-    pub fn all(mut self, enable: bool) -> Self {
-        self.all = enable;
-        self
-    }
-
-    pub fn last(mut self, enable: bool) -> Self {
-        self.last = enable;
-        self
-    }
-
-    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
-        self.overrides = overrides;
-        self
-    }
-}
-
-impl Default for ResumeSessionRequest {
-    fn default() -> Self {
-        Self::new()
-    }
-}
-
-/// Request for `codex fork [OPTIONS] [SESSION_ID] [PROMPT]`.
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub struct ForkSessionRequest {
-    pub session_id: Option<String>,
-    pub prompt: Option<String>,
-    pub all: bool,
-    pub last: bool,
-    /// Per-call CLI overrides layered on top of the builder.
-    pub overrides: CliOverridesPatch,
-}
-
-impl ForkSessionRequest {
-    pub fn new() -> Self {
-        Self {
-            session_id: None,
-            prompt: None,
-            all: false,
-            last: false,
-            overrides: CliOverridesPatch::default(),
-        }
-    }
-
-    pub fn session_id(mut self, session_id: impl Into<String>) -> Self {
-        let session_id = session_id.into();
-        self.session_id = (!session_id.trim().is_empty()).then_some(session_id);
-        self
-    }
-
-    pub fn prompt(mut self, prompt: impl Into<String>) -> Self {
-        let prompt = prompt.into();
-        self.prompt = (!prompt.trim().is_empty()).then_some(prompt);
-        self
-    }
-
-    pub fn all(mut self, enable: bool) -> Self {
-        self.all = enable;
-        self
-    }
-
-    pub fn last(mut self, enable: bool) -> Self {
-        self.last = enable;
-        self
-    }
-
-    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
-        self.overrides = overrides;
-        self
-    }
-}
-
-impl Default for ForkSessionRequest {
-    fn default() -> Self {
-        Self::new()
-    }
-}
-
-/// Request for `codex cloud` (overview/help).
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub struct CloudOverviewRequest {
-    pub overrides: CliOverridesPatch,
-}
-
-impl CloudOverviewRequest {
-    pub fn new() -> Self {
-        Self {
-            overrides: CliOverridesPatch::default(),
-        }
-    }
-
-    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
-        self.overrides = overrides;
-        self
-    }
-}
-
-impl Default for CloudOverviewRequest {
-    fn default() -> Self {
-        Self::new()
-    }
-}
-
-/// Request for `codex cloud list`.
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub struct CloudListRequest {
-    pub json: bool,
-    pub env_id: Option<String>,
-    pub limit: Option<u32>,
-    pub cursor: Option<String>,
-    pub overrides: CliOverridesPatch,
-}
-
-impl CloudListRequest {
-    pub fn new() -> Self {
-        Self {
-            json: false,
-            env_id: None,
-            limit: None,
-            cursor: None,
-            overrides: CliOverridesPatch::default(),
-        }
-    }
-
-    pub fn json(mut self, enable: bool) -> Self {
-        self.json = enable;
-        self
-    }
-
-    pub fn env_id(mut self, env_id: impl Into<String>) -> Self {
-        let env_id = env_id.into();
-        self.env_id = (!env_id.trim().is_empty()).then_some(env_id);
-        self
-    }
-
-    pub fn limit(mut self, limit: u32) -> Self {
-        self.limit = Some(limit);
-        self
-    }
-
-    pub fn cursor(mut self, cursor: impl Into<String>) -> Self {
-        let cursor = cursor.into();
-        self.cursor = (!cursor.trim().is_empty()).then_some(cursor);
-        self
-    }
-
-    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
-        self.overrides = overrides;
-        self
-    }
-}
-
-impl Default for CloudListRequest {
-    fn default() -> Self {
-        Self::new()
-    }
-}
-
-/// Output from `codex cloud list`.
-#[derive(Clone, Debug, PartialEq)]
-pub struct CloudListOutput {
-    pub status: ExitStatus,
-    pub stdout: String,
-    pub stderr: String,
-    /// Parsed JSON output when `--json` was requested.
-    pub json: Option<Value>,
-}
-
-/// Request for `codex cloud status <TASK_ID>`.
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub struct CloudStatusRequest {
-    pub task_id: String,
-    pub overrides: CliOverridesPatch,
-}
-
-impl CloudStatusRequest {
-    pub fn new(task_id: impl Into<String>) -> Self {
-        Self {
-            task_id: task_id.into(),
-            overrides: CliOverridesPatch::default(),
-        }
-    }
-
-    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
-        self.overrides = overrides;
-        self
-    }
-}
-
-/// Request for `codex cloud exec`.
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub struct CloudExecRequest {
-    pub env_id: String,
-    pub query: Option<String>,
-    pub attempts: Option<u32>,
-    pub branch: Option<String>,
-    pub overrides: CliOverridesPatch,
-}
-
-impl CloudExecRequest {
-    pub fn new(env_id: impl Into<String>) -> Self {
-        Self {
-            env_id: env_id.into(),
-            query: None,
-            attempts: None,
-            branch: None,
-            overrides: CliOverridesPatch::default(),
-        }
-    }
-
-    pub fn query(mut self, query: impl Into<String>) -> Self {
-        let query = query.into();
-        self.query = (!query.trim().is_empty()).then_some(query);
-        self
-    }
-
-    pub fn attempts(mut self, attempts: u32) -> Self {
-        self.attempts = Some(attempts);
-        self
-    }
-
-    pub fn branch(mut self, branch: impl Into<String>) -> Self {
-        let branch = branch.into();
-        self.branch = (!branch.trim().is_empty()).then_some(branch);
-        self
-    }
-
-    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
-        self.overrides = overrides;
-        self
-    }
-}
-
-/// Request for `codex mcp` (overview/help).
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub struct McpOverviewRequest {
-    pub overrides: CliOverridesPatch,
-}
-
-impl McpOverviewRequest {
-    pub fn new() -> Self {
-        Self {
-            overrides: CliOverridesPatch::default(),
-        }
-    }
-
-    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
-        self.overrides = overrides;
-        self
-    }
-}
-
-impl Default for McpOverviewRequest {
-    fn default() -> Self {
-        Self::new()
-    }
-}
-
-/// Request for `codex mcp list`.
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub struct McpListRequest {
-    pub json: bool,
-    pub overrides: CliOverridesPatch,
-}
-
-impl McpListRequest {
-    pub fn new() -> Self {
-        Self {
-            json: false,
-            overrides: CliOverridesPatch::default(),
-        }
-    }
-
-    pub fn json(mut self, enable: bool) -> Self {
-        self.json = enable;
-        self
-    }
-
-    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
-        self.overrides = overrides;
-        self
-    }
-}
-
-impl Default for McpListRequest {
-    fn default() -> Self {
-        Self::new()
-    }
-}
-
-/// Output from `codex mcp list`.
-#[derive(Clone, Debug, PartialEq)]
-pub struct McpListOutput {
-    pub status: ExitStatus,
-    pub stdout: String,
-    pub stderr: String,
-    pub json: Option<Value>,
-}
-
-/// Request for `codex mcp get <NAME>`.
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub struct McpGetRequest {
-    pub name: String,
-    pub json: bool,
-    pub overrides: CliOverridesPatch,
-}
-
-impl McpGetRequest {
-    pub fn new(name: impl Into<String>) -> Self {
-        Self {
-            name: name.into(),
-            json: false,
-            overrides: CliOverridesPatch::default(),
-        }
-    }
-
-    pub fn json(mut self, enable: bool) -> Self {
-        self.json = enable;
-        self
-    }
-
-    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
-        self.overrides = overrides;
-        self
-    }
-}
-
-/// Transport for `codex mcp add`.
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub enum McpAddTransport {
-    Stdio {
-        env: Vec<(String, String)>,
-        command: Vec<OsString>,
-    },
-    StreamableHttp {
-        url: String,
-        bearer_token_env_var: Option<String>,
-    },
-}
-
-/// Request for `codex mcp add`.
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub struct McpAddRequest {
-    pub name: String,
-    pub transport: McpAddTransport,
-    pub overrides: CliOverridesPatch,
-}
-
-impl McpAddRequest {
-    pub fn stdio(name: impl Into<String>, command: Vec<OsString>) -> Self {
-        Self {
-            name: name.into(),
-            transport: McpAddTransport::Stdio {
-                env: Vec::new(),
-                command,
-            },
-            overrides: CliOverridesPatch::default(),
-        }
-    }
-
-    pub fn streamable_http(name: impl Into<String>, url: impl Into<String>) -> Self {
-        Self {
-            name: name.into(),
-            transport: McpAddTransport::StreamableHttp {
-                url: url.into(),
-                bearer_token_env_var: None,
-            },
-            overrides: CliOverridesPatch::default(),
-        }
-    }
-
-    pub fn env(mut self, key: impl Into<String>, value: impl Into<String>) -> Self {
-        if let McpAddTransport::Stdio { env, .. } = &mut self.transport {
-            env.push((key.into(), value.into()));
-        }
-        self
-    }
-
-    pub fn bearer_token_env_var(mut self, env_var: impl Into<String>) -> Self {
-        if let McpAddTransport::StreamableHttp {
-            bearer_token_env_var,
-            ..
-        } = &mut self.transport
-        {
-            let env_var = env_var.into();
-            *bearer_token_env_var = (!env_var.trim().is_empty()).then_some(env_var);
-        }
-        self
-    }
-
-    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
-        self.overrides = overrides;
-        self
-    }
-}
-
-/// Request for `codex mcp remove <NAME>`.
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub struct McpRemoveRequest {
-    pub name: String,
-    pub overrides: CliOverridesPatch,
-}
-
-impl McpRemoveRequest {
-    pub fn new(name: impl Into<String>) -> Self {
-        Self {
-            name: name.into(),
-            overrides: CliOverridesPatch::default(),
-        }
-    }
-
-    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
-        self.overrides = overrides;
-        self
-    }
-}
-
-/// Request for `codex mcp logout <NAME>`.
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub struct McpLogoutRequest {
-    pub name: String,
-    pub overrides: CliOverridesPatch,
-}
-
-impl McpLogoutRequest {
-    pub fn new(name: impl Into<String>) -> Self {
-        Self {
-            name: name.into(),
-            overrides: CliOverridesPatch::default(),
-        }
-    }
-
-    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
-        self.overrides = overrides;
-        self
-    }
-}
-
-/// Request for `codex mcp login <NAME>` (OAuth).
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub struct McpOauthLoginRequest {
-    pub name: String,
-    pub scopes: Vec<String>,
-    pub overrides: CliOverridesPatch,
-}
-
-impl McpOauthLoginRequest {
-    pub fn new(name: impl Into<String>) -> Self {
-        Self {
-            name: name.into(),
-            scopes: Vec::new(),
-            overrides: CliOverridesPatch::default(),
-        }
-    }
-
-    pub fn scopes<I, S>(mut self, scopes: I) -> Self
-    where
-        I: IntoIterator<Item = S>,
-        S: Into<String>,
-    {
-        self.scopes.extend(
-            scopes
-                .into_iter()
-                .map(|s| s.into())
-                .filter(|s| !s.trim().is_empty()),
-        );
-        self
-    }
-
-    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
-        self.overrides = overrides;
-        self
-    }
-}
-
-/// Target for app-server code generation.
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub enum AppServerCodegenTarget {
-    /// Emits TypeScript bindings for the app-server protocol. Optionally formats the output with Prettier.
-    TypeScript { prettier: Option<PathBuf> },
-    /// Emits a JSON schema bundle for the app-server protocol.
-    JsonSchema,
-}
-
-impl AppServerCodegenTarget {
-    fn subcommand(&self) -> &'static str {
-        match self {
-            AppServerCodegenTarget::TypeScript { .. } => "generate-ts",
-            AppServerCodegenTarget::JsonSchema => "generate-json-schema",
-        }
-    }
-
-    fn prettier(&self) -> Option<&PathBuf> {
-        match self {
-            AppServerCodegenTarget::TypeScript { prettier } => prettier.as_ref(),
-            AppServerCodegenTarget::JsonSchema => None,
-        }
-    }
-}
-
-/// Request for `codex app-server generate-ts` or `generate-json-schema`.
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub struct AppServerCodegenRequest {
-    /// Codegen target and optional Prettier path (TypeScript only).
-    pub target: AppServerCodegenTarget,
-    /// Output directory passed to `--out`; created if missing.
-    pub out_dir: PathBuf,
-    /// Per-call CLI overrides layered on top of the builder.
-    pub overrides: CliOverridesPatch,
-}
-
-impl AppServerCodegenRequest {
-    /// Generates TypeScript bindings into `out_dir`.
-    pub fn typescript(out_dir: impl Into<PathBuf>) -> Self {
-        Self {
-            target: AppServerCodegenTarget::TypeScript { prettier: None },
-            out_dir: out_dir.into(),
-            overrides: CliOverridesPatch::default(),
-        }
-    }
-
-    /// Generates a JSON schema bundle into `out_dir`.
-    pub fn json_schema(out_dir: impl Into<PathBuf>) -> Self {
-        Self {
-            target: AppServerCodegenTarget::JsonSchema,
-            out_dir: out_dir.into(),
-            overrides: CliOverridesPatch::default(),
-        }
-    }
-
-    /// Formats TypeScript output with the provided Prettier executable (no-op for JSON schema).
-    pub fn prettier(mut self, prettier: impl Into<PathBuf>) -> Self {
-        if let AppServerCodegenTarget::TypeScript { prettier: slot } = &mut self.target {
-            *slot = Some(prettier.into());
-        }
-        self
-    }
-
-    /// Replaces the default CLI overrides for this request.
-    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
-        self.overrides = overrides;
-        self
-    }
-
-    /// Adds a `--config key=value` override for this request.
-    pub fn config_override(mut self, key: impl Into<String>, value: impl Into<String>) -> Self {
-        self.overrides
-            .config_overrides
-            .push(ConfigOverride::new(key, value));
-        self
-    }
-
-    /// Adds a raw `--config key=value` override without validation.
-    pub fn config_override_raw(mut self, raw: impl Into<String>) -> Self {
-        self.overrides
-            .config_overrides
-            .push(ConfigOverride::from_raw(raw));
-        self
-    }
-
-    /// Sets the config profile (`--profile`) for this request.
-    pub fn profile(mut self, profile: impl Into<String>) -> Self {
-        let profile = profile.into();
-        self.overrides.profile = (!profile.trim().is_empty()).then_some(profile);
-        self
-    }
-
-    /// Requests the CLI `--oss` flag for this codegen call.
-    pub fn oss(mut self, enable: bool) -> Self {
-        self.overrides.oss = if enable {
-            FlagState::Enable
-        } else {
-            FlagState::Disable
-        };
-        self
-    }
-
-    /// Adds a `--enable <feature>` toggle for this codegen call.
-    pub fn enable_feature(mut self, name: impl Into<String>) -> Self {
-        self.overrides.feature_toggles.enable.push(name.into());
-        self
-    }
-
-    /// Adds a `--disable <feature>` toggle for this codegen call.
-    pub fn disable_feature(mut self, name: impl Into<String>) -> Self {
-        self.overrides.feature_toggles.disable.push(name.into());
-        self
-    }
-
-    /// Controls whether `--search` is passed through to Codex.
-    pub fn search(mut self, enable: bool) -> Self {
-        self.overrides.search = if enable {
-            FlagState::Enable
-        } else {
-            FlagState::Disable
-        };
-        self
-    }
-}
-
-/// Captured output from app-server codegen commands.
-#[derive(Clone, Debug)]
-pub struct AppServerCodegenOutput {
-    /// Exit status returned by the subcommand.
-    pub status: ExitStatus,
-    /// Captured stdout (mirrored to the console when `mirror_stdout` is true).
-    pub stdout: String,
-    /// Captured stderr (mirrored unless `quiet` is set).
-    pub stderr: String,
-    /// Output directory passed to `--out`.
-    pub out_dir: PathBuf,
-}
-
-/// Ergonomic container for the streaming surface; produced by `stream_exec` (implemented in D2).
-///
-/// `events` yields parsed [`ThreadEvent`] values as soon as each JSONL line arrives from the CLI.
-/// `completion` resolves once the Codex process exits and is the place to surface `--output-last-message`
-/// and `--output-schema` paths after streaming finishes.
-pub struct ExecStream {
-    pub events: DynThreadEventStream,
-    pub completion: DynExecCompletion,
-}
-
-/// Type-erased stream of events from the Codex CLI.
-pub type DynThreadEventStream =
-    Pin<Box<dyn Stream<Item = Result<ThreadEvent, ExecStreamError>> + Send>>;
-
-/// Type-erased completion future that resolves when streaming stops.
-pub type DynExecCompletion =
-    Pin<Box<dyn Future<Output = Result<ExecCompletion, ExecStreamError>> + Send>>;
-
-/// Summary returned when the codex child process exits.
-#[derive(Clone, Debug)]
-pub struct ExecCompletion {
-    pub status: ExitStatus,
-    /// Path that codex wrote when `--output-last-message` was enabled. The wrapper may eagerly
-    /// read the file and populate `last_message` when feasible.
-    pub last_message_path: Option<PathBuf>,
-    pub last_message: Option<String>,
-    /// Path to the JSON schema requested via `--output-schema`, if provided by the caller.
-    pub schema_path: Option<PathBuf>,
-}
-
-/// Errors that may occur while consuming the JSONL stream.
-#[derive(Debug, Error)]
-pub enum ExecStreamError {
-    #[error(transparent)]
-    Codex(#[from] CodexError),
-    #[error("failed to parse codex JSONL event: {source}: `{line}`")]
-    Parse {
-        line: String,
-        #[source]
-        source: serde_json::Error,
-    },
-    #[error("codex JSONL event missing required context: {message}: `{line}`")]
-    Normalize { line: String, message: String },
-    #[error("codex JSON stream idle for {idle_for:?}")]
-    IdleTimeout { idle_for: Duration },
-    #[error("codex JSON stream closed unexpectedly")]
-    ChannelClosed,
-}
-
-async fn read_last_message(path: &Path) -> Option<String> {
-    (fs::read_to_string(path).await).ok()
-}
-
-fn unique_temp_path(prefix: &str, extension: &str) -> PathBuf {
-    let mut path = env::temp_dir();
-    let timestamp = SystemTime::now()
-        .duration_since(UNIX_EPOCH)
-        .unwrap_or_else(|_| Duration::from_secs(0))
-        .as_nanos();
-    path.push(format!(
-        "{prefix}{timestamp}_{}.{}",
-        std::process::id(),
-        extension
-    ));
-    path
-}
-
-enum DirectoryContext {
-    Fixed(PathBuf),
-    Ephemeral(TempDir),
-}
-
-impl DirectoryContext {
-    fn path(&self) -> &Path {
-        match self {
-            DirectoryContext::Fixed(path) => path.as_path(),
-            DirectoryContext::Ephemeral(dir) => dir.path(),
-        }
-    }
-}
-
-fn command_output_text(output: &CommandOutput) -> String {
-    let stdout = String::from_utf8_lossy(&output.stdout).into_owned();
-    let stderr = String::from_utf8_lossy(&output.stderr).into_owned();
-    let stdout = stdout.trim_end();
-    let stderr = stderr.trim_end();
-    if stdout.is_empty() {
-        stderr.to_string()
-    } else if stderr.is_empty() {
-        stdout.to_string()
-    } else {
-        format!("{stdout}\n{stderr}")
-    }
-}
-
-fn parse_semver_from_raw(raw: &str) -> Option<Version> {
-    for token in raw.split_whitespace() {
-        let candidate = token
-            .trim_matches(|c: char| matches!(c, '(' | ')' | ',' | ';'))
-            .trim_start_matches('v');
-        if let Ok(version) = Version::parse(candidate) {
-            return Some(version);
-        }
-    }
-    None
-}
-
-fn parse_version_output(output: &str) -> CodexVersionInfo {
-    let raw = output.trim().to_string();
-    let parsed_version = parse_semver_from_raw(&raw);
-    let semantic = parsed_version
-        .as_ref()
-        .map(|version| (version.major, version.minor, version.patch));
-    let mut commit = extract_commit_hash(&raw);
-    if commit.is_none() {
-        for token in raw.split_whitespace() {
-            let candidate = token
-                .trim_matches(|c: char| matches!(c, '(' | ')' | ',' | ';'))
-                .trim_start_matches('v');
-            if let Some(cleaned) = cleaned_hex(candidate) {
-                commit = Some(cleaned);
-                break;
-            }
-        }
-    }
-    let channel = parsed_version
-        .as_ref()
-        .map(release_channel_for_version)
-        .unwrap_or_else(|| infer_release_channel(&raw));
-
-    CodexVersionInfo {
-        raw,
-        semantic,
-        commit,
-        channel,
-    }
-}
-
-fn release_channel_for_version(version: &Version) -> CodexReleaseChannel {
-    if version.pre.is_empty() {
-        CodexReleaseChannel::Stable
-    } else {
-        let prerelease = version.pre.as_str().to_ascii_lowercase();
-        if prerelease.contains("beta") {
-            CodexReleaseChannel::Beta
-        } else if prerelease.contains("nightly") {
-            CodexReleaseChannel::Nightly
-        } else {
-            CodexReleaseChannel::Custom
-        }
-    }
-}
-
-fn infer_release_channel(raw: &str) -> CodexReleaseChannel {
-    let lower = raw.to_ascii_lowercase();
-    if lower.contains("beta") {
-        CodexReleaseChannel::Beta
-    } else if lower.contains("nightly") {
-        CodexReleaseChannel::Nightly
-    } else {
-        CodexReleaseChannel::Custom
-    }
-}
-
-fn codex_semver(info: &CodexVersionInfo) -> Option<Version> {
-    if let Some(parsed) = parse_semver_from_raw(&info.raw) {
-        return Some(parsed);
-    }
-    let (major, minor, patch) = info.semantic?;
-    let mut version = Version::new(major, minor, patch);
-    if version.pre.is_empty() {
-        match info.channel {
-            CodexReleaseChannel::Beta => {
-                version.pre = Prerelease::new("beta").ok()?;
-            }
-            CodexReleaseChannel::Nightly => {
-                version.pre = Prerelease::new("nightly").ok()?;
-            }
-            CodexReleaseChannel::Stable | CodexReleaseChannel::Custom => {}
-        }
-    }
-    Some(version)
-}
-
-fn codex_release_from_info(info: &CodexVersionInfo) -> Option<CodexRelease> {
-    let version = codex_semver(info)?;
-    Some(CodexRelease {
-        channel: info.channel,
-        version,
-    })
-}
-
-fn extract_commit_hash(raw: &str) -> Option<String> {
-    let tokens: Vec<&str> = raw.split_whitespace().collect();
-    for window in tokens.windows(2) {
-        if window[0].eq_ignore_ascii_case("commit") {
-            if let Some(cleaned) = cleaned_hex(window[1]) {
-                return Some(cleaned);
-            }
-        }
-    }
-
-    for token in tokens {
-        if let Some(cleaned) = cleaned_hex(token) {
-            return Some(cleaned);
-        }
-    }
-    None
-}
-
-fn cleaned_hex(token: &str) -> Option<String> {
-    let trimmed = token
-        .trim_matches(|c: char| matches!(c, '(' | ')' | ',' | ';'))
-        .trim_start_matches("commit")
-        .trim_start_matches(':')
-        .trim_start_matches('g');
-    if trimmed.len() >= 7 && trimmed.chars().all(|c| c.is_ascii_hexdigit()) {
-        Some(trimmed.to_string())
-    } else {
-        None
-    }
-}
-
-fn parse_features_from_json(output: &str) -> Option<CodexFeatureFlags> {
-    let parsed: Value = serde_json::from_str(output).ok()?;
-    let mut tokens = HashSet::new();
-    collect_feature_tokens(&parsed, &mut tokens);
-    if tokens.is_empty() {
-        return None;
-    }
-
-    let mut flags = CodexFeatureFlags::default();
-    for token in tokens {
-        apply_feature_token(&mut flags, &token);
-    }
-    Some(flags)
-}
-
-fn collect_feature_tokens(value: &Value, tokens: &mut HashSet<String>) {
-    match value {
-        Value::String(value) => {
-            if !value.trim().is_empty() {
-                tokens.insert(value.clone());
-            }
-        }
-        Value::Array(items) => {
-            for item in items {
-                collect_feature_tokens(item, tokens);
-            }
-        }
-        Value::Object(map) => {
-            for (key, value) in map {
-                if let Value::Bool(true) = value {
-                    tokens.insert(key.clone());
-                }
-                collect_feature_tokens(value, tokens);
-            }
-        }
-        _ => {}
-    }
-}
-
-fn parse_features_from_text(output: &str) -> CodexFeatureFlags {
-    let mut flags = CodexFeatureFlags::default();
-    let lower = output.to_ascii_lowercase();
-    if lower.contains("features list") {
-        flags.supports_features_list = true;
-    }
-    if lower.contains("--output-schema") || lower.contains("output schema") {
-        flags.supports_output_schema = true;
-    }
-    if lower.contains("add-dir") || lower.contains("add dir") {
-        flags.supports_add_dir = true;
-    }
-    if lower.contains("login --mcp") || lower.contains("mcp login") {
-        flags.supports_mcp_login = true;
-    }
-    if lower.contains("login") && lower.contains("mcp") {
-        flags.supports_mcp_login = true;
-    }
-
-    for token in lower
-        .split(|c: char| c.is_ascii_whitespace() || c == ',' || c == ';' || c == '|')
-        .filter(|token| !token.is_empty())
-    {
-        apply_feature_token(&mut flags, token);
-    }
-    flags
-}
-
-fn parse_help_output(output: &str) -> CodexFeatureFlags {
-    let mut flags = parse_features_from_text(output);
-    let lower = output.to_ascii_lowercase();
-    if lower.contains("features list") {
-        flags.supports_features_list = true;
-    }
-    flags
-}
-
-fn merge_feature_flags(target: &mut CodexFeatureFlags, update: CodexFeatureFlags) {
-    target.supports_features_list |= update.supports_features_list;
-    target.supports_output_schema |= update.supports_output_schema;
-    target.supports_add_dir |= update.supports_add_dir;
-    target.supports_mcp_login |= update.supports_mcp_login;
-}
-
-fn detected_feature_flags(flags: &CodexFeatureFlags) -> bool {
-    flags.supports_output_schema || flags.supports_add_dir || flags.supports_mcp_login
-}
-
-fn should_run_help_fallback(flags: &CodexFeatureFlags) -> bool {
-    !flags.supports_features_list
-        || !flags.supports_output_schema
-        || !flags.supports_add_dir
-        || !flags.supports_mcp_login
-}
-
-fn normalize_feature_token(token: &str) -> String {
-    token
-        .chars()
-        .map(|c| {
-            if c.is_ascii_alphanumeric() {
-                c.to_ascii_lowercase()
-            } else {
-                '_'
-            }
-        })
-        .collect()
-}
-
-fn apply_feature_token(flags: &mut CodexFeatureFlags, token: &str) {
-    let normalized = normalize_feature_token(token);
-    let compact = normalized.replace('_', "");
-    if normalized.contains("features_list") || compact.contains("featureslist") {
-        flags.supports_features_list = true;
-    }
-    if normalized.contains("output_schema") || compact.contains("outputschema") {
-        flags.supports_output_schema = true;
-    }
-    if normalized.contains("add_dir") || compact.contains("adddir") {
-        flags.supports_add_dir = true;
-    }
-    if normalized.contains("mcp_login")
-        || (normalized.contains("login") && normalized.contains("mcp"))
-    {
-        flags.supports_mcp_login = true;
-    }
-}
-
-fn parse_feature_list_output(
-    stdout: &str,
-    prefer_json: bool,
-) -> Result<(Vec<CodexFeature>, FeaturesListFormat), String> {
-    let trimmed = stdout.trim();
-    if trimmed.is_empty() {
-        return Err("features list output was empty".to_string());
-    }
-
-    if prefer_json {
-        if let Some(features) = parse_feature_list_json(trimmed) {
-            if !features.is_empty() {
-                return Ok((features, FeaturesListFormat::Json));
-            }
-        }
-        if let Some(features) = parse_feature_list_text(trimmed) {
-            if !features.is_empty() {
-                return Ok((features, FeaturesListFormat::Text));
-            }
-        }
-    } else {
-        if let Some(features) = parse_feature_list_text(trimmed) {
-            if !features.is_empty() {
-                return Ok((features, FeaturesListFormat::Text));
-            }
-        }
-        if let Some(features) = parse_feature_list_json(trimmed) {
-            if !features.is_empty() {
-                return Ok((features, FeaturesListFormat::Json));
-            }
-        }
-    }
-
-    Err("could not parse JSON or text feature rows".to_string())
-}
-
-fn parse_feature_list_json(output: &str) -> Option<Vec<CodexFeature>> {
-    let parsed: Value = serde_json::from_str(output).ok()?;
-    parse_feature_list_json_value(&parsed)
-}
-
-fn parse_feature_list_json_value(value: &Value) -> Option<Vec<CodexFeature>> {
-    match value {
-        Value::Array(items) => Some(
-            items
-                .iter()
-                .filter_map(|item| match item {
-                    Value::Object(map) => feature_from_json_fields(None, map),
-                    Value::String(name) => Some(CodexFeature {
-                        name: name.clone(),
-                        stage: None,
-                        enabled: true,
-                        extra: BTreeMap::new(),
-                    }),
-                    _ => None,
-                })
-                .collect(),
-        ),
-        Value::Object(map) => {
-            if let Some(features) = map.get("features") {
-                return parse_feature_list_json_value(features);
-            }
-            if map.contains_key("name") || map.contains_key("enabled") || map.contains_key("stage")
-            {
-                return feature_from_json_fields(None, map).map(|feature| vec![feature]);
-            }
-            Some(
-                map.iter()
-                    .filter_map(|(name, value)| match value {
-                        Value::Object(inner) => {
-                            feature_from_json_fields(Some(name.as_str()), inner)
-                        }
-                        Value::Bool(flag) => Some(CodexFeature {
-                            name: name.clone(),
-                            stage: None,
-                            enabled: *flag,
-                            extra: BTreeMap::new(),
-                        }),
-                        Value::String(flag) => parse_feature_enabled_str(flag)
-                            .map(|enabled| CodexFeature {
-                                name: name.clone(),
-                                stage: None,
-                                enabled,
-                                extra: BTreeMap::new(),
-                            })
-                            .or_else(|| {
-                                Some(CodexFeature {
-                                    name: name.clone(),
-                                    stage: Some(CodexFeatureStage::parse(flag)),
-                                    enabled: true,
-                                    extra: BTreeMap::new(),
-                                })
-                            }),
-                        _ => None,
-                    })
-                    .collect(),
-            )
-        }
-        _ => None,
-    }
-}
-
-fn parse_feature_list_text(output: &str) -> Option<Vec<CodexFeature>> {
-    let mut features = Vec::new();
-    for line in output.lines() {
-        let trimmed = line.trim();
-        if trimmed.is_empty() {
-            continue;
-        }
-        if trimmed
-            .chars()
-            .all(|c| matches!(c, '-' | '=' | '+' | '*' | '|'))
-        {
-            continue;
-        }
-
-        let tokens: Vec<&str> = trimmed.split_whitespace().collect();
-        if tokens.len() < 3 {
-            continue;
-        }
-        if tokens[0].eq_ignore_ascii_case("feature")
-            && tokens[1].eq_ignore_ascii_case("stage")
-            && tokens[2].eq_ignore_ascii_case("enabled")
-        {
-            continue;
-        }
-
-        let enabled_token = tokens.last().copied().unwrap_or_default();
-        let enabled = match parse_feature_enabled_str(enabled_token) {
-            Some(value) => value,
-            None => continue,
-        };
-        let stage_token = tokens.get(tokens.len() - 2).copied().unwrap_or_default();
-        let name = tokens[..tokens.len() - 2].join(" ");
-        if name.is_empty() {
-            continue;
-        }
-        let stage = (!stage_token.is_empty()).then(|| CodexFeatureStage::parse(stage_token));
-        features.push(CodexFeature {
-            name,
-            stage,
-            enabled,
-            extra: BTreeMap::new(),
-        });
-    }
-
-    if features.is_empty() {
-        None
-    } else {
-        Some(features)
-    }
-}
-
-fn parse_feature_enabled_value(value: &Value) -> Option<bool> {
-    match value {
-        Value::Bool(flag) => Some(*flag),
-        Value::String(raw) => parse_feature_enabled_str(raw),
-        _ => None,
-    }
-}
-
-fn parse_feature_enabled_str(raw: &str) -> Option<bool> {
-    match raw.trim().to_ascii_lowercase().as_str() {
-        "true" | "yes" | "y" | "on" | "1" | "enabled" => Some(true),
-        "false" | "no" | "n" | "off" | "0" | "disabled" => Some(false),
-        _ => None,
-    }
-}
-
-fn feature_from_json_fields(
-    name_hint: Option<&str>,
-    map: &serde_json::Map<String, Value>,
-) -> Option<CodexFeature> {
-    let name = map
-        .get("name")
-        .and_then(Value::as_str)
-        .map(str::to_string)
-        .or_else(|| name_hint.map(str::to_string))?;
-    let enabled = map
-        .get("enabled")
-        .and_then(parse_feature_enabled_value)
-        .or_else(|| map.get("value").and_then(parse_feature_enabled_value))?;
-    let stage = map
-        .get("stage")
-        .or_else(|| map.get("status"))
-        .and_then(Value::as_str)
-        .map(CodexFeatureStage::parse);
-
-    let mut extra = BTreeMap::new();
-    for (key, value) in map {
-        if matches!(
-            key.as_str(),
-            "name" | "stage" | "status" | "enabled" | "value"
-        ) {
-            continue;
-        }
-        extra.insert(key.clone(), value.clone());
-    }
-
-    Some(CodexFeature {
-        name,
-        stage,
-        enabled,
-        extra,
-    })
-}
-
-/// Computes an update advisory for a previously probed binary.
-///
-/// Callers that already have a [`CodexCapabilities`] snapshot can use this
-/// helper to avoid re-running `codex --version`. Provide a [`CodexLatestReleases`]
-/// table sourced from your preferred distribution channel.
-pub fn update_advisory_from_capabilities(
-    capabilities: &CodexCapabilities,
-    latest_releases: &CodexLatestReleases,
-) -> CodexUpdateAdvisory {
-    let local_release = capabilities
-        .version
-        .as_ref()
-        .and_then(codex_release_from_info);
-    let preferred_channel = local_release
-        .as_ref()
-        .map(|release| release.channel)
-        .unwrap_or(CodexReleaseChannel::Stable);
-    let (latest_release, comparison_channel, fell_back) =
-        latest_releases.select_for_channel(preferred_channel);
-    let mut notes = Vec::new();
-
-    if fell_back {
-        notes.push(format!(
-            "No latest {preferred_channel} release provided; comparing against {comparison_channel}."
-        ));
-    }
-
-    let status = match (local_release.as_ref(), latest_release.as_ref()) {
-        (None, None) => CodexUpdateStatus::UnknownLatestVersion,
-        (None, Some(_)) => CodexUpdateStatus::UnknownLocalVersion,
-        (Some(_), None) => CodexUpdateStatus::UnknownLatestVersion,
-        (Some(local), Some(latest)) => {
-            if local.version < latest.version {
-                CodexUpdateStatus::UpdateRecommended
-            } else if local.version > latest.version {
-                CodexUpdateStatus::LocalNewerThanKnown
-            } else {
-                CodexUpdateStatus::UpToDate
-            }
-        }
-    };
-
-    match status {
-        CodexUpdateStatus::UpdateRecommended => {
-            if let (Some(local), Some(latest)) = (local_release.as_ref(), latest_release.as_ref()) {
-                notes.push(format!(
-                    "Local codex {local_version} is behind latest {comparison_channel} {latest_version}.",
-                    local_version = local.version,
-                    latest_version = latest.version
-                ));
-            }
-        }
-        CodexUpdateStatus::LocalNewerThanKnown => {
-            if let Some(local) = local_release.as_ref() {
-                let known = latest_release
-                    .as_ref()
-                    .map(|release| release.version.to_string())
-                    .unwrap_or_else(|| "unknown".to_string());
-                notes.push(format!(
-                    "Local codex {local_version} is newer than provided {comparison_channel} metadata (latest table: {known}).",
-                    local_version = local.version
-                ));
-            }
-        }
-        CodexUpdateStatus::UnknownLocalVersion => {
-            if let Some(latest) = latest_release.as_ref() {
-                notes.push(format!(
-                    "Latest known {comparison_channel} release is {latest_version}; local version could not be parsed.",
-                    latest_version = latest.version
-                ));
-            } else {
-                notes.push(
-                    "Local version could not be parsed and no latest release was provided."
-                        .to_string(),
-                );
-            }
-        }
-        CodexUpdateStatus::UnknownLatestVersion => notes.push(
-            "No latest Codex release information provided; update advisory unavailable."
-                .to_string(),
-        ),
-        CodexUpdateStatus::UpToDate => {
-            if let Some(latest) = latest_release.as_ref() {
-                notes.push(format!(
-                    "Local codex matches latest {comparison_channel} release {latest_version}.",
-                    latest_version = latest.version
-                ));
-            }
-        }
-    }
-
-    CodexUpdateAdvisory {
-        local_release,
-        latest_release,
-        comparison_channel,
-        status,
-        notes,
-    }
-}
-
-#[cfg(test)]
-mod tests {
-    use super::*;
-    use crate::builder::ResolvedCliOverrides;
-    use futures_util::{pin_mut, StreamExt};
-    use serde_json::json;
-    use std::collections::HashMap;
-    use std::fs as std_fs;
-    #[cfg(unix)]
-    use std::os::unix::fs::PermissionsExt;
-    use std::sync::OnceLock;
-    use std::time::{Duration, SystemTime};
-    use tokio::{
-        fs,
-        io::{AsyncBufReadExt, AsyncWriteExt, BufReader},
-    };
-
-    fn env_mutex() -> &'static tokio::sync::Mutex<()> {
-        static ENV_MUTEX: OnceLock<tokio::sync::Mutex<()>> = OnceLock::new();
-        ENV_MUTEX.get_or_init(|| tokio::sync::Mutex::new(()))
-    }
-
-    fn env_guard() -> tokio::sync::MutexGuard<'static, ()> {
-        env_mutex().blocking_lock()
-    }
-
-    async fn env_guard_async() -> tokio::sync::MutexGuard<'static, ()> {
-        env_mutex().lock().await
-    }
-
-    #[tokio::test]
-    async fn json_stream_preserves_order_and_parses_tool_calls() {
-        let lines = [
-            r#"{"type":"thread.started","thread_id":"thread-1"}"#.to_string(),
-            serde_json::to_string(&json!({
-                "type": "item.started",
-                "thread_id": "thread-1",
-                "turn_id": "turn-1",
-                "item_id": "item-1",
-                "item_type": "mcp_tool_call",
-                "content": {
-                    "server_name": "files",
-                    "tool_name": "list",
-                    "status": "running"
-                }
-            }))
-            .unwrap(),
-            serde_json::to_string(&json!({
-                "type": "item.delta",
-                "thread_id": "thread-1",
-                "turn_id": "turn-1",
-                "item_id": "item-1",
-                "item_type": "mcp_tool_call",
-                "delta": {
-                    "result": {"paths": ["foo.rs"]},
-                    "status": "completed"
-                }
-            }))
-            .unwrap(),
-        ];
-
-        let (mut writer, reader) = tokio::io::duplex(4096);
-        let (tx, rx) = mpsc::channel(8);
-        let forward_handle =
-            tokio::spawn(crate::jsonl::forward_json_events(reader, tx, false, None));
-
-        for line in &lines {
-            writer.write_all(line.as_bytes()).await.unwrap();
-            writer.write_all(b"\n").await.unwrap();
-        }
-        writer.shutdown().await.unwrap();
-
-        let stream = crate::jsonl::EventChannelStream::new(rx, None);
-        pin_mut!(stream);
-        let events: Vec<_> = stream.collect().await;
-        forward_handle.await.unwrap().unwrap();
-
-        assert_eq!(events.len(), lines.len(), "events: {events:?}");
-
-        match &events[0] {
-            Ok(ThreadEvent::ThreadStarted(event)) => {
-                assert_eq!(event.thread_id, "thread-1");
-            }
-            other => panic!("unexpected first event: {other:?}"),
-        }
-
-        match &events[1] {
-            Ok(ThreadEvent::ItemStarted(envelope)) => {
-                assert_eq!(envelope.thread_id, "thread-1");
-                assert_eq!(envelope.turn_id, "turn-1");
-                match &envelope.item.payload {
-                    ItemPayload::McpToolCall(state) => {
-                        assert_eq!(state.server_name, "files");
-                        assert_eq!(state.tool_name, "list");
-                        assert_eq!(state.status, ToolCallStatus::Running);
-                    }
-                    other => panic!("unexpected payload: {other:?}"),
-                }
-            }
-            other => panic!("unexpected second event: {other:?}"),
-        }
-
-        match &events[2] {
-            Ok(ThreadEvent::ItemDelta(delta)) => {
-                assert_eq!(delta.item_id, "item-1");
-                match &delta.delta {
-                    ItemDeltaPayload::McpToolCall(call_delta) => {
-                        assert_eq!(call_delta.status, ToolCallStatus::Completed);
-                        let result = call_delta
-                            .result
-                            .as_ref()
-                            .expect("tool call delta result is captured");
-                        assert_eq!(result["paths"][0], "foo.rs");
-                    }
-                    other => panic!("unexpected delta payload: {other:?}"),
-                }
-            }
-            other => panic!("unexpected third event: {other:?}"),
-        }
-    }
-
-    #[tokio::test]
-    async fn json_stream_propagates_parse_errors() {
-        let (mut writer, reader) = tokio::io::duplex(1024);
-        let (tx, rx) = mpsc::channel(4);
-        let forward_handle =
-            tokio::spawn(crate::jsonl::forward_json_events(reader, tx, false, None));
-
-        writer
-            .write_all(br#"{"type":"thread.started","thread_id":"thread-err"}"#)
-            .await
-            .unwrap();
-        writer.write_all(b"\nthis is not json\n").await.unwrap();
-        writer.shutdown().await.unwrap();
-
-        let stream = crate::jsonl::EventChannelStream::new(rx, None);
-        pin_mut!(stream);
-        let events: Vec<_> = stream.collect().await;
-        forward_handle.await.unwrap().unwrap();
-
-        assert_eq!(events.len(), 2);
-        assert!(matches!(
-            events[0],
-            Ok(ThreadEvent::ThreadStarted(ThreadStarted { ref thread_id, .. }))
-                if thread_id == "thread-err"
-        ));
-        match &events[1] {
-            Err(ExecStreamError::Parse { line, .. }) => assert_eq!(line, "this is not json"),
-            other => panic!("expected parse error, got {other:?}"),
-        }
-    }
-
-    #[tokio::test]
-    async fn json_stream_tees_logs_before_forwarding() {
-        let lines = [
-            r#"{"type":"thread.started","thread_id":"tee-thread"}"#.to_string(),
-            r#"{"type":"turn.started","thread_id":"tee-thread","turn_id":"turn-tee"}"#.to_string(),
-        ];
-
-        let dir = tempfile::tempdir().unwrap();
-        let log_path = dir.path().join("events.log");
-
-        let (mut writer, reader) = tokio::io::duplex(2048);
-        let (tx, rx) = mpsc::channel(4);
-        let log_sink = crate::jsonl::JsonLogSink::new(log_path.clone())
-            .await
-            .unwrap();
-        let forward_handle = tokio::spawn(crate::jsonl::forward_json_events(
-            reader,
-            tx,
-            false,
-            Some(log_sink),
-        ));
-
-        let stream = crate::jsonl::EventChannelStream::new(rx, None);
-        pin_mut!(stream);
-
-        writer.write_all(lines[0].as_bytes()).await.unwrap();
-        writer.write_all(b"\n").await.unwrap();
-
-        let first = stream.next().await.unwrap().unwrap();
-        assert!(matches!(first, ThreadEvent::ThreadStarted(_)));
-
-        let logged = fs::read_to_string(&log_path).await.unwrap();
-        assert_eq!(logged, format!("{}\n", lines[0]));
-
-        writer.write_all(lines[1].as_bytes()).await.unwrap();
-        writer.write_all(b"\n").await.unwrap();
-        writer.shutdown().await.unwrap();
-
-        let second = stream.next().await.unwrap().unwrap();
-        assert!(matches!(second, ThreadEvent::TurnStarted(_)));
-        assert!(stream.next().await.is_none());
-
-        forward_handle.await.unwrap().unwrap();
-
-        let final_log = fs::read_to_string(&log_path).await.unwrap();
-        assert_eq!(final_log, format!("{}\n{}\n", lines[0], lines[1]));
-    }
-
-    #[tokio::test]
-    async fn json_event_log_captures_apply_diff_and_tool_payloads() {
-        let diff = "@@ -1 +1 @@\n-fn foo() {}\n+fn bar() {}";
-        let lines = vec![
-            r#"{"type":"thread.started","thread_id":"log-thread"}"#.to_string(),
-            serde_json::to_string(&json!({
-                "type": "item.started",
-                "thread_id": "log-thread",
-                "turn_id": "turn-log",
-                "item_id": "apply-1",
-                "item_type": "file_change",
-                "content": {
-                    "path": "src/main.rs",
-                    "change": "apply",
-                    "diff": diff,
-                    "stdout": "patched\n"
-                }
-            }))
-            .unwrap(),
-            serde_json::to_string(&json!({
-                "type": "item.delta",
-                "thread_id": "log-thread",
-                "turn_id": "turn-log",
-                "item_id": "apply-1",
-                "item_type": "file_change",
-                "delta": {
-                    "diff": diff,
-                    "stderr": "warning",
-                    "exit_code": 2
-                }
-            }))
-            .unwrap(),
-            serde_json::to_string(&json!({
-                "type": "item.delta",
-                "thread_id": "log-thread",
-                "turn_id": "turn-log",
-                "item_id": "tool-1",
-                "item_type": "mcp_tool_call",
-                "delta": {
-                    "result": {"paths": ["a.rs", "b.rs"]},
-                    "status": "completed"
-                }
-            }))
-            .unwrap(),
-        ];
-
-        let dir = tempfile::tempdir().unwrap();
-        let log_path = dir.path().join("json.log");
-
-        let (mut writer, reader) = tokio::io::duplex(4096);
-        let (tx, rx) = mpsc::channel(8);
-        let log_sink = crate::jsonl::JsonLogSink::new(log_path.clone())
-            .await
-            .unwrap();
-        let forward_handle = tokio::spawn(crate::jsonl::forward_json_events(
-            reader,
-            tx,
-            false,
-            Some(log_sink),
-        ));
-
-        for line in &lines {
-            writer.write_all(line.as_bytes()).await.unwrap();
-            writer.write_all(b"\n").await.unwrap();
-        }
-        writer.shutdown().await.unwrap();
-
-        let stream = crate::jsonl::EventChannelStream::new(rx, None);
-        pin_mut!(stream);
-        let events: Vec<_> = stream.collect().await;
-        forward_handle.await.unwrap().unwrap();
-
-        assert_eq!(events.len(), lines.len());
-
-        let log_contents = fs::read_to_string(&log_path).await.unwrap();
-        assert_eq!(log_contents, lines.join("\n") + "\n");
-    }
-
-    #[tokio::test]
-    async fn event_channel_stream_times_out_when_idle() {
-        let (_tx, rx) = mpsc::channel(1);
-        let stream = crate::jsonl::EventChannelStream::new(rx, Some(Duration::from_millis(5)));
-        pin_mut!(stream);
-
-        let next = stream.next().await;
-        match next {
-            Some(Err(ExecStreamError::IdleTimeout { idle_for })) => {
-                assert_eq!(idle_for, Duration::from_millis(5));
-            }
-            other => panic!("expected idle timeout, got {other:?}"),
-        }
-    }
-
-    fn write_executable(dir: &Path, name: &str, script: &str) -> PathBuf {
-        let path = dir.join(name);
-        std_fs::write(&path, script).unwrap();
-        let mut perms = std_fs::metadata(&path).unwrap().permissions();
-        #[cfg(unix)]
-        {
-            perms.set_mode(0o755);
-        }
-        std_fs::set_permissions(&path, perms).unwrap();
-        path
-    }
-
-    fn write_fake_codex(dir: &Path, script: &str) -> PathBuf {
-        write_executable(dir, "codex", script)
-    }
-
-    fn write_fake_bundled_codex(dir: &Path, platform: &str, script: &str) -> PathBuf {
-        write_executable(dir, bundled_binary_filename(platform), script)
-    }
-
-    #[test]
-    fn resolve_bundled_binary_defaults_to_runtime_platform() {
-        let temp = tempfile::tempdir().unwrap();
-        let platform = default_bundled_platform_label();
-        let version = "1.2.3";
-        let version_dir = temp.path().join(&platform).join(version);
-        std_fs::create_dir_all(&version_dir).unwrap();
-        let binary =
-            write_fake_bundled_codex(&version_dir, &platform, "#!/usr/bin/env bash\necho ok");
-
-        let resolved = resolve_bundled_binary(BundledBinarySpec {
-            bundle_root: temp.path(),
-            version,
-            platform: None,
-        })
-        .unwrap();
-
-        assert_eq!(resolved.platform, platform);
-        assert_eq!(resolved.version, version);
-        assert_eq!(resolved.binary_path, std_fs::canonicalize(&binary).unwrap());
-    }
-
-    #[test]
-    fn resolve_bundled_binary_honors_platform_override() {
-        let temp = tempfile::tempdir().unwrap();
-        let platform = "windows-x64";
-        let version = "5.6.7";
-        let version_dir = temp.path().join(platform).join(version);
-        std_fs::create_dir_all(&version_dir).unwrap();
-        let binary =
-            write_fake_bundled_codex(&version_dir, platform, "#!/usr/bin/env bash\necho win");
-
-        let resolved = resolve_bundled_binary(BundledBinarySpec {
-            bundle_root: temp.path(),
-            version,
-            platform: Some(platform),
-        })
-        .unwrap();
-
-        assert_eq!(resolved.platform, platform);
-        assert_eq!(resolved.version, version);
-        assert_eq!(resolved.binary_path, std_fs::canonicalize(&binary).unwrap());
-        assert_eq!(
-            resolved
-                .binary_path
-                .file_name()
-                .and_then(|name| name.to_str()),
-            Some("codex.exe")
-        );
-    }
-
-    #[test]
-    fn resolve_bundled_binary_errors_when_binary_missing() {
-        let temp = tempfile::tempdir().unwrap();
-        let platform = default_bundled_platform_label();
-        let version = "0.0.1";
-        let version_dir = temp.path().join(&platform).join(version);
-        std_fs::create_dir_all(&version_dir).unwrap();
-
-        let err = resolve_bundled_binary(BundledBinarySpec {
-            bundle_root: temp.path(),
-            version,
-            platform: None,
-        })
-        .unwrap_err();
-
-        match err {
-            BundledBinaryError::BinaryUnreadable { binary, .. }
-            | BundledBinaryError::BinaryNotFile { binary }
-            | BundledBinaryError::BinaryNotExecutable { binary } => {
-                assert_eq!(binary, version_dir.join(bundled_binary_filename(&platform)));
-            }
-            other => panic!("unexpected error: {other:?}"),
-        }
-    }
-
-    #[test]
-    fn resolve_bundled_binary_rejects_empty_version() {
-        let temp = tempfile::tempdir().unwrap();
-        let err = resolve_bundled_binary(BundledBinarySpec {
-            bundle_root: temp.path(),
-            version: "  ",
-            platform: None,
-        })
-        .unwrap_err();
-        assert!(matches!(err, BundledBinaryError::EmptyVersion));
-    }
-
-    #[cfg(unix)]
-    #[tokio::test]
-    async fn sandbox_maps_platform_flags_and_command() {
-        let dir = tempfile::tempdir().unwrap();
-        let script_path = write_fake_codex(
-            dir.path(),
-            r#"#!/usr/bin/env bash
-echo "$PWD"
-printf "%s\n" "$@"
-"#,
-        );
-
-        let client = CodexClient::builder()
-            .binary(&script_path)
-            .mirror_stdout(false)
-            .quiet(true)
-            .build();
-
-        let request = SandboxCommandRequest::new(
-            SandboxPlatform::Linux,
-            [OsString::from("echo"), OsString::from("hello world")],
-        )
-        .full_auto(true)
-        .log_denials(true)
-        .config_override("foo", "bar")
-        .enable_feature("alpha")
-        .disable_feature("beta");
-
-        let run = client.run_sandbox(request).await.unwrap();
-        let mut lines = run.stdout.lines();
-        let pwd = lines.next().unwrap();
-        assert_eq!(Path::new(pwd), env::current_dir().unwrap().as_path());
-
-        let args: Vec<_> = lines.map(str::to_string).collect();
-        assert!(!args.contains(&"--log-denials".to_string()));
-        assert_eq!(
-            args,
-            vec![
-                "sandbox",
-                "linux",
-                "--full-auto",
-                "--config",
-                "foo=bar",
-                "--enable",
-                "alpha",
-                "--disable",
-                "beta",
-                "--",
-                "echo",
-                "hello world"
-            ]
-        );
-        assert!(run.status.success());
-    }
-
-    #[cfg(unix)]
-    #[tokio::test]
-    async fn sandbox_includes_log_denials_on_macos() {
-        let dir = tempfile::tempdir().unwrap();
-        let script_path = write_fake_codex(
-            dir.path(),
-            r#"#!/usr/bin/env bash
-printf "%s\n" "$@"
-"#,
-        );
-
-        let client = CodexClient::builder()
-            .binary(&script_path)
-            .mirror_stdout(false)
-            .quiet(true)
-            .build();
-
-        let run = client
-            .run_sandbox(
-                SandboxCommandRequest::new(SandboxPlatform::Macos, ["ls"]).log_denials(true),
-            )
-            .await
-            .unwrap();
-        let args: Vec<_> = run.stdout.lines().collect();
-        assert!(args.contains(&"--log-denials"));
-        assert_eq!(args[0], "sandbox");
-        assert_eq!(args[1], "macos");
-    }
-
-    #[cfg(unix)]
-    #[tokio::test]
-    async fn sandbox_honors_working_dir_precedence() {
-        let dir = tempfile::tempdir().unwrap();
-        let script_path = write_fake_codex(
-            dir.path(),
-            r#"#!/usr/bin/env bash
-echo "$PWD"
-"#,
-        );
-
-        let request_dir = dir.path().join("request_cwd");
-        let builder_dir = dir.path().join("builder_cwd");
-        std_fs::create_dir_all(&request_dir).unwrap();
-        std_fs::create_dir_all(&builder_dir).unwrap();
-
-        let client = CodexClient::builder()
-            .binary(&script_path)
-            .mirror_stdout(false)
-            .quiet(true)
-            .working_dir(&builder_dir)
-            .build();
-
-        let run_request = client
-            .run_sandbox(
-                SandboxCommandRequest::new(SandboxPlatform::Windows, ["echo", "cwd"])
-                    .working_dir(&request_dir),
-            )
-            .await
-            .unwrap();
-        let request_pwd = run_request.stdout.lines().next().unwrap();
-        assert_eq!(Path::new(request_pwd), request_dir.as_path());
-
-        let run_builder = client
-            .run_sandbox(SandboxCommandRequest::new(
-                SandboxPlatform::Windows,
-                ["echo", "builder"],
-            ))
-            .await
-            .unwrap();
-        let builder_pwd = run_builder.stdout.lines().next().unwrap();
-        assert_eq!(Path::new(builder_pwd), builder_dir.as_path());
-
-        let client_default = CodexClient::builder()
-            .binary(&script_path)
-            .mirror_stdout(false)
-            .quiet(true)
-            .build();
-        let run_default = client_default
-            .run_sandbox(SandboxCommandRequest::new(
-                SandboxPlatform::Windows,
-                ["echo", "default"],
-            ))
-            .await
-            .unwrap();
-        let default_pwd = run_default.stdout.lines().next().unwrap();
-        assert_eq!(
-            Path::new(default_pwd),
-            env::current_dir().unwrap().as_path()
-        );
-    }
-
-    #[cfg(unix)]
-    #[tokio::test]
-    async fn sandbox_returns_non_zero_status_without_error() {
-        let dir = tempfile::tempdir().unwrap();
-        let script_path = write_fake_codex(
-            dir.path(),
-            r#"#!/usr/bin/env bash
-echo "failing"
-exit 7
-"#,
-        );
-
-        let client = CodexClient::builder()
-            .binary(&script_path)
-            .mirror_stdout(false)
-            .quiet(true)
-            .build();
-        let run = client
-            .run_sandbox(SandboxCommandRequest::new(
-                SandboxPlatform::Linux,
-                ["false"],
-            ))
-            .await
-            .unwrap();
-
-        assert!(!run.status.success());
-        assert_eq!(run.status.code(), Some(7));
-        assert_eq!(run.stdout.trim(), "failing");
-    }
-
-    #[cfg(unix)]
-    #[tokio::test]
-    async fn execpolicy_maps_policies_and_overrides() {
-        let dir = tempfile::tempdir().unwrap();
-        let script_path = dir.path().join("codex-execpolicy");
-        std_fs::write(
-            &script_path,
-            r#"#!/usr/bin/env bash
-printf "%s\n" "$PWD" "$@" 1>&2
-cat <<'JSON'
-{"match":{"decision":"prompt","rules":[{"name":"rule1","decision":"forbidden"}]}}
-JSON
-"#,
-        )
-        .unwrap();
-        let mut perms = std_fs::metadata(&script_path).unwrap().permissions();
-        perms.set_mode(0o755);
-        std_fs::set_permissions(&script_path, perms).unwrap();
-
-        let workdir = dir.path().join("workdir");
-        std_fs::create_dir_all(&workdir).unwrap();
-        let policy_one = dir.path().join("policy_a.codexpolicy");
-        let policy_two = dir.path().join("policy_b.codexpolicy");
-        std_fs::write(&policy_one, "").unwrap();
-        std_fs::write(&policy_two, "").unwrap();
-
-        let client = CodexClient::builder()
-            .binary(&script_path)
-            .mirror_stdout(false)
-            .quiet(true)
-            .working_dir(&workdir)
-            .approval_policy(ApprovalPolicy::OnRequest)
-            .build();
-
-        let result = client
-            .check_execpolicy(
-                ExecPolicyCheckRequest::new([
-                    OsString::from("bash"),
-                    OsString::from("-lc"),
-                    OsString::from("echo ok"),
-                ])
-                .policies([&policy_one, &policy_two])
-                .pretty(true)
-                .profile("dev")
-                .config_override("features.execpolicy", "true"),
-            )
-            .await
-            .unwrap();
-
-        assert_eq!(result.decision(), Some(ExecPolicyDecision::Prompt));
-        let match_result = result.evaluation.match_result.unwrap();
-        assert_eq!(match_result.rules.len(), 1);
-        assert_eq!(match_result.rules[0].name.as_deref(), Some("rule1"));
-        assert_eq!(
-            match_result.rules[0].decision,
-            Some(ExecPolicyDecision::Forbidden)
-        );
-
-        let mut lines = result.stderr.lines();
-        let pwd = lines.next().unwrap();
-        assert_eq!(Path::new(pwd), workdir.as_path());
-
-        let args: Vec<_> = lines.map(str::to_string).collect();
-        assert_eq!(
-            args,
-            vec![
-                "execpolicy",
-                "check",
-                "--policy",
-                policy_one.to_string_lossy().as_ref(),
-                "--policy",
-                policy_two.to_string_lossy().as_ref(),
-                "--pretty",
-                "--config",
-                "features.execpolicy=true",
-                "--profile",
-                "dev",
-                "--ask-for-approval",
-                "on-request",
-                "--",
-                "bash",
-                "-lc",
-                "echo ok"
-            ]
-        );
-    }
-
-    #[tokio::test]
-    async fn execpolicy_rejects_empty_command() {
-        let client = CodexClient::builder().build();
-        let request = ExecPolicyCheckRequest::new(Vec::<OsString>::new());
-        let err = client.check_execpolicy(request).await.unwrap_err();
-        assert!(matches!(err, CodexError::EmptyExecPolicyCommand));
-    }
-
-    #[cfg(unix)]
-    #[tokio::test]
-    async fn execpolicy_surfaces_parse_errors() {
-        let dir = tempfile::tempdir().unwrap();
-        let script_path = dir.path().join("codex-execpolicy-bad");
-        std_fs::write(
-            &script_path,
-            r#"#!/usr/bin/env bash
-echo "not-json"
-"#,
-        )
-        .unwrap();
-        let mut perms = std_fs::metadata(&script_path).unwrap().permissions();
-        perms.set_mode(0o755);
-        std_fs::set_permissions(&script_path, perms).unwrap();
-
-        let client = CodexClient::builder()
-            .binary(&script_path)
-            .mirror_stdout(false)
-            .quiet(true)
-            .build();
-
-        let err = client
-            .check_execpolicy(
-                ExecPolicyCheckRequest::new([OsString::from("echo"), OsString::from("noop")])
-                    .policy(dir.path().join("policy.codexpolicy")),
-            )
-            .await
-            .unwrap_err();
-
-        match err {
-            CodexError::ExecPolicyParse { stdout, .. } => assert!(stdout.contains("not-json")),
-            other => panic!("expected ExecPolicyParse, got {other:?}"),
-        }
-    }
-
-    #[cfg(unix)]
-    #[tokio::test]
-    async fn features_list_maps_overrides_and_json_flag() {
-        let dir = tempfile::tempdir().unwrap();
-        let script_path = write_fake_codex(
-            dir.path(),
-            r#"#!/usr/bin/env bash
-echo "$PWD" 1>&2
-printf "%s\n" "$@" 1>&2
-cat <<'JSON'
-[{"name":"json-stream","stage":"stable","enabled":true},{"name":"cloud-exec","stage":"experimental","enabled":false}]
-JSON
-"#,
-        );
-
-        let workdir = dir.path().join("features-workdir");
-        std_fs::create_dir_all(&workdir).unwrap();
-
-        let client = CodexClient::builder()
-            .binary(&script_path)
-            .mirror_stdout(false)
-            .quiet(true)
-            .working_dir(&workdir)
-            .approval_policy(ApprovalPolicy::OnRequest)
-            .search(true)
-            .build();
-
-        let output = client
-            .list_features(
-                FeaturesListRequest::new()
-                    .json(true)
-                    .profile("dev")
-                    .config_override("features.extras", "true"),
-            )
-            .await
-            .unwrap();
-
-        assert_eq!(output.format, FeaturesListFormat::Json);
-        assert_eq!(output.features.len(), 2);
-        assert_eq!(output.features[0].stage, Some(CodexFeatureStage::Stable));
-        assert!(output.features[0].enabled);
-        assert!(!output.features[1].enabled);
-
-        let mut lines = output.stderr.lines();
-        let pwd = lines.next().unwrap();
-        assert_eq!(Path::new(pwd), workdir.as_path());
-
-        let args: Vec<_> = lines.map(str::to_string).collect();
-        assert_eq!(
-            args,
-            vec![
-                "features",
-                "list",
-                "--config",
-                "features.extras=true",
-                "--profile",
-                "dev",
-                "--ask-for-approval",
-                "on-request",
-                "--search",
-                "--json"
-            ]
-        );
-    }
-
-    #[cfg(unix)]
-    #[tokio::test]
-    async fn supports_help_review_fork_resume_and_features_commands() {
-        let dir = tempfile::tempdir().unwrap();
-        let script_path = write_fake_codex(
-            dir.path(),
-            r#"#!/usr/bin/env bash
-printf "%s\n" "$@"
-"#,
-        );
-
-        let client = CodexClient::builder()
-            .binary(&script_path)
-            .mirror_stdout(false)
-            .quiet(true)
-            .build();
-
-        let features = client
-            .features(FeaturesCommandRequest::new())
-            .await
-            .unwrap();
-        assert_eq!(
-            features.stdout.lines().collect::<Vec<_>>(),
-            vec!["features"]
-        );
-
-        let help = client
-            .help(HelpCommandRequest::new(HelpScope::Root).command(["exec", "review"]))
-            .await
-            .unwrap();
-        assert_eq!(
-            help.stdout.lines().collect::<Vec<_>>(),
-            vec!["help", "exec", "review"]
-        );
-
-        let review = client
-            .review(
-                ReviewCommandRequest::new()
-                    .base("main")
-                    .commit("abc123")
-                    .title("hello")
-                    .uncommitted(true)
-                    .prompt("please review"),
-            )
-            .await
-            .unwrap();
-        assert_eq!(
-            review.stdout.lines().collect::<Vec<_>>(),
-            vec![
-                "review",
-                "--base",
-                "main",
-                "--commit",
-                "abc123",
-                "--title",
-                "hello",
-                "--uncommitted",
-                "please review"
-            ]
-        );
-
-        let exec_review = client
-            .exec_review(
-                ExecReviewCommandRequest::new()
-                    .base("main")
-                    .commit("abc123")
-                    .title("hello")
-                    .uncommitted(true)
-                    .json(true)
-                    .prompt("please review"),
-            )
-            .await
-            .unwrap();
-        assert_eq!(
-            exec_review.stdout.lines().collect::<Vec<_>>(),
-            vec![
-                "exec",
-                "review",
-                "--base",
-                "main",
-                "--commit",
-                "abc123",
-                "--json",
-                "--skip-git-repo-check",
-                "--title",
-                "hello",
-                "--uncommitted",
-                "please review"
-            ]
-        );
-
-        let resume = client
-            .resume_session(
-                ResumeSessionRequest::new()
-                    .all(true)
-                    .last(true)
-                    .session_id("sess-1")
-                    .prompt("resume prompt"),
-            )
-            .await
-            .unwrap();
-        assert_eq!(
-            resume.stdout.lines().collect::<Vec<_>>(),
-            vec!["resume", "--all", "--last", "sess-1", "resume prompt"]
-        );
-
-        let fork = client
-            .fork_session(
-                ForkSessionRequest::new()
-                    .all(true)
-                    .last(true)
-                    .session_id("sess-1")
-                    .prompt("fork prompt"),
-            )
-            .await
-            .unwrap();
-        assert_eq!(
-            fork.stdout.lines().collect::<Vec<_>>(),
-            vec!["fork", "--all", "--last", "sess-1", "fork prompt"]
-        );
-    }
-
-    #[cfg(unix)]
-    #[tokio::test]
-    async fn cloud_list_parses_json_and_maps_args() {
-        let dir = tempfile::tempdir().unwrap();
-        let script_path = write_fake_codex(
-            dir.path(),
-            r#"#!/usr/bin/env bash
-printf "%s\n" "$@" 1>&2
-cat <<'JSON'
-{"tasks":[],"cursor":null}
-JSON
-"#,
-        );
-
-        let client = CodexClient::builder()
-            .binary(&script_path)
-            .mirror_stdout(false)
-            .quiet(true)
-            .build();
-
-        let output = client
-            .cloud_list(
-                CloudListRequest::new()
-                    .json(true)
-                    .env_id("env-1")
-                    .limit(3)
-                    .cursor("cur-1"),
-            )
-            .await
-            .unwrap();
-
-        assert_eq!(output.json, Some(json!({"tasks": [], "cursor": null})));
-        assert_eq!(
-            output.stderr.lines().collect::<Vec<_>>(),
-            vec!["cloud", "list", "--env", "env-1", "--limit", "3", "--cursor", "cur-1", "--json"]
-        );
-    }
-
-    #[cfg(unix)]
-    #[tokio::test]
-    async fn cloud_exec_maps_args_and_rejects_empty_env_id() {
-        let dir = tempfile::tempdir().unwrap();
-        let script_path = write_fake_codex(
-            dir.path(),
-            r#"#!/usr/bin/env bash
-printf "%s\n" "$@"
-"#,
-        );
-
-        let client = CodexClient::builder()
-            .binary(&script_path)
-            .mirror_stdout(false)
-            .quiet(true)
-            .build();
-
-        let output = client
-            .cloud_exec(
-                CloudExecRequest::new("env-1")
-                    .attempts(2)
-                    .branch("main")
-                    .query("hello"),
-            )
-            .await
-            .unwrap();
-        assert_eq!(
-            output.stdout.lines().collect::<Vec<_>>(),
-            vec![
-                "cloud",
-                "exec",
-                "--env",
-                "env-1",
-                "--attempts",
-                "2",
-                "--branch",
-                "main",
-                "hello"
-            ]
-        );
-
-        let err = client
-            .cloud_exec(CloudExecRequest::new("  "))
-            .await
-            .unwrap_err();
-        assert!(matches!(err, CodexError::EmptyEnvId));
-    }
-
-    #[cfg(unix)]
-    #[tokio::test]
-    async fn mcp_list_get_and_add_map_args_and_parse_json() {
-        let dir = tempfile::tempdir().unwrap();
-        let script_path = write_fake_codex(
-            dir.path(),
-            r#"#!/usr/bin/env bash
-printf "%s\n" "$@" 1>&2
-cat <<'JSON'
-{"servers":[{"name":"files"}]}
-JSON
-"#,
-        );
-
-        let client = CodexClient::builder()
-            .binary(&script_path)
-            .mirror_stdout(false)
-            .quiet(true)
-            .build();
-
-        let list = client
-            .mcp_list(McpListRequest::new().json(true))
-            .await
-            .unwrap();
-        assert_eq!(list.json, Some(json!({"servers": [{"name": "files"}]})));
-        assert_eq!(
-            list.stderr.lines().collect::<Vec<_>>(),
-            vec!["mcp", "list", "--json"]
-        );
-
-        let get = client
-            .mcp_get(McpGetRequest::new("files").json(true))
-            .await
-            .unwrap();
-        assert_eq!(get.json, Some(json!({"servers": [{"name": "files"}]})));
-        assert_eq!(
-            get.stderr.lines().collect::<Vec<_>>(),
-            vec!["mcp", "get", "--json", "files"]
-        );
-    }
-
-    #[cfg(unix)]
-    #[tokio::test]
-    async fn mcp_add_maps_transports_and_validates_required_fields() {
-        let dir = tempfile::tempdir().unwrap();
-        let script_path = write_fake_codex(
-            dir.path(),
-            r#"#!/usr/bin/env bash
-printf "%s\n" "$@"
-"#,
-        );
-
-        let client = CodexClient::builder()
-            .binary(&script_path)
-            .mirror_stdout(false)
-            .quiet(true)
-            .build();
-
-        let stdio = client
-            .mcp_add(
-                McpAddRequest::stdio("files", vec![OsString::from("node"), OsString::from("srv")])
-                    .env("TOKEN", "abc"),
-            )
-            .await
-            .unwrap();
-        assert_eq!(
-            stdio.stdout.lines().collect::<Vec<_>>(),
-            vec![
-                "mcp",
-                "add",
-                "files",
-                "--env",
-                "TOKEN=abc",
-                "--",
-                "node",
-                "srv"
-            ]
-        );
-
-        let http = client
-            .mcp_add(
-                McpAddRequest::streamable_http("http", "https://example.test")
-                    .bearer_token_env_var("TOKEN_ENV"),
-            )
-            .await
-            .unwrap();
-        assert_eq!(
-            http.stdout.lines().collect::<Vec<_>>(),
-            vec![
-                "mcp",
-                "add",
-                "http",
-                "--url",
-                "https://example.test",
-                "--bearer-token-env-var",
-                "TOKEN_ENV"
-            ]
-        );
-
-        let err = client
-            .mcp_add(McpAddRequest::stdio("files", Vec::new()))
-            .await
-            .unwrap_err();
-        assert!(matches!(err, CodexError::EmptyMcpCommand));
-
-        let err = client
-            .mcp_add(McpAddRequest::streamable_http("bad", "  "))
-            .await
-            .unwrap_err();
-        assert!(matches!(err, CodexError::EmptyMcpUrl));
-    }
-
-    #[cfg(unix)]
-    #[tokio::test]
-    async fn app_server_codegen_maps_overrides_and_prettier() {
-        let dir = tempfile::tempdir().unwrap();
-        let script_path = write_fake_codex(
-            dir.path(),
-            r#"#!/usr/bin/env bash
-echo "$PWD"
-printf "%s\n" "$@"
-"#,
-        );
-
-        let workdir = dir.path().join("workdir");
-        std_fs::create_dir_all(&workdir).unwrap();
-        let out_dir = dir.path().join("out/ts");
-        let prettier = dir.path().join("bin/prettier.js");
-
-        let client = CodexClient::builder()
-            .binary(&script_path)
-            .mirror_stdout(false)
-            .quiet(true)
-            .working_dir(&workdir)
-            .approval_policy(ApprovalPolicy::OnRequest)
-            .search(true)
-            .build();
-
-        let result = client
-            .generate_app_server_bindings(
-                AppServerCodegenRequest::typescript(&out_dir)
-                    .prettier(&prettier)
-                    .profile("dev")
-                    .config_override("features.codegen", "true"),
-            )
-            .await
-            .unwrap();
-
-        let mut lines = result.stdout.lines();
-        let pwd = lines.next().unwrap();
-        assert_eq!(Path::new(pwd), workdir.as_path());
-
-        let args: Vec<_> = lines.map(str::to_string).collect();
-        assert_eq!(
-            args,
-            vec![
-                "app-server",
-                "generate-ts",
-                "--out",
-                out_dir.to_string_lossy().as_ref(),
-                "--config",
-                "features.codegen=true",
-                "--profile",
-                "dev",
-                "--ask-for-approval",
-                "on-request",
-                "--search",
-                "--prettier",
-                prettier.to_string_lossy().as_ref(),
-            ]
-        );
-        assert!(out_dir.is_dir());
-        assert_eq!(result.out_dir, out_dir);
-        assert!(result.status.success());
-    }
-
-    #[cfg(unix)]
-    #[tokio::test]
-    async fn app_server_codegen_surfaces_non_zero_exit() {
-        let dir = tempfile::tempdir().unwrap();
-        let script_path = write_fake_codex(
-            dir.path(),
-            r#"#!/usr/bin/env bash
-echo "ts error"
-echo "bad format" 1>&2
-exit 5
-"#,
-        );
-
-        let client = CodexClient::builder()
-            .binary(&script_path)
-            .mirror_stdout(false)
-            .quiet(true)
-            .build();
-
-        let out_dir = dir.path().join("schema");
-        let err = client
-            .generate_app_server_bindings(AppServerCodegenRequest::json_schema(&out_dir))
-            .await
-            .unwrap_err();
-
-        match err {
-            CodexError::NonZeroExit { status, stderr } => {
-                assert_eq!(status.code(), Some(5));
-                assert!(stderr.contains("bad format"));
-            }
-            other => panic!("expected NonZeroExit, got {other:?}"),
-        }
-        assert!(out_dir.is_dir());
-    }
-
-    #[cfg(unix)]
-    #[tokio::test]
-    async fn responses_api_proxy_maps_flags_and_parses_server_info() {
-        let dir = tempfile::tempdir().unwrap();
-        let server_info = dir.path().join("server-info.json");
-        let script_path = write_fake_codex(
-            dir.path(),
-            r#"#!/usr/bin/env bash
-echo "$PWD"
-printf "%s\n" "$@"
-info_path=""
-while [[ $# -gt 0 ]]; do
-  if [[ $1 == "--server-info" ]]; then
-    info_path=$2
-  fi
-  shift
-done
-read -r key || exit 1
-echo "key:${key}"
-if [[ -n "$info_path" ]]; then
-  printf '{"port":4567,"pid":1234}\n' > "$info_path"
-fi
-"#,
-        );
-
-        let workdir = dir.path().join("responses-workdir");
-        std_fs::create_dir_all(&workdir).unwrap();
-
-        let client = CodexClient::builder()
-            .binary(&script_path)
-            .mirror_stdout(false)
-            .quiet(true)
-            .working_dir(&workdir)
-            .build();
-
-        let mut proxy = client
-            .start_responses_api_proxy(
-                ResponsesApiProxyRequest::new("sk-test-123")
-                    .port(8080)
-                    .server_info(&server_info)
-                    .http_shutdown(true)
-                    .upstream_url("https://example.com/v1/responses"),
-            )
-            .await
-            .unwrap();
-
-        assert_eq!(
-            proxy.server_info_path.as_deref(),
-            Some(server_info.as_path())
-        );
-
-        let stdout = proxy.child.stdout.take().unwrap();
-        let mut lines = BufReader::new(stdout).lines();
-
-        let pwd = lines.next_line().await.unwrap().unwrap();
-        assert_eq!(Path::new(&pwd), workdir.as_path());
-
-        let mut args = Vec::new();
-        for _ in 0..8 {
-            args.push(lines.next_line().await.unwrap().unwrap());
-        }
-        assert_eq!(
-            args,
-            vec![
-                "responses-api-proxy",
-                "--port",
-                "8080",
-                "--server-info",
-                server_info.to_string_lossy().as_ref(),
-                "--http-shutdown",
-                "--upstream-url",
-                "https://example.com/v1/responses",
-            ]
-        );
-
-        let api_key_line = lines.next_line().await.unwrap().unwrap();
-        assert_eq!(api_key_line, "key:sk-test-123");
-
-        let info = proxy.read_server_info().await.unwrap().unwrap();
-        assert_eq!(info.port, 4567);
-        assert_eq!(info.pid, 1234);
-
-        let status = proxy.child.wait().await.unwrap();
-        assert!(status.success());
-    }
-
-    #[tokio::test]
-    async fn responses_api_proxy_rejects_empty_api_key() {
-        let client = CodexClient::builder().build();
-        let err = client
-            .start_responses_api_proxy(ResponsesApiProxyRequest::new("  "))
-            .await
-            .unwrap_err();
-        assert!(matches!(err, CodexError::EmptyApiKey));
-    }
-
-    #[cfg(unix)]
-    #[tokio::test]
-    async fn stdio_to_uds_maps_args_and_pipes_stdio() {
-        let dir = tempfile::tempdir().unwrap();
-        let socket_path = dir.path().join("bridge.sock");
-        let script_path = write_fake_codex(
-            dir.path(),
-            r#"#!/usr/bin/env bash
-echo "$PWD"
-printf "%s\n" "$@"
-while read -r line; do
-  echo "relay:${line}"
-done
-"#,
-        );
-
-        let workdir = dir.path().join("uds-workdir");
-        std_fs::create_dir_all(&workdir).unwrap();
-
-        let client = CodexClient::builder()
-            .binary(&script_path)
-            .mirror_stdout(false)
-            .quiet(true)
-            .working_dir(&workdir)
-            .build();
-
-        let request = StdioToUdsRequest::new(&socket_path).working_dir(&workdir);
-        let mut child = match client.stdio_to_uds(request.clone()) {
-            Ok(child) => child,
-            Err(CodexError::Spawn { source, .. }) if source.raw_os_error() == Some(26) => {
-                time::sleep(Duration::from_millis(25)).await;
-                client.stdio_to_uds(request).unwrap()
-            }
-            Err(other) => panic!("unexpected spawn error: {other:?}"),
-        };
-
-        let stdout = child.stdout.take().unwrap();
-        let mut lines = BufReader::new(stdout).lines();
-
-        let pwd = lines.next_line().await.unwrap().unwrap();
-        assert_eq!(Path::new(&pwd), workdir.as_path());
-
-        let arg_one = lines.next_line().await.unwrap().unwrap();
-        let arg_two = lines.next_line().await.unwrap().unwrap();
-        assert_eq!(arg_one, "stdio-to-uds");
-        assert_eq!(arg_two, socket_path.to_string_lossy().as_ref());
-
-        let mut stdin = child.stdin.take().unwrap();
-        stdin.write_all(b"ping\n").await.unwrap();
-        stdin.shutdown().await.unwrap();
-        drop(stdin);
-
-        let echoed = lines.next_line().await.unwrap().unwrap();
-        assert_eq!(echoed, "relay:ping");
-
-        let status = time::timeout(Duration::from_secs(5), child.wait())
-            .await
-            .expect("stdio-to-uds wait timed out")
-            .unwrap();
-        assert!(status.success());
-    }
-
-    #[tokio::test]
-    async fn stdio_to_uds_rejects_empty_socket_path() {
-        let client = CodexClient::builder().build();
-        let err = client
-            .stdio_to_uds(StdioToUdsRequest::new(PathBuf::new()))
-            .unwrap_err();
-        assert!(matches!(err, CodexError::EmptySocketPath));
-    }
-
-    #[tokio::test]
-    async fn sandbox_rejects_empty_command() {
-        let client = CodexClient::builder().build();
-        let request = SandboxCommandRequest::new(SandboxPlatform::Linux, Vec::<OsString>::new());
-        let err = client.run_sandbox(request).await.unwrap_err();
-        assert!(matches!(err, CodexError::EmptySandboxCommand));
-    }
-
-    fn capabilities_with_version(raw_version: &str) -> CodexCapabilities {
-        CodexCapabilities {
-            cache_key: CapabilityCacheKey {
-                binary_path: PathBuf::from("codex"),
-            },
-            fingerprint: None,
-            version: Some(parse_version_output(raw_version)),
-            features: CodexFeatureFlags::default(),
-            probe_plan: CapabilityProbePlan::default(),
-            collected_at: SystemTime::now(),
-        }
-    }
-
-    fn capabilities_without_version() -> CodexCapabilities {
-        CodexCapabilities {
-            cache_key: CapabilityCacheKey {
-                binary_path: PathBuf::from("codex"),
-            },
-            fingerprint: None,
-            version: None,
-            features: CodexFeatureFlags::default(),
-            probe_plan: CapabilityProbePlan::default(),
-            collected_at: SystemTime::now(),
-        }
-    }
-
-    fn capabilities_with_feature_flags(features: CodexFeatureFlags) -> CodexCapabilities {
-        CodexCapabilities {
-            cache_key: CapabilityCacheKey {
-                binary_path: PathBuf::from("codex"),
-            },
-            fingerprint: None,
-            version: None,
-            features,
-            probe_plan: CapabilityProbePlan::default(),
-            collected_at: SystemTime::now(),
-        }
-    }
-
-    fn sample_capabilities_snapshot() -> CodexCapabilities {
-        CodexCapabilities {
-            cache_key: CapabilityCacheKey {
-                binary_path: PathBuf::from("/tmp/codex"),
-            },
-            fingerprint: Some(BinaryFingerprint {
-                canonical_path: Some(PathBuf::from("/tmp/codex")),
-                modified: Some(SystemTime::UNIX_EPOCH + Duration::from_secs(5)),
-                len: Some(1234),
-            }),
-            version: Some(CodexVersionInfo {
-                raw: "codex 3.4.5-beta (commit cafe)".to_string(),
-                semantic: Some((3, 4, 5)),
-                commit: Some("cafe".to_string()),
-                channel: CodexReleaseChannel::Beta,
-            }),
-            features: CodexFeatureFlags {
-                supports_features_list: true,
-                supports_output_schema: true,
-                supports_add_dir: false,
-                supports_mcp_login: true,
-            },
-            probe_plan: CapabilityProbePlan {
-                steps: vec![
-                    CapabilityProbeStep::VersionFlag,
-                    CapabilityProbeStep::FeaturesListJson,
-                    CapabilityProbeStep::ManualOverride,
-                ],
-            },
-            collected_at: SystemTime::UNIX_EPOCH + Duration::from_secs(10),
-        }
-    }
-
-    fn sample_capability_overrides() -> CapabilityOverrides {
-        CapabilityOverrides {
-            snapshot: Some(sample_capabilities_snapshot()),
-            version: Some(parse_version_output("codex 9.9.9-nightly")),
-            features: CapabilityFeatureOverrides {
-                supports_features_list: Some(true),
-                supports_output_schema: Some(true),
-                supports_add_dir: Some(true),
-                supports_mcp_login: None,
-            },
-        }
-    }
-
-    fn capability_snapshot_with_metadata(
-        collected_at: SystemTime,
-        fingerprint: Option<BinaryFingerprint>,
-    ) -> CodexCapabilities {
-        CodexCapabilities {
-            cache_key: CapabilityCacheKey {
-                binary_path: PathBuf::from("/tmp/codex"),
-            },
-            fingerprint,
-            version: None,
-            features: CodexFeatureFlags::default(),
-            probe_plan: CapabilityProbePlan::default(),
-            collected_at,
-        }
-    }
-
-    #[test]
-    fn builder_defaults_are_sane() {
-        let builder = CodexClient::builder();
-        assert!(builder.model.is_none());
-        assert_eq!(builder.timeout, DEFAULT_TIMEOUT);
-        assert_eq!(builder.color_mode, ColorMode::Never);
-        assert!(builder.codex_home.is_none());
-        assert!(builder.create_home_dirs);
-        assert!(builder.working_dir.is_none());
-        assert!(builder.images.is_empty());
-        assert!(!builder.json_output);
-        assert!(!builder.quiet);
-        assert!(builder.json_event_log.is_none());
-        assert!(builder.cli_overrides.config_overrides.is_empty());
-        assert!(!builder.cli_overrides.reasoning.has_overrides());
-        assert!(builder.cli_overrides.approval_policy.is_none());
-        assert!(builder.cli_overrides.sandbox_mode.is_none());
-        assert_eq!(
-            builder.cli_overrides.safety_override,
-            SafetyOverride::Inherit
-        );
-        assert!(builder.cli_overrides.cd.is_none());
-        assert!(builder.cli_overrides.local_provider.is_none());
-        assert_eq!(builder.cli_overrides.search, FlagState::Inherit);
-        assert!(builder.cli_overrides.auto_reasoning_defaults);
-        assert!(builder.capability_overrides.is_empty());
-        assert_eq!(
-            builder.capability_cache_policy,
-            CapabilityCachePolicy::PreferCache
-        );
-    }
-
-    #[test]
-    fn builder_collects_images() {
-        let client = CodexClient::builder()
-            .image("foo.png")
-            .image("bar.jpg")
-            .build();
-        assert_eq!(client.images.len(), 2);
-        assert_eq!(client.images[0], PathBuf::from("foo.png"));
-        assert_eq!(client.images[1], PathBuf::from("bar.jpg"));
-    }
-
-    #[test]
-    fn builder_sets_json_flag() {
-        let client = CodexClient::builder().json(true).build();
-        assert!(client.json_output);
-    }
-
-    #[test]
-    fn builder_sets_json_event_log() {
-        let client = CodexClient::builder().json_event_log("events.log").build();
-        assert_eq!(client.json_event_log, Some(PathBuf::from("events.log")));
-    }
-
-    #[test]
-    fn builder_sets_quiet_flag() {
-        let client = CodexClient::builder().quiet(true).build();
-        assert!(client.quiet);
-    }
-
-    #[test]
-    fn builder_mirrors_stdout_by_default() {
-        let client = CodexClient::builder().build();
-        assert!(client.mirror_stdout);
-    }
-
-    #[test]
-    fn builder_can_disable_stdout_mirroring() {
-        let client = CodexClient::builder().mirror_stdout(false).build();
-        assert!(!client.mirror_stdout);
-    }
-
-    #[test]
-    fn builder_uses_env_binary_when_set() {
-        let _guard = env_guard();
-        let key = CODEX_BINARY_ENV;
-        let original = env::var_os(key);
-        env::set_var(key, "custom_codex");
-        let builder = CodexClient::builder();
-        assert_eq!(builder.binary, PathBuf::from("custom_codex"));
-        if let Some(value) = original {
-            env::set_var(key, value);
-        } else {
-            env::remove_var(key);
-        }
-    }
-
-    #[test]
-    fn default_binary_falls_back_when_env_missing() {
-        let _guard = env_guard();
-        let key = CODEX_BINARY_ENV;
-        let original = env::var_os(key);
-        env::remove_var(key);
-
-        assert_eq!(default_binary_path(), PathBuf::from("codex"));
-
-        if let Some(value) = original {
-            env::set_var(key, value);
-        } else {
-            env::remove_var(key);
-        }
-    }
-
-    #[test]
-    fn default_rust_log_is_error_when_unset() {
-        let _guard = env_guard();
-        let original = env::var_os("RUST_LOG");
-        env::remove_var("RUST_LOG");
-
-        assert_eq!(default_rust_log_value(), Some("error"));
-
-        if let Some(value) = original {
-            env::set_var("RUST_LOG", value);
-        } else {
-            env::remove_var("RUST_LOG");
-        }
-    }
-
-    #[test]
-    fn default_rust_log_respects_existing_env() {
-        let _guard = env_guard();
-        let original = env::var_os("RUST_LOG");
-        env::set_var("RUST_LOG", "info");
-
-        assert_eq!(default_rust_log_value(), None);
-
-        if let Some(value) = original {
-            env::set_var("RUST_LOG", value);
-        } else {
-            env::remove_var("RUST_LOG");
-        }
-    }
-
-    #[test]
-    fn command_env_sets_expected_overrides() {
-        let _guard = env_guard();
-        let rust_log_original = env::var_os(RUST_LOG_ENV);
-        env::remove_var(RUST_LOG_ENV);
-
-        let temp = tempfile::tempdir().unwrap();
-        let home = temp.path().join("codex_home");
-        let env_prep =
-            CommandEnvironment::new(PathBuf::from("/custom/codex"), Some(home.clone()), true);
-        let overrides = env_prep.environment_overrides().unwrap();
-        let map: HashMap<OsString, OsString> = overrides.into_iter().collect();
-
-        assert_eq!(
-            map.get(&OsString::from(CODEX_BINARY_ENV)),
-            Some(&OsString::from("/custom/codex"))
-        );
-        assert_eq!(
-            map.get(&OsString::from(CODEX_HOME_ENV)),
-            Some(&home.as_os_str().to_os_string())
-        );
-        assert_eq!(
-            map.get(&OsString::from(RUST_LOG_ENV)),
-            Some(&OsString::from(DEFAULT_RUST_LOG))
-        );
-
-        assert!(home.is_dir());
-        assert!(home.join("conversations").is_dir());
-        assert!(home.join("logs").is_dir());
-
-        match rust_log_original {
-            Some(value) => env::set_var(RUST_LOG_ENV, value),
-            None => env::remove_var(RUST_LOG_ENV),
-        }
-    }
-
-    #[test]
-    fn command_env_applies_home_and_binary_per_command() {
-        let _guard = env_guard();
-        let binary_key = CODEX_BINARY_ENV;
-        let home_key = CODEX_HOME_ENV;
-        let rust_log_key = RUST_LOG_ENV;
-        let original_binary = env::var_os(binary_key);
-        let original_home = env::var_os(home_key);
-        let original_rust_log = env::var_os(rust_log_key);
-
-        env::set_var(binary_key, "/tmp/ignored_codex");
-        env::set_var(home_key, "/tmp/ambient_home");
-        env::remove_var(rust_log_key);
-
-        let temp = tempfile::tempdir().unwrap();
-        let home = temp.path().join("scoped_home");
-        let env_prep = CommandEnvironment::new(
-            PathBuf::from("/app/bundled/codex"),
-            Some(home.clone()),
-            true,
-        );
-
-        let mut command = Command::new("echo");
-        env_prep.apply(&mut command).unwrap();
-
-        let envs: HashMap<OsString, Option<OsString>> = command
-            .as_std()
-            .get_envs()
-            .map(|(key, value)| (key.to_os_string(), value.map(|v| v.to_os_string())))
-            .collect();
-
-        assert_eq!(
-            envs.get(&OsString::from(binary_key)),
-            Some(&Some(OsString::from("/app/bundled/codex")))
-        );
-        assert_eq!(
-            envs.get(&OsString::from(home_key)),
-            Some(&Some(home.as_os_str().to_os_string()))
-        );
-        assert_eq!(
-            envs.get(&OsString::from(rust_log_key)),
-            Some(&Some(OsString::from(DEFAULT_RUST_LOG)))
-        );
-        assert_eq!(
-            env::var_os(home_key),
-            Some(OsString::from("/tmp/ambient_home"))
-        );
-        assert!(home.is_dir());
-        assert!(home.join("conversations").is_dir());
-        assert!(home.join("logs").is_dir());
-
-        match original_binary {
-            Some(value) => env::set_var(binary_key, value),
-            None => env::remove_var(binary_key),
-        }
-        match original_home {
-            Some(value) => env::set_var(home_key, value),
-            None => env::remove_var(home_key),
-        }
-        match original_rust_log {
-            Some(value) => env::set_var(rust_log_key, value),
-            None => env::remove_var(rust_log_key),
-        }
-    }
-
-    #[cfg(unix)]
-    #[tokio::test]
-    async fn apply_and_diff_capture_outputs_and_status() {
-        let dir = tempfile::tempdir().unwrap();
-        let script_path = dir.path().join("codex");
-        std::fs::write(
-            &script_path,
-            r#"#!/usr/bin/env bash
-set -e
-cmd="$1"
-if [[ "$cmd" == "apply" ]]; then
-  echo "applied"
-  echo "apply-stderr" >&2
-  exit 0
-elif [[ "$cmd" == "cloud" && "${2:-}" == "diff" ]]; then
-  echo "diff-body"
-  echo "diff-stderr" >&2
-  exit 3
-else
-  echo "unknown $cmd" >&2
-  exit 99
-fi
-"#,
-        )
-        .unwrap();
-        let mut perms = std::fs::metadata(&script_path).unwrap().permissions();
-        perms.set_mode(0o755);
-        std::fs::set_permissions(&script_path, perms).unwrap();
-
-        let client = CodexClient::builder()
-            .binary(&script_path)
-            .mirror_stdout(false)
-            .quiet(true)
-            .build();
-
-        let apply = client.apply().await.unwrap();
-        assert!(apply.status.success());
-        assert_eq!(apply.stdout.trim(), "applied");
-        assert_eq!(apply.stderr.trim(), "apply-stderr");
-
-        let diff = client.diff().await.unwrap();
-        assert!(!diff.status.success());
-        assert_eq!(diff.status.code(), Some(3));
-        assert_eq!(diff.stdout.trim(), "diff-body");
-        assert_eq!(diff.stderr.trim(), "diff-stderr");
-    }
-
-    #[cfg(unix)]
-    #[tokio::test]
-    async fn apply_respects_rust_log_default() {
-        let _guard = env_guard_async().await;
-        let original = env::var_os("RUST_LOG");
-        env::remove_var("RUST_LOG");
-
-        let dir = tempfile::tempdir().unwrap();
-        let script_path = dir.path().join("codex-rust-log");
-        std::fs::write(
-            &script_path,
-            r#"#!/usr/bin/env bash
-echo "${RUST_LOG:-missing}"
-exit 0
-"#,
-        )
-        .unwrap();
-        let mut perms = std::fs::metadata(&script_path).unwrap().permissions();
-        perms.set_mode(0o755);
-        std::fs::set_permissions(&script_path, perms).unwrap();
-
-        let client = CodexClient::builder()
-            .binary(&script_path)
-            .mirror_stdout(false)
-            .quiet(true)
-            .build();
-
-        let apply = client.apply().await.unwrap();
-        assert_eq!(apply.stdout.trim(), "error");
-
-        if let Some(value) = original {
-            env::set_var("RUST_LOG", value);
-        } else {
-            env::remove_var("RUST_LOG");
-        }
-    }
-
-    #[test]
-    fn command_env_respects_existing_rust_log() {
-        let _guard = env_guard();
-        let rust_log_original = env::var_os(RUST_LOG_ENV);
-        env::set_var(RUST_LOG_ENV, "trace");
-
-        let env_prep = CommandEnvironment::new(PathBuf::from("codex"), None, true);
-        let overrides = env_prep.environment_overrides().unwrap();
-        let map: HashMap<OsString, OsString> = overrides.into_iter().collect();
-
-        assert_eq!(
-            map.get(&OsString::from(CODEX_BINARY_ENV)),
-            Some(&OsString::from("codex"))
-        );
-        assert!(!map.contains_key(&OsString::from(RUST_LOG_ENV)));
-
-        match rust_log_original {
-            Some(value) => env::set_var(RUST_LOG_ENV, value),
-            None => env::remove_var(RUST_LOG_ENV),
-        }
-    }
-
-    #[test]
-    fn command_env_can_skip_home_creation() {
-        let _guard = env_guard();
-        let rust_log_original = env::var_os(RUST_LOG_ENV);
-        env::remove_var(RUST_LOG_ENV);
-
-        let temp = tempfile::tempdir().unwrap();
-        let home = temp.path().join("codex_home");
-        let env_prep = CommandEnvironment::new(PathBuf::from("codex"), Some(home.clone()), false);
-        let overrides = env_prep.environment_overrides().unwrap();
-        let map: HashMap<OsString, OsString> = overrides.into_iter().collect();
-
-        assert!(!home.exists());
-        assert!(!home.join("conversations").exists());
-        assert!(!home.join("logs").exists());
-        assert_eq!(
-            map.get(&OsString::from(CODEX_HOME_ENV)),
-            Some(&home.as_os_str().to_os_string())
-        );
-
-        match rust_log_original {
-            Some(value) => env::set_var(RUST_LOG_ENV, value),
-            None => env::remove_var(RUST_LOG_ENV),
-        }
-    }
-
-    #[test]
-    fn codex_home_layout_exposes_paths() {
-        let root = PathBuf::from("/tmp/codex_layout_root");
-        let layout = CodexHomeLayout::new(&root);
-
-        assert_eq!(layout.root(), root.as_path());
-        assert_eq!(layout.config_path(), root.join("config.toml"));
-        assert_eq!(layout.auth_path(), root.join("auth.json"));
-        assert_eq!(layout.credentials_path(), root.join(".credentials.json"));
-        assert_eq!(layout.history_path(), root.join("history.jsonl"));
-        assert_eq!(layout.conversations_dir(), root.join("conversations"));
-        assert_eq!(layout.logs_dir(), root.join("logs"));
-    }
-
-    #[test]
-    fn codex_home_layout_respects_materialization_flag() {
-        let temp = tempfile::tempdir().unwrap();
-        let root = temp.path().join("codex_home_layout");
-        let layout = CodexHomeLayout::new(&root);
-
-        layout.materialize(false).unwrap();
-        assert!(!root.exists());
-
-        layout.materialize(true).unwrap();
-        assert!(root.is_dir());
-        assert!(layout.conversations_dir().is_dir());
-        assert!(layout.logs_dir().is_dir());
-    }
-
-    #[test]
-    fn seed_auth_copies_files_and_creates_targets() {
-        let temp = tempfile::tempdir().unwrap();
-        let seed = temp.path().join("seed_home");
-        std::fs::create_dir_all(&seed).unwrap();
-        std::fs::write(seed.join("auth.json"), "auth").unwrap();
-        std::fs::write(seed.join(".credentials.json"), "creds").unwrap();
-
-        let target_root = temp.path().join("target_home");
-        let layout = CodexHomeLayout::new(&target_root);
-        let outcome = layout
-            .seed_auth_from(&seed, AuthSeedOptions::default())
-            .unwrap();
-
-        assert!(outcome.copied_auth);
-        assert!(outcome.copied_credentials);
-        assert_eq!(std::fs::read_to_string(layout.auth_path()).unwrap(), "auth");
-        assert_eq!(
-            std::fs::read_to_string(layout.credentials_path()).unwrap(),
-            "creds"
-        );
-    }
-
-    #[test]
-    fn seed_auth_skips_optional_files() {
-        let temp = tempfile::tempdir().unwrap();
-        let seed = temp.path().join("seed_home");
-        std::fs::create_dir_all(&seed).unwrap();
-        std::fs::write(seed.join("auth.json"), "auth").unwrap();
-
-        let target_root = temp.path().join("target_home");
-        let layout = CodexHomeLayout::new(&target_root);
-        let outcome = layout
-            .seed_auth_from(&seed, AuthSeedOptions::default())
-            .unwrap();
-
-        assert!(outcome.copied_auth);
-        assert!(!outcome.copied_credentials);
-        assert_eq!(std::fs::read_to_string(layout.auth_path()).unwrap(), "auth");
-        assert!(!layout.credentials_path().exists());
-    }
-
-    #[test]
-    fn seed_auth_errors_when_required_missing() {
-        let temp = tempfile::tempdir().unwrap();
-        let seed = temp.path().join("seed_home");
-        std::fs::create_dir_all(&seed).unwrap();
-
-        let target_root = temp.path().join("target_home");
-        let layout = CodexHomeLayout::new(&target_root);
-        let err = layout
-            .seed_auth_from(
-                &seed,
-                AuthSeedOptions {
-                    require_auth: true,
-                    require_credentials: true,
-                    ..Default::default()
-                },
-            )
-            .unwrap_err();
-
-        match err {
-            AuthSeedError::SeedFileMissing { path } => {
-                assert!(path.ends_with("auth.json"), "{path:?}")
-            }
-            other => panic!("unexpected error: {other:?}"),
-        }
-    }
-
-    #[test]
-    fn codex_client_returns_configured_home_layout() {
-        let temp = tempfile::tempdir().unwrap();
-        let root = temp.path().join("app_codex_home");
-        let client = CodexClient::builder().codex_home(&root).build();
-
-        let layout = client.codex_home_layout().expect("layout missing");
-        assert_eq!(layout.root(), root.as_path());
-        assert!(!root.exists());
-
-        let client_without_home = CodexClient::builder().build();
-        assert!(client_without_home.codex_home_layout().is_none());
-    }
-
-    #[test]
-    fn parses_version_output_fields() {
-        let parsed = parse_version_output("codex v3.4.5-nightly (commit abc1234)");
-        assert_eq!(parsed.semantic, Some((3, 4, 5)));
-        assert_eq!(parsed.channel, CodexReleaseChannel::Nightly);
-        assert_eq!(parsed.commit.as_deref(), Some("abc1234"));
-        assert_eq!(
-            parsed.raw,
-            "codex v3.4.5-nightly (commit abc1234)".to_string()
-        );
-    }
-
-    #[test]
-    fn update_advisory_detects_newer_release() {
-        let capabilities = capabilities_with_version("codex 1.0.0");
-        let latest = CodexLatestReleases {
-            stable: Some(Version::parse("1.1.0").unwrap()),
-            ..Default::default()
-        };
-        let advisory = update_advisory_from_capabilities(&capabilities, &latest);
-        assert_eq!(advisory.status, CodexUpdateStatus::UpdateRecommended);
-        assert!(advisory.is_update_recommended());
-        assert_eq!(
-            advisory
-                .latest_release
-                .as_ref()
-                .map(|release| release.version.clone()),
-            latest.stable
-        );
-    }
-
-    #[test]
-    fn normalize_stream_infers_missing_thread_and_turn() {
-        let mut context = crate::jsonl::StreamContext::default();
-        // thread.started establishes thread context
-        let thread_line = r#"{"type":"thread.started","thread_id":"thread-1"}"#;
-        let thread_event = crate::jsonl::normalize_thread_event(thread_line, &mut context).unwrap();
-        match thread_event {
-            ThreadEvent::ThreadStarted(t) => assert_eq!(t.thread_id, "thread-1"),
-            other => panic!("unexpected event: {other:?}"),
-        }
-        // turn.started without thread_id should inherit
-        let turn_line = r#"{"type":"turn.started","turn_id":"turn-1"}"#;
-        let turn_event = crate::jsonl::normalize_thread_event(turn_line, &mut context).unwrap();
-        match turn_event {
-            ThreadEvent::TurnStarted(t) => {
-                assert_eq!(t.thread_id, "thread-1");
-                assert_eq!(t.turn_id, "turn-1");
-            }
-            other => panic!("unexpected event: {other:?}"),
-        }
-        // item.completed without ids should inherit both
-        let item_line =
-            r#"{"type":"item.completed","item":{"id":"msg-1","type":"agent_message","text":"hi"}}"#;
-        let item_event = crate::jsonl::normalize_thread_event(item_line, &mut context).unwrap();
-        match item_event {
-            ThreadEvent::ItemCompleted(item) => {
-                assert_eq!(item.turn_id, "turn-1");
-                assert_eq!(item.thread_id, "thread-1");
-                assert_eq!(item.item.item_id, "msg-1");
-            }
-            other => panic!("unexpected event: {other:?}"),
-        }
-    }
-
-    #[test]
-    fn normalize_stream_errors_without_context() {
-        let mut context = crate::jsonl::StreamContext::default();
-        let line = r#"{"type":"turn.started"}"#;
-        let err = crate::jsonl::normalize_thread_event(line, &mut context).unwrap_err();
-        match err {
-            ExecStreamError::Normalize { .. } => {}
-            other => panic!("unexpected error: {other:?}"),
-        }
-    }
-
-    #[test]
-    fn update_advisory_handles_unknown_local_version() {
-        let capabilities = capabilities_without_version();
-        let latest = CodexLatestReleases {
-            stable: Some(Version::parse("3.2.1").unwrap()),
-            ..Default::default()
-        };
-        let advisory = update_advisory_from_capabilities(&capabilities, &latest);
-        assert_eq!(advisory.status, CodexUpdateStatus::UnknownLocalVersion);
-        assert!(advisory.is_update_recommended());
-        assert!(advisory
-            .notes
-            .iter()
-            .any(|note| note.contains("could not be parsed")));
-    }
-
-    #[test]
-    fn update_advisory_marks_up_to_date() {
-        let capabilities = capabilities_with_version("codex 2.0.1");
-        let latest = CodexLatestReleases {
-            stable: Some(Version::parse("2.0.1").unwrap()),
-            ..Default::default()
-        };
-        let advisory = update_advisory_from_capabilities(&capabilities, &latest);
-        assert_eq!(advisory.status, CodexUpdateStatus::UpToDate);
-        assert!(!advisory.is_update_recommended());
-    }
-
-    #[test]
-    fn update_advisory_falls_back_when_channel_missing() {
-        let capabilities = capabilities_with_version("codex 2.0.0-beta");
-        let latest = CodexLatestReleases {
-            stable: Some(Version::parse("2.0.1").unwrap()),
-            ..Default::default()
-        };
-        let advisory = update_advisory_from_capabilities(&capabilities, &latest);
-        assert_eq!(advisory.comparison_channel, CodexReleaseChannel::Stable);
-        assert_eq!(advisory.status, CodexUpdateStatus::UpdateRecommended);
-        assert!(advisory
-            .notes
-            .iter()
-            .any(|note| note.contains("comparing against stable")));
-    }
-
-    #[test]
-    fn update_advisory_handles_local_newer_than_known() {
-        let capabilities = capabilities_with_version("codex 2.0.0");
-        let latest = CodexLatestReleases {
-            stable: Some(Version::parse("1.9.9").unwrap()),
-            ..Default::default()
-        };
-        let advisory = update_advisory_from_capabilities(&capabilities, &latest);
-        assert_eq!(advisory.status, CodexUpdateStatus::LocalNewerThanKnown);
-        assert!(!advisory.is_update_recommended());
-        assert!(advisory
-            .notes
-            .iter()
-            .any(|note| note.contains("newer than provided")));
-    }
-
-    #[test]
-    fn update_advisory_handles_missing_latest_metadata() {
-        let capabilities = capabilities_with_version("codex 1.0.0");
-        let latest = CodexLatestReleases::default();
-        let advisory = update_advisory_from_capabilities(&capabilities, &latest);
-        assert_eq!(advisory.status, CodexUpdateStatus::UnknownLatestVersion);
-        assert!(!advisory.is_update_recommended());
-        assert!(advisory
-            .notes
-            .iter()
-            .any(|note| note.contains("advisory unavailable")));
-    }
-
-    #[test]
-    fn capability_snapshots_serialize_to_json_and_toml() {
-        let snapshot = sample_capabilities_snapshot();
-
-        let json = serialize_capabilities_snapshot(&snapshot, CapabilitySnapshotFormat::Json)
-            .expect("serialize json");
-        let parsed_json = deserialize_capabilities_snapshot(&json, CapabilitySnapshotFormat::Json)
-            .expect("parse json");
-        assert_eq!(parsed_json, snapshot);
-
-        let toml = serialize_capabilities_snapshot(&snapshot, CapabilitySnapshotFormat::Toml)
-            .expect("serialize toml");
-        let parsed_toml = deserialize_capabilities_snapshot(&toml, CapabilitySnapshotFormat::Toml)
-            .expect("parse toml");
-        assert_eq!(parsed_toml, snapshot);
-    }
-
-    #[test]
-    fn capability_snapshots_and_overrides_round_trip_via_files() {
-        let snapshot = sample_capabilities_snapshot();
-        let overrides = sample_capability_overrides();
-        let temp = tempfile::tempdir().unwrap();
-
-        let snapshot_path = temp.path().join("capabilities.toml");
-        write_capabilities_snapshot(&snapshot_path, &snapshot, None).unwrap();
-        let loaded_snapshot = read_capabilities_snapshot(&snapshot_path, None).unwrap();
-        assert_eq!(loaded_snapshot, snapshot);
-
-        let overrides_path = temp.path().join("overrides.json");
-        write_capability_overrides(&overrides_path, &overrides, None).unwrap();
-        let loaded_overrides = read_capability_overrides(&overrides_path, None).unwrap();
-        assert_eq!(loaded_overrides, overrides);
-    }
-
-    #[test]
-    fn capability_snapshot_match_checks_fingerprint() {
-        let temp = tempfile::tempdir().unwrap();
-        let script = "#!/bin/bash\necho ok";
-        let binary = write_fake_codex(temp.path(), script);
-        let cache_key = capability_cache_key(&binary);
-        let fingerprint = current_fingerprint(&cache_key);
-
-        let snapshot = CodexCapabilities {
-            cache_key: cache_key.clone(),
-            fingerprint: fingerprint.clone(),
-            version: None,
-            features: CodexFeatureFlags::default(),
-            probe_plan: CapabilityProbePlan::default(),
-            collected_at: SystemTime::UNIX_EPOCH,
-        };
-
-        assert!(capability_snapshot_matches_binary(&snapshot, &binary));
-        let mut missing_fingerprint = snapshot.clone();
-        missing_fingerprint.fingerprint = None;
-        assert!(!capability_snapshot_matches_binary(
-            &missing_fingerprint,
-            &binary
-        ));
-
-        std_fs::write(&binary, "#!/bin/bash\necho changed").unwrap();
-        let mut perms = std_fs::metadata(&binary).unwrap().permissions();
-        perms.set_mode(0o755);
-        std_fs::set_permissions(&binary, perms).unwrap();
-
-        assert!(!capability_snapshot_matches_binary(&snapshot, &binary));
-    }
-
-    #[test]
-    fn capability_cache_entries_exposes_cache_state() {
-        let _guard = env_guard();
-        clear_capability_cache();
-
-        let temp = tempfile::tempdir().unwrap();
-        let binary = write_fake_codex(temp.path(), "#!/bin/bash\necho ok");
-        let cache_key = capability_cache_key(&binary);
-        let fingerprint = current_fingerprint(&cache_key);
-
-        let snapshot = CodexCapabilities {
+        CodexCapabilities {
             cache_key: cache_key.clone(),
-            fingerprint: fingerprint.clone(),
-            version: Some(parse_version_output("codex 0.0.1")),
-            features: CodexFeatureFlags {
-                supports_features_list: true,
-                supports_output_schema: true,
-                supports_add_dir: false,
-                supports_mcp_login: false,
-            },
-            probe_plan: CapabilityProbePlan {
-                steps: vec![CapabilityProbeStep::VersionFlag],
-            },
-            collected_at: SystemTime::UNIX_EPOCH,
-        };
-
-        update_capability_cache(snapshot.clone());
-
-        let entries = capability_cache_entries();
-        assert!(entries.iter().any(|entry| entry.cache_key == cache_key));
-
-        let fetched = capability_cache_entry(&binary).expect("expected cache entry");
-        assert_eq!(fetched.cache_key, cache_key);
-        assert!(clear_capability_cache_entry(&binary));
-        assert!(capability_cache_entry(&binary).is_none());
-        assert!(capability_cache_entries().is_empty());
-        clear_capability_cache();
-    }
-
-    #[test]
-    fn capability_ttl_decision_reuses_fresh_snapshot() {
-        let collected_at = SystemTime::UNIX_EPOCH + Duration::from_secs(10);
-        let snapshot = capability_snapshot_with_metadata(
-            collected_at,
-            Some(BinaryFingerprint {
-                canonical_path: Some(PathBuf::from("/tmp/codex")),
-                modified: Some(SystemTime::UNIX_EPOCH + Duration::from_secs(1)),
-                len: Some(123),
-            }),
-        );
-
-        let decision = capability_cache_ttl_decision(
-            Some(&snapshot),
-            Duration::from_secs(300),
-            SystemTime::UNIX_EPOCH + Duration::from_secs(100),
-        );
-        assert!(!decision.should_probe);
-        assert_eq!(decision.policy, CapabilityCachePolicy::PreferCache);
-    }
-
-    #[test]
-    fn capability_ttl_decision_refreshes_after_ttl_with_fingerprint() {
-        let collected_at = SystemTime::UNIX_EPOCH + Duration::from_secs(1);
-        let snapshot = capability_snapshot_with_metadata(
-            collected_at,
-            Some(BinaryFingerprint {
-                canonical_path: Some(PathBuf::from("/tmp/codex")),
-                modified: Some(SystemTime::UNIX_EPOCH + Duration::from_secs(1)),
-                len: Some(321),
-            }),
-        );
-
-        let decision = capability_cache_ttl_decision(
-            Some(&snapshot),
-            Duration::from_secs(5),
-            SystemTime::UNIX_EPOCH + Duration::from_secs(10),
-        );
-        assert!(decision.should_probe);
-        assert_eq!(decision.policy, CapabilityCachePolicy::Refresh);
-    }
-
-    #[test]
-    fn capability_ttl_decision_bypasses_when_metadata_missing() {
-        let collected_at = SystemTime::UNIX_EPOCH + Duration::from_secs(2);
-        let snapshot = capability_snapshot_with_metadata(collected_at, None);
-
-        let decision = capability_cache_ttl_decision(
-            Some(&snapshot),
-            Duration::from_secs(5),
-            SystemTime::UNIX_EPOCH + Duration::from_secs(10),
-        );
-        assert!(decision.should_probe);
-        assert_eq!(decision.policy, CapabilityCachePolicy::Bypass);
-    }
-
-    #[tokio::test]
-    async fn probe_reprobes_when_metadata_missing() {
-        let _guard = env_guard_async().await;
-        clear_capability_cache();
-
-        let temp = tempfile::tempdir().unwrap();
-        let binary = temp.path().join("missing_codex");
-        let cache_key = capability_cache_key(&binary);
-
-        {
-            let mut cache = capability_cache().lock().unwrap();
-            cache.insert(
-                cache_key.clone(),
-                CodexCapabilities {
-                    cache_key: cache_key.clone(),
-                    fingerprint: None,
-                    version: Some(parse_version_output("codex 9.9.9")),
-                    features: CodexFeatureFlags {
-                        supports_features_list: true,
-                        supports_output_schema: true,
-                        supports_add_dir: true,
-                        supports_mcp_login: true,
-                    },
-                    probe_plan: CapabilityProbePlan::default(),
-                    collected_at: SystemTime::UNIX_EPOCH,
-                },
-            );
-        }
-
-        let client = CodexClient::builder()
-            .binary(&binary)
-            .timeout(Duration::from_secs(1))
-            .build();
-
-        let capabilities = client.probe_capabilities().await;
-        assert!(!capabilities.features.supports_output_schema);
-        assert!(capabilities
-            .probe_plan
-            .steps
-            .contains(&CapabilityProbeStep::VersionFlag));
-
-        clear_capability_cache();
-    }
-
-    #[tokio::test]
-    async fn probe_refresh_policy_forces_new_snapshot() {
-        let _guard = env_guard_async().await;
-        clear_capability_cache();
-
-        let temp = tempfile::tempdir().unwrap();
-        let log_path = temp.path().join("probe.log");
-        let script = format!(
-            r#"#!/bin/bash
-echo "$@" >> "{log}"
-if [[ "$1" == "--version" ]]; then
-  echo "codex 1.0.0"
-elif [[ "$1" == "features" && "$2" == "list" && "$3" == "--json" ]]; then
-  echo '{{"features":["output_schema"]}}'
-elif [[ "$1" == "features" && "$2" == "list" ]]; then
-  echo "output_schema"
-fi
-"#,
-            log = log_path.display()
-        );
-        let binary = write_fake_codex(temp.path(), &script);
-        let client = CodexClient::builder()
-            .binary(&binary)
-            .timeout(Duration::from_secs(5))
-            .build();
-
-        let first = client.probe_capabilities().await;
-        assert!(first.features.supports_output_schema);
-        let first_lines = std_fs::read_to_string(&log_path).unwrap().lines().count();
-        assert!(first_lines >= 2);
-
-        let refreshed = client
-            .probe_capabilities_with_policy(CapabilityCachePolicy::Refresh)
-            .await;
-        assert!(refreshed.features.supports_output_schema);
-        let refreshed_lines = std_fs::read_to_string(&log_path).unwrap().lines().count();
-        assert!(
-            refreshed_lines > first_lines,
-            "expected refresh policy to re-run probes"
-        );
-        clear_capability_cache();
-    }
-
-    #[tokio::test]
-    async fn probe_bypass_policy_skips_cache_writes() {
-        let _guard = env_guard_async().await;
-        clear_capability_cache();
-
-        let temp = tempfile::tempdir().unwrap();
-        let script = r#"#!/bin/bash
-if [[ "$1" == "--version" ]]; then
-  echo "codex 1.0.0"
-elif [[ "$1" == "features" && "$2" == "list" && "$3" == "--json" ]]; then
-  echo '{"features":["output_schema"]}'
-elif [[ "$1" == "features" && "$2" == "list" ]]; then
-  echo "output_schema"
-fi
-"#;
-        let binary = write_fake_codex(temp.path(), script);
-
-        let client = CodexClient::builder()
-            .binary(&binary)
-            .timeout(Duration::from_secs(5))
-            .build();
-
-        let capabilities = client
-            .probe_capabilities_with_policy(CapabilityCachePolicy::Bypass)
-            .await;
-        assert!(capabilities.features.supports_output_schema);
-        assert!(capability_cache_entry(&binary).is_none());
-        clear_capability_cache();
-    }
-
-    #[test]
-    fn parses_features_from_json_and_text() {
-        let json = r#"{"features":["output_schema","add_dir"],"mcp_login":true}"#;
-        let parsed_json = parse_features_from_json(json).unwrap();
-        assert!(parsed_json.supports_output_schema);
-        assert!(parsed_json.supports_add_dir);
-        assert!(parsed_json.supports_mcp_login);
-
-        let text = "Features: output-schema add-dir login --mcp";
-        let parsed_text = parse_features_from_text(text);
-        assert!(parsed_text.supports_output_schema);
-        assert!(parsed_text.supports_add_dir);
-        assert!(parsed_text.supports_mcp_login);
-    }
-
-    #[test]
-    fn parses_feature_list_json_and_text_tables() {
-        let json = r#"{"features":[{"name":"json-stream","stage":"stable","enabled":true,"notes":"keep"},{"name":"cloud-exec","stage":"experimental","enabled":false}]}"#;
-        let (json_features, json_format) = parse_feature_list_output(json, true).unwrap();
-        assert_eq!(json_format, FeaturesListFormat::Json);
-        assert_eq!(json_features.len(), 2);
-        assert_eq!(json_features[0].name, "json-stream");
-        assert_eq!(json_features[0].stage, Some(CodexFeatureStage::Stable));
-        assert!(json_features[0].enabled);
-        assert!(json_features[0].extra.contains_key("notes"));
-        assert_eq!(
-            json_features[1].stage,
-            Some(CodexFeatureStage::Experimental)
-        );
-        assert!(!json_features[1].enabled);
-
-        let text = r#"
-Feature   Stage         Enabled
-json-stream stable      true
-cloud-exec experimental false
-"#;
-        let (text_features, text_format) = parse_feature_list_output(text, false).unwrap();
-        assert_eq!(text_format, FeaturesListFormat::Text);
-        assert_eq!(text_features.len(), 2);
-        assert_eq!(
-            text_features[1].stage,
-            Some(CodexFeatureStage::Experimental)
-        );
-        assert!(!text_features[1].enabled);
-
-        let (fallback_features, fallback_format) = parse_feature_list_output(text, true).unwrap();
-        assert_eq!(fallback_format, FeaturesListFormat::Text);
-        assert_eq!(fallback_features.len(), 2);
-    }
-
-    #[test]
-    fn parses_help_output_flags() {
-        let help =
-            "Usage: codex --output-schema ... add-dir ... login --mcp. See `codex features list`.";
-        let parsed = parse_help_output(help);
-        assert!(parsed.supports_output_schema);
-        assert!(parsed.supports_add_dir);
-        assert!(parsed.supports_mcp_login);
-        assert!(parsed.supports_features_list);
-    }
-
-    #[test]
-    fn capability_guard_reports_detected_support() {
-        let flags = CodexFeatureFlags {
-            supports_features_list: true,
-            supports_output_schema: true,
-            supports_add_dir: true,
-            supports_mcp_login: true,
-        };
-        let capabilities = capabilities_with_feature_flags(flags);
-
-        let output_schema = capabilities.guard_output_schema();
-        assert_eq!(output_schema.support, CapabilitySupport::Supported);
-        assert!(output_schema.is_supported());
-
-        let add_dir = capabilities.guard_add_dir();
-        assert_eq!(add_dir.support, CapabilitySupport::Supported);
-        assert!(add_dir.is_supported());
-
-        let mcp_login = capabilities.guard_mcp_login();
-        assert_eq!(mcp_login.support, CapabilitySupport::Supported);
-
-        let features_list = capabilities.guard_features_list();
-        assert_eq!(features_list.support, CapabilitySupport::Supported);
-    }
-
-    #[test]
-    fn capability_guard_marks_absent_feature_as_unsupported() {
-        let flags = CodexFeatureFlags {
-            supports_features_list: true,
-            supports_output_schema: false,
-            supports_add_dir: false,
-            supports_mcp_login: false,
-        };
-        let capabilities = capabilities_with_feature_flags(flags);
-
-        let output_schema = capabilities.guard_output_schema();
-        assert_eq!(output_schema.support, CapabilitySupport::Unsupported);
-        assert!(!output_schema.is_supported());
-        assert!(output_schema
-            .notes
-            .iter()
-            .any(|note| note.contains("features list")));
-
-        let mcp_login = capabilities.guard_mcp_login();
-        assert_eq!(mcp_login.support, CapabilitySupport::Unsupported);
-    }
-
-    #[test]
-    fn capability_guard_returns_unknown_without_feature_list() {
-        let capabilities = capabilities_with_feature_flags(CodexFeatureFlags::default());
-
-        let add_dir = capabilities.guard_add_dir();
-        assert_eq!(add_dir.support, CapabilitySupport::Unknown);
-        assert!(add_dir.is_unknown());
-        assert!(add_dir
-            .notes
-            .iter()
-            .any(|note| note.contains("unknown") || note.contains("unavailable")));
-
-        let features_list = capabilities.guard_features_list();
-        assert_eq!(features_list.support, CapabilitySupport::Unknown);
-    }
-
-    #[tokio::test]
-    async fn capability_snapshot_short_circuits_probes() {
-        let _guard = env_guard_async().await;
-        clear_capability_cache();
-
-        let temp = tempfile::tempdir().unwrap();
-        let log_path = temp.path().join("probe.log");
-        let script = format!(
-            r#"#!/bin/bash
-echo "$@" >> "{log}"
-exit 99
-"#,
-            log = log_path.display()
-        );
-        let binary = write_fake_codex(temp.path(), &script);
-
-        let snapshot = CodexCapabilities {
-            cache_key: CapabilityCacheKey {
-                binary_path: PathBuf::from("codex"),
-            },
-            fingerprint: None,
-            version: Some(parse_version_output("codex 9.9.9-custom")),
-            features: CodexFeatureFlags {
-                supports_features_list: true,
-                supports_output_schema: true,
-                supports_add_dir: false,
-                supports_mcp_login: true,
-            },
-            probe_plan: CapabilityProbePlan::default(),
+            fingerprint,
+            version,
+            features,
+            probe_plan: plan,
             collected_at: SystemTime::now(),
-        };
-
-        let client = CodexClient::builder()
-            .binary(&binary)
-            .capability_snapshot(snapshot)
-            .timeout(Duration::from_secs(5))
-            .build();
-
-        let capabilities = client.probe_capabilities().await;
-        assert_eq!(
-            capabilities.cache_key.binary_path,
-            std_fs::canonicalize(&binary).unwrap()
-        );
-        assert!(capabilities.fingerprint.is_some());
-        assert!(capabilities.features.supports_output_schema);
-        assert!(capabilities.features.supports_mcp_login);
-        assert_eq!(
-            capabilities.version.as_ref().and_then(|v| v.semantic),
-            Some((9, 9, 9))
-        );
-        assert!(capabilities
-            .probe_plan
-            .steps
-            .contains(&CapabilityProbeStep::ManualOverride));
-        assert!(!log_path.exists());
-    }
-
-    #[tokio::test]
-    async fn capability_feature_overrides_apply_to_cached_entries() {
-        let _guard = env_guard_async().await;
-        clear_capability_cache();
-
-        let temp = tempfile::tempdir().unwrap();
-        let script = r#"#!/bin/bash
-if [[ "$1" == "--version" ]]; then
-  echo "codex 1.0.0"
-elif [[ "$1" == "features" && "$2" == "list" && "$3" == "--json" ]]; then
-  echo '{"features":[]}'
-elif [[ "$1" == "features" && "$2" == "list" ]]; then
-  echo "features list"
-elif [[ "$1" == "--help" ]]; then
-  echo "Usage: codex exec"
-fi
-"#;
-        let binary = write_fake_codex(temp.path(), script);
-
-        let base_client = CodexClient::builder()
-            .binary(&binary)
-            .timeout(Duration::from_secs(5))
-            .build();
-        let base_capabilities = base_client.probe_capabilities().await;
-        assert!(base_capabilities.features.supports_features_list);
-        assert!(!base_capabilities.features.supports_output_schema);
-
-        let overrides = CapabilityFeatureOverrides::enabling(CodexFeatureFlags {
-            supports_features_list: false,
-            supports_output_schema: true,
-            supports_add_dir: false,
-            supports_mcp_login: true,
-        });
-
-        let client = CodexClient::builder()
-            .binary(&binary)
-            .capability_feature_overrides(overrides)
-            .timeout(Duration::from_secs(5))
-            .build();
-
-        let capabilities = client.probe_capabilities().await;
-        assert!(capabilities.features.supports_output_schema);
-        assert!(capabilities.features.supports_mcp_login);
-        assert!(capabilities
-            .probe_plan
-            .steps
-            .contains(&CapabilityProbeStep::ManualOverride));
-        assert_eq!(
-            capabilities.guard_output_schema().support,
-            CapabilitySupport::Supported
-        );
-    }
-
-    #[tokio::test]
-    async fn capability_version_override_replaces_probe_version() {
-        let _guard = env_guard_async().await;
-        clear_capability_cache();
-
-        let temp = tempfile::tempdir().unwrap();
-        let script = r#"#!/bin/bash
-if [[ "$1" == "--version" ]]; then
-  echo "codex 0.1.0"
-elif [[ "$1" == "features" && "$2" == "list" && "$3" == "--json" ]]; then
-  echo '{"features":["add_dir"]}'
-elif [[ "$1" == "features" && "$2" == "list" ]]; then
-  echo "add_dir"
-elif [[ "$1" == "--help" ]]; then
-  echo "Usage: codex add-dir"
-fi
-"#;
-        let binary = write_fake_codex(temp.path(), script);
-        let version_override = parse_version_output("codex 9.9.9-nightly (commit beefcafe)");
-
-        let client = CodexClient::builder()
-            .binary(&binary)
-            .timeout(Duration::from_secs(5))
-            .capability_version_override(version_override)
-            .build();
-
-        let capabilities = client.probe_capabilities().await;
-        assert_eq!(
-            capabilities.version.as_ref().and_then(|v| v.semantic),
-            Some((9, 9, 9))
-        );
-        assert!(matches!(
-            capabilities.version.as_ref().map(|v| v.channel),
-            Some(CodexReleaseChannel::Nightly)
-        ));
-        assert!(capabilities.features.supports_add_dir);
-        assert!(capabilities
-            .probe_plan
-            .steps
-            .contains(&CapabilityProbeStep::ManualOverride));
-        assert_eq!(
-            capabilities.guard_add_dir().support,
-            CapabilitySupport::Supported
-        );
-    }
-
-    #[tokio::test]
-    async fn exec_applies_guarded_flags_when_supported() {
-        let _guard = env_guard_async().await;
-        clear_capability_cache();
-
-        let temp = tempfile::tempdir().unwrap();
-        let log_path = temp.path().join("exec.log");
-        let script = format!(
-            r#"#!/bin/bash
-log="{log}"
-if [[ "$1" == "--version" ]]; then
-  echo "codex 1.2.3"
-elif [[ "$1" == "features" && "$2" == "list" && "$3" == "--json" ]]; then
-  echo '{{"features":["output_schema","add_dir","mcp_login"]}}'
-elif [[ "$1" == "features" && "$2" == "list" ]]; then
-  echo "output_schema add_dir login --mcp"
-elif [[ "$1" == "--help" ]]; then
-  echo "Usage: codex --output-schema add-dir login --mcp"
-elif [[ "$1" == "exec" ]]; then
-  echo "$@" >> "$log"
-  echo "ok"
-fi
-"#,
-            log = log_path.display()
-        );
-        let binary = write_fake_codex(temp.path(), &script);
-        let client = CodexClient::builder()
-            .binary(&binary)
-            .timeout(Duration::from_secs(5))
-            .add_dir("src")
-            .output_schema(true)
-            .quiet(true)
-            .mirror_stdout(false)
-            .build();
-
-        let response = client.send_prompt("hello").await.unwrap();
-        assert_eq!(response.trim(), "ok");
-
-        let logged = std_fs::read_to_string(&log_path).unwrap();
-        assert!(logged.contains("--add-dir"));
-        assert!(logged.contains("src"));
-        assert!(logged.contains("--output-schema"));
-    }
-
-    #[tokio::test]
-    async fn exec_skips_guarded_flags_when_unknown() {
-        let _guard = env_guard_async().await;
-        clear_capability_cache();
-
-        let temp = tempfile::tempdir().unwrap();
-        let log_path = temp.path().join("exec.log");
-        let script = format!(
-            r#"#!/bin/bash
-log="{log}"
-if [[ "$1" == "--version" ]]; then
-  echo "codex 0.9.0"
-elif [[ "$1" == "features" && "$2" == "list" && "$3" == "--json" ]]; then
-  echo "feature list unavailable" >&2
-  exit 1
-elif [[ "$1" == "features" && "$2" == "list" ]]; then
-  echo "feature list unavailable" >&2
-  exit 1
-elif [[ "$1" == "--help" ]]; then
-  echo "Usage: codex exec"
-elif [[ "$1" == "exec" ]]; then
-  echo "$@" >> "$log"
-  echo "ok"
-fi
-"#,
-            log = log_path.display()
-        );
-        let binary = write_fake_codex(temp.path(), &script);
-        let client = CodexClient::builder()
-            .binary(&binary)
-            .timeout(Duration::from_secs(5))
-            .add_dir("src")
-            .output_schema(true)
-            .quiet(true)
-            .mirror_stdout(false)
-            .build();
-
-        let response = client.send_prompt("hello").await.unwrap();
-        assert_eq!(response.trim(), "ok");
-
-        let logged = std_fs::read_to_string(&log_path).unwrap();
-        assert!(!logged.contains("--add-dir"));
-        assert!(!logged.contains("--output-schema"));
-    }
-
-    #[tokio::test]
-    async fn mcp_login_skips_when_unsupported() {
-        let _guard = env_guard_async().await;
-        clear_capability_cache();
-
-        let temp = tempfile::tempdir().unwrap();
-        let log_path = temp.path().join("login.log");
-        let script = format!(
-            r#"#!/bin/bash
-log="{log}"
-if [[ "$1" == "--version" ]]; then
-  echo "codex 1.0.0"
-elif [[ "$1" == "features" && "$2" == "list" && "$3" == "--json" ]]; then
-  echo '{{"features":["output_schema","add_dir"]}}'
-elif [[ "$1" == "features" && "$2" == "list" ]]; then
-  echo "output_schema add-dir"
-elif [[ "$1" == "--help" ]]; then
-  echo "Usage: codex exec"
-elif [[ "$1" == "login" ]]; then
-  echo "$@" >> "$log"
-  echo "login invoked"
-fi
-"#,
-            log = log_path.display()
-        );
-        let binary = write_fake_codex(temp.path(), &script);
-        let client = CodexClient::builder()
-            .binary(&binary)
-            .timeout(Duration::from_secs(5))
-            .build();
-
-        let login = client.spawn_mcp_login_process().await.unwrap();
-        assert!(login.is_none());
-        assert!(!log_path.exists());
-    }
-
-    #[tokio::test]
-    async fn mcp_login_runs_when_supported() {
-        let _guard = env_guard_async().await;
-        clear_capability_cache();
-
-        let temp = tempfile::tempdir().unwrap();
-        let log_path = temp.path().join("login.log");
-        let script = format!(
-            r#"#!/bin/bash
-log="{log}"
-if [[ "$1" == "--version" ]]; then
-  echo "codex 2.0.0"
-elif [[ "$1" == "features" && "$2" == "list" && "$3" == "--json" ]]; then
-  echo '{{"features":["output_schema","add_dir"],"mcp_login":true}}'
-elif [[ "$1" == "features" && "$2" == "list" ]]; then
-  echo "output_schema add_dir login --mcp"
-elif [[ "$1" == "--help" ]]; then
-  echo "Usage: codex --output-schema add-dir login --mcp"
-elif [[ "$1" == "login" ]]; then
-  echo "$@" >> "$log"
-  echo "login invoked"
-fi
-"#,
-            log = log_path.display()
-        );
-        let binary = write_fake_codex(temp.path(), &script);
-        let client = CodexClient::builder()
-            .binary(&binary)
-            .timeout(Duration::from_secs(5))
-            .build();
-
-        let login = client
-            .spawn_mcp_login_process()
-            .await
-            .unwrap()
-            .expect("expected login child");
-        let output = login.wait_with_output().await.unwrap();
-        assert!(output.status.success());
-
-        let logged = std_fs::read_to_string(&log_path).unwrap();
-        assert!(logged.contains("login --mcp"));
-    }
-
-    #[tokio::test]
-    async fn probe_capabilities_caches_and_invalidates() {
-        let _guard = env_guard_async().await;
-        clear_capability_cache();
-
-        let temp = tempfile::tempdir().unwrap();
-        let script_v1 = r#"#!/bin/bash
-if [[ "$1" == "--version" ]]; then
-  echo "codex 1.2.3-beta (commit cafe123)"
-elif [[ "$1" == "features" && "$2" == "list" && "$3" == "--json" ]]; then
-  echo '{"features":["output_schema","add_dir","mcp_login"]}'
-elif [[ "$1" == "features" && "$2" == "list" ]]; then
-  echo "output_schema add-dir login --mcp"
-elif [[ "$1" == "--help" ]]; then
-  echo "Usage: codex --output-schema add-dir login --mcp"
-fi
-"#;
-        let binary = write_fake_codex(temp.path(), script_v1);
-        let client = CodexClient::builder()
-            .binary(&binary)
-            .timeout(Duration::from_secs(5))
-            .build();
-
-        let first = client.probe_capabilities().await;
-        assert_eq!(
-            first.version.as_ref().and_then(|v| v.semantic),
-            Some((1, 2, 3))
-        );
-        assert_eq!(
-            first.version.as_ref().map(|v| v.channel),
-            Some(CodexReleaseChannel::Beta)
-        );
-        assert_eq!(
-            first.version.as_ref().and_then(|v| v.commit.as_deref()),
-            Some("cafe123")
-        );
-        assert!(first.features.supports_features_list);
-        assert!(first.features.supports_output_schema);
-        assert!(first.features.supports_add_dir);
-        assert!(first.features.supports_mcp_login);
-
-        let cached = client.probe_capabilities().await;
-        assert_eq!(cached, first);
-
-        let script_v2 = r#"#!/bin/bash
-if [[ "$1" == "--version" ]]; then
-  echo "codex 2.0.0 (commit deadbeef)"
-elif [[ "$1" == "features" && "$2" == "list" && "$3" == "--json" ]]; then
-  echo '{"features":["add_dir"]}'
-elif [[ "$1" == "features" && "$2" == "list" ]]; then
-  echo "add-dir"
-elif [[ "$1" == "--help" ]]; then
-  echo "Usage: codex add-dir"
-fi
-"#;
-        std_fs::write(&binary, script_v2).unwrap();
-        let mut perms = std_fs::metadata(&binary).unwrap().permissions();
-        perms.set_mode(0o755);
-        std_fs::set_permissions(&binary, perms).unwrap();
-
-        let refreshed = client.probe_capabilities().await;
-        assert_ne!(refreshed.version, first.version);
-        assert_eq!(
-            refreshed.version.as_ref().and_then(|v| v.semantic),
-            Some((2, 0, 0))
-        );
-        assert!(refreshed.features.supports_features_list);
-        assert!(refreshed.features.supports_add_dir);
-        assert!(!refreshed.features.supports_output_schema);
-        assert!(!refreshed.features.supports_mcp_login);
-        clear_capability_cache();
-    }
-
-    #[test]
-    fn reasoning_config_by_model() {
-        assert_eq!(
-            reasoning_config_for(Some("gpt-5")).unwrap(),
-            DEFAULT_REASONING_CONFIG_GPT5
-        );
-        assert_eq!(
-            reasoning_config_for(Some("gpt-5.1-codex-max")).unwrap(),
-            DEFAULT_REASONING_CONFIG_GPT5_1
-        );
-        assert_eq!(
-            reasoning_config_for(Some("gpt-5-codex")).unwrap(),
-            DEFAULT_REASONING_CONFIG_GPT5_CODEX
-        );
-        assert!(reasoning_config_for(None).is_none());
-        assert!(reasoning_config_for(Some("gpt-4.1-mini")).is_none());
-    }
-
-    #[test]
-    fn resolve_cli_overrides_respects_reasoning_defaults() {
-        let builder = CliOverrides::default();
-        let patch = CliOverridesPatch::default();
-
-        let resolved = resolve_cli_overrides(&builder, &patch, Some("gpt-5"));
-        let keys: Vec<_> = resolved
-            .config_overrides
-            .iter()
-            .map(|override_| override_.key.as_str())
-            .collect();
-        assert!(keys.contains(&"model_reasoning_effort"));
-        assert!(keys.contains(&"model_reasoning_summary"));
-        assert!(keys.contains(&"model_verbosity"));
-
-        let resolved_without_model = resolve_cli_overrides(&builder, &patch, None);
-        assert!(resolved_without_model.config_overrides.is_empty());
-    }
-
-    #[test]
-    fn explicit_reasoning_overrides_disable_defaults() {
-        let mut builder = CliOverrides::default();
-        builder
-            .config_overrides
-            .push(ConfigOverride::new("model_reasoning_effort", "high"));
-
-        let resolved =
-            resolve_cli_overrides(&builder, &CliOverridesPatch::default(), Some("gpt-5"));
-        assert_eq!(resolved.config_overrides.len(), 1);
-        assert_eq!(resolved.config_overrides[0].value, "high");
-    }
-
-    #[test]
-    fn request_can_disable_auto_reasoning_defaults() {
-        let builder = CliOverrides::default();
-        let patch = CliOverridesPatch {
-            auto_reasoning_defaults: Some(false),
-            ..Default::default()
-        };
-
-        let resolved = resolve_cli_overrides(&builder, &patch, Some("gpt-5"));
-        assert!(resolved.config_overrides.is_empty());
-    }
-
-    #[test]
-    fn request_config_overrides_follow_builder_order() {
-        let mut builder_overrides = CliOverrides {
-            auto_reasoning_defaults: false,
-            ..Default::default()
-        };
-        builder_overrides
-            .config_overrides
-            .push(ConfigOverride::new("foo", "bar"));
-
-        let mut patch = CliOverridesPatch::default();
-        patch
-            .config_overrides
-            .push(ConfigOverride::new("foo", "baz"));
-
-        let resolved = resolve_cli_overrides(&builder_overrides, &patch, None);
-        let values: Vec<_> = resolved
-            .config_overrides
-            .iter()
-            .map(|override_| override_.value.as_str())
-            .collect();
-        assert_eq!(values, vec!["bar", "baz"]);
-    }
-
-    #[test]
-    fn request_search_override_can_disable_builder_flag() {
-        let builder_overrides = CliOverrides {
-            search: FlagState::Enable,
-            ..Default::default()
-        };
-
-        let patch = CliOverridesPatch {
-            search: FlagState::Disable,
-            ..Default::default()
-        };
-
-        let resolved = resolve_cli_overrides(&builder_overrides, &patch, None);
-        let args = cli_override_args(&resolved, true);
-        let args: Vec<_> = args
-            .iter()
-            .map(|arg| arg.to_string_lossy().into_owned())
-            .collect();
-        assert!(!args.contains(&"--search".to_string()));
-    }
-
-    #[test]
-    fn request_profile_override_replaces_builder_value() {
-        let builder_overrides = CliOverrides {
-            profile: Some("builder".to_string()),
-            ..Default::default()
-        };
-
-        let patch = CliOverridesPatch {
-            profile: Some("request".to_string()),
-            ..Default::default()
-        };
-
-        let resolved = resolve_cli_overrides(&builder_overrides, &patch, None);
-        let args: Vec<_> = cli_override_args(&resolved, true)
-            .iter()
-            .map(|arg| arg.to_string_lossy().into_owned())
-            .collect();
-        assert!(args.windows(2).any(|window| {
-            window.first().map(String::as_str) == Some("--profile")
-                && window.get(1).map(String::as_str) == Some("request")
-        }));
-        assert!(!args.contains(&"builder".to_string()));
-    }
-
-    #[test]
-    fn request_oss_override_can_disable_builder_flag() {
-        let builder_overrides = CliOverrides {
-            oss: FlagState::Enable,
-            ..Default::default()
-        };
-
-        let resolved =
-            resolve_cli_overrides(&builder_overrides, &CliOverridesPatch::default(), None);
-        let args: Vec<_> = cli_override_args(&resolved, true)
-            .iter()
-            .map(|arg| arg.to_string_lossy().into_owned())
-            .collect();
-        assert!(args.contains(&"--oss".to_string()));
-
-        let patch = CliOverridesPatch {
-            oss: FlagState::Disable,
-            ..Default::default()
-        };
-        let resolved = resolve_cli_overrides(&builder_overrides, &patch, None);
-        let args: Vec<_> = cli_override_args(&resolved, true)
-            .iter()
-            .map(|arg| arg.to_string_lossy().into_owned())
-            .collect();
-        assert!(!args.contains(&"--oss".to_string()));
-    }
-
-    #[test]
-    fn feature_toggles_merge_builder_and_request() {
-        let mut builder_overrides = CliOverrides::default();
-        builder_overrides
-            .feature_toggles
-            .enable
-            .push("builder-enable".to_string());
-        builder_overrides
-            .feature_toggles
-            .disable
-            .push("builder-disable".to_string());
-
-        let mut patch = CliOverridesPatch::default();
-        patch
-            .feature_toggles
-            .enable
-            .push("request-enable".to_string());
-        patch
-            .feature_toggles
-            .disable
-            .push("request-disable".to_string());
-
-        let resolved = resolve_cli_overrides(&builder_overrides, &patch, None);
-        let args: Vec<_> = cli_override_args(&resolved, true)
-            .iter()
-            .map(|arg| arg.to_string_lossy().into_owned())
-            .collect();
-
-        assert!(args.windows(2).any(|window| {
-            window.first().map(String::as_str) == Some("--enable")
-                && window.get(1).map(String::as_str) == Some("builder-enable")
-        }));
-        assert!(args.windows(2).any(|window| {
-            window.first().map(String::as_str) == Some("--enable")
-                && window.get(1).map(String::as_str) == Some("request-enable")
-        }));
-        assert!(args.windows(2).any(|window| {
-            window.first().map(String::as_str) == Some("--disable")
-                && window.get(1).map(String::as_str) == Some("builder-disable")
-        }));
-        assert!(args.windows(2).any(|window| {
-            window.first().map(String::as_str) == Some("--disable")
-                && window.get(1).map(String::as_str) == Some("request-disable")
-        }));
-    }
-
-    #[test]
-    fn cli_override_args_apply_safety_precedence() {
-        let mut resolved = ResolvedCliOverrides {
-            config_overrides: Vec::new(),
-            feature_toggles: FeatureToggles::default(),
-            approval_policy: None,
-            sandbox_mode: None,
-            safety_override: SafetyOverride::FullAuto,
-            profile: None,
-            cd: None,
-            local_provider: None,
-            oss: false,
-            search: FlagState::Enable,
-        };
-        let args = cli_override_args(&resolved, true);
-        let args: Vec<_> = args
-            .iter()
-            .map(|value| value.to_string_lossy().into_owned())
-            .collect();
-        assert!(args.contains(&"--full-auto".to_string()));
-        assert!(args.contains(&"--search".to_string()));
-        assert!(!args.contains(&"--ask-for-approval".to_string()));
-
-        resolved.approval_policy = Some(ApprovalPolicy::OnRequest);
-        let args_with_policy = cli_override_args(&resolved, true);
-        let args_with_policy: Vec<_> = args_with_policy
-            .iter()
-            .map(|value| value.to_string_lossy().into_owned())
-            .collect();
-        assert!(!args_with_policy.contains(&"--full-auto".to_string()));
-        assert!(args_with_policy.contains(&"--ask-for-approval".to_string()));
-
-        let resolved = ResolvedCliOverrides {
-            config_overrides: vec![ConfigOverride::new("foo", "bar")],
-            feature_toggles: FeatureToggles::default(),
-            approval_policy: Some(ApprovalPolicy::OnRequest),
-            sandbox_mode: Some(SandboxMode::WorkspaceWrite),
-            safety_override: SafetyOverride::DangerouslyBypass,
-            profile: Some("team".to_string()),
-            cd: Some(PathBuf::from("/tmp/worktree")),
-            local_provider: Some(LocalProvider::Ollama),
-            oss: false,
-            search: FlagState::Enable,
-        };
-        let args = cli_override_args(&resolved, true);
-        let args: Vec<_> = args
-            .iter()
-            .map(|value| value.to_string_lossy().into_owned())
-            .collect();
-        assert!(args.contains(&"--config".to_string()));
-        assert!(args.contains(&"foo=bar".to_string()));
-        assert!(args.contains(&"--dangerously-bypass-approvals-and-sandbox".to_string()));
-        assert!(args.contains(&"--profile".to_string()));
-        assert!(args.contains(&"team".to_string()));
-        assert!(args.contains(&"--cd".to_string()));
-        assert!(args.contains(&"/tmp/worktree".to_string()));
-        assert!(args.contains(&"--local-provider".to_string()));
-        assert!(args.contains(&"ollama".to_string()));
-        assert!(args.contains(&"--search".to_string()));
-        assert!(!args.contains(&"--ask-for-approval".to_string()));
-        assert!(!args.contains(&"--sandbox".to_string()));
-
-        let args_without_search = cli_override_args(&resolved, false);
-        let args_without_search: Vec<_> = args_without_search
-            .iter()
-            .map(|value| value.to_string_lossy().into_owned())
-            .collect();
-        assert!(!args_without_search.contains(&"--search".to_string()));
-    }
-
-    #[tokio::test]
-    async fn exec_applies_cli_overrides_and_request_patch() {
-        let _guard = env_guard_async().await;
-        clear_capability_cache();
-
-        let temp = tempfile::tempdir().unwrap();
-        let log_path = temp.path().join("exec.log");
-        let builder_cd = temp.path().join("builder-cd");
-        let request_cd = temp.path().join("request-cd");
-        let script = format!(
-            r#"#!/bin/bash
-echo "$@" >> "{log}"
-if [[ "$1" == "exec" ]]; then
-  echo "ok"
-fi
-"#,
-            log = log_path.display()
-        );
-        let binary = write_fake_codex(temp.path(), &script);
-        let client = CodexClient::builder()
-            .binary(&binary)
-            .timeout(Duration::from_secs(5))
-            .mirror_stdout(false)
-            .quiet(true)
-            .auto_reasoning_defaults(false)
-            .config_override("foo", "bar")
-            .reasoning_summary(ReasoningSummary::Concise)
-            .approval_policy(ApprovalPolicy::OnRequest)
-            .sandbox_mode(SandboxMode::WorkspaceWrite)
-            .cd(&builder_cd)
-            .local_provider(LocalProvider::Custom)
-            .oss(true)
-            .enable_feature("builder-on")
-            .disable_feature("builder-off")
-            .search(true)
-            .build();
-
-        let mut request = ExecRequest::new("list flags")
-            .config_override("extra", "value")
-            .oss(false)
-            .enable_feature("request-on")
-            .disable_feature("request-off")
-            .search(false);
-        request.overrides.cd = Some(request_cd.clone());
-        request.overrides.safety_override = Some(SafetyOverride::DangerouslyBypass);
-
-        let response = client.send_prompt_with(request).await.unwrap();
-        assert_eq!(response.trim(), "ok");
-
-        let logged = std_fs::read_to_string(&log_path).unwrap();
-        assert!(logged.contains("--config"));
-        assert!(logged.contains("foo=bar"));
-        assert!(logged.contains("extra=value"));
-        assert!(logged.contains("model_reasoning_summary=concise"));
-        assert!(logged.contains("--dangerously-bypass-approvals-and-sandbox"));
-        assert!(logged.contains(&request_cd.display().to_string()));
-        assert!(!logged.contains(&builder_cd.display().to_string()));
-        assert!(logged.contains("--local-provider"));
-        assert!(logged.contains("custom"));
-        assert!(logged.contains("--enable"));
-        assert!(logged.contains("builder-on"));
-        assert!(logged.contains("request-on"));
-        assert!(logged.contains("--disable"));
-        assert!(logged.contains("builder-off"));
-        assert!(logged.contains("request-off"));
-        assert!(!logged.contains("--oss"));
-        assert!(!logged.contains("--ask-for-approval"));
-        assert!(!logged.contains("--sandbox"));
-        assert!(!logged.contains("--search"));
-    }
-
-    #[tokio::test]
-    async fn resume_applies_search_and_selector_overrides() {
-        let _guard = env_guard_async().await;
-        clear_capability_cache();
-
-        let temp = tempfile::tempdir().unwrap();
-        let log_path = temp.path().join("resume.log");
-        let builder_cd = temp.path().join("builder-cd");
-        let request_cd = temp.path().join("request-cd");
-        let script = format!(
-            r#"#!/bin/bash
-echo "$@" >> "{log}"
-if [[ "$1" == "exec" ]]; then
-  echo '{{"type":"thread.started","thread_id":"thread-1"}}'
-  echo '{{"type":"turn.started","thread_id":"thread-1","turn_id":"turn-1"}}'
-  echo '{{"type":"turn.completed","thread_id":"thread-1","turn_id":"turn-1"}}'
-fi
-"#,
-            log = log_path.display()
-        );
-        let binary = write_fake_codex(temp.path(), &script);
-        let client = CodexClient::builder()
-            .binary(&binary)
-            .timeout(Duration::from_secs(5))
-            .mirror_stdout(false)
-            .quiet(true)
-            .config_override("resume_hint", "enabled")
-            .approval_policy(ApprovalPolicy::OnRequest)
-            .sandbox_mode(SandboxMode::WorkspaceWrite)
-            .local_provider(LocalProvider::Ollama)
-            .cd(&builder_cd)
-            .search(true)
-            .build();
-
-        let request_last = ResumeRequest::last().prompt("continue");
-        let stream = client.stream_resume(request_last).await.unwrap();
-        let events: Vec<_> = stream.events.collect().await;
-        assert_eq!(events.len(), 3);
-        stream.completion.await.unwrap();
-
-        let mut request_all = ResumeRequest::all().prompt("summarize");
-        request_all.overrides.search = FlagState::Disable;
-        request_all.overrides.safety_override = Some(SafetyOverride::DangerouslyBypass);
-        request_all.overrides.cd = Some(request_cd.clone());
-        let stream_all = client.stream_resume(request_all).await.unwrap();
-        let _ = stream_all.events.collect::<Vec<_>>().await;
-        stream_all.completion.await.unwrap();
-
-        let logged: Vec<_> = std_fs::read_to_string(&log_path)
-            .unwrap()
-            .lines()
-            .map(str::to_string)
-            .collect();
-        assert!(logged.len() >= 2);
-
-        assert!(logged[0].contains("--last"));
-        assert!(logged[0].contains("--search"));
-        assert!(logged[0].contains("resume_hint=enabled"));
-        assert!(logged[0].contains("--ask-for-approval"));
-        assert!(logged[0].contains("--sandbox"));
-        assert!(logged[0].contains(&builder_cd.display().to_string()));
-        assert!(logged[0].contains("ollama"));
-
-        assert!(logged[1].contains("--all"));
-        assert!(logged[1].contains("--dangerously-bypass-approvals-and-sandbox"));
-        assert!(logged[1].contains(&request_cd.display().to_string()));
-        assert!(!logged[1].contains(&builder_cd.display().to_string()));
-        assert!(!logged[1].contains("--ask-for-approval"));
-        assert!(!logged[1].contains("--sandbox"));
-        assert!(!logged[1].contains("--search"));
-    }
-
-    #[tokio::test]
-    async fn apply_respects_cli_overrides_without_search() {
-        let _guard = env_guard_async().await;
-        clear_capability_cache();
-
-        let temp = tempfile::tempdir().unwrap();
-        let log_path = temp.path().join("apply.log");
-        let script = format!(
-            r#"#!/bin/bash
-echo "$@" >> "{log}"
-if [[ "$1" == "apply" ]]; then
-  echo "applied"
-fi
-"#,
-            log = log_path.display()
-        );
-        let binary = write_fake_codex(temp.path(), &script);
-        let client = CodexClient::builder()
-            .binary(&binary)
-            .timeout(Duration::from_secs(5))
-            .mirror_stdout(false)
-            .quiet(true)
-            .cd(temp.path().join("apply-cd"))
-            .config_override("feature.toggle", "true")
-            .search(true)
-            .build();
-
-        let artifacts = client.apply().await.unwrap();
-        assert_eq!(artifacts.stdout.trim(), "applied");
-
-        let logged = std_fs::read_to_string(&log_path).unwrap();
-        assert!(logged.contains("--config"));
-        assert!(logged.contains("feature.toggle=true"));
-        assert!(logged.contains("apply-cd"));
-        assert!(!logged.contains("--search"));
-    }
-
-    #[test]
-    fn color_mode_strings_are_stable() {
-        assert_eq!(ColorMode::Auto.as_str(), "auto");
-        assert_eq!(ColorMode::Always.as_str(), "always");
-        assert_eq!(ColorMode::Never.as_str(), "never");
-    }
-
-    #[tokio::test]
-    async fn auth_helper_uses_app_scoped_home_without_mutating_env() {
-        let _guard = env_guard_async().await;
-        let temp = tempfile::tempdir().unwrap();
-        let log_path = temp.path().join("auth.log");
-        let app_home = temp.path().join("app-home");
-        let caller_home = temp.path().join("caller-home");
-        let previous_home = env::var("CODEX_HOME").ok();
-        env::set_var("CODEX_HOME", &caller_home);
-        env::set_var("AUTH_HELPER_LOG", &log_path);
-
-        let script = r#"#!/usr/bin/env bash
-set -e
-echo "args:$*" >> "$AUTH_HELPER_LOG"
-echo "CODEX_HOME=${CODEX_HOME:-missing}" >> "$AUTH_HELPER_LOG"
-if [[ "$1" == "login" && "$2" == "status" ]]; then
-  echo "Logged in using ChatGPT"
-  exit 0
-fi
-echo "Not logged in" >&2
-exit 1
-"#;
-        let binary = write_fake_codex(temp.path(), script);
-        let helper = AuthSessionHelper::with_client(
-            CodexClient::builder()
-                .binary(&binary)
-                .codex_home(&app_home)
-                .build(),
-        );
-
-        let status = helper.status().await.unwrap();
-        assert!(matches!(
-            status,
-            CodexAuthStatus::LoggedIn(CodexAuthMethod::ChatGpt)
-        ));
-
-        let logged = std_fs::read_to_string(&log_path).unwrap();
-        assert!(logged.contains("args:login status"));
-        assert!(logged.contains(&format!("CODEX_HOME={}", app_home.display())));
-
-        assert_eq!(
-            env::var("CODEX_HOME").unwrap(),
-            caller_home.display().to_string()
-        );
-
-        env::remove_var("AUTH_HELPER_LOG");
-        if let Some(previous) = previous_home {
-            env::set_var("CODEX_HOME", previous);
-        } else {
-            env::remove_var("CODEX_HOME");
-        }
-    }
-
-    #[tokio::test]
-    async fn ensure_api_key_login_runs_when_logged_out() {
-        let _guard = env_guard_async().await;
-        let temp = tempfile::tempdir().unwrap();
-        let log_path = temp.path().join("login.log");
-        let state_path = temp.path().join("api-key-state");
-        let script = format!(
-            r#"#!/usr/bin/env bash
-set -e
-echo "$@" >> "{log}"
-if [[ "$1" == "login" && "$2" == "status" ]]; then
-  if [[ -f "{state}" ]]; then
-    echo "Logged in using an API key - sk-already"
-    exit 0
-  fi
-  echo "Not logged in" >&2
-  exit 1
-fi
-if [[ "$1" == "login" && "$2" == "--api-key" ]]; then
-  echo "Logged in using an API key - $3" > "{state}"
-  echo "Logged in using an API key - $3"
-  exit 0
-fi
-echo "unexpected args: $*" >&2
-exit 2
-"#,
-            log = log_path.display(),
-            state = state_path.display()
-        );
-        let binary = write_fake_codex(temp.path(), &script);
-        let helper = AuthSessionHelper::with_client(
-            CodexClient::builder()
-                .binary(&binary)
-                .codex_home(temp.path().join("app-home"))
-                .build(),
-        );
-
-        let status = helper.ensure_api_key_login("sk-test-key").await.unwrap();
-        match status {
-            CodexAuthStatus::LoggedIn(CodexAuthMethod::ApiKey { masked_key }) => {
-                assert_eq!(masked_key.as_deref(), Some("sk-test-key"));
-            }
-            other => panic!("unexpected status: {other:?}"),
-        }
-
-        let second = helper.ensure_api_key_login("sk-other").await.unwrap();
-        assert!(matches!(
-            second,
-            CodexAuthStatus::LoggedIn(CodexAuthMethod::ApiKey { .. })
-        ));
-
-        let log = std_fs::read_to_string(&log_path).unwrap();
-        assert!(log.contains("login status"));
-        assert!(log.contains("login --api-key sk-test-key"));
-        assert_eq!(
-            log.lines()
-                .filter(|line| line.contains("--api-key"))
-                .count(),
-            1
-        );
-    }
-
-    #[tokio::test]
-    async fn ensure_chatgpt_login_launches_when_needed() {
-        let _guard = env_guard_async().await;
-        let temp = tempfile::tempdir().unwrap();
-        let log_path = temp.path().join("chatgpt.log");
-        let state_path = temp.path().join("chatgpt-state");
-        let script = format!(
-            r#"#!/usr/bin/env bash
-set -e
-echo "$@" >> "{log}"
-if [[ "$1" == "login" && "$2" == "status" ]]; then
-  if [[ -f "{state}" ]]; then
-    echo "Logged in using ChatGPT"
-    exit 0
-  fi
-  echo "Not logged in" >&2
-  exit 1
-fi
-if [[ "$1" == "login" && -z "$2" ]]; then
-  echo "Logged in using ChatGPT" > "{state}"
-  echo "Logged in using ChatGPT"
-  exit 0
-fi
-echo "unknown args: $*" >&2
-exit 2
-"#,
-            log = log_path.display(),
-            state = state_path.display()
-        );
-        let binary = write_fake_codex(temp.path(), &script);
-        let helper = AuthSessionHelper::with_client(
-            CodexClient::builder()
-                .binary(&binary)
-                .codex_home(temp.path().join("app-home"))
-                .build(),
-        );
-
-        let child = helper.ensure_chatgpt_login().await.unwrap();
-        let child = child.expect("expected ChatGPT login child");
-        let output = child.wait_with_output().await.unwrap();
-        let stdout = String::from_utf8_lossy(&output.stdout);
-        assert!(stdout.contains("Logged in using ChatGPT"));
-
-        let second = helper.ensure_chatgpt_login().await.unwrap();
-        assert!(second.is_none());
-
-        let log = std_fs::read_to_string(&log_path).unwrap();
-        assert!(log.lines().any(|line| line == "login"));
-        assert_eq!(log.lines().filter(|line| line == &"login").count(), 1);
-    }
-
-    #[test]
-    fn parses_chatgpt_login() {
-        let message = "Logged in using ChatGPT";
-        let parsed = parse_login_success(message);
-        assert!(matches!(
-            parsed,
-            Some(CodexAuthStatus::LoggedIn(CodexAuthMethod::ChatGpt))
-        ));
-    }
-
-    #[test]
-    fn parses_api_key_login() {
-        let message = "Logged in using an API key - sk-1234***abcd";
-        let parsed = parse_login_success(message);
-        match parsed {
-            Some(CodexAuthStatus::LoggedIn(CodexAuthMethod::ApiKey { masked_key })) => {
-                assert_eq!(masked_key.as_deref(), Some("sk-1234***abcd"));
-            }
-            other => panic!("unexpected status: {other:?}"),
-        }
-    }
-
-    #[test]
-    fn parse_login_accepts_unknown_on_success() {
-        let message = "Authenticated";
-        assert!(parse_login_success(message).is_none());
-        let status = CodexAuthStatus::LoggedIn(CodexAuthMethod::Unknown {
-            raw: message.to_string(),
-        });
-        assert!(matches!(
-            status,
-            CodexAuthStatus::LoggedIn(CodexAuthMethod::Unknown { .. })
-        ));
-    }
-}
-
-fn default_rust_log_value() -> Option<&'static str> {
-    env::var_os(RUST_LOG_ENV)
-        .is_none()
-        .then_some(DEFAULT_RUST_LOG)
-}
-
-fn default_binary_path() -> PathBuf {
-    env::var_os(CODEX_BINARY_ENV)
-        .map(PathBuf::from)
-        .unwrap_or_else(|| PathBuf::from("codex"))
-}
-
-#[derive(Clone, Copy)]
-enum ConsoleTarget {
-    Stdout,
-    Stderr,
-}
-
-async fn tee_stream<R>(
-    mut reader: R,
-    target: ConsoleTarget,
-    mirror_console: bool,
-) -> Result<Vec<u8>, std::io::Error>
-where
-    R: AsyncRead + Unpin,
-{
-    let mut buffer = Vec::new();
-    let mut chunk = [0u8; 4096];
-    loop {
-        let n = reader.read(&mut chunk).await?;
-        if n == 0 {
-            break;
-        }
-        if mirror_console {
-            task::block_in_place(|| match target {
-                ConsoleTarget::Stdout => {
-                    let mut out = stdio::stdout();
-                    out.write_all(&chunk[..n])?;
-                    out.flush()
-                }
-                ConsoleTarget::Stderr => {
-                    let mut out = stdio::stderr();
-                    out.write_all(&chunk[..n])?;
-                    out.flush()
-                }
-            })?;
         }
-        buffer.extend_from_slice(&chunk[..n]);
     }
-    Ok(buffer)
-}
 
-fn parse_login_success(output: &str) -> Option<CodexAuthStatus> {
-    let lower = output.to_lowercase();
-    if lower.contains("chatgpt") {
-        return Some(CodexAuthStatus::LoggedIn(CodexAuthMethod::ChatGpt));
-    }
-    if lower.contains("api key") || lower.contains("apikey") {
-        // Prefer everything after the first " - " so we do not chop the key itself.
-        let masked = output
-            .split_once(" - ")
-            .map(|(_, value)| value.trim().to_string())
-            .filter(|value| !value.is_empty())
-            .or_else(|| output.split_whitespace().last().map(|v| v.to_string()));
-        return Some(CodexAuthStatus::LoggedIn(CodexAuthMethod::ApiKey {
-            masked_key: masked,
-        }));
+    /// Computes an update advisory by comparing the probed Codex version against
+    /// caller-supplied latest releases.
+    ///
+    /// The crate does not fetch release metadata itself; hosts should populate
+    /// [`CodexLatestReleases`] using their preferred update channel (npm,
+    /// Homebrew, GitHub releases) and then call this helper. Results leverage
+    /// the capability probe cache; callers with an existing
+    /// [`CodexCapabilities`] snapshot can skip the probe by invoking
+    /// [`update_advisory_from_capabilities`].
+    pub async fn update_advisory(
+        &self,
+        latest_releases: &CodexLatestReleases,
+    ) -> CodexUpdateAdvisory {
+        let capabilities = self.probe_capabilities().await;
+        update_advisory_from_capabilities(&capabilities, latest_releases)
     }
-    None
 }
 
-fn preferred_output_channel(output: &CommandOutput) -> String {
-    let stderr = String::from_utf8(output.stderr.clone()).unwrap_or_default();
-    let stdout = String::from_utf8(output.stdout.clone()).unwrap_or_default();
-    if stderr.trim().is_empty() {
-        stdout
-    } else {
-        stderr
+impl Default for CodexClient {
+    fn default() -> Self {
+        CodexClient::builder().build()
     }
 }
 
-struct CommandOutput {
-    status: ExitStatus,
-    stdout: Vec<u8>,
-    stderr: Vec<u8>,
-}
+#[cfg(test)]
+mod tests;
diff --git a/crates/codex/src/mcp.rs b/crates/codex/src/mcp.rs
index 8b94464..1329087 100644
--- a/crates/codex/src/mcp.rs
+++ b/crates/codex/src/mcp.rs
@@ -16,11 +16,6 @@
 //! requests. Runtime and pool helpers keep resume hints/metadata intact while starting,
 //! reusing, and stopping app-server instances.
 
-use std::{io, sync::Arc, time::Duration};
-
-use serde_json::{json, Value};
-use thiserror::Error;
-
 mod protocol;
 pub use protocol::*;
 
@@ -33,2471 +28,12 @@ mod app;
 pub use app::*;
 mod jsonrpc;
 
-use jsonrpc::{map_response, JsonRpcTransport};
-
-/// Errors surfaced while managing MCP/app-server transports.
-#[derive(Debug, Error)]
-pub enum McpError {
-    #[error("failed to spawn `{command}`: {source}")]
-    Spawn {
-        command: String,
-        #[source]
-        source: io::Error,
-    },
-    #[error("server did not respond to initialize: {0}")]
-    Handshake(String),
-    #[error("transport task failed: {0}")]
-    Transport(String),
-    #[error("server returned JSON-RPC error {code}: {message}")]
-    Rpc {
-        code: i64,
-        message: String,
-        data: Option<Value>,
-    },
-    #[error("server reported an error: {0}")]
-    Server(String),
-    #[error("request was cancelled")]
-    Cancelled,
-    #[error("timed out after {0:?}")]
-    Timeout(Duration),
-    #[error("serialization failed: {0}")]
-    Serialization(#[from] serde_json::Error),
-    #[error("transport channel closed unexpectedly")]
-    ChannelClosed,
-}
-
-/// Client wrapper around the stdio MCP server.
-pub struct CodexMcpServer {
-    transport: Arc<JsonRpcTransport>,
-}
-
-impl CodexMcpServer {
-    /// Launch `codex mcp-server`, issue `initialize`, and return a connected handle.
-    pub async fn start(config: StdioServerConfig, client: ClientInfo) -> Result<Self, McpError> {
-        Self::with_capabilities(config, client, Value::Object(Default::default())).await
-    }
-
-    /// Launch with explicit capabilities to send during `initialize`.
-    pub async fn with_capabilities(
-        config: StdioServerConfig,
-        client: ClientInfo,
-        capabilities: Value,
-    ) -> Result<Self, McpError> {
-        let capabilities = match capabilities {
-            Value::Null => Value::Object(Default::default()),
-            other => other,
-        };
-        let transport = JsonRpcTransport::spawn_mcp(config).await?;
-        let params = InitializeParams {
-            client,
-            protocol_version: "2024-11-05".to_string(),
-            capabilities,
-        };
-
-        transport
-            .initialize(params, transport.startup_timeout())
-            .await
-            .map_err(|err| McpError::Handshake(err.to_string()))?;
-
-        Ok(Self {
-            transport: Arc::new(transport),
-        })
-    }
-
-    /// Send a new Codex prompt via `codex/codex`.
-    pub async fn codex(&self, params: CodexCallParams) -> Result<CodexCallHandle, McpError> {
-        self.invoke_tool_call("codex", serde_json::to_value(params)?)
-            .await
-    }
-
-    /// Continue an existing conversation via `codex/codex-reply`.
-    pub async fn codex_reply(&self, params: CodexReplyParams) -> Result<CodexCallHandle, McpError> {
-        self.invoke_tool_call("codex-reply", serde_json::to_value(params)?)
-            .await
-    }
-
-    /// Send an approval decision back to the MCP server.
-    pub async fn send_approval(&self, decision: ApprovalDecision) -> Result<(), McpError> {
-        let (_, rx) = self
-            .transport
-            .request(METHOD_CODEX_APPROVAL, serde_json::to_value(decision)?)
-            .await?;
-
-        match rx.await {
-            Ok(Ok(_)) => Ok(()),
-            Ok(Err(err)) => Err(err),
-            Err(_) => Err(McpError::ChannelClosed),
-        }
-    }
-
-    /// Request cancellation for a pending call.
-    pub fn cancel(&self, request_id: RequestId) -> Result<(), McpError> {
-        self.transport.cancel(request_id)
-    }
-
-    /// Gracefully shut down the MCP server.
-    pub async fn shutdown(&self) -> Result<(), McpError> {
-        self.transport.shutdown().await
-    }
-
-    async fn invoke_tool_call(
-        &self,
-        tool_name: &str,
-        arguments: Value,
-    ) -> Result<CodexCallHandle, McpError> {
-        let events = self.transport.register_codex_listener().await;
-        let request = json!({
-            "name": tool_name,
-            "arguments": arguments,
-        });
-        let (request_id, raw_response) = self.transport.request(METHOD_CODEX, request).await?;
-        let response = map_response::<CodexCallResult>(raw_response);
-
-        Ok(CodexCallHandle {
-            request_id,
-            events,
-            response,
-        })
-    }
-}
-
-/// Client wrapper around the stdio app-server.
-pub struct CodexAppServer {
-    transport: Arc<JsonRpcTransport>,
-}
-
-impl CodexAppServer {
-    /// Launch `codex app-server`, issue `initialize`, and return a connected handle.
-    pub async fn start(config: StdioServerConfig, client: ClientInfo) -> Result<Self, McpError> {
-        Self::with_capabilities(config, client, Value::Object(Default::default())).await
-    }
-
-    /// Launch with explicit capabilities to send during `initialize`.
-    pub async fn with_capabilities(
-        config: StdioServerConfig,
-        client: ClientInfo,
-        capabilities: Value,
-    ) -> Result<Self, McpError> {
-        let capabilities = match capabilities {
-            Value::Null => Value::Object(Default::default()),
-            other => other,
-        };
-        let transport = JsonRpcTransport::spawn_app(config).await?;
-        let params = InitializeParams {
-            client,
-            protocol_version: "2024-11-05".to_string(),
-            capabilities,
-        };
-
-        transport
-            .initialize(params, transport.startup_timeout())
-            .await
-            .map_err(|err| McpError::Handshake(err.to_string()))?;
-
-        Ok(Self {
-            transport: Arc::new(transport),
-        })
-    }
-
-    /// Start a new thread (or use a provided ID) via `thread/start`.
-    pub async fn thread_start(&self, params: ThreadStartParams) -> Result<AppCallHandle, McpError> {
-        self.invoke_app_call(METHOD_THREAD_START, serde_json::to_value(params)?)
-            .await
-    }
-
-    /// Resume an existing thread via `thread/resume`.
-    pub async fn thread_resume(
-        &self,
-        params: ThreadResumeParams,
-    ) -> Result<AppCallHandle, McpError> {
-        self.invoke_app_call(METHOD_THREAD_RESUME, serde_json::to_value(params)?)
-            .await
-    }
-
-    /// Start a new turn on a thread via `turn/start`.
-    pub async fn turn_start(&self, params: TurnStartParams) -> Result<AppCallHandle, McpError> {
-        self.invoke_app_call(METHOD_TURN_START, serde_json::to_value(params)?)
-            .await
-    }
-
-    /// Interrupt an active turn via `turn/interrupt`.
-    pub async fn turn_interrupt(
-        &self,
-        params: TurnInterruptParams,
-    ) -> Result<AppCallHandle, McpError> {
-        self.invoke_app_call(METHOD_TURN_INTERRUPT, serde_json::to_value(params)?)
-            .await
-    }
-
-    /// Request cancellation for a pending call.
-    pub fn cancel(&self, request_id: RequestId) -> Result<(), McpError> {
-        self.transport.cancel(request_id)
-    }
-
-    /// Gracefully shut down the app-server.
-    pub async fn shutdown(&self) -> Result<(), McpError> {
-        self.transport.shutdown().await
-    }
-
-    async fn invoke_app_call(
-        &self,
-        method: &str,
-        params: Value,
-    ) -> Result<AppCallHandle, McpError> {
-        let events = self.transport.register_app_listener().await;
-        let (request_id, raw_response) = self.transport.request(method, params).await?;
-        let response = map_response::<Value>(raw_response);
-
-        Ok(AppCallHandle {
-            request_id,
-            events,
-            response,
-        })
-    }
-}
+mod client;
+pub use client::*;
 
 #[cfg(test)]
-mod tests {
-    use super::*;
-    use std::{
-        collections::{BTreeMap, HashMap},
-        env,
-        ffi::OsString,
-        fs,
-        os::unix::fs::PermissionsExt,
-        path::PathBuf,
-    };
-    use tokio::{
-        io::{AsyncBufReadExt, BufReader},
-        time,
-    };
-    use toml::Value as TomlValue;
-
-    fn temp_config_manager() -> (tempfile::TempDir, McpConfigManager) {
-        let dir = tempfile::tempdir().expect("tempdir");
-        let manager = McpConfigManager::from_code_home(dir.path());
-        (dir, manager)
-    }
-
-    fn stdio_definition(command: &str) -> McpServerDefinition {
-        McpServerDefinition {
-            transport: McpTransport::Stdio(StdioServerDefinition {
-                command: command.to_string(),
-                args: Vec::new(),
-                env: BTreeMap::new(),
-                timeout_ms: Some(1500),
-            }),
-            description: None,
-            tags: Vec::new(),
-            tools: None,
-        }
-    }
-
-    fn streamable_definition(url: &str, bearer_var: &str) -> McpServerDefinition {
-        McpServerDefinition {
-            transport: McpTransport::StreamableHttp(StreamableHttpDefinition {
-                url: url.to_string(),
-                headers: BTreeMap::new(),
-                bearer_env_var: Some(bearer_var.to_string()),
-                connect_timeout_ms: Some(5000),
-                request_timeout_ms: Some(5000),
-            }),
-            description: None,
-            tags: Vec::new(),
-            tools: Some(McpToolConfig {
-                enabled: vec![],
-                disabled: vec![],
-            }),
-        }
-    }
-
-    fn write_fake_mcp_server() -> (tempfile::TempDir, PathBuf) {
-        let dir = tempfile::tempdir().expect("tempdir");
-        let script_path = dir.path().join("fake-codex");
-        let script = r#"#!/usr/bin/env python3
-import json
-import sys
-import threading
-import time
-
-pending = {}
-
-def send(payload):
-    sys.stdout.write(json.dumps(payload) + "\n")
-    sys.stdout.flush()
-
-def mark_cancelled(target, reason="cancelled"):
-    if target is None:
-        return
-    state = pending.get(str(target)) or {}
-    conv_id = state.get("conversation_id")
-    pending[str(target)] = {"status": "cancelled", "conversation_id": conv_id}
-    if conv_id:
-        send({"jsonrpc": "2.0", "method": "codex/event", "params": {"type": "cancelled", "conversation_id": conv_id, "reason": reason}})
-    send({"jsonrpc": "2.0", "id": target, "error": {"code": -32800, "message": reason}})
-
-def handle_codex(req_id, params):
-    conversation_id = params.get("conversation_id") or params.get("conversationId") or f"conv-{req_id}"
-    pending[str(req_id)] = {"status": "pending", "conversation_id": conversation_id}
-    def worker():
-        time.sleep(0.05)
-        state = pending.get(str(req_id))
-        if not state or state.get("status") == "cancelled":
-            return
-        send({"jsonrpc": "2.0", "method": "codex/event", "params": {"type": "approval_required", "approval_id": f"ap-{req_id}", "kind": "exec"}})
-        time.sleep(0.05)
-        state = pending.get(str(req_id))
-        if not state or state.get("status") == "cancelled":
-            return
-        send({"jsonrpc": "2.0", "method": "codex/event", "params": {"type": "task_complete", "conversation_id": conversation_id, "result": {"ok": True}}})
-        send({"jsonrpc": "2.0", "id": req_id, "result": {"conversation_id": conversation_id, "output": {"ok": True}}})
-        pending.pop(str(req_id), None)
-    threading.Thread(target=worker, daemon=True).start()
-
-for line in sys.stdin:
-    if not line.strip():
-        continue
-    msg = json.loads(line)
-    method = msg.get("method")
-    if method == "initialize":
-        send({"jsonrpc": "2.0", "id": msg.get("id"), "result": {"ready": True}})
-    elif method == "tools/call":
-        params = msg.get("params", {})
-        tool = params.get("name")
-        args = params.get("arguments", {})
-        if tool in ["codex", "codex-reply"]:
-            handle_codex(msg.get("id"), args)
-    elif method == "$/cancelRequest":
-        target = msg.get("params", {}).get("id")
-        mark_cancelled(target, reason="client_cancel")
-    elif method == "shutdown":
-        send({"jsonrpc": "2.0", "id": msg.get("id"), "result": {"ok": True}})
-        break
-    elif method == "exit":
-        break
-"#;
-
-        fs::write(&script_path, script).expect("write script");
-        let mut perms = fs::metadata(&script_path).expect("metadata").permissions();
-        perms.set_mode(0o755);
-        fs::set_permissions(&script_path, perms).expect("chmod");
-        (dir, script_path)
-    }
-
-    fn write_fake_app_server() -> (tempfile::TempDir, PathBuf) {
-        let dir = tempfile::tempdir().expect("tempdir");
-        let script_path = dir.path().join("fake-codex-app");
-        let script = r#"#!/usr/bin/env python3
-import json
-import os
-import sys
-import threading
-import time
-
-pending = {}
-turn_lookup = {}
-
-log_path = os.environ.get("ARGV_LOG")
-if log_path:
-    with open(log_path, "w", encoding="utf-8") as fh:
-        fh.write(json.dumps(sys.argv[1:]) + "\n")
-
-def send(payload):
-    sys.stdout.write(json.dumps(payload) + "\n")
-    sys.stdout.flush()
-
-def mark_cancelled(req_id, reason="cancelled"):
-    if req_id is None:
-        return
-    state = pending.get(str(req_id)) or {}
-    thread_id = state.get("thread_id") or "thread-unknown"
-    turn_id = state.get("turn_id")
-    pending[str(req_id)] = {"status": "cancelled", "thread_id": thread_id, "turn_id": turn_id}
-    if turn_id:
-        send({"jsonrpc": "2.0", "method": "task/notification", "params": {"type": "task_complete", "thread_id": thread_id, "turn_id": turn_id, "result": {"cancelled": True, "reason": reason}}})
-    send({"jsonrpc": "2.0", "id": req_id, "error": {"code": -32800, "message": reason}})
-
-def handle_turn(req_id, params):
-    thread_id = params.get("threadId") or params.get("thread_id") or "thread-unknown"
-    turn_id = params.get("turnId") or params.get("turn_id") or f"turn-{req_id}"
-    pending[str(req_id)] = {"status": "pending", "thread_id": thread_id, "turn_id": turn_id}
-    turn_lookup[turn_id] = req_id
-
-    def worker():
-        time.sleep(0.05)
-        state = pending.get(str(req_id))
-        if not state or state.get("status") == "cancelled":
-            return
-        send({"jsonrpc": "2.0", "method": "task/notification", "params": {"type": "item", "thread_id": thread_id, "turn_id": turn_id, "item": {"message": "processing"}}})
-        time.sleep(0.05)
-        state = pending.get(str(req_id))
-        if not state or state.get("status") == "cancelled":
-            return
-        send({"jsonrpc": "2.0", "method": "task/notification", "params": {"type": "task_complete", "thread_id": thread_id, "turn_id": turn_id, "result": {"ok": True}}})
-        send({"jsonrpc": "2.0", "id": req_id, "result": {"turn_id": turn_id, "accepted": True}})
-        pending.pop(str(req_id), None)
-        turn_lookup.pop(turn_id, None)
-
-    threading.Thread(target=worker, daemon=True).start()
-
-for line in sys.stdin:
-    if not line.strip():
-        continue
-    msg = json.loads(line)
-    method = msg.get("method")
-    if method == "initialize":
-        send({"jsonrpc": "2.0", "id": msg.get("id"), "result": {"ready": True}})
-    elif method == "thread/start":
-        params = msg.get("params", {})
-        thread_id = params.get("thread_id") or f"thread-{msg.get('id')}"
-        send({"jsonrpc": "2.0", "id": msg.get("id"), "result": {"thread_id": thread_id}})
-    elif method == "thread/resume":
-        params = msg.get("params", {})
-        thread_id = params.get("threadId") or params.get("thread_id")
-        send({"jsonrpc": "2.0", "id": msg.get("id"), "result": {"thread_id": thread_id, "resumed": True}})
-    elif method == "turn/start":
-        handle_turn(msg.get("id"), msg.get("params", {}))
-    elif method == "turn/interrupt":
-        params = msg.get("params", {})
-        turn_id = params.get("turnId") or params.get("turn_id")
-        req_id = turn_lookup.get(turn_id)
-        if req_id:
-            mark_cancelled(req_id, reason="interrupted")
-            turn_lookup.pop(turn_id, None)
-            pending.pop(str(req_id), None)
-        send({"jsonrpc": "2.0", "id": msg.get("id"), "result": {"interrupted": True}})
-    elif method == "$/cancelRequest":
-        target = msg.get("params", {}).get("id")
-        mark_cancelled(target, reason="client_cancel")
-    elif method == "shutdown":
-        send({"jsonrpc": "2.0", "id": msg.get("id"), "result": {"ok": True}})
-        break
-    elif method == "exit":
-        break
-"#;
-
-        fs::write(&script_path, script).expect("write script");
-        let mut perms = fs::metadata(&script_path).expect("metadata").permissions();
-        perms.set_mode(0o755);
-        fs::set_permissions(&script_path, perms).expect("chmod");
-        (dir, script_path)
-    }
-
-    fn write_env_probe_server(var: &str) -> (tempfile::TempDir, PathBuf) {
-        let dir = tempfile::tempdir().expect("tempdir");
-        let script_path = dir.path().join("env-probe-server");
-        let script = format!(
-            r#"#!/usr/bin/env python3
-import os
-import sys
-import time
-
-sys.stdout.write(os.environ.get("{var}", "") + "\n")
-sys.stdout.flush()
-time.sleep(30)
-"#
-        );
-
-        fs::write(&script_path, script).expect("write script");
-        let mut perms = fs::metadata(&script_path).expect("metadata").permissions();
-        perms.set_mode(0o755);
-        fs::set_permissions(&script_path, perms).expect("chmod");
-        (dir, script_path)
-    }
-
-    fn test_config(binary: PathBuf) -> StdioServerConfig {
-        StdioServerConfig {
-            binary,
-            code_home: None,
-            current_dir: None,
-            env: Vec::new(),
-            app_server_analytics_default_enabled: false,
-            mirror_stdio: false,
-            startup_timeout: Duration::from_secs(5),
-        }
-    }
-
-    fn test_client() -> ClientInfo {
-        ClientInfo {
-            name: "tests".to_string(),
-            version: "0.0.0".to_string(),
-        }
-    }
-
-    async fn start_fake_mcp_server() -> (tempfile::TempDir, CodexMcpServer) {
-        let (dir, script) = write_fake_mcp_server();
-        let config = test_config(script);
-        let client = test_client();
-        let server = CodexMcpServer::start(config, client)
-            .await
-            .expect("spawn mcp server");
-        (dir, server)
-    }
-
-    async fn start_fake_app_server() -> (tempfile::TempDir, CodexAppServer) {
-        let (dir, script) = write_fake_app_server();
-        let config = test_config(script);
-        let client = test_client();
-        let server = CodexAppServer::start(config, client)
-            .await
-            .expect("spawn app server");
-        (dir, server)
-    }
-
-    #[tokio::test]
-    async fn app_server_launch_can_enable_analytics_flag() {
-        let (dir, script) = write_fake_app_server();
-        let log_path = dir.path().join("argv.json");
-
-        let mut config = test_config(script);
-        config.app_server_analytics_default_enabled = true;
-        config.env.push((
-            OsString::from("ARGV_LOG"),
-            OsString::from(log_path.as_os_str()),
-        ));
-
-        let client = test_client();
-        let server = CodexAppServer::start(config, client)
-            .await
-            .expect("spawn app server");
-
-        let mut argv_line = None;
-        for _ in 0..50 {
-            if let Ok(contents) = fs::read_to_string(&log_path) {
-                argv_line = contents.lines().next().map(str::to_string);
-                break;
-            }
-            tokio::time::sleep(Duration::from_millis(5)).await;
-        }
-
-        let argv_line = argv_line.expect("argv log should be written");
-        let argv: Vec<String> = serde_json::from_str(&argv_line).expect("argv json");
-        assert_eq!(argv, vec!["app-server", "--analytics-default-enabled"]);
-
-        server.shutdown().await.expect("shutdown server");
-    }
-
-    #[test]
-    fn add_stdio_server_injects_env_and_persists() {
-        let (dir, manager) = temp_config_manager();
-        let env_key = "MCP_STDIO_TEST_KEY";
-        env::remove_var(env_key);
-
-        let mut env_map = BTreeMap::new();
-        env_map.insert(env_key.to_string(), "secret".to_string());
-
-        let added = manager
-            .add_server(AddServerRequest {
-                name: "local".into(),
-                definition: stdio_definition("my-mcp"),
-                overwrite: false,
-                env: env_map,
-                bearer_token: None,
-            })
-            .expect("add server");
-
-        match added.definition.transport {
-            McpTransport::Stdio(def) => {
-                assert_eq!(def.command, "my-mcp");
-                assert_eq!(def.env.get(env_key), Some(&"secret".to_string()));
-            }
-            _ => panic!("expected stdio transport"),
-        }
-
-        let listed = manager.list_servers().expect("list servers");
-        assert_eq!(listed.len(), 1);
-        assert_eq!(listed[0].name, "local");
-
-        let fetched = manager.get_server("local").expect("get server");
-        match fetched.definition.transport {
-            McpTransport::Stdio(def) => {
-                assert_eq!(def.env.get(env_key), Some(&"secret".to_string()))
-            }
-            _ => panic!("expected stdio transport"),
-        }
-
-        let config_path = dir.path().join(DEFAULT_CONFIG_FILE);
-        let serialized = fs::read_to_string(config_path).expect("read config");
-        let value: TomlValue = serialized.parse().expect("parse toml");
-        let table = value.as_table().expect("table root");
-        let servers_table = table.get("mcp_servers").expect("mcp_servers");
-        let decoded: BTreeMap<String, McpServerDefinition> = servers_table
-            .clone()
-            .try_into()
-            .expect("decode mcp_servers");
-        let stored = decoded.get("local").expect("stored server");
-        match &stored.transport {
-            McpTransport::Stdio(def) => {
-                assert_eq!(def.env.get(env_key), Some(&"secret".to_string()))
-            }
-            _ => panic!("expected stdio transport"),
-        }
-
-        assert_eq!(env::var(env_key).unwrap(), "secret");
-        env::remove_var(env_key);
-    }
-
-    #[test]
-    fn add_streamable_http_sets_token_and_allows_login_logout() {
-        let (_dir, manager) = temp_config_manager();
-        let env_var = "MCP_HTTP_TOKEN_E5";
-        env::remove_var(env_var);
-
-        let mut definition = streamable_definition("https://example.test/mcp", env_var);
-        if let McpTransport::StreamableHttp(ref mut http) = definition.transport {
-            http.headers.insert("X-Test".into(), "true".into());
-        }
-
-        let _added = manager
-            .add_server(AddServerRequest {
-                name: "remote".into(),
-                definition,
-                overwrite: false,
-                env: BTreeMap::new(),
-                bearer_token: Some("token-a".into()),
-            })
-            .expect("add server");
-
-        assert_eq!(env::var(env_var).unwrap(), "token-a");
-
-        let logout = manager.logout("remote").expect("logout");
-        assert_eq!(logout.env_var.as_deref(), Some(env_var));
-        assert!(logout.cleared);
-        assert!(env::var(env_var).is_err());
-
-        let login = manager.login("remote", "token-b").expect("login");
-        assert_eq!(login.env_var.as_deref(), Some(env_var));
-        assert_eq!(env::var(env_var).unwrap(), "token-b");
-
-        env::remove_var(env_var);
-    }
-
-    #[test]
-    fn remove_server_prunes_config() {
-        let (_dir, manager) = temp_config_manager();
-
-        manager
-            .add_server(AddServerRequest {
-                name: "one".into(),
-                definition: stdio_definition("one"),
-                overwrite: false,
-                env: BTreeMap::new(),
-                bearer_token: None,
-            })
-            .expect("add first");
-
-        manager
-            .add_server(AddServerRequest {
-                name: "two".into(),
-                definition: stdio_definition("two"),
-                overwrite: false,
-                env: BTreeMap::new(),
-                bearer_token: None,
-            })
-            .expect("add second");
-
-        let removed = manager.remove_server("one").expect("remove");
-        assert!(removed.is_some());
-
-        let listed = manager.list_servers().expect("list");
-        assert_eq!(listed.len(), 1);
-        assert_eq!(listed[0].name, "two");
-
-        let config = fs::read_to_string(manager.config_path()).expect("read config");
-        let value: TomlValue = config.parse().expect("parse config");
-        let table = value.as_table().expect("table root");
-        let servers_value = table.get("mcp_servers").cloned().expect("servers");
-        let servers: BTreeMap<String, McpServerDefinition> =
-            servers_value.try_into().expect("decode servers");
-        assert!(!servers.contains_key("one"));
-        assert!(servers.contains_key("two"));
-    }
-
-    #[test]
-    fn runtime_stdio_server_resolves_env_and_tools() {
-        let (_dir, manager) = temp_config_manager();
-        let mut definition = stdio_definition("my-mcp");
-        definition.description = Some("local mcp".into());
-        definition.tags = vec!["dev".into(), "local".into()];
-        definition.tools = Some(McpToolConfig {
-            enabled: vec!["tool-a".into()],
-            disabled: vec!["tool-b".into()],
-        });
-
-        if let McpTransport::Stdio(ref mut stdio) = definition.transport {
-            stdio.args = vec!["--flag".into()];
-            stdio.env.insert("EXAMPLE".into(), "value".into());
-            stdio.timeout_ms = Some(2500);
-        }
-
-        let mut injected = BTreeMap::new();
-        injected.insert("MCP_STDIO_INJECT_E6".into(), "yes".into());
-
-        manager
-            .add_server(AddServerRequest {
-                name: "local".into(),
-                definition,
-                overwrite: false,
-                env: injected,
-                bearer_token: None,
-            })
-            .expect("add server");
-
-        let runtime = manager.runtime_server("local").expect("runtime server");
-        assert_eq!(runtime.name, "local");
-        assert_eq!(runtime.description.as_deref(), Some("local mcp"));
-        assert_eq!(runtime.tags, vec!["dev".to_string(), "local".to_string()]);
-
-        let tools = runtime.tools.as_ref().expect("tool hints");
-        assert_eq!(tools.enabled, vec!["tool-a".to_string()]);
-        assert_eq!(tools.disabled, vec!["tool-b".to_string()]);
-
-        match &runtime.transport {
-            McpRuntimeTransport::Stdio(def) => {
-                assert_eq!(def.command, "my-mcp");
-                assert_eq!(def.args, vec!["--flag".to_string()]);
-                assert_eq!(def.timeout_ms, Some(2500));
-                assert_eq!(def.env.get("EXAMPLE").map(String::as_str), Some("value"));
-                assert_eq!(
-                    def.env.get("MCP_STDIO_INJECT_E6").map(String::as_str),
-                    Some("yes")
-                );
-            }
-            other => panic!("expected stdio transport, got {other:?}"),
-        }
-
-        serde_json::to_string(&runtime).expect("serialize runtime");
-        env::remove_var("MCP_STDIO_INJECT_E6");
-    }
-
-    #[test]
-    fn runtime_http_resolves_bearer_and_sets_header() {
-        let (_dir, manager) = temp_config_manager();
-        let env_var = "MCP_HTTP_TOKEN_E6";
-        env::set_var(env_var, "token-123");
-
-        let mut definition = streamable_definition("https://example.test/mcp", env_var);
-        if let McpTransport::StreamableHttp(ref mut http) = definition.transport {
-            http.headers.insert("X-Test".into(), "true".into());
-            http.connect_timeout_ms = Some(1200);
-            http.request_timeout_ms = Some(3400);
-        }
-
-        manager
-            .add_server(AddServerRequest {
-                name: "remote".into(),
-                definition,
-                overwrite: false,
-                env: BTreeMap::new(),
-                bearer_token: None,
-            })
-            .expect("add server");
-
-        let runtime = manager.runtime_server("remote").expect("runtime server");
-        match &runtime.transport {
-            McpRuntimeTransport::StreamableHttp(def) => {
-                assert_eq!(def.url, "https://example.test/mcp");
-                assert_eq!(def.bearer_env_var.as_deref(), Some(env_var));
-                assert_eq!(def.bearer_token.as_deref(), Some("token-123"));
-                assert_eq!(def.headers.get("X-Test").map(String::as_str), Some("true"));
-                assert_eq!(
-                    def.headers.get("Authorization").map(String::as_str),
-                    Some("Bearer token-123")
-                );
-                assert_eq!(def.connect_timeout_ms, Some(1200));
-                assert_eq!(def.request_timeout_ms, Some(3400));
-            }
-            other => panic!("expected streamable_http transport, got {other:?}"),
-        }
-
-        let serialized = serde_json::to_value(&runtime).expect("serialize runtime");
-        assert!(serialized.get("transport").is_some());
-
-        env::remove_var(env_var);
-    }
-
-    #[test]
-    fn runtime_http_preserves_existing_auth_header() {
-        let (_dir, manager) = temp_config_manager();
-        let env_var = "MCP_HTTP_TOKEN_E6B";
-        env::set_var(env_var, "token-override");
-
-        let mut definition = streamable_definition("https://example.test/custom", env_var);
-        if let McpTransport::StreamableHttp(ref mut http) = definition.transport {
-            http.headers
-                .insert("Authorization".into(), "Custom 123".into());
-        }
-
-        manager
-            .add_server(AddServerRequest {
-                name: "remote-custom".into(),
-                definition,
-                overwrite: false,
-                env: BTreeMap::new(),
-                bearer_token: None,
-            })
-            .expect("add server");
-
-        let runtime = manager
-            .runtime_server("remote-custom")
-            .expect("runtime server");
-        match &runtime.transport {
-            McpRuntimeTransport::StreamableHttp(def) => {
-                assert_eq!(def.bearer_token.as_deref(), Some("token-override"));
-                assert_eq!(
-                    def.headers.get("Authorization").map(String::as_str),
-                    Some("Custom 123")
-                );
-            }
-            other => panic!("expected streamable_http transport, got {other:?}"),
-        }
-
-        env::remove_var(env_var);
-    }
-
-    #[test]
-    fn runtime_stdio_launcher_merges_env_timeout_and_tools() {
-        let base_dir = tempfile::tempdir().expect("tempdir");
-        let code_home = base_dir.path().join("code_home");
-
-        let defaults = StdioServerConfig {
-            binary: PathBuf::from("codex"),
-            code_home: Some(code_home.clone()),
-            current_dir: Some(base_dir.path().to_path_buf()),
-            env: vec![
-                (OsString::from("BASE_ONLY"), OsString::from("base")),
-                (OsString::from("OVERRIDE_ME"), OsString::from("base")),
-            ],
-            app_server_analytics_default_enabled: false,
-            mirror_stdio: true,
-            startup_timeout: Duration::from_secs(5),
-        };
-
-        let mut definition = StdioServerDefinition {
-            command: "my-mcp".into(),
-            args: vec!["--flag".into()],
-            env: BTreeMap::new(),
-            timeout_ms: Some(1500),
-        };
-        definition
-            .env
-            .insert("OVERRIDE_ME".into(), "runtime".into());
-        definition
-            .env
-            .insert("RUNTIME_ONLY".into(), "runtime-env".into());
-
-        let runtime = McpRuntimeServer {
-            name: "local".into(),
-            transport: McpRuntimeTransport::Stdio(definition),
-            description: Some("example".into()),
-            tags: vec!["dev".into()],
-            tools: Some(McpToolConfig {
-                enabled: vec!["tool-1".into()],
-                disabled: vec!["tool-2".into()],
-            }),
-        };
-
-        let launcher = runtime.into_launcher(&defaults);
-        assert_eq!(launcher.name, "local");
-        assert_eq!(launcher.description.as_deref(), Some("example"));
-        assert_eq!(launcher.tags, vec!["dev".to_string()]);
-
-        let tools = launcher.tools.clone().expect("tool hints");
-        assert_eq!(tools.enabled, vec!["tool-1".to_string()]);
-        assert_eq!(tools.disabled, vec!["tool-2".to_string()]);
-
-        match launcher.transport {
-            McpServerLauncherTransport::Stdio(launch) => {
-                assert_eq!(launch.command, PathBuf::from("my-mcp"));
-                assert_eq!(launch.args, vec!["--flag".to_string()]);
-                assert_eq!(launch.current_dir.as_ref(), defaults.current_dir.as_ref());
-                assert_eq!(launch.timeout, Duration::from_millis(1500));
-                assert!(launch.mirror_stdio);
-
-                let env_map: HashMap<OsString, OsString> = launch.env.into_iter().collect();
-                assert_eq!(
-                    env_map.get(&OsString::from("BASE_ONLY")),
-                    Some(&OsString::from("base"))
-                );
-                assert_eq!(
-                    env_map.get(&OsString::from("OVERRIDE_ME")),
-                    Some(&OsString::from("runtime"))
-                );
-                assert_eq!(
-                    env_map.get(&OsString::from("RUNTIME_ONLY")),
-                    Some(&OsString::from("runtime-env"))
-                );
-                assert_eq!(
-                    env_map.get(&OsString::from("CODEX_HOME")),
-                    Some(&code_home.as_os_str().to_os_string())
-                );
-            }
-            other => panic!("expected stdio launcher, got {other:?}"),
-        }
-    }
-
-    #[test]
-    fn streamable_http_connector_converts_timeouts_and_headers() {
-        let env_var = "MCP_HTTP_TOKEN_E7";
-        env::set_var(env_var, "token-launcher");
-
-        let mut definition = StreamableHttpDefinition {
-            url: "https://example.test/stream".into(),
-            headers: BTreeMap::new(),
-            bearer_env_var: Some(env_var.to_string()),
-            connect_timeout_ms: Some(1200),
-            request_timeout_ms: Some(3400),
-        };
-        definition.headers.insert("X-Test".into(), "true".into());
-
-        let runtime = McpRuntimeServer::from_definition(
-            "remote",
-            McpServerDefinition {
-                transport: McpTransport::StreamableHttp(definition),
-                description: None,
-                tags: vec!["http".into()],
-                tools: Some(McpToolConfig {
-                    enabled: vec!["tool-a".into()],
-                    disabled: vec![],
-                }),
-            },
-        );
-
-        let defaults = StdioServerConfig {
-            binary: PathBuf::from("codex"),
-            code_home: None,
-            current_dir: None,
-            env: Vec::new(),
-            app_server_analytics_default_enabled: false,
-            mirror_stdio: false,
-            startup_timeout: Duration::from_secs(2),
-        };
-
-        let launcher = runtime.into_launcher(&defaults);
-        match launcher.transport {
-            McpServerLauncherTransport::StreamableHttp(connector) => {
-                assert_eq!(connector.url, "https://example.test/stream");
-                assert_eq!(
-                    connector.headers.get("X-Test").map(String::as_str),
-                    Some("true")
-                );
-                assert_eq!(
-                    connector.headers.get("Authorization").map(String::as_str),
-                    Some("Bearer token-launcher")
-                );
-                assert_eq!(connector.connect_timeout, Some(Duration::from_millis(1200)));
-                assert_eq!(connector.request_timeout, Some(Duration::from_millis(3400)));
-                assert_eq!(connector.bearer_env_var.as_deref(), Some(env_var));
-                assert_eq!(connector.bearer_token.as_deref(), Some("token-launcher"));
-
-                let tools = launcher.tools.as_ref().expect("tool hints present");
-                assert_eq!(tools.enabled, vec!["tool-a".to_string()]);
-                assert!(tools.disabled.is_empty());
-            }
-            other => panic!("expected http connector, got {other:?}"),
-        }
-
-        env::remove_var(env_var);
-    }
-
-    #[tokio::test]
-    async fn codex_flow_streams_events_and_response() {
-        let (_dir, server) = start_fake_mcp_server().await;
-
-        let params = CodexCallParams {
-            prompt: "hello".into(),
-            model: None,
-            cwd: None,
-            sandbox: None,
-            approval_policy: None,
-            profile: None,
-            config: BTreeMap::new(),
-        };
-
-        let mut handle = server.codex(params).await.expect("codex call");
-
-        let first_event = time::timeout(Duration::from_secs(2), handle.events.recv())
-            .await
-            .expect("event timeout")
-            .expect("event value");
-        match first_event {
-            CodexEvent::ApprovalRequired(req) => {
-                assert!(req.approval_id.starts_with("ap-"));
-                assert_eq!(req.kind, ApprovalKind::Exec);
-            }
-            other => panic!("unexpected event: {other:?}"),
-        }
-
-        let second_event = time::timeout(Duration::from_secs(2), handle.events.recv())
-            .await
-            .expect("event timeout")
-            .expect("event value");
-        let event_conversation = match second_event {
-            CodexEvent::TaskComplete {
-                conversation_id, ..
-            } => {
-                assert!(!conversation_id.is_empty());
-                conversation_id
-            }
-            other => panic!("unexpected event: {other:?}"),
-        };
-
-        let response = time::timeout(Duration::from_secs(2), handle.response)
-            .await
-            .expect("response timeout")
-            .expect("response recv");
-        let response = response.expect("response ok");
-        assert_eq!(
-            response.conversation_id.as_deref(),
-            Some(event_conversation.as_str())
-        );
-        assert_eq!(response.output, serde_json::json!({ "ok": true }));
-
-        let _ = server.shutdown().await;
-    }
-
-    #[tokio::test]
-    async fn canceling_request_returns_cancelled_error() {
-        let (_dir, server) = start_fake_mcp_server().await;
-
-        let params = CodexCallParams {
-            prompt: "cancel me".into(),
-            model: None,
-            cwd: None,
-            sandbox: None,
-            approval_policy: None,
-            profile: None,
-            config: BTreeMap::new(),
-        };
-
-        let mut handle = server.codex(params).await.expect("codex call");
-        server.cancel(handle.request_id).expect("cancel send");
-
-        let expected_conversation = format!("conv-{}", handle.request_id);
-        let cancel_event = time::timeout(Duration::from_secs(2), handle.events.recv())
-            .await
-            .expect("event timeout")
-            .expect("cancel notification");
-        match cancel_event {
-            CodexEvent::Cancelled {
-                conversation_id,
-                reason,
-            } => {
-                assert_eq!(
-                    conversation_id.as_deref(),
-                    Some(expected_conversation.as_str())
-                );
-                assert_eq!(reason.as_deref(), Some("client_cancel"));
-            }
-            other => panic!("expected cancellation event, got {other:?}"),
-        }
-
-        let response = time::timeout(Duration::from_secs(2), handle.response)
-            .await
-            .expect("response timeout")
-            .expect("recv");
-        assert!(matches!(response, Err(McpError::Cancelled)));
-
-        let _ = server.shutdown().await;
-    }
-
-    #[tokio::test]
-    async fn codex_reply_streams_follow_up_notifications() {
-        let (_dir, server) = start_fake_mcp_server().await;
-
-        let params = CodexCallParams {
-            prompt: "hello".into(),
-            model: None,
-            cwd: None,
-            sandbox: None,
-            approval_policy: None,
-            profile: None,
-            config: BTreeMap::new(),
-        };
-        let first = server.codex(params).await.expect("start codex");
-        let first_response = time::timeout(Duration::from_secs(2), first.response)
-            .await
-            .expect("response timeout")
-            .expect("recv")
-            .expect("ok");
-        let conversation_id = first_response.conversation_id.expect("conversation id set");
-        assert!(!conversation_id.is_empty());
-
-        let reply_params = CodexReplyParams {
-            conversation_id: conversation_id.clone(),
-            prompt: "follow up".into(),
-        };
-        let mut reply = server.codex_reply(reply_params).await.expect("codex reply");
-
-        let expected_approval = format!("ap-{}", reply.request_id);
-        let approval = time::timeout(Duration::from_secs(2), reply.events.recv())
-            .await
-            .expect("event timeout")
-            .expect("approval");
-        match approval {
-            CodexEvent::ApprovalRequired(req) => {
-                assert_eq!(req.approval_id, expected_approval);
-                assert_eq!(req.kind, ApprovalKind::Exec);
-            }
-            other => panic!("unexpected event: {other:?}"),
-        }
-
-        let complete = time::timeout(Duration::from_secs(2), reply.events.recv())
-            .await
-            .expect("event timeout")
-            .expect("task completion");
-        match complete {
-            CodexEvent::TaskComplete {
-                conversation_id: event_conv,
-                ..
-            } => assert_eq!(event_conv, conversation_id),
-            other => panic!("unexpected event: {other:?}"),
-        }
-
-        let reply_response = time::timeout(Duration::from_secs(2), reply.response)
-            .await
-            .expect("response timeout")
-            .expect("recv")
-            .expect("ok");
-        assert_eq!(
-            reply_response.conversation_id.as_deref(),
-            Some(conversation_id.as_str())
-        );
-        assert_eq!(reply_response.output, serde_json::json!({ "ok": true }));
-
-        let _ = server.shutdown().await;
-    }
-
-    #[tokio::test]
-    async fn app_flow_streams_notifications_and_response() {
-        let (_dir, server) = start_fake_app_server().await;
-
-        let thread_params = ThreadStartParams {
-            thread_id: None,
-            metadata: Value::Null,
-        };
-        let thread_handle = server
-            .thread_start(thread_params)
-            .await
-            .expect("thread start");
-        let thread_response = time::timeout(Duration::from_secs(2), thread_handle.response)
-            .await
-            .expect("thread response timeout")
-            .expect("thread response recv")
-            .expect("thread response ok");
-        let thread_id = thread_response
-            .get("thread_id")
-            .and_then(Value::as_str)
-            .unwrap_or_default()
-            .to_string();
-        assert!(!thread_id.is_empty());
-
-        let params = TurnStartParams {
-            thread_id: thread_id.clone(),
-            input: vec![TurnInput {
-                kind: "text".to_string(),
-                text: Some("hi".to_string()),
-            }],
-            model: None,
-            config: BTreeMap::new(),
-        };
-        let mut handle = server.turn_start(params).await.expect("turn start");
-
-        let first_event = time::timeout(Duration::from_secs(2), handle.events.recv())
-            .await
-            .expect("event timeout")
-            .expect("event value");
-        let turn_id = match first_event {
-            AppNotification::Item {
-                thread_id: tid,
-                turn_id: Some(turn),
-                item,
-            } => {
-                assert_eq!(tid, thread_id);
-                assert!(item.get("message").is_some());
-                turn
-            }
-            other => panic!("unexpected event: {other:?}"),
-        };
-
-        let second_event = time::timeout(Duration::from_secs(2), handle.events.recv())
-            .await
-            .expect("event timeout")
-            .expect("event value");
-        match second_event {
-            AppNotification::TaskComplete {
-                thread_id: tid,
-                turn_id: event_turn,
-                result,
-            } => {
-                assert_eq!(tid, thread_id);
-                assert_eq!(event_turn.as_deref(), Some(turn_id.as_str()));
-                assert_eq!(result, serde_json::json!({ "ok": true }));
-            }
-            other => panic!("unexpected event: {other:?}"),
-        }
-
-        let response = time::timeout(Duration::from_secs(2), handle.response)
-            .await
-            .expect("response timeout")
-            .expect("response recv");
-        let response = response.expect("response ok");
-        assert_eq!(
-            response
-                .get("turn_id")
-                .and_then(Value::as_str)
-                .unwrap_or_default(),
-            turn_id
-        );
-
-        let _ = server.shutdown().await;
-    }
-
-    #[tokio::test]
-    async fn canceling_app_request_returns_cancelled_error() {
-        let (_dir, server) = start_fake_app_server().await;
-
-        let thread_params = ThreadStartParams {
-            thread_id: None,
-            metadata: Value::Null,
-        };
-        let thread_handle = server
-            .thread_start(thread_params)
-            .await
-            .expect("thread start");
-        let thread_response = time::timeout(Duration::from_secs(2), thread_handle.response)
-            .await
-            .expect("thread response timeout")
-            .expect("thread response recv")
-            .expect("thread response ok");
-        let thread_id = thread_response
-            .get("thread_id")
-            .and_then(Value::as_str)
-            .unwrap_or_default()
-            .to_string();
-
-        let params = TurnStartParams {
-            thread_id: thread_id.clone(),
-            input: vec![TurnInput {
-                kind: "text".to_string(),
-                text: Some("cancel me".to_string()),
-            }],
-            model: None,
-            config: BTreeMap::new(),
-        };
-
-        let mut handle = server.turn_start(params).await.expect("turn start");
-        server.cancel(handle.request_id).expect("send cancel");
-
-        let cancel_event = time::timeout(Duration::from_secs(2), handle.events.recv())
-            .await
-            .expect("event timeout")
-            .expect("cancel event");
-        match cancel_event {
-            AppNotification::TaskComplete {
-                thread_id: tid,
-                turn_id,
-                result,
-            } => {
-                assert_eq!(tid, thread_id);
-                assert!(turn_id.is_some());
-                assert_eq!(result.get("cancelled"), Some(&Value::Bool(true)));
-                assert_eq!(
-                    result.get("reason"),
-                    Some(&Value::String("client_cancel".into()))
-                );
-            }
-            other => panic!("unexpected cancellation notification: {other:?}"),
-        }
-
-        let response = time::timeout(Duration::from_secs(2), handle.response)
-            .await
-            .expect("response timeout")
-            .expect("recv");
-        assert!(matches!(response, Err(McpError::Cancelled)));
-
-        let _ = server.shutdown().await;
-    }
-
-    #[tokio::test]
-    async fn thread_resume_allows_follow_up_turns() {
-        let (_dir, server) = start_fake_app_server().await;
-
-        let thread_params = ThreadStartParams {
-            thread_id: None,
-            metadata: Value::Null,
-        };
-        let thread_handle = server
-            .thread_start(thread_params)
-            .await
-            .expect("thread start");
-        let thread_response = time::timeout(Duration::from_secs(2), thread_handle.response)
-            .await
-            .expect("thread response timeout")
-            .expect("recv")
-            .expect("ok");
-        let thread_id = thread_response
-            .get("thread_id")
-            .and_then(Value::as_str)
-            .unwrap_or_default()
-            .to_string();
-
-        let resume_params = ThreadResumeParams {
-            thread_id: thread_id.clone(),
-        };
-        let resume_handle = server
-            .thread_resume(resume_params)
-            .await
-            .expect("thread resume");
-        let resume_response = time::timeout(Duration::from_secs(2), resume_handle.response)
-            .await
-            .expect("resume response timeout")
-            .expect("recv")
-            .expect("ok");
-        assert_eq!(
-            resume_response
-                .get("thread_id")
-                .and_then(Value::as_str)
-                .unwrap_or_default(),
-            thread_id
-        );
-        assert!(resume_response
-            .get("resumed")
-            .and_then(Value::as_bool)
-            .unwrap_or(false));
-
-        let params = TurnStartParams {
-            thread_id: thread_id.clone(),
-            input: vec![TurnInput {
-                kind: "text".to_string(),
-                text: Some("resume flow".to_string()),
-            }],
-            model: None,
-            config: BTreeMap::new(),
-        };
-        let mut turn = server.turn_start(params).await.expect("turn start");
-
-        let item = time::timeout(Duration::from_secs(2), turn.events.recv())
-            .await
-            .expect("event timeout")
-            .expect("item event");
-        let turn_id = match item {
-            AppNotification::Item {
-                thread_id: tid,
-                turn_id: Some(turn_id),
-                ..
-            } => {
-                assert_eq!(tid, thread_id);
-                turn_id
-            }
-            other => panic!("unexpected event: {other:?}"),
-        };
-
-        let complete = time::timeout(Duration::from_secs(2), turn.events.recv())
-            .await
-            .expect("event timeout")
-            .expect("completion event");
-        match complete {
-            AppNotification::TaskComplete {
-                thread_id: tid,
-                turn_id: event_turn,
-                result,
-            } => {
-                assert_eq!(tid, thread_id);
-                assert_eq!(event_turn.as_deref(), Some(turn_id.as_str()));
-                assert_eq!(result, serde_json::json!({ "ok": true }));
-            }
-            other => panic!("unexpected event: {other:?}"),
-        }
-
-        let turn_response = time::timeout(Duration::from_secs(2), turn.response)
-            .await
-            .expect("response timeout")
-            .expect("recv")
-            .expect("ok");
-        assert_eq!(
-            turn_response
-                .get("turn_id")
-                .and_then(Value::as_str)
-                .unwrap_or_default(),
-            turn_id
-        );
-
-        let _ = server.shutdown().await;
-    }
-
-    #[tokio::test]
-    async fn turn_interrupt_sends_cancel_notification() {
-        let (_dir, server) = start_fake_app_server().await;
-
-        let thread_params = ThreadStartParams {
-            thread_id: None,
-            metadata: Value::Null,
-        };
-        let thread_handle = server
-            .thread_start(thread_params)
-            .await
-            .expect("thread start");
-        let thread_response = time::timeout(Duration::from_secs(2), thread_handle.response)
-            .await
-            .expect("thread response timeout")
-            .expect("recv")
-            .expect("ok");
-        let thread_id = thread_response
-            .get("thread_id")
-            .and_then(Value::as_str)
-            .unwrap_or_default()
-            .to_string();
-
-        let params = TurnStartParams {
-            thread_id: thread_id.clone(),
-            input: vec![TurnInput {
-                kind: "text".to_string(),
-                text: Some("please interrupt".to_string()),
-            }],
-            model: None,
-            config: BTreeMap::new(),
-        };
-        let mut turn = server.turn_start(params).await.expect("turn start");
-
-        let first_event = time::timeout(Duration::from_secs(2), turn.events.recv())
-            .await
-            .expect("event timeout")
-            .expect("event value");
-        let turn_id = match first_event {
-            AppNotification::Item {
-                thread_id: tid,
-                turn_id: Some(turn),
-                ..
-            } => {
-                assert_eq!(tid, thread_id);
-                turn
-            }
-            other => panic!("unexpected event: {other:?}"),
-        };
-
-        let interrupt = server
-            .turn_interrupt(TurnInterruptParams {
-                thread_id: Some(thread_id.clone()),
-                turn_id: turn_id.clone(),
-            })
-            .await
-            .expect("send interrupt");
-
-        let cancel_event = time::timeout(Duration::from_secs(2), turn.events.recv())
-            .await
-            .expect("event timeout")
-            .expect("cancel event");
-        match cancel_event {
-            AppNotification::TaskComplete {
-                thread_id: tid,
-                turn_id: event_turn,
-                result,
-            } => {
-                assert_eq!(tid, thread_id);
-                assert_eq!(event_turn.as_deref(), Some(turn_id.as_str()));
-                assert_eq!(result.get("cancelled"), Some(&Value::Bool(true)));
-                assert_eq!(
-                    result.get("reason"),
-                    Some(&Value::String("interrupted".into()))
-                );
-            }
-            other => panic!("unexpected cancel notification: {other:?}"),
-        }
-
-        let turn_response = time::timeout(Duration::from_secs(2), turn.response)
-            .await
-            .expect("response timeout")
-            .expect("recv");
-        assert!(matches!(turn_response, Err(McpError::Cancelled)));
-
-        let interrupt_response = time::timeout(Duration::from_secs(2), interrupt.response)
-            .await
-            .expect("interrupt response timeout")
-            .expect("recv")
-            .expect("ok");
-        assert!(interrupt_response
-            .get("interrupted")
-            .and_then(Value::as_bool)
-            .unwrap_or(false));
-
-        let _ = server.shutdown().await;
-    }
-
-    #[test]
-    fn runtime_api_lists_launchers_without_changing_config() {
-        let (dir, manager) = temp_config_manager();
-        let stdio_env_key = "MCP_RUNTIME_API_STDIO_ENV";
-        let request_env_key = "MCP_RUNTIME_API_REQUEST_ENV";
-        let http_env_key = "MCP_RUNTIME_API_HTTP_ENV";
-        env::set_var(http_env_key, "token-api");
-
-        let mut stdio = stdio_definition("runtime-api-stdio");
-        stdio.description = Some("stdio runtime".into());
-        stdio.tags = vec!["local".into()];
-        stdio.tools = Some(McpToolConfig {
-            enabled: vec!["fmt".into()],
-            disabled: vec!["lint".into()],
-        });
-        if let McpTransport::Stdio(ref mut stdio_def) = stdio.transport {
-            stdio_def.args.push("--flag".into());
-            stdio_def
-                .env
-                .insert(stdio_env_key.into(), "runtime-env".into());
-            stdio_def.timeout_ms = Some(2400);
-        }
-
-        let mut env_map = BTreeMap::new();
-        env_map.insert(request_env_key.to_string(), "injected".to_string());
-
-        manager
-            .add_server(AddServerRequest {
-                name: "local-api".into(),
-                definition: stdio,
-                overwrite: false,
-                env: env_map,
-                bearer_token: None,
-            })
-            .expect("add stdio server");
-
-        let mut http = streamable_definition("https://example.test/runtime-api", http_env_key);
-        http.description = Some("http runtime".into());
-        http.tags = vec!["remote".into()];
-        http.tools = Some(McpToolConfig {
-            enabled: vec!["alpha".into()],
-            disabled: vec!["beta".into()],
-        });
-        if let McpTransport::StreamableHttp(ref mut http_def) = http.transport {
-            http_def.headers.insert("X-Req".into(), "true".into());
-            http_def.request_timeout_ms = Some(2200);
-        }
-
-        manager
-            .add_server(AddServerRequest {
-                name: "remote-api".into(),
-                definition: http,
-                overwrite: false,
-                env: BTreeMap::new(),
-                bearer_token: None,
-            })
-            .expect("add http server");
-
-        let before = fs::read_to_string(manager.config_path()).expect("read config before");
-        let cwd = dir.path().join("cwd");
-
-        let defaults = StdioServerConfig {
-            binary: PathBuf::from("codex"),
-            code_home: Some(dir.path().to_path_buf()),
-            current_dir: Some(cwd.clone()),
-            env: vec![
-                (OsString::from("DEFAULT_ONLY"), OsString::from("default")),
-                (
-                    OsString::from(request_env_key),
-                    OsString::from("base-default"),
-                ),
-            ],
-            app_server_analytics_default_enabled: false,
-            mirror_stdio: true,
-            startup_timeout: Duration::from_secs(3),
-        };
-
-        let api = McpRuntimeApi::from_config(&manager, &defaults).expect("runtime api");
-
-        let available = api.available();
-        assert_eq!(available.len(), 2);
-
-        let stdio_summary = available
-            .iter()
-            .find(|entry| entry.name == "local-api")
-            .expect("stdio summary");
-        assert_eq!(stdio_summary.transport, McpRuntimeSummaryTransport::Stdio);
-        let stdio_tools = stdio_summary.tools.as_ref().expect("stdio tools");
-        assert_eq!(stdio_tools.enabled, vec!["fmt".to_string()]);
-        assert_eq!(stdio_tools.disabled, vec!["lint".to_string()]);
-
-        let stdio_launcher = api.stdio_launcher("local-api").expect("stdio launcher");
-        assert_eq!(stdio_launcher.args, vec!["--flag".to_string()]);
-        assert_eq!(stdio_launcher.timeout, Duration::from_millis(2400));
-        assert!(stdio_launcher.mirror_stdio);
-        assert_eq!(stdio_launcher.current_dir.as_deref(), Some(cwd.as_path()));
-
-        let env_map: HashMap<OsString, OsString> = stdio_launcher.env.into_iter().collect();
-        assert_eq!(
-            env_map.get(&OsString::from("CODEX_HOME")),
-            Some(&dir.path().as_os_str().to_os_string())
-        );
-        assert_eq!(
-            env_map.get(&OsString::from("DEFAULT_ONLY")),
-            Some(&OsString::from("default"))
-        );
-        assert_eq!(
-            env_map.get(&OsString::from(request_env_key)),
-            Some(&OsString::from("injected"))
-        );
-        assert_eq!(
-            env_map.get(&OsString::from(stdio_env_key)),
-            Some(&OsString::from("runtime-env"))
-        );
-
-        let http_connector = api.http_connector("remote-api").expect("http connector");
-        assert_eq!(http_connector.bearer_token.as_deref(), Some("token-api"));
-        assert_eq!(
-            http_connector
-                .headers
-                .get("Authorization")
-                .map(String::as_str),
-            Some("Bearer token-api")
-        );
-        assert_eq!(
-            http_connector.headers.get("X-Req").map(String::as_str),
-            Some("true")
-        );
-        assert_eq!(
-            http_connector.request_timeout,
-            Some(Duration::from_millis(2200))
-        );
-
-        let http_tools = available
-            .iter()
-            .find(|entry| entry.name == "remote-api")
-            .and_then(|entry| entry.tools.as_ref())
-            .expect("http tools");
-        assert_eq!(http_tools.enabled, vec!["alpha".to_string()]);
-        assert_eq!(http_tools.disabled, vec!["beta".to_string()]);
-
-        match api.stdio_launcher("remote-api") {
-            Err(McpRuntimeError::UnsupportedTransport {
-                name,
-                expected,
-                actual,
-            }) => {
-                assert_eq!(name, "remote-api");
-                assert_eq!(expected, "stdio");
-                assert_eq!(actual, "streamable_http");
-            }
-            other => panic!("unexpected result: {other:?}"),
-        }
-
-        match api.http_connector("local-api") {
-            Err(McpRuntimeError::UnsupportedTransport {
-                name,
-                expected,
-                actual,
-            }) => {
-                assert_eq!(name, "local-api");
-                assert_eq!(expected, "streamable_http");
-                assert_eq!(actual, "stdio");
-            }
-            other => panic!("unexpected http result: {other:?}"),
-        }
-
-        let after = fs::read_to_string(manager.config_path()).expect("read config after");
-        assert_eq!(before, after);
-
-        env::remove_var(http_env_key);
-        env::remove_var(request_env_key);
-    }
-
-    #[test]
-    fn runtime_api_prepare_http_is_non_destructive() {
-        let (dir, manager) = temp_config_manager();
-        let env_var = "MCP_RUNTIME_API_PREPARE";
-        env::set_var(env_var, "prepare-token");
-
-        let mut http = streamable_definition("https://example.test/prepare", env_var);
-        http.tags = vec!["prepare".into()];
-        http.tools = Some(McpToolConfig {
-            enabled: vec!["delta".into()],
-            disabled: vec![],
-        });
-
-        manager
-            .add_server(AddServerRequest {
-                name: "prepare-http".into(),
-                definition: http,
-                overwrite: false,
-                env: BTreeMap::new(),
-                bearer_token: None,
-            })
-            .expect("add http server");
-
-        let before = fs::read_to_string(manager.config_path()).expect("read config before");
-
-        let defaults = StdioServerConfig {
-            binary: PathBuf::from("codex"),
-            code_home: Some(dir.path().to_path_buf()),
-            current_dir: None,
-            env: Vec::new(),
-            app_server_analytics_default_enabled: false,
-            mirror_stdio: false,
-            startup_timeout: Duration::from_secs(2),
-        };
-
-        let api = McpRuntimeApi::from_config(&manager, &defaults).expect("runtime api");
-        let handle = api.prepare("prepare-http").expect("prepare http");
-
-        match handle {
-            McpRuntimeHandle::StreamableHttp(http_handle) => {
-                assert_eq!(http_handle.name, "prepare-http");
-                assert_eq!(
-                    http_handle.connector.bearer_token.as_deref(),
-                    Some("prepare-token")
-                );
-                assert_eq!(
-                    http_handle
-                        .connector
-                        .headers
-                        .get("Authorization")
-                        .map(String::as_str),
-                    Some("Bearer prepare-token")
-                );
-                let tools = http_handle.tools.expect("tool hints");
-                assert_eq!(tools.enabled, vec!["delta".to_string()]);
-            }
-            other => panic!("expected http handle, got {other:?}"),
-        }
-
-        let after = fs::read_to_string(manager.config_path()).expect("read config after");
-        assert_eq!(before, after);
-
-        env::remove_var(env_var);
-    }
-
-    #[test]
-    fn app_runtime_api_lists_and_merges_without_writes() {
-        let (dir, manager) = temp_config_manager();
-
-        let alpha_home = dir.path().join("app-home-a");
-        let alpha_cwd = dir.path().join("app-cwd-a");
-        let mut alpha_env = BTreeMap::new();
-        alpha_env.insert("APP_RUNTIME_ENV".into(), "alpha".into());
-        alpha_env.insert("OVERRIDE_ME".into(), "runtime".into());
-
-        manager
-            .add_app_runtime(AddAppRuntimeRequest {
-                name: "alpha".into(),
-                definition: AppRuntimeDefinition {
-                    description: Some("local app".into()),
-                    tags: vec!["local".into()],
-                    env: alpha_env,
-                    code_home: Some(alpha_home.clone()),
-                    current_dir: Some(alpha_cwd.clone()),
-                    mirror_stdio: Some(true),
-                    startup_timeout_ms: Some(4200),
-                    binary: Some(PathBuf::from("/bin/app-alpha")),
-                    metadata: serde_json::json!({"thread": "t-alpha"}),
-                },
-                overwrite: false,
-            })
-            .expect("add alpha app runtime");
-
-        let mut beta_env = BTreeMap::new();
-        beta_env.insert("APP_RUNTIME_ENV".into(), "beta".into());
-
-        manager
-            .add_app_runtime(AddAppRuntimeRequest {
-                name: "beta".into(),
-                definition: AppRuntimeDefinition {
-                    description: None,
-                    tags: vec!["default".into()],
-                    env: beta_env,
-                    code_home: None,
-                    current_dir: None,
-                    mirror_stdio: None,
-                    startup_timeout_ms: None,
-                    binary: None,
-                    metadata: serde_json::json!({"resume": true}),
-                },
-                overwrite: false,
-            })
-            .expect("add beta app runtime");
-
-        let before = fs::read_to_string(manager.config_path()).expect("read config before");
-
-        let default_home = dir.path().join("default-home");
-        let default_cwd = dir.path().join("default-cwd");
-        let defaults = StdioServerConfig {
-            binary: PathBuf::from("codex"),
-            code_home: Some(default_home.clone()),
-            current_dir: Some(default_cwd.clone()),
-            env: vec![
-                (OsString::from("DEFAULT_ONLY"), OsString::from("base")),
-                (OsString::from("OVERRIDE_ME"), OsString::from("base")),
-            ],
-            app_server_analytics_default_enabled: false,
-            mirror_stdio: false,
-            startup_timeout: Duration::from_secs(3),
-        };
-
-        let api = AppRuntimeApi::from_config(&manager, &defaults).expect("app runtime api");
-
-        let available = api.available();
-        assert_eq!(available.len(), 2);
-
-        let alpha_summary = available
-            .iter()
-            .find(|entry| entry.name == "alpha")
-            .expect("alpha summary");
-        assert_eq!(alpha_summary.description.as_deref(), Some("local app"));
-        assert_eq!(alpha_summary.tags, vec!["local".to_string()]);
-        assert_eq!(
-            alpha_summary.metadata,
-            serde_json::json!({"thread": "t-alpha"})
-        );
-
-        let alpha = api.prepare("alpha").expect("prepare alpha");
-        assert_eq!(alpha.name, "alpha");
-        assert_eq!(alpha.metadata, serde_json::json!({"thread": "t-alpha"}));
-        assert_eq!(alpha.config.binary, PathBuf::from("/bin/app-alpha"));
-        assert_eq!(
-            alpha.config.code_home.as_deref(),
-            Some(alpha_home.as_path())
-        );
-        assert_eq!(
-            alpha.config.current_dir.as_deref(),
-            Some(alpha_cwd.as_path())
-        );
-        assert!(alpha.config.mirror_stdio);
-        assert_eq!(alpha.config.startup_timeout, Duration::from_millis(4200));
-
-        let alpha_env: HashMap<OsString, OsString> = alpha.config.env.into_iter().collect();
-        assert_eq!(
-            alpha_env.get(&OsString::from("CODEX_HOME")),
-            Some(&alpha_home.as_os_str().to_os_string())
-        );
-        assert_eq!(
-            alpha_env.get(&OsString::from("DEFAULT_ONLY")),
-            Some(&OsString::from("base"))
-        );
-        assert_eq!(
-            alpha_env.get(&OsString::from("OVERRIDE_ME")),
-            Some(&OsString::from("runtime"))
-        );
-        assert_eq!(
-            alpha_env.get(&OsString::from("APP_RUNTIME_ENV")),
-            Some(&OsString::from("alpha"))
-        );
-
-        let beta = api.stdio_config("beta").expect("beta config");
-        assert_eq!(beta.binary, PathBuf::from("codex"));
-        assert_eq!(beta.code_home.as_deref(), Some(default_home.as_path()));
-        assert_eq!(beta.current_dir.as_deref(), Some(default_cwd.as_path()));
-        assert!(!beta.mirror_stdio);
-        assert_eq!(beta.startup_timeout, Duration::from_secs(3));
-
-        let beta_env: HashMap<OsString, OsString> = beta.env.into_iter().collect();
-        assert_eq!(
-            beta_env.get(&OsString::from("CODEX_HOME")),
-            Some(&default_home.as_os_str().to_os_string())
-        );
-        assert_eq!(
-            beta_env.get(&OsString::from("DEFAULT_ONLY")),
-            Some(&OsString::from("base"))
-        );
-        assert_eq!(
-            beta_env.get(&OsString::from("OVERRIDE_ME")),
-            Some(&OsString::from("base"))
-        );
-        assert_eq!(
-            beta_env.get(&OsString::from("APP_RUNTIME_ENV")),
-            Some(&OsString::from("beta"))
-        );
-
-        let beta_summary = available
-            .iter()
-            .find(|entry| entry.name == "beta")
-            .expect("beta summary");
-        assert_eq!(beta_summary.metadata, serde_json::json!({"resume": true}));
-
-        let after = fs::read_to_string(manager.config_path()).expect("read config after");
-        assert_eq!(before, after);
-    }
-
-    #[tokio::test]
-    async fn app_runtime_lifecycle_starts_and_stops_without_mutation() {
-        let (config_dir, manager) = temp_config_manager();
-        let (_server_dir, server_path) = write_fake_app_server();
-        let code_home = config_dir.path().join("app-lifecycle-home");
-
-        let mut env_map = BTreeMap::new();
-        env_map.insert("APP_RUNTIME_LIFECYCLE".into(), "runtime-env".into());
-
-        let metadata = serde_json::json!({"resume_thread": "thread-lifecycle"});
-        manager
-            .add_app_runtime(AddAppRuntimeRequest {
-                name: "lifecycle".into(),
-                definition: AppRuntimeDefinition {
-                    description: Some("app lifecycle".into()),
-                    tags: vec!["app".into()],
-                    env: env_map,
-                    code_home: None,
-                    current_dir: None,
-                    mirror_stdio: Some(true),
-                    startup_timeout_ms: Some(1500),
-                    binary: None,
-                    metadata: metadata.clone(),
-                },
-                overwrite: false,
-            })
-            .expect("add app runtime");
-
-        let defaults = StdioServerConfig {
-            binary: server_path.clone(),
-            code_home: Some(code_home.clone()),
-            current_dir: None,
-            env: vec![(
-                OsString::from("APP_RUNTIME_LIFECYCLE"),
-                OsString::from("default"),
-            )],
-            app_server_analytics_default_enabled: false,
-            mirror_stdio: false,
-            startup_timeout: Duration::from_secs(3),
-        };
-
-        let before = fs::read_to_string(manager.config_path()).expect("read config before");
-        let api = AppRuntimeApi::from_config(&manager, &defaults).expect("build api");
-        let client = test_client();
-
-        let runtime = api
-            .start("lifecycle", client.clone())
-            .await
-            .expect("start runtime");
-        assert_eq!(runtime.name, "lifecycle");
-        assert_eq!(runtime.metadata, metadata);
-
-        let env_values: HashMap<OsString, OsString> = runtime.config.env.iter().cloned().collect();
-        assert_eq!(
-            env_values.get(&OsString::from("CODEX_HOME")),
-            Some(&code_home.as_os_str().to_os_string())
-        );
-        assert_eq!(
-            env_values.get(&OsString::from("APP_RUNTIME_LIFECYCLE")),
-            Some(&OsString::from("runtime-env"))
-        );
-
-        let thread = runtime
-            .server
-            .thread_start(ThreadStartParams {
-                thread_id: None,
-                metadata: serde_json::json!({"from": "lifecycle"}),
-            })
-            .await
-            .expect("thread start");
-        let thread_response = time::timeout(Duration::from_secs(2), thread.response)
-            .await
-            .expect("thread response timeout")
-            .expect("recv thread response")
-            .expect("thread response ok");
-        let thread_id = thread_response
-            .get("thread_id")
-            .and_then(Value::as_str)
-            .unwrap_or_default()
-            .to_string();
-        assert!(!thread_id.is_empty());
-
-        runtime.stop().await.expect("shutdown runtime");
-
-        let after = fs::read_to_string(manager.config_path()).expect("read config after");
-        assert_eq!(before, after);
-
-        let prepared = api.prepare("lifecycle").expect("prepare after stop");
-        assert_eq!(prepared.metadata, metadata);
-    }
-
-    #[tokio::test]
-    async fn app_runtime_api_not_found_errors() {
-        let api = AppRuntimeApi::new(Vec::new());
-        match api.prepare("missing") {
-            Err(AppRuntimeError::NotFound(name)) => assert_eq!(name, "missing"),
-            other => panic!("unexpected result: {other:?}"),
-        }
-
-        let client = test_client();
-        match api.start("missing", client).await {
-            Err(AppRuntimeError::NotFound(name)) => assert_eq!(name, "missing"),
-            other => panic!("unexpected start result: {other:?}"),
-        }
-    }
-
-    #[tokio::test]
-    async fn app_runtime_pool_api_reuses_and_restarts_stdio() {
-        let (config_dir, manager) = temp_config_manager();
-        let (_server_dir, server_path) = write_fake_app_server();
-        let code_home = config_dir.path().join("app-pool-home");
-
-        let mut env_map = BTreeMap::new();
-        env_map.insert("APP_POOL_ENV".into(), "runtime".into());
-
-        let metadata = serde_json::json!({"resume_thread": "thread-pool"});
-        manager
-            .add_app_runtime(AddAppRuntimeRequest {
-                name: "pooled".into(),
-                definition: AppRuntimeDefinition {
-                    description: Some("pooled app".into()),
-                    tags: vec!["pool".into()],
-                    env: env_map,
-                    code_home: None,
-                    current_dir: None,
-                    mirror_stdio: Some(true),
-                    startup_timeout_ms: Some(2000),
-                    binary: None,
-                    metadata: metadata.clone(),
-                },
-                overwrite: false,
-            })
-            .expect("add app runtime");
-
-        let defaults = StdioServerConfig {
-            binary: server_path.clone(),
-            code_home: Some(code_home.clone()),
-            current_dir: None,
-            env: vec![
-                (OsString::from("APP_POOL_ENV"), OsString::from("default")),
-                (OsString::from("POOL_ONLY"), OsString::from("base")),
-            ],
-            app_server_analytics_default_enabled: false,
-            mirror_stdio: false,
-            startup_timeout: Duration::from_secs(3),
-        };
-
-        let before = fs::read_to_string(manager.config_path()).expect("read config before");
-        let api = AppRuntimePoolApi::from_config(&manager, &defaults).expect("build pool api");
-        let client = test_client();
-
-        let available = api.available();
-        assert_eq!(available.len(), 1);
-        let pooled_summary = &available[0];
-        assert_eq!(pooled_summary.name, "pooled");
-        assert_eq!(pooled_summary.metadata, metadata);
-
-        let launcher = api.launcher("pooled").expect("pooled launcher");
-        assert_eq!(launcher.description.as_deref(), Some("pooled app"));
-        assert_eq!(launcher.metadata, metadata);
-
-        let launcher_config = launcher.config.clone();
-        assert_eq!(launcher_config.binary, server_path);
-        assert_eq!(
-            launcher_config.code_home.as_deref(),
-            Some(code_home.as_path())
-        );
-        assert_eq!(launcher_config.startup_timeout, Duration::from_secs(2));
-
-        let launcher_env: HashMap<OsString, OsString> = launcher_config.env.into_iter().collect();
-        assert_eq!(
-            launcher_env.get(&OsString::from("CODEX_HOME")),
-            Some(&code_home.as_os_str().to_os_string())
-        );
-        assert_eq!(
-            launcher_env.get(&OsString::from("POOL_ONLY")),
-            Some(&OsString::from("base"))
-        );
-        assert_eq!(
-            launcher_env.get(&OsString::from("APP_POOL_ENV")),
-            Some(&OsString::from("runtime"))
-        );
-
-        let stdio_config = api
-            .stdio_config("pooled")
-            .expect("pooled stdio config without starting");
-        assert_eq!(stdio_config.binary, server_path);
-        assert_eq!(stdio_config.code_home.as_deref(), Some(code_home.as_path()));
-        let stdio_env: HashMap<OsString, OsString> = stdio_config.env.into_iter().collect();
-        assert_eq!(
-            stdio_env.get(&OsString::from("POOL_ONLY")),
-            Some(&OsString::from("base"))
-        );
-        assert_eq!(
-            stdio_env.get(&OsString::from("CODEX_HOME")),
-            Some(&code_home.as_os_str().to_os_string())
-        );
-        assert_eq!(
-            stdio_env.get(&OsString::from("APP_POOL_ENV")),
-            Some(&OsString::from("runtime"))
-        );
-
-        assert!(api.running().await.is_empty());
-
-        let runtime = api
-            .start("pooled", client.clone())
-            .await
-            .expect("start pooled runtime");
-        assert_eq!(runtime.name, "pooled");
-        assert_eq!(runtime.metadata, metadata);
-
-        let env_values: HashMap<OsString, OsString> = runtime.config.env.iter().cloned().collect();
-        assert_eq!(
-            env_values.get(&OsString::from("CODEX_HOME")),
-            Some(&code_home.as_os_str().to_os_string())
-        );
-        assert_eq!(
-            env_values.get(&OsString::from("POOL_ONLY")),
-            Some(&OsString::from("base"))
-        );
-        assert_eq!(
-            env_values.get(&OsString::from("APP_POOL_ENV")),
-            Some(&OsString::from("runtime"))
-        );
-
-        let thread = runtime
-            .server
-            .thread_start(ThreadStartParams {
-                thread_id: None,
-                metadata: serde_json::json!({"from": "pool"}),
-            })
-            .await
-            .expect("thread start");
-        let response = time::timeout(Duration::from_secs(2), thread.response)
-            .await
-            .expect("thread response timeout")
-            .expect("recv thread response")
-            .expect("thread response ok");
-        let thread_id = response
-            .get("thread_id")
-            .and_then(Value::as_str)
-            .unwrap_or_default()
-            .to_string();
-        assert!(!thread_id.is_empty());
-
-        let running = api.running().await;
-        let running_summary = running
-            .iter()
-            .find(|summary| summary.name == "pooled")
-            .expect("running summary present");
-        assert_eq!(running_summary.metadata, metadata);
-
-        let reused = api
-            .start("pooled", client.clone())
-            .await
-            .expect("reuse pooled runtime");
-        assert!(Arc::ptr_eq(&runtime, &reused));
-
-        api.stop("pooled").await.expect("stop pooled runtime");
-        match api.stop("pooled").await {
-            Err(AppRuntimeError::NotFound(name)) => assert_eq!(name, "pooled"),
-            other => panic!("expected not found on second stop, got {other:?}"),
-        }
-
-        assert!(api.running().await.is_empty());
-
-        let restarted = api
-            .start("pooled", client)
-            .await
-            .expect("restart pooled runtime");
-        assert!(!Arc::ptr_eq(&runtime, &restarted));
-        assert_eq!(restarted.metadata, metadata);
-
-        let prepared = api.prepare("pooled").expect("prepare after restart");
-        assert_eq!(prepared.metadata, metadata);
-
-        let after = fs::read_to_string(manager.config_path()).expect("read config after");
-        assert_eq!(before, after);
-    }
-
-    #[tokio::test]
-    async fn app_runtime_pool_api_stop_all_shuts_down_runtimes() {
-        let (config_dir, manager) = temp_config_manager();
-        let (_server_dir, server_path) = write_fake_app_server();
-        let code_home = config_dir.path().join("app-pool-stop-home");
-
-        let alpha_metadata = serde_json::json!({"resume_thread": "alpha"});
-        manager
-            .add_app_runtime(AddAppRuntimeRequest {
-                name: "alpha".into(),
-                definition: AppRuntimeDefinition {
-                    description: Some("alpha runtime".into()),
-                    tags: vec!["pool".into()],
-                    env: BTreeMap::new(),
-                    code_home: None,
-                    current_dir: None,
-                    mirror_stdio: Some(false),
-                    startup_timeout_ms: Some(2000),
-                    binary: None,
-                    metadata: alpha_metadata.clone(),
-                },
-                overwrite: false,
-            })
-            .expect("add alpha runtime");
-
-        let beta_metadata = serde_json::json!({"resume_thread": "beta"});
-        manager
-            .add_app_runtime(AddAppRuntimeRequest {
-                name: "beta".into(),
-                definition: AppRuntimeDefinition {
-                    description: Some("beta runtime".into()),
-                    tags: vec!["pool".into()],
-                    env: BTreeMap::new(),
-                    code_home: None,
-                    current_dir: None,
-                    mirror_stdio: Some(false),
-                    startup_timeout_ms: Some(2000),
-                    binary: None,
-                    metadata: beta_metadata.clone(),
-                },
-                overwrite: false,
-            })
-            .expect("add beta runtime");
-
-        let defaults = StdioServerConfig {
-            binary: server_path.clone(),
-            code_home: Some(code_home.clone()),
-            current_dir: None,
-            env: Vec::new(),
-            app_server_analytics_default_enabled: false,
-            mirror_stdio: false,
-            startup_timeout: Duration::from_secs(3),
-        };
-
-        let before = fs::read_to_string(manager.config_path()).expect("read config before");
-        let api = AppRuntimePoolApi::from_config(&manager, &defaults).expect("build pool api");
-        let client = test_client();
-
-        assert!(api.running().await.is_empty());
-
-        let alpha = api
-            .start("alpha", client.clone())
-            .await
-            .expect("start alpha runtime");
-        let beta = api
-            .start("beta", client.clone())
-            .await
-            .expect("start beta runtime");
-
-        assert_eq!(alpha.metadata, alpha_metadata);
-        assert_eq!(beta.metadata, beta_metadata);
-
-        let mut running = api.running().await;
-        running.sort_by(|a, b| a.name.cmp(&b.name));
-        assert_eq!(running.len(), 2);
-        assert_eq!(running[0].name, "alpha");
-        assert_eq!(running[0].metadata, alpha_metadata);
-        assert_eq!(running[1].name, "beta");
-        assert_eq!(running[1].metadata, beta_metadata);
-
-        let alpha_thread = alpha
-            .server
-            .thread_start(ThreadStartParams {
-                thread_id: None,
-                metadata: serde_json::json!({"from": "alpha"}),
-            })
-            .await
-            .expect("alpha thread start");
-        let _ = time::timeout(Duration::from_secs(2), alpha_thread.response)
-            .await
-            .expect("alpha thread response timeout")
-            .expect("alpha response recv")
-            .expect("alpha ok");
-
-        api.stop_all().await.expect("stop all runtimes");
-        assert!(api.running().await.is_empty());
-
-        let restarted_alpha = api
-            .start("alpha", client.clone())
-            .await
-            .expect("restart alpha");
-        assert!(!Arc::ptr_eq(&alpha, &restarted_alpha));
-        assert_eq!(restarted_alpha.metadata, alpha_metadata);
-
-        let restarted_beta = api.start("beta", client).await.expect("restart beta");
-        assert!(!Arc::ptr_eq(&beta, &restarted_beta));
-        assert_eq!(restarted_beta.metadata, beta_metadata);
-
-        let prepared_alpha = api.prepare("alpha").expect("prepare alpha");
-        assert_eq!(prepared_alpha.metadata, alpha_metadata);
-        let prepared_beta = api.prepare("beta").expect("prepare beta");
-        assert_eq!(prepared_beta.metadata, beta_metadata);
-
-        let after = fs::read_to_string(manager.config_path()).expect("read config after");
-        assert_eq!(before, after);
-    }
-
-    #[tokio::test]
-    async fn runtime_manager_starts_and_stops_stdio() {
-        let (_dir, script) = write_env_probe_server("MCP_RUNTIME_ENV_E8");
-        let code_home = tempfile::tempdir().expect("code_home");
-
-        let defaults = StdioServerConfig {
-            binary: PathBuf::from("codex"),
-            code_home: Some(code_home.path().to_path_buf()),
-            current_dir: None,
-            env: vec![(
-                OsString::from("MCP_RUNTIME_ENV_E8"),
-                OsString::from("manager-ok"),
-            )],
-            app_server_analytics_default_enabled: false,
-            mirror_stdio: false,
-            startup_timeout: Duration::from_secs(5),
-        };
-
-        let runtime = McpRuntimeServer {
-            name: "env-probe".into(),
-            transport: McpRuntimeTransport::Stdio(StdioServerDefinition {
-                command: script.to_string_lossy().to_string(),
-                args: Vec::new(),
-                env: BTreeMap::new(),
-                timeout_ms: Some(1500),
-            }),
-            description: None,
-            tags: vec!["local".into()],
-            tools: Some(McpToolConfig {
-                enabled: vec!["tool-x".into()],
-                disabled: vec![],
-            }),
-        };
-
-        let launcher = runtime.into_launcher(&defaults);
-        let manager = McpRuntimeManager::new(vec![launcher]);
-
-        let mut handle = match manager.prepare("env-probe").expect("prepare stdio") {
-            McpRuntimeHandle::Stdio(handle) => handle,
-            other => panic!("expected stdio handle, got {other:?}"),
-        };
-
-        let mut reader = BufReader::new(handle.stdout_mut());
-        let mut line = String::new();
-        let _ = time::timeout(Duration::from_secs(2), reader.read_line(&mut line))
-            .await
-            .expect("read timeout")
-            .expect("read env line");
-        assert_eq!(line.trim(), "manager-ok");
-
-        let tools = handle.tools().expect("tool hints");
-        assert_eq!(tools.enabled, vec!["tool-x".to_string()]);
-
-        handle.stop().await.expect("stop server");
-    }
-
-    #[test]
-    fn runtime_manager_propagates_tool_hints_for_http() {
-        let env_var = "MCP_HTTP_TOKEN_E8_HINTS";
-        env::set_var(env_var, "token-hints");
-
-        let mut http = StreamableHttpDefinition {
-            url: "https://example.test/hints".into(),
-            headers: BTreeMap::new(),
-            bearer_env_var: Some(env_var.to_string()),
-            connect_timeout_ms: Some(1200),
-            request_timeout_ms: Some(2400),
-        };
-        http.headers.insert("X-Test".into(), "true".into());
-
-        let runtime = McpRuntimeServer::from_definition(
-            "remote-http",
-            McpServerDefinition {
-                transport: McpTransport::StreamableHttp(http),
-                description: Some("http runtime".into()),
-                tags: vec!["http".into()],
-                tools: Some(McpToolConfig {
-                    enabled: vec!["alpha".into()],
-                    disabled: vec!["beta".into()],
-                }),
-            },
-        );
-
-        let defaults = StdioServerConfig {
-            binary: PathBuf::from("codex"),
-            code_home: None,
-            current_dir: None,
-            env: Vec::new(),
-            app_server_analytics_default_enabled: false,
-            mirror_stdio: false,
-            startup_timeout: Duration::from_secs(2),
-        };
-
-        let launcher = runtime.into_launcher(&defaults);
-        let manager = McpRuntimeManager::new(vec![launcher]);
-
-        let available = manager.available();
-        assert_eq!(available.len(), 1);
-        let summary = &available[0];
-        assert_eq!(summary.name, "remote-http");
-        assert_eq!(
-            summary.transport,
-            McpRuntimeSummaryTransport::StreamableHttp
-        );
-        let summary_tools = summary.tools.as_ref().expect("tool hints present");
-        assert_eq!(summary_tools.enabled, vec!["alpha".to_string()]);
-        assert_eq!(summary_tools.disabled, vec!["beta".to_string()]);
-
-        match manager.prepare("remote-http").expect("prepare http") {
-            McpRuntimeHandle::StreamableHttp(http_handle) => {
-                let tools = http_handle.tools.as_ref().expect("tool hints on handle");
-                assert_eq!(tools.enabled, vec!["alpha".to_string()]);
-                assert_eq!(tools.disabled, vec!["beta".to_string()]);
-                assert_eq!(
-                    http_handle.connector.bearer_token.as_deref(),
-                    Some("token-hints")
-                );
-            }
-            other => panic!("expected http handle, got {other:?}"),
-        }
-
-        env::remove_var(env_var);
-    }
-
-    #[test]
-    fn http_connector_retrieval_is_non_destructive() {
-        let env_var = "MCP_HTTP_TOKEN_E8_REUSE";
-        env::set_var(env_var, "token-reuse");
-
-        let runtime = McpRuntimeServer::from_definition(
-            "remote-reuse",
-            McpServerDefinition {
-                transport: McpTransport::StreamableHttp(StreamableHttpDefinition {
-                    url: "https://example.test/reuse".into(),
-                    headers: BTreeMap::new(),
-                    bearer_env_var: Some(env_var.to_string()),
-                    connect_timeout_ms: Some(1500),
-                    request_timeout_ms: Some(3200),
-                }),
-                description: None,
-                tags: vec!["http".into()],
-                tools: Some(McpToolConfig {
-                    enabled: vec!["one".into()],
-                    disabled: vec![],
-                }),
-            },
-        );
-
-        let defaults = StdioServerConfig {
-            binary: PathBuf::from("codex"),
-            code_home: None,
-            current_dir: None,
-            env: Vec::new(),
-            app_server_analytics_default_enabled: false,
-            mirror_stdio: false,
-            startup_timeout: Duration::from_secs(2),
-        };
-
-        let launcher = runtime.into_launcher(&defaults);
-        let manager = McpRuntimeManager::new(vec![launcher]);
-
-        let first = manager.prepare("remote-reuse").expect("first prepare");
-        let second = manager.prepare("remote-reuse").expect("second prepare");
-
-        let first_token = match first {
-            McpRuntimeHandle::StreamableHttp(handle) => handle.connector.bearer_token,
-            other => panic!("expected http handle, got {other:?}"),
-        };
-        let second_token = match second {
-            McpRuntimeHandle::StreamableHttp(handle) => handle.connector.bearer_token,
-            other => panic!("expected http handle, got {other:?}"),
-        };
-
-        assert_eq!(first_token.as_deref(), Some("token-reuse"));
-        assert_eq!(second_token.as_deref(), Some("token-reuse"));
-
-        let summary = manager
-            .available()
-            .into_iter()
-            .find(|s| s.name == "remote-reuse")
-            .expect("summary present");
-        assert_eq!(
-            summary.transport,
-            McpRuntimeSummaryTransport::StreamableHttp
-        );
-        let tools = summary.tools.as_ref().expect("tool hints preserved");
-        assert_eq!(tools.enabled, vec!["one".to_string()]);
-
-        env::remove_var(env_var);
-    }
-}
+mod test_support;
+#[cfg(test)]
+mod tests_core;
+#[cfg(test)]
+mod tests_runtime_app;
diff --git a/crates/codex/src/mcp/client.rs b/crates/codex/src/mcp/client.rs
new file mode 100644
index 0000000..6118e6e
--- /dev/null
+++ b/crates/codex/src/mcp/client.rs
@@ -0,0 +1,240 @@
+use std::{io, sync::Arc, time::Duration};
+
+use serde_json::{json, Value};
+use thiserror::Error;
+
+use super::{
+    AppCallHandle, ApprovalDecision, ClientInfo, CodexCallHandle, CodexCallParams, CodexCallResult,
+    CodexReplyParams, InitializeParams, RequestId, StdioServerConfig, METHOD_CODEX,
+    METHOD_CODEX_APPROVAL, METHOD_THREAD_RESUME, METHOD_THREAD_START, METHOD_TURN_INTERRUPT,
+    METHOD_TURN_START,
+};
+
+use super::jsonrpc::{map_response, JsonRpcTransport};
+
+/// Errors surfaced while managing MCP/app-server transports.
+#[derive(Debug, Error)]
+pub enum McpError {
+    #[error("failed to spawn `{command}`: {source}")]
+    Spawn {
+        command: String,
+        #[source]
+        source: io::Error,
+    },
+    #[error("server did not respond to initialize: {0}")]
+    Handshake(String),
+    #[error("transport task failed: {0}")]
+    Transport(String),
+    #[error("server returned JSON-RPC error {code}: {message}")]
+    Rpc {
+        code: i64,
+        message: String,
+        data: Option<Value>,
+    },
+    #[error("server reported an error: {0}")]
+    Server(String),
+    #[error("request was cancelled")]
+    Cancelled,
+    #[error("timed out after {0:?}")]
+    Timeout(Duration),
+    #[error("serialization failed: {0}")]
+    Serialization(#[from] serde_json::Error),
+    #[error("transport channel closed unexpectedly")]
+    ChannelClosed,
+}
+
+/// Client wrapper around the stdio MCP server.
+pub struct CodexMcpServer {
+    transport: Arc<JsonRpcTransport>,
+}
+
+impl CodexMcpServer {
+    /// Launch `codex mcp-server`, issue `initialize`, and return a connected handle.
+    pub async fn start(config: StdioServerConfig, client: ClientInfo) -> Result<Self, McpError> {
+        Self::with_capabilities(config, client, Value::Object(Default::default())).await
+    }
+
+    /// Launch with explicit capabilities to send during `initialize`.
+    pub async fn with_capabilities(
+        config: StdioServerConfig,
+        client: ClientInfo,
+        capabilities: Value,
+    ) -> Result<Self, McpError> {
+        let capabilities = match capabilities {
+            Value::Null => Value::Object(Default::default()),
+            other => other,
+        };
+        let transport = JsonRpcTransport::spawn_mcp(config).await?;
+        let params = InitializeParams {
+            client,
+            protocol_version: "2024-11-05".to_string(),
+            capabilities,
+        };
+
+        transport
+            .initialize(params, transport.startup_timeout())
+            .await
+            .map_err(|err| McpError::Handshake(err.to_string()))?;
+
+        Ok(Self {
+            transport: Arc::new(transport),
+        })
+    }
+
+    /// Send a new Codex prompt via `codex/codex`.
+    pub async fn codex(&self, params: CodexCallParams) -> Result<CodexCallHandle, McpError> {
+        self.invoke_tool_call("codex", serde_json::to_value(params)?)
+            .await
+    }
+
+    /// Continue an existing conversation via `codex/codex-reply`.
+    pub async fn codex_reply(&self, params: CodexReplyParams) -> Result<CodexCallHandle, McpError> {
+        self.invoke_tool_call("codex-reply", serde_json::to_value(params)?)
+            .await
+    }
+
+    /// Send an approval decision back to the MCP server.
+    pub async fn send_approval(&self, decision: ApprovalDecision) -> Result<(), McpError> {
+        let (_, rx) = self
+            .transport
+            .request(METHOD_CODEX_APPROVAL, serde_json::to_value(decision)?)
+            .await?;
+
+        match rx.await {
+            Ok(Ok(_)) => Ok(()),
+            Ok(Err(err)) => Err(err),
+            Err(_) => Err(McpError::ChannelClosed),
+        }
+    }
+
+    /// Request cancellation for a pending call.
+    pub fn cancel(&self, request_id: RequestId) -> Result<(), McpError> {
+        self.transport.cancel(request_id)
+    }
+
+    /// Gracefully shut down the MCP server.
+    pub async fn shutdown(&self) -> Result<(), McpError> {
+        self.transport.shutdown().await
+    }
+
+    async fn invoke_tool_call(
+        &self,
+        tool_name: &str,
+        arguments: Value,
+    ) -> Result<CodexCallHandle, McpError> {
+        let events = self.transport.register_codex_listener().await;
+        let request = json!({
+            "name": tool_name,
+            "arguments": arguments,
+        });
+        let (request_id, raw_response) = self.transport.request(METHOD_CODEX, request).await?;
+        let response = map_response::<CodexCallResult>(raw_response);
+
+        Ok(CodexCallHandle {
+            request_id,
+            events,
+            response,
+        })
+    }
+}
+
+/// Client wrapper around the stdio app-server.
+pub struct CodexAppServer {
+    transport: Arc<JsonRpcTransport>,
+}
+
+impl CodexAppServer {
+    /// Launch `codex app-server`, issue `initialize`, and return a connected handle.
+    pub async fn start(config: StdioServerConfig, client: ClientInfo) -> Result<Self, McpError> {
+        Self::with_capabilities(config, client, Value::Object(Default::default())).await
+    }
+
+    /// Launch with explicit capabilities to send during `initialize`.
+    pub async fn with_capabilities(
+        config: StdioServerConfig,
+        client: ClientInfo,
+        capabilities: Value,
+    ) -> Result<Self, McpError> {
+        let capabilities = match capabilities {
+            Value::Null => Value::Object(Default::default()),
+            other => other,
+        };
+        let transport = JsonRpcTransport::spawn_app(config).await?;
+        let params = InitializeParams {
+            client,
+            protocol_version: "2024-11-05".to_string(),
+            capabilities,
+        };
+
+        transport
+            .initialize(params, transport.startup_timeout())
+            .await
+            .map_err(|err| McpError::Handshake(err.to_string()))?;
+
+        Ok(Self {
+            transport: Arc::new(transport),
+        })
+    }
+
+    /// Start a new thread (or use a provided ID) via `thread/start`.
+    pub async fn thread_start(
+        &self,
+        params: super::ThreadStartParams,
+    ) -> Result<AppCallHandle, McpError> {
+        self.invoke_app_call(METHOD_THREAD_START, serde_json::to_value(params)?)
+            .await
+    }
+
+    /// Resume an existing thread via `thread/resume`.
+    pub async fn thread_resume(
+        &self,
+        params: super::ThreadResumeParams,
+    ) -> Result<AppCallHandle, McpError> {
+        self.invoke_app_call(METHOD_THREAD_RESUME, serde_json::to_value(params)?)
+            .await
+    }
+
+    /// Start a new turn on a thread via `turn/start`.
+    pub async fn turn_start(
+        &self,
+        params: super::TurnStartParams,
+    ) -> Result<AppCallHandle, McpError> {
+        self.invoke_app_call(METHOD_TURN_START, serde_json::to_value(params)?)
+            .await
+    }
+
+    /// Interrupt an active turn via `turn/interrupt`.
+    pub async fn turn_interrupt(
+        &self,
+        params: super::TurnInterruptParams,
+    ) -> Result<AppCallHandle, McpError> {
+        self.invoke_app_call(METHOD_TURN_INTERRUPT, serde_json::to_value(params)?)
+            .await
+    }
+
+    /// Request cancellation for a pending call.
+    pub fn cancel(&self, request_id: RequestId) -> Result<(), McpError> {
+        self.transport.cancel(request_id)
+    }
+
+    /// Gracefully shut down the app-server.
+    pub async fn shutdown(&self) -> Result<(), McpError> {
+        self.transport.shutdown().await
+    }
+
+    async fn invoke_app_call(
+        &self,
+        method: &str,
+        params: Value,
+    ) -> Result<AppCallHandle, McpError> {
+        let events = self.transport.register_app_listener().await;
+        let (request_id, raw_response) = self.transport.request(method, params).await?;
+        let response = map_response::<Value>(raw_response);
+
+        Ok(AppCallHandle {
+            request_id,
+            events,
+            response,
+        })
+    }
+}
diff --git a/crates/codex/src/mcp/test_support.rs b/crates/codex/src/mcp/test_support.rs
new file mode 100644
index 0000000..f45ee44
--- /dev/null
+++ b/crates/codex/src/mcp/test_support.rs
@@ -0,0 +1,293 @@
+use super::*;
+
+pub(super) mod prelude {
+    pub(crate) use serde_json::Value;
+    pub(crate) use std::{
+        collections::{BTreeMap, HashMap},
+        env,
+        ffi::OsString,
+        fs,
+        os::unix::fs::PermissionsExt,
+        path::PathBuf,
+        sync::Arc,
+        time::Duration,
+    };
+    pub(crate) use tokio::{
+        io::{AsyncBufReadExt, BufReader},
+        time,
+    };
+    pub(crate) use toml::Value as TomlValue;
+}
+
+use prelude::*;
+
+pub(super) fn temp_config_manager() -> (tempfile::TempDir, McpConfigManager) {
+    let dir = tempfile::tempdir().expect("tempdir");
+    let manager = McpConfigManager::from_code_home(dir.path());
+    (dir, manager)
+}
+
+pub(super) fn stdio_definition(command: &str) -> McpServerDefinition {
+    McpServerDefinition {
+        transport: McpTransport::Stdio(StdioServerDefinition {
+            command: command.to_string(),
+            args: Vec::new(),
+            env: BTreeMap::new(),
+            timeout_ms: Some(1500),
+        }),
+        description: None,
+        tags: Vec::new(),
+        tools: None,
+    }
+}
+
+pub(super) fn streamable_definition(url: &str, bearer_var: &str) -> McpServerDefinition {
+    McpServerDefinition {
+        transport: McpTransport::StreamableHttp(StreamableHttpDefinition {
+            url: url.to_string(),
+            headers: BTreeMap::new(),
+            bearer_env_var: Some(bearer_var.to_string()),
+            connect_timeout_ms: Some(5000),
+            request_timeout_ms: Some(5000),
+        }),
+        description: None,
+        tags: Vec::new(),
+        tools: Some(McpToolConfig {
+            enabled: vec![],
+            disabled: vec![],
+        }),
+    }
+}
+
+pub(super) fn write_fake_mcp_server() -> (tempfile::TempDir, PathBuf) {
+    let dir = tempfile::tempdir().expect("tempdir");
+    let script_path = dir.path().join("fake-codex");
+    let script = r#"#!/usr/bin/env python3
+import json
+import sys
+import threading
+import time
+
+pending = {}
+
+def send(payload):
+    sys.stdout.write(json.dumps(payload) + "\n")
+    sys.stdout.flush()
+
+def mark_cancelled(target, reason="cancelled"):
+    if target is None:
+        return
+    state = pending.get(str(target)) or {}
+    conv_id = state.get("conversation_id")
+    pending[str(target)] = {"status": "cancelled", "conversation_id": conv_id}
+    if conv_id:
+        send({"jsonrpc": "2.0", "method": "codex/event", "params": {"type": "cancelled", "conversation_id": conv_id, "reason": reason}})
+    send({"jsonrpc": "2.0", "id": target, "error": {"code": -32800, "message": reason}})
+
+def handle_codex(req_id, params):
+    conversation_id = params.get("conversation_id") or params.get("conversationId") or f"conv-{req_id}"
+    pending[str(req_id)] = {"status": "pending", "conversation_id": conversation_id}
+    def worker():
+        time.sleep(0.05)
+        state = pending.get(str(req_id))
+        if not state or state.get("status") == "cancelled":
+            return
+        send({"jsonrpc": "2.0", "method": "codex/event", "params": {"type": "approval_required", "approval_id": f"ap-{req_id}", "kind": "exec"}})
+        time.sleep(0.05)
+        state = pending.get(str(req_id))
+        if not state or state.get("status") == "cancelled":
+            return
+        send({"jsonrpc": "2.0", "method": "codex/event", "params": {"type": "task_complete", "conversation_id": conversation_id, "result": {"ok": True}}})
+        send({"jsonrpc": "2.0", "id": req_id, "result": {"conversation_id": conversation_id, "output": {"ok": True}}})
+        pending.pop(str(req_id), None)
+    threading.Thread(target=worker, daemon=True).start()
+
+for line in sys.stdin:
+    if not line.strip():
+        continue
+    msg = json.loads(line)
+    method = msg.get("method")
+    if method == "initialize":
+        send({"jsonrpc": "2.0", "id": msg.get("id"), "result": {"ready": True}})
+    elif method == "tools/call":
+        params = msg.get("params", {})
+        tool = params.get("name")
+        args = params.get("arguments", {})
+        if tool in ["codex", "codex-reply"]:
+            handle_codex(msg.get("id"), args)
+    elif method == "$/cancelRequest":
+        target = msg.get("params", {}).get("id")
+        mark_cancelled(target, reason="client_cancel")
+    elif method == "shutdown":
+        send({"jsonrpc": "2.0", "id": msg.get("id"), "result": {"ok": True}})
+        break
+    elif method == "exit":
+        break
+"#;
+
+    fs::write(&script_path, script).expect("write script");
+    let mut perms = fs::metadata(&script_path).expect("metadata").permissions();
+    perms.set_mode(0o755);
+    fs::set_permissions(&script_path, perms).expect("chmod");
+    (dir, script_path)
+}
+
+pub(super) fn write_fake_app_server() -> (tempfile::TempDir, PathBuf) {
+    let dir = tempfile::tempdir().expect("tempdir");
+    let script_path = dir.path().join("fake-codex-app");
+    let script = r#"#!/usr/bin/env python3
+import json
+import os
+import sys
+import threading
+import time
+
+pending = {}
+turn_lookup = {}
+
+log_path = os.environ.get("ARGV_LOG")
+if log_path:
+    with open(log_path, "w", encoding="utf-8") as fh:
+        fh.write(json.dumps(sys.argv[1:]) + "\n")
+
+def send(payload):
+    sys.stdout.write(json.dumps(payload) + "\n")
+    sys.stdout.flush()
+
+def mark_cancelled(req_id, reason="cancelled"):
+    if req_id is None:
+        return
+    state = pending.get(str(req_id)) or {}
+    thread_id = state.get("thread_id") or "thread-unknown"
+    turn_id = state.get("turn_id")
+    pending[str(req_id)] = {"status": "cancelled", "thread_id": thread_id, "turn_id": turn_id}
+    if turn_id:
+        send({"jsonrpc": "2.0", "method": "task/notification", "params": {"type": "task_complete", "thread_id": thread_id, "turn_id": turn_id, "result": {"cancelled": True, "reason": reason}}})
+    send({"jsonrpc": "2.0", "id": req_id, "error": {"code": -32800, "message": reason}})
+
+def handle_turn(req_id, params):
+    thread_id = params.get("threadId") or params.get("thread_id") or "thread-unknown"
+    turn_id = params.get("turnId") or params.get("turn_id") or f"turn-{req_id}"
+    pending[str(req_id)] = {"status": "pending", "thread_id": thread_id, "turn_id": turn_id}
+    turn_lookup[turn_id] = req_id
+
+    def worker():
+        time.sleep(0.05)
+        state = pending.get(str(req_id))
+        if not state or state.get("status") == "cancelled":
+            return
+        send({"jsonrpc": "2.0", "method": "task/notification", "params": {"type": "item", "thread_id": thread_id, "turn_id": turn_id, "item": {"message": "processing"}}})
+        time.sleep(0.05)
+        state = pending.get(str(req_id))
+        if not state or state.get("status") == "cancelled":
+            return
+        send({"jsonrpc": "2.0", "method": "task/notification", "params": {"type": "task_complete", "thread_id": thread_id, "turn_id": turn_id, "result": {"ok": True}}})
+        send({"jsonrpc": "2.0", "id": req_id, "result": {"turn_id": turn_id, "accepted": True}})
+        pending.pop(str(req_id), None)
+        turn_lookup.pop(turn_id, None)
+
+    threading.Thread(target=worker, daemon=True).start()
+
+for line in sys.stdin:
+    if not line.strip():
+        continue
+    msg = json.loads(line)
+    method = msg.get("method")
+    if method == "initialize":
+        send({"jsonrpc": "2.0", "id": msg.get("id"), "result": {"ready": True}})
+    elif method == "thread/start":
+        params = msg.get("params", {})
+        thread_id = params.get("thread_id") or f"thread-{msg.get('id')}"
+        send({"jsonrpc": "2.0", "id": msg.get("id"), "result": {"thread_id": thread_id}})
+    elif method == "thread/resume":
+        params = msg.get("params", {})
+        thread_id = params.get("threadId") or params.get("thread_id")
+        send({"jsonrpc": "2.0", "id": msg.get("id"), "result": {"thread_id": thread_id, "resumed": True}})
+    elif method == "turn/start":
+        handle_turn(msg.get("id"), msg.get("params", {}))
+    elif method == "turn/interrupt":
+        params = msg.get("params", {})
+        turn_id = params.get("turnId") or params.get("turn_id")
+        req_id = turn_lookup.get(turn_id)
+        if req_id:
+            mark_cancelled(req_id, reason="interrupted")
+            turn_lookup.pop(turn_id, None)
+            pending.pop(str(req_id), None)
+        send({"jsonrpc": "2.0", "id": msg.get("id"), "result": {"interrupted": True}})
+    elif method == "$/cancelRequest":
+        target = msg.get("params", {}).get("id")
+        mark_cancelled(target, reason="client_cancel")
+    elif method == "shutdown":
+        send({"jsonrpc": "2.0", "id": msg.get("id"), "result": {"ok": True}})
+        break
+    elif method == "exit":
+        break
+"#;
+
+    fs::write(&script_path, script).expect("write script");
+    let mut perms = fs::metadata(&script_path).expect("metadata").permissions();
+    perms.set_mode(0o755);
+    fs::set_permissions(&script_path, perms).expect("chmod");
+    (dir, script_path)
+}
+
+pub(super) fn write_env_probe_server(var: &str) -> (tempfile::TempDir, PathBuf) {
+    let dir = tempfile::tempdir().expect("tempdir");
+    let script_path = dir.path().join("env-probe-server");
+    let script = format!(
+        r#"#!/usr/bin/env python3
+import os
+import sys
+import time
+
+sys.stdout.write(os.environ.get("{var}", "") + "\n")
+sys.stdout.flush()
+time.sleep(30)
+"#
+    );
+
+    fs::write(&script_path, script).expect("write script");
+    let mut perms = fs::metadata(&script_path).expect("metadata").permissions();
+    perms.set_mode(0o755);
+    fs::set_permissions(&script_path, perms).expect("chmod");
+    (dir, script_path)
+}
+
+pub(super) fn test_config(binary: PathBuf) -> StdioServerConfig {
+    StdioServerConfig {
+        binary,
+        code_home: None,
+        current_dir: None,
+        env: Vec::new(),
+        app_server_analytics_default_enabled: false,
+        mirror_stdio: false,
+        startup_timeout: Duration::from_secs(5),
+    }
+}
+
+pub(super) fn test_client() -> ClientInfo {
+    ClientInfo {
+        name: "tests".to_string(),
+        version: "0.0.0".to_string(),
+    }
+}
+
+pub(super) async fn start_fake_mcp_server() -> (tempfile::TempDir, CodexMcpServer) {
+    let (dir, script) = write_fake_mcp_server();
+    let config = test_config(script);
+    let client = test_client();
+    let server = CodexMcpServer::start(config, client)
+        .await
+        .expect("spawn mcp server");
+    (dir, server)
+}
+
+pub(super) async fn start_fake_app_server() -> (tempfile::TempDir, CodexAppServer) {
+    let (dir, script) = write_fake_app_server();
+    let config = test_config(script);
+    let client = test_client();
+    let server = CodexAppServer::start(config, client)
+        .await
+        .expect("spawn app server");
+    (dir, server)
+}
diff --git a/crates/codex/src/mcp/tests_core.rs b/crates/codex/src/mcp/tests_core.rs
new file mode 100644
index 0000000..f73a948
--- /dev/null
+++ b/crates/codex/src/mcp/tests_core.rs
@@ -0,0 +1,982 @@
+use super::test_support::{prelude::*, *};
+use super::*;
+
+#[tokio::test]
+async fn app_server_launch_can_enable_analytics_flag() {
+    let (dir, script) = write_fake_app_server();
+    let log_path = dir.path().join("argv.json");
+
+    let mut config = test_config(script);
+    config.app_server_analytics_default_enabled = true;
+    config.env.push((
+        OsString::from("ARGV_LOG"),
+        OsString::from(log_path.as_os_str()),
+    ));
+
+    let client = test_client();
+    let server = CodexAppServer::start(config, client)
+        .await
+        .expect("spawn app server");
+
+    let mut argv_line = None;
+    for _ in 0..50 {
+        if let Ok(contents) = fs::read_to_string(&log_path) {
+            argv_line = contents.lines().next().map(str::to_string);
+            break;
+        }
+        tokio::time::sleep(Duration::from_millis(5)).await;
+    }
+
+    let argv_line = argv_line.expect("argv log should be written");
+    let argv: Vec<String> = serde_json::from_str(&argv_line).expect("argv json");
+    assert_eq!(argv, vec!["app-server", "--analytics-default-enabled"]);
+
+    server.shutdown().await.expect("shutdown server");
+}
+
+#[test]
+fn add_stdio_server_injects_env_and_persists() {
+    let (dir, manager) = temp_config_manager();
+    let env_key = "MCP_STDIO_TEST_KEY";
+    env::remove_var(env_key);
+
+    let mut env_map = BTreeMap::new();
+    env_map.insert(env_key.to_string(), "secret".to_string());
+
+    let added = manager
+        .add_server(AddServerRequest {
+            name: "local".into(),
+            definition: stdio_definition("my-mcp"),
+            overwrite: false,
+            env: env_map,
+            bearer_token: None,
+        })
+        .expect("add server");
+
+    match added.definition.transport {
+        McpTransport::Stdio(def) => {
+            assert_eq!(def.command, "my-mcp");
+            assert_eq!(def.env.get(env_key), Some(&"secret".to_string()));
+        }
+        _ => panic!("expected stdio transport"),
+    }
+
+    let listed = manager.list_servers().expect("list servers");
+    assert_eq!(listed.len(), 1);
+    assert_eq!(listed[0].name, "local");
+
+    let fetched = manager.get_server("local").expect("get server");
+    match fetched.definition.transport {
+        McpTransport::Stdio(def) => {
+            assert_eq!(def.env.get(env_key), Some(&"secret".to_string()))
+        }
+        _ => panic!("expected stdio transport"),
+    }
+
+    let config_path = dir.path().join(DEFAULT_CONFIG_FILE);
+    let serialized = fs::read_to_string(config_path).expect("read config");
+    let value: TomlValue = serialized.parse().expect("parse toml");
+    let table = value.as_table().expect("table root");
+    let servers_table = table.get("mcp_servers").expect("mcp_servers");
+    let decoded: BTreeMap<String, McpServerDefinition> = servers_table
+        .clone()
+        .try_into()
+        .expect("decode mcp_servers");
+    let stored = decoded.get("local").expect("stored server");
+    match &stored.transport {
+        McpTransport::Stdio(def) => {
+            assert_eq!(def.env.get(env_key), Some(&"secret".to_string()))
+        }
+        _ => panic!("expected stdio transport"),
+    }
+
+    assert_eq!(env::var(env_key).unwrap(), "secret");
+    env::remove_var(env_key);
+}
+
+#[test]
+fn add_streamable_http_sets_token_and_allows_login_logout() {
+    let (_dir, manager) = temp_config_manager();
+    let env_var = "MCP_HTTP_TOKEN_E5";
+    env::remove_var(env_var);
+
+    let mut definition = streamable_definition("https://example.test/mcp", env_var);
+    if let McpTransport::StreamableHttp(ref mut http) = definition.transport {
+        http.headers.insert("X-Test".into(), "true".into());
+    }
+
+    let _added = manager
+        .add_server(AddServerRequest {
+            name: "remote".into(),
+            definition,
+            overwrite: false,
+            env: BTreeMap::new(),
+            bearer_token: Some("token-a".into()),
+        })
+        .expect("add server");
+
+    assert_eq!(env::var(env_var).unwrap(), "token-a");
+
+    let logout = manager.logout("remote").expect("logout");
+    assert_eq!(logout.env_var.as_deref(), Some(env_var));
+    assert!(logout.cleared);
+    assert!(env::var(env_var).is_err());
+
+    let login = manager.login("remote", "token-b").expect("login");
+    assert_eq!(login.env_var.as_deref(), Some(env_var));
+    assert_eq!(env::var(env_var).unwrap(), "token-b");
+
+    env::remove_var(env_var);
+}
+
+#[test]
+fn remove_server_prunes_config() {
+    let (_dir, manager) = temp_config_manager();
+
+    manager
+        .add_server(AddServerRequest {
+            name: "one".into(),
+            definition: stdio_definition("one"),
+            overwrite: false,
+            env: BTreeMap::new(),
+            bearer_token: None,
+        })
+        .expect("add first");
+
+    manager
+        .add_server(AddServerRequest {
+            name: "two".into(),
+            definition: stdio_definition("two"),
+            overwrite: false,
+            env: BTreeMap::new(),
+            bearer_token: None,
+        })
+        .expect("add second");
+
+    let removed = manager.remove_server("one").expect("remove");
+    assert!(removed.is_some());
+
+    let listed = manager.list_servers().expect("list");
+    assert_eq!(listed.len(), 1);
+    assert_eq!(listed[0].name, "two");
+
+    let config = fs::read_to_string(manager.config_path()).expect("read config");
+    let value: TomlValue = config.parse().expect("parse config");
+    let table = value.as_table().expect("table root");
+    let servers_value = table.get("mcp_servers").cloned().expect("servers");
+    let servers: BTreeMap<String, McpServerDefinition> =
+        servers_value.try_into().expect("decode servers");
+    assert!(!servers.contains_key("one"));
+    assert!(servers.contains_key("two"));
+}
+
+#[test]
+fn runtime_stdio_server_resolves_env_and_tools() {
+    let (_dir, manager) = temp_config_manager();
+    let mut definition = stdio_definition("my-mcp");
+    definition.description = Some("local mcp".into());
+    definition.tags = vec!["dev".into(), "local".into()];
+    definition.tools = Some(McpToolConfig {
+        enabled: vec!["tool-a".into()],
+        disabled: vec!["tool-b".into()],
+    });
+
+    if let McpTransport::Stdio(ref mut stdio) = definition.transport {
+        stdio.args = vec!["--flag".into()];
+        stdio.env.insert("EXAMPLE".into(), "value".into());
+        stdio.timeout_ms = Some(2500);
+    }
+
+    let mut injected = BTreeMap::new();
+    injected.insert("MCP_STDIO_INJECT_E6".into(), "yes".into());
+
+    manager
+        .add_server(AddServerRequest {
+            name: "local".into(),
+            definition,
+            overwrite: false,
+            env: injected,
+            bearer_token: None,
+        })
+        .expect("add server");
+
+    let runtime = manager.runtime_server("local").expect("runtime server");
+    assert_eq!(runtime.name, "local");
+    assert_eq!(runtime.description.as_deref(), Some("local mcp"));
+    assert_eq!(runtime.tags, vec!["dev".to_string(), "local".to_string()]);
+
+    let tools = runtime.tools.as_ref().expect("tool hints");
+    assert_eq!(tools.enabled, vec!["tool-a".to_string()]);
+    assert_eq!(tools.disabled, vec!["tool-b".to_string()]);
+
+    match &runtime.transport {
+        McpRuntimeTransport::Stdio(def) => {
+            assert_eq!(def.command, "my-mcp");
+            assert_eq!(def.args, vec!["--flag".to_string()]);
+            assert_eq!(def.timeout_ms, Some(2500));
+            assert_eq!(def.env.get("EXAMPLE").map(String::as_str), Some("value"));
+            assert_eq!(
+                def.env.get("MCP_STDIO_INJECT_E6").map(String::as_str),
+                Some("yes")
+            );
+        }
+        other => panic!("expected stdio transport, got {other:?}"),
+    }
+
+    serde_json::to_string(&runtime).expect("serialize runtime");
+    env::remove_var("MCP_STDIO_INJECT_E6");
+}
+
+#[test]
+fn runtime_http_resolves_bearer_and_sets_header() {
+    let (_dir, manager) = temp_config_manager();
+    let env_var = "MCP_HTTP_TOKEN_E6";
+    env::set_var(env_var, "token-123");
+
+    let mut definition = streamable_definition("https://example.test/mcp", env_var);
+    if let McpTransport::StreamableHttp(ref mut http) = definition.transport {
+        http.headers.insert("X-Test".into(), "true".into());
+        http.connect_timeout_ms = Some(1200);
+        http.request_timeout_ms = Some(3400);
+    }
+
+    manager
+        .add_server(AddServerRequest {
+            name: "remote".into(),
+            definition,
+            overwrite: false,
+            env: BTreeMap::new(),
+            bearer_token: None,
+        })
+        .expect("add server");
+
+    let runtime = manager.runtime_server("remote").expect("runtime server");
+    match &runtime.transport {
+        McpRuntimeTransport::StreamableHttp(def) => {
+            assert_eq!(def.url, "https://example.test/mcp");
+            assert_eq!(def.bearer_env_var.as_deref(), Some(env_var));
+            assert_eq!(def.bearer_token.as_deref(), Some("token-123"));
+            assert_eq!(def.headers.get("X-Test").map(String::as_str), Some("true"));
+            assert_eq!(
+                def.headers.get("Authorization").map(String::as_str),
+                Some("Bearer token-123")
+            );
+            assert_eq!(def.connect_timeout_ms, Some(1200));
+            assert_eq!(def.request_timeout_ms, Some(3400));
+        }
+        other => panic!("expected streamable_http transport, got {other:?}"),
+    }
+
+    let serialized = serde_json::to_value(&runtime).expect("serialize runtime");
+    assert!(serialized.get("transport").is_some());
+
+    env::remove_var(env_var);
+}
+
+#[test]
+fn runtime_http_preserves_existing_auth_header() {
+    let (_dir, manager) = temp_config_manager();
+    let env_var = "MCP_HTTP_TOKEN_E6B";
+    env::set_var(env_var, "token-override");
+
+    let mut definition = streamable_definition("https://example.test/custom", env_var);
+    if let McpTransport::StreamableHttp(ref mut http) = definition.transport {
+        http.headers
+            .insert("Authorization".into(), "Custom 123".into());
+    }
+
+    manager
+        .add_server(AddServerRequest {
+            name: "remote-custom".into(),
+            definition,
+            overwrite: false,
+            env: BTreeMap::new(),
+            bearer_token: None,
+        })
+        .expect("add server");
+
+    let runtime = manager
+        .runtime_server("remote-custom")
+        .expect("runtime server");
+    match &runtime.transport {
+        McpRuntimeTransport::StreamableHttp(def) => {
+            assert_eq!(def.bearer_token.as_deref(), Some("token-override"));
+            assert_eq!(
+                def.headers.get("Authorization").map(String::as_str),
+                Some("Custom 123")
+            );
+        }
+        other => panic!("expected streamable_http transport, got {other:?}"),
+    }
+
+    env::remove_var(env_var);
+}
+
+#[test]
+fn runtime_stdio_launcher_merges_env_timeout_and_tools() {
+    let base_dir = tempfile::tempdir().expect("tempdir");
+    let code_home = base_dir.path().join("code_home");
+
+    let defaults = StdioServerConfig {
+        binary: PathBuf::from("codex"),
+        code_home: Some(code_home.clone()),
+        current_dir: Some(base_dir.path().to_path_buf()),
+        env: vec![
+            (OsString::from("BASE_ONLY"), OsString::from("base")),
+            (OsString::from("OVERRIDE_ME"), OsString::from("base")),
+        ],
+        app_server_analytics_default_enabled: false,
+        mirror_stdio: true,
+        startup_timeout: Duration::from_secs(5),
+    };
+
+    let mut definition = StdioServerDefinition {
+        command: "my-mcp".into(),
+        args: vec!["--flag".into()],
+        env: BTreeMap::new(),
+        timeout_ms: Some(1500),
+    };
+    definition
+        .env
+        .insert("OVERRIDE_ME".into(), "runtime".into());
+    definition
+        .env
+        .insert("RUNTIME_ONLY".into(), "runtime-env".into());
+
+    let runtime = McpRuntimeServer {
+        name: "local".into(),
+        transport: McpRuntimeTransport::Stdio(definition),
+        description: Some("example".into()),
+        tags: vec!["dev".into()],
+        tools: Some(McpToolConfig {
+            enabled: vec!["tool-1".into()],
+            disabled: vec!["tool-2".into()],
+        }),
+    };
+
+    let launcher = runtime.into_launcher(&defaults);
+    assert_eq!(launcher.name, "local");
+    assert_eq!(launcher.description.as_deref(), Some("example"));
+    assert_eq!(launcher.tags, vec!["dev".to_string()]);
+
+    let tools = launcher.tools.clone().expect("tool hints");
+    assert_eq!(tools.enabled, vec!["tool-1".to_string()]);
+    assert_eq!(tools.disabled, vec!["tool-2".to_string()]);
+
+    match launcher.transport {
+        McpServerLauncherTransport::Stdio(launch) => {
+            assert_eq!(launch.command, PathBuf::from("my-mcp"));
+            assert_eq!(launch.args, vec!["--flag".to_string()]);
+            assert_eq!(launch.current_dir.as_ref(), defaults.current_dir.as_ref());
+            assert_eq!(launch.timeout, Duration::from_millis(1500));
+            assert!(launch.mirror_stdio);
+
+            let env_map: HashMap<OsString, OsString> = launch.env.into_iter().collect();
+            assert_eq!(
+                env_map.get(&OsString::from("BASE_ONLY")),
+                Some(&OsString::from("base"))
+            );
+            assert_eq!(
+                env_map.get(&OsString::from("OVERRIDE_ME")),
+                Some(&OsString::from("runtime"))
+            );
+            assert_eq!(
+                env_map.get(&OsString::from("RUNTIME_ONLY")),
+                Some(&OsString::from("runtime-env"))
+            );
+            assert_eq!(
+                env_map.get(&OsString::from("CODEX_HOME")),
+                Some(&code_home.as_os_str().to_os_string())
+            );
+        }
+        other => panic!("expected stdio launcher, got {other:?}"),
+    }
+}
+
+#[test]
+fn streamable_http_connector_converts_timeouts_and_headers() {
+    let env_var = "MCP_HTTP_TOKEN_E7";
+    env::set_var(env_var, "token-launcher");
+
+    let mut definition = StreamableHttpDefinition {
+        url: "https://example.test/stream".into(),
+        headers: BTreeMap::new(),
+        bearer_env_var: Some(env_var.to_string()),
+        connect_timeout_ms: Some(1200),
+        request_timeout_ms: Some(3400),
+    };
+    definition.headers.insert("X-Test".into(), "true".into());
+
+    let runtime = McpRuntimeServer::from_definition(
+        "remote",
+        McpServerDefinition {
+            transport: McpTransport::StreamableHttp(definition),
+            description: None,
+            tags: vec!["http".into()],
+            tools: Some(McpToolConfig {
+                enabled: vec!["tool-a".into()],
+                disabled: vec![],
+            }),
+        },
+    );
+
+    let defaults = StdioServerConfig {
+        binary: PathBuf::from("codex"),
+        code_home: None,
+        current_dir: None,
+        env: Vec::new(),
+        app_server_analytics_default_enabled: false,
+        mirror_stdio: false,
+        startup_timeout: Duration::from_secs(2),
+    };
+
+    let launcher = runtime.into_launcher(&defaults);
+    match launcher.transport {
+        McpServerLauncherTransport::StreamableHttp(connector) => {
+            assert_eq!(connector.url, "https://example.test/stream");
+            assert_eq!(
+                connector.headers.get("X-Test").map(String::as_str),
+                Some("true")
+            );
+            assert_eq!(
+                connector.headers.get("Authorization").map(String::as_str),
+                Some("Bearer token-launcher")
+            );
+            assert_eq!(connector.connect_timeout, Some(Duration::from_millis(1200)));
+            assert_eq!(connector.request_timeout, Some(Duration::from_millis(3400)));
+            assert_eq!(connector.bearer_env_var.as_deref(), Some(env_var));
+            assert_eq!(connector.bearer_token.as_deref(), Some("token-launcher"));
+
+            let tools = launcher.tools.as_ref().expect("tool hints present");
+            assert_eq!(tools.enabled, vec!["tool-a".to_string()]);
+            assert!(tools.disabled.is_empty());
+        }
+        other => panic!("expected http connector, got {other:?}"),
+    }
+
+    env::remove_var(env_var);
+}
+
+#[tokio::test]
+async fn codex_flow_streams_events_and_response() {
+    let (_dir, server) = start_fake_mcp_server().await;
+
+    let params = CodexCallParams {
+        prompt: "hello".into(),
+        model: None,
+        cwd: None,
+        sandbox: None,
+        approval_policy: None,
+        profile: None,
+        config: BTreeMap::new(),
+    };
+
+    let mut handle = server.codex(params).await.expect("codex call");
+
+    let first_event = time::timeout(Duration::from_secs(2), handle.events.recv())
+        .await
+        .expect("event timeout")
+        .expect("event value");
+    match first_event {
+        CodexEvent::ApprovalRequired(req) => {
+            assert!(req.approval_id.starts_with("ap-"));
+            assert_eq!(req.kind, ApprovalKind::Exec);
+        }
+        other => panic!("unexpected event: {other:?}"),
+    }
+
+    let second_event = time::timeout(Duration::from_secs(2), handle.events.recv())
+        .await
+        .expect("event timeout")
+        .expect("event value");
+    let event_conversation = match second_event {
+        CodexEvent::TaskComplete {
+            conversation_id, ..
+        } => {
+            assert!(!conversation_id.is_empty());
+            conversation_id
+        }
+        other => panic!("unexpected event: {other:?}"),
+    };
+
+    let response = time::timeout(Duration::from_secs(2), handle.response)
+        .await
+        .expect("response timeout")
+        .expect("response recv");
+    let response = response.expect("response ok");
+    assert_eq!(
+        response.conversation_id.as_deref(),
+        Some(event_conversation.as_str())
+    );
+    assert_eq!(response.output, serde_json::json!({ "ok": true }));
+
+    let _ = server.shutdown().await;
+}
+
+#[tokio::test]
+async fn canceling_request_returns_cancelled_error() {
+    let (_dir, server) = start_fake_mcp_server().await;
+
+    let params = CodexCallParams {
+        prompt: "cancel me".into(),
+        model: None,
+        cwd: None,
+        sandbox: None,
+        approval_policy: None,
+        profile: None,
+        config: BTreeMap::new(),
+    };
+
+    let mut handle = server.codex(params).await.expect("codex call");
+    server.cancel(handle.request_id).expect("cancel send");
+
+    let expected_conversation = format!("conv-{}", handle.request_id);
+    let cancel_event = time::timeout(Duration::from_secs(2), handle.events.recv())
+        .await
+        .expect("event timeout")
+        .expect("cancel notification");
+    match cancel_event {
+        CodexEvent::Cancelled {
+            conversation_id,
+            reason,
+        } => {
+            assert_eq!(
+                conversation_id.as_deref(),
+                Some(expected_conversation.as_str())
+            );
+            assert_eq!(reason.as_deref(), Some("client_cancel"));
+        }
+        other => panic!("expected cancellation event, got {other:?}"),
+    }
+
+    let response = time::timeout(Duration::from_secs(2), handle.response)
+        .await
+        .expect("response timeout")
+        .expect("recv");
+    assert!(matches!(response, Err(McpError::Cancelled)));
+
+    let _ = server.shutdown().await;
+}
+
+#[tokio::test]
+async fn codex_reply_streams_follow_up_notifications() {
+    let (_dir, server) = start_fake_mcp_server().await;
+
+    let params = CodexCallParams {
+        prompt: "hello".into(),
+        model: None,
+        cwd: None,
+        sandbox: None,
+        approval_policy: None,
+        profile: None,
+        config: BTreeMap::new(),
+    };
+    let first = server.codex(params).await.expect("start codex");
+    let first_response = time::timeout(Duration::from_secs(2), first.response)
+        .await
+        .expect("response timeout")
+        .expect("recv")
+        .expect("ok");
+    let conversation_id = first_response.conversation_id.expect("conversation id set");
+    assert!(!conversation_id.is_empty());
+
+    let reply_params = CodexReplyParams {
+        conversation_id: conversation_id.clone(),
+        prompt: "follow up".into(),
+    };
+    let mut reply = server.codex_reply(reply_params).await.expect("codex reply");
+
+    let expected_approval = format!("ap-{}", reply.request_id);
+    let approval = time::timeout(Duration::from_secs(2), reply.events.recv())
+        .await
+        .expect("event timeout")
+        .expect("approval");
+    match approval {
+        CodexEvent::ApprovalRequired(req) => {
+            assert_eq!(req.approval_id, expected_approval);
+            assert_eq!(req.kind, ApprovalKind::Exec);
+        }
+        other => panic!("unexpected event: {other:?}"),
+    }
+
+    let complete = time::timeout(Duration::from_secs(2), reply.events.recv())
+        .await
+        .expect("event timeout")
+        .expect("task completion");
+    match complete {
+        CodexEvent::TaskComplete {
+            conversation_id: event_conv,
+            ..
+        } => assert_eq!(event_conv, conversation_id),
+        other => panic!("unexpected event: {other:?}"),
+    }
+
+    let reply_response = time::timeout(Duration::from_secs(2), reply.response)
+        .await
+        .expect("response timeout")
+        .expect("recv")
+        .expect("ok");
+    assert_eq!(
+        reply_response.conversation_id.as_deref(),
+        Some(conversation_id.as_str())
+    );
+    assert_eq!(reply_response.output, serde_json::json!({ "ok": true }));
+
+    let _ = server.shutdown().await;
+}
+
+#[tokio::test]
+async fn app_flow_streams_notifications_and_response() {
+    let (_dir, server) = start_fake_app_server().await;
+
+    let thread_params = ThreadStartParams {
+        thread_id: None,
+        metadata: Value::Null,
+    };
+    let thread_handle = server
+        .thread_start(thread_params)
+        .await
+        .expect("thread start");
+    let thread_response = time::timeout(Duration::from_secs(2), thread_handle.response)
+        .await
+        .expect("thread response timeout")
+        .expect("thread response recv")
+        .expect("thread response ok");
+    let thread_id = thread_response
+        .get("thread_id")
+        .and_then(Value::as_str)
+        .unwrap_or_default()
+        .to_string();
+    assert!(!thread_id.is_empty());
+
+    let params = TurnStartParams {
+        thread_id: thread_id.clone(),
+        input: vec![TurnInput {
+            kind: "text".to_string(),
+            text: Some("hi".to_string()),
+        }],
+        model: None,
+        config: BTreeMap::new(),
+    };
+    let mut handle = server.turn_start(params).await.expect("turn start");
+
+    let first_event = time::timeout(Duration::from_secs(2), handle.events.recv())
+        .await
+        .expect("event timeout")
+        .expect("event value");
+    let turn_id = match first_event {
+        AppNotification::Item {
+            thread_id: tid,
+            turn_id: Some(turn),
+            item,
+        } => {
+            assert_eq!(tid, thread_id);
+            assert!(item.get("message").is_some());
+            turn
+        }
+        other => panic!("unexpected event: {other:?}"),
+    };
+
+    let second_event = time::timeout(Duration::from_secs(2), handle.events.recv())
+        .await
+        .expect("event timeout")
+        .expect("event value");
+    match second_event {
+        AppNotification::TaskComplete {
+            thread_id: tid,
+            turn_id: event_turn,
+            result,
+        } => {
+            assert_eq!(tid, thread_id);
+            assert_eq!(event_turn.as_deref(), Some(turn_id.as_str()));
+            assert_eq!(result, serde_json::json!({ "ok": true }));
+        }
+        other => panic!("unexpected event: {other:?}"),
+    }
+
+    let response = time::timeout(Duration::from_secs(2), handle.response)
+        .await
+        .expect("response timeout")
+        .expect("response recv");
+    let response = response.expect("response ok");
+    assert_eq!(
+        response
+            .get("turn_id")
+            .and_then(Value::as_str)
+            .unwrap_or_default(),
+        turn_id
+    );
+
+    let _ = server.shutdown().await;
+}
+
+#[tokio::test]
+async fn canceling_app_request_returns_cancelled_error() {
+    let (_dir, server) = start_fake_app_server().await;
+
+    let thread_params = ThreadStartParams {
+        thread_id: None,
+        metadata: Value::Null,
+    };
+    let thread_handle = server
+        .thread_start(thread_params)
+        .await
+        .expect("thread start");
+    let thread_response = time::timeout(Duration::from_secs(2), thread_handle.response)
+        .await
+        .expect("thread response timeout")
+        .expect("thread response recv")
+        .expect("thread response ok");
+    let thread_id = thread_response
+        .get("thread_id")
+        .and_then(Value::as_str)
+        .unwrap_or_default()
+        .to_string();
+
+    let params = TurnStartParams {
+        thread_id: thread_id.clone(),
+        input: vec![TurnInput {
+            kind: "text".to_string(),
+            text: Some("cancel me".to_string()),
+        }],
+        model: None,
+        config: BTreeMap::new(),
+    };
+
+    let mut handle = server.turn_start(params).await.expect("turn start");
+    server.cancel(handle.request_id).expect("send cancel");
+
+    let cancel_event = time::timeout(Duration::from_secs(2), handle.events.recv())
+        .await
+        .expect("event timeout")
+        .expect("cancel event");
+    match cancel_event {
+        AppNotification::TaskComplete {
+            thread_id: tid,
+            turn_id,
+            result,
+        } => {
+            assert_eq!(tid, thread_id);
+            assert!(turn_id.is_some());
+            assert_eq!(result.get("cancelled"), Some(&Value::Bool(true)));
+            assert_eq!(
+                result.get("reason"),
+                Some(&Value::String("client_cancel".into()))
+            );
+        }
+        other => panic!("unexpected cancellation notification: {other:?}"),
+    }
+
+    let response = time::timeout(Duration::from_secs(2), handle.response)
+        .await
+        .expect("response timeout")
+        .expect("recv");
+    assert!(matches!(response, Err(McpError::Cancelled)));
+
+    let _ = server.shutdown().await;
+}
+
+#[tokio::test]
+async fn thread_resume_allows_follow_up_turns() {
+    let (_dir, server) = start_fake_app_server().await;
+
+    let thread_params = ThreadStartParams {
+        thread_id: None,
+        metadata: Value::Null,
+    };
+    let thread_handle = server
+        .thread_start(thread_params)
+        .await
+        .expect("thread start");
+    let thread_response = time::timeout(Duration::from_secs(2), thread_handle.response)
+        .await
+        .expect("thread response timeout")
+        .expect("recv")
+        .expect("ok");
+    let thread_id = thread_response
+        .get("thread_id")
+        .and_then(Value::as_str)
+        .unwrap_or_default()
+        .to_string();
+
+    let resume_params = ThreadResumeParams {
+        thread_id: thread_id.clone(),
+    };
+    let resume_handle = server
+        .thread_resume(resume_params)
+        .await
+        .expect("thread resume");
+    let resume_response = time::timeout(Duration::from_secs(2), resume_handle.response)
+        .await
+        .expect("resume response timeout")
+        .expect("recv")
+        .expect("ok");
+    assert_eq!(
+        resume_response
+            .get("thread_id")
+            .and_then(Value::as_str)
+            .unwrap_or_default(),
+        thread_id
+    );
+    assert!(resume_response
+        .get("resumed")
+        .and_then(Value::as_bool)
+        .unwrap_or(false));
+
+    let params = TurnStartParams {
+        thread_id: thread_id.clone(),
+        input: vec![TurnInput {
+            kind: "text".to_string(),
+            text: Some("resume flow".to_string()),
+        }],
+        model: None,
+        config: BTreeMap::new(),
+    };
+    let mut turn = server.turn_start(params).await.expect("turn start");
+
+    let item = time::timeout(Duration::from_secs(2), turn.events.recv())
+        .await
+        .expect("event timeout")
+        .expect("item event");
+    let turn_id = match item {
+        AppNotification::Item {
+            thread_id: tid,
+            turn_id: Some(turn_id),
+            ..
+        } => {
+            assert_eq!(tid, thread_id);
+            turn_id
+        }
+        other => panic!("unexpected event: {other:?}"),
+    };
+
+    let complete = time::timeout(Duration::from_secs(2), turn.events.recv())
+        .await
+        .expect("event timeout")
+        .expect("completion event");
+    match complete {
+        AppNotification::TaskComplete {
+            thread_id: tid,
+            turn_id: event_turn,
+            result,
+        } => {
+            assert_eq!(tid, thread_id);
+            assert_eq!(event_turn.as_deref(), Some(turn_id.as_str()));
+            assert_eq!(result, serde_json::json!({ "ok": true }));
+        }
+        other => panic!("unexpected event: {other:?}"),
+    }
+
+    let turn_response = time::timeout(Duration::from_secs(2), turn.response)
+        .await
+        .expect("response timeout")
+        .expect("recv")
+        .expect("ok");
+    assert_eq!(
+        turn_response
+            .get("turn_id")
+            .and_then(Value::as_str)
+            .unwrap_or_default(),
+        turn_id
+    );
+
+    let _ = server.shutdown().await;
+}
+
+#[tokio::test]
+async fn turn_interrupt_sends_cancel_notification() {
+    let (_dir, server) = start_fake_app_server().await;
+
+    let thread_params = ThreadStartParams {
+        thread_id: None,
+        metadata: Value::Null,
+    };
+    let thread_handle = server
+        .thread_start(thread_params)
+        .await
+        .expect("thread start");
+    let thread_response = time::timeout(Duration::from_secs(2), thread_handle.response)
+        .await
+        .expect("thread response timeout")
+        .expect("recv")
+        .expect("ok");
+    let thread_id = thread_response
+        .get("thread_id")
+        .and_then(Value::as_str)
+        .unwrap_or_default()
+        .to_string();
+
+    let params = TurnStartParams {
+        thread_id: thread_id.clone(),
+        input: vec![TurnInput {
+            kind: "text".to_string(),
+            text: Some("please interrupt".to_string()),
+        }],
+        model: None,
+        config: BTreeMap::new(),
+    };
+    let mut turn = server.turn_start(params).await.expect("turn start");
+
+    let first_event = time::timeout(Duration::from_secs(2), turn.events.recv())
+        .await
+        .expect("event timeout")
+        .expect("event value");
+    let turn_id = match first_event {
+        AppNotification::Item {
+            thread_id: tid,
+            turn_id: Some(turn),
+            ..
+        } => {
+            assert_eq!(tid, thread_id);
+            turn
+        }
+        other => panic!("unexpected event: {other:?}"),
+    };
+
+    let interrupt = server
+        .turn_interrupt(TurnInterruptParams {
+            thread_id: Some(thread_id.clone()),
+            turn_id: turn_id.clone(),
+        })
+        .await
+        .expect("send interrupt");
+
+    let cancel_event = time::timeout(Duration::from_secs(2), turn.events.recv())
+        .await
+        .expect("event timeout")
+        .expect("cancel event");
+    match cancel_event {
+        AppNotification::TaskComplete {
+            thread_id: tid,
+            turn_id: event_turn,
+            result,
+        } => {
+            assert_eq!(tid, thread_id);
+            assert_eq!(event_turn.as_deref(), Some(turn_id.as_str()));
+            assert_eq!(result.get("cancelled"), Some(&Value::Bool(true)));
+            assert_eq!(
+                result.get("reason"),
+                Some(&Value::String("interrupted".into()))
+            );
+        }
+        other => panic!("unexpected cancel notification: {other:?}"),
+    }
+
+    let turn_response = time::timeout(Duration::from_secs(2), turn.response)
+        .await
+        .expect("response timeout")
+        .expect("recv");
+    assert!(matches!(turn_response, Err(McpError::Cancelled)));
+
+    let interrupt_response = time::timeout(Duration::from_secs(2), interrupt.response)
+        .await
+        .expect("interrupt response timeout")
+        .expect("recv")
+        .expect("ok");
+    assert!(interrupt_response
+        .get("interrupted")
+        .and_then(Value::as_bool)
+        .unwrap_or(false));
+
+    let _ = server.shutdown().await;
+}
diff --git a/crates/codex/src/mcp/tests_runtime_app.rs b/crates/codex/src/mcp/tests_runtime_app.rs
new file mode 100644
index 0000000..490143a
--- /dev/null
+++ b/crates/codex/src/mcp/tests_runtime_app.rs
@@ -0,0 +1,979 @@
+use super::test_support::{prelude::*, *};
+use super::*;
+
+#[test]
+fn runtime_api_lists_launchers_without_changing_config() {
+    let (dir, manager) = temp_config_manager();
+    let stdio_env_key = "MCP_RUNTIME_API_STDIO_ENV";
+    let request_env_key = "MCP_RUNTIME_API_REQUEST_ENV";
+    let http_env_key = "MCP_RUNTIME_API_HTTP_ENV";
+    env::set_var(http_env_key, "token-api");
+
+    let mut stdio = stdio_definition("runtime-api-stdio");
+    stdio.description = Some("stdio runtime".into());
+    stdio.tags = vec!["local".into()];
+    stdio.tools = Some(McpToolConfig {
+        enabled: vec!["fmt".into()],
+        disabled: vec!["lint".into()],
+    });
+    if let McpTransport::Stdio(ref mut stdio_def) = stdio.transport {
+        stdio_def.args.push("--flag".into());
+        stdio_def
+            .env
+            .insert(stdio_env_key.into(), "runtime-env".into());
+        stdio_def.timeout_ms = Some(2400);
+    }
+
+    let mut env_map = BTreeMap::new();
+    env_map.insert(request_env_key.to_string(), "injected".to_string());
+
+    manager
+        .add_server(AddServerRequest {
+            name: "local-api".into(),
+            definition: stdio,
+            overwrite: false,
+            env: env_map,
+            bearer_token: None,
+        })
+        .expect("add stdio server");
+
+    let mut http = streamable_definition("https://example.test/runtime-api", http_env_key);
+    http.description = Some("http runtime".into());
+    http.tags = vec!["remote".into()];
+    http.tools = Some(McpToolConfig {
+        enabled: vec!["alpha".into()],
+        disabled: vec!["beta".into()],
+    });
+    if let McpTransport::StreamableHttp(ref mut http_def) = http.transport {
+        http_def.headers.insert("X-Req".into(), "true".into());
+        http_def.request_timeout_ms = Some(2200);
+    }
+
+    manager
+        .add_server(AddServerRequest {
+            name: "remote-api".into(),
+            definition: http,
+            overwrite: false,
+            env: BTreeMap::new(),
+            bearer_token: None,
+        })
+        .expect("add http server");
+
+    let before = fs::read_to_string(manager.config_path()).expect("read config before");
+    let cwd = dir.path().join("cwd");
+
+    let defaults = StdioServerConfig {
+        binary: PathBuf::from("codex"),
+        code_home: Some(dir.path().to_path_buf()),
+        current_dir: Some(cwd.clone()),
+        env: vec![
+            (OsString::from("DEFAULT_ONLY"), OsString::from("default")),
+            (
+                OsString::from(request_env_key),
+                OsString::from("base-default"),
+            ),
+        ],
+        app_server_analytics_default_enabled: false,
+        mirror_stdio: true,
+        startup_timeout: Duration::from_secs(3),
+    };
+
+    let api = McpRuntimeApi::from_config(&manager, &defaults).expect("runtime api");
+
+    let available = api.available();
+    assert_eq!(available.len(), 2);
+
+    let stdio_summary = available
+        .iter()
+        .find(|entry| entry.name == "local-api")
+        .expect("stdio summary");
+    assert_eq!(stdio_summary.transport, McpRuntimeSummaryTransport::Stdio);
+    let stdio_tools = stdio_summary.tools.as_ref().expect("stdio tools");
+    assert_eq!(stdio_tools.enabled, vec!["fmt".to_string()]);
+    assert_eq!(stdio_tools.disabled, vec!["lint".to_string()]);
+
+    let stdio_launcher = api.stdio_launcher("local-api").expect("stdio launcher");
+    assert_eq!(stdio_launcher.args, vec!["--flag".to_string()]);
+    assert_eq!(stdio_launcher.timeout, Duration::from_millis(2400));
+    assert!(stdio_launcher.mirror_stdio);
+    assert_eq!(stdio_launcher.current_dir.as_deref(), Some(cwd.as_path()));
+
+    let env_map: HashMap<OsString, OsString> = stdio_launcher.env.into_iter().collect();
+    assert_eq!(
+        env_map.get(&OsString::from("CODEX_HOME")),
+        Some(&dir.path().as_os_str().to_os_string())
+    );
+    assert_eq!(
+        env_map.get(&OsString::from("DEFAULT_ONLY")),
+        Some(&OsString::from("default"))
+    );
+    assert_eq!(
+        env_map.get(&OsString::from(request_env_key)),
+        Some(&OsString::from("injected"))
+    );
+    assert_eq!(
+        env_map.get(&OsString::from(stdio_env_key)),
+        Some(&OsString::from("runtime-env"))
+    );
+
+    let http_connector = api.http_connector("remote-api").expect("http connector");
+    assert_eq!(http_connector.bearer_token.as_deref(), Some("token-api"));
+    assert_eq!(
+        http_connector
+            .headers
+            .get("Authorization")
+            .map(String::as_str),
+        Some("Bearer token-api")
+    );
+    assert_eq!(
+        http_connector.headers.get("X-Req").map(String::as_str),
+        Some("true")
+    );
+    assert_eq!(
+        http_connector.request_timeout,
+        Some(Duration::from_millis(2200))
+    );
+
+    let http_tools = available
+        .iter()
+        .find(|entry| entry.name == "remote-api")
+        .and_then(|entry| entry.tools.as_ref())
+        .expect("http tools");
+    assert_eq!(http_tools.enabled, vec!["alpha".to_string()]);
+    assert_eq!(http_tools.disabled, vec!["beta".to_string()]);
+
+    match api.stdio_launcher("remote-api") {
+        Err(McpRuntimeError::UnsupportedTransport {
+            name,
+            expected,
+            actual,
+        }) => {
+            assert_eq!(name, "remote-api");
+            assert_eq!(expected, "stdio");
+            assert_eq!(actual, "streamable_http");
+        }
+        other => panic!("unexpected result: {other:?}"),
+    }
+
+    match api.http_connector("local-api") {
+        Err(McpRuntimeError::UnsupportedTransport {
+            name,
+            expected,
+            actual,
+        }) => {
+            assert_eq!(name, "local-api");
+            assert_eq!(expected, "streamable_http");
+            assert_eq!(actual, "stdio");
+        }
+        other => panic!("unexpected http result: {other:?}"),
+    }
+
+    let after = fs::read_to_string(manager.config_path()).expect("read config after");
+    assert_eq!(before, after);
+
+    env::remove_var(http_env_key);
+    env::remove_var(request_env_key);
+}
+
+#[test]
+fn runtime_api_prepare_http_is_non_destructive() {
+    let (dir, manager) = temp_config_manager();
+    let env_var = "MCP_RUNTIME_API_PREPARE";
+    env::set_var(env_var, "prepare-token");
+
+    let mut http = streamable_definition("https://example.test/prepare", env_var);
+    http.tags = vec!["prepare".into()];
+    http.tools = Some(McpToolConfig {
+        enabled: vec!["delta".into()],
+        disabled: vec![],
+    });
+
+    manager
+        .add_server(AddServerRequest {
+            name: "prepare-http".into(),
+            definition: http,
+            overwrite: false,
+            env: BTreeMap::new(),
+            bearer_token: None,
+        })
+        .expect("add http server");
+
+    let before = fs::read_to_string(manager.config_path()).expect("read config before");
+
+    let defaults = StdioServerConfig {
+        binary: PathBuf::from("codex"),
+        code_home: Some(dir.path().to_path_buf()),
+        current_dir: None,
+        env: Vec::new(),
+        app_server_analytics_default_enabled: false,
+        mirror_stdio: false,
+        startup_timeout: Duration::from_secs(2),
+    };
+
+    let api = McpRuntimeApi::from_config(&manager, &defaults).expect("runtime api");
+    let handle = api.prepare("prepare-http").expect("prepare http");
+
+    match handle {
+        McpRuntimeHandle::StreamableHttp(http_handle) => {
+            assert_eq!(http_handle.name, "prepare-http");
+            assert_eq!(
+                http_handle.connector.bearer_token.as_deref(),
+                Some("prepare-token")
+            );
+            assert_eq!(
+                http_handle
+                    .connector
+                    .headers
+                    .get("Authorization")
+                    .map(String::as_str),
+                Some("Bearer prepare-token")
+            );
+            let tools = http_handle.tools.expect("tool hints");
+            assert_eq!(tools.enabled, vec!["delta".to_string()]);
+        }
+        other => panic!("expected http handle, got {other:?}"),
+    }
+
+    let after = fs::read_to_string(manager.config_path()).expect("read config after");
+    assert_eq!(before, after);
+
+    env::remove_var(env_var);
+}
+
+#[test]
+fn app_runtime_api_lists_and_merges_without_writes() {
+    let (dir, manager) = temp_config_manager();
+
+    let alpha_home = dir.path().join("app-home-a");
+    let alpha_cwd = dir.path().join("app-cwd-a");
+    let mut alpha_env = BTreeMap::new();
+    alpha_env.insert("APP_RUNTIME_ENV".into(), "alpha".into());
+    alpha_env.insert("OVERRIDE_ME".into(), "runtime".into());
+
+    manager
+        .add_app_runtime(AddAppRuntimeRequest {
+            name: "alpha".into(),
+            definition: AppRuntimeDefinition {
+                description: Some("local app".into()),
+                tags: vec!["local".into()],
+                env: alpha_env,
+                code_home: Some(alpha_home.clone()),
+                current_dir: Some(alpha_cwd.clone()),
+                mirror_stdio: Some(true),
+                startup_timeout_ms: Some(4200),
+                binary: Some(PathBuf::from("/bin/app-alpha")),
+                metadata: serde_json::json!({"thread": "t-alpha"}),
+            },
+            overwrite: false,
+        })
+        .expect("add alpha app runtime");
+
+    let mut beta_env = BTreeMap::new();
+    beta_env.insert("APP_RUNTIME_ENV".into(), "beta".into());
+
+    manager
+        .add_app_runtime(AddAppRuntimeRequest {
+            name: "beta".into(),
+            definition: AppRuntimeDefinition {
+                description: None,
+                tags: vec!["default".into()],
+                env: beta_env,
+                code_home: None,
+                current_dir: None,
+                mirror_stdio: None,
+                startup_timeout_ms: None,
+                binary: None,
+                metadata: serde_json::json!({"resume": true}),
+            },
+            overwrite: false,
+        })
+        .expect("add beta app runtime");
+
+    let before = fs::read_to_string(manager.config_path()).expect("read config before");
+
+    let default_home = dir.path().join("default-home");
+    let default_cwd = dir.path().join("default-cwd");
+    let defaults = StdioServerConfig {
+        binary: PathBuf::from("codex"),
+        code_home: Some(default_home.clone()),
+        current_dir: Some(default_cwd.clone()),
+        env: vec![
+            (OsString::from("DEFAULT_ONLY"), OsString::from("base")),
+            (OsString::from("OVERRIDE_ME"), OsString::from("base")),
+        ],
+        app_server_analytics_default_enabled: false,
+        mirror_stdio: false,
+        startup_timeout: Duration::from_secs(3),
+    };
+
+    let api = AppRuntimeApi::from_config(&manager, &defaults).expect("app runtime api");
+
+    let available = api.available();
+    assert_eq!(available.len(), 2);
+
+    let alpha_summary = available
+        .iter()
+        .find(|entry| entry.name == "alpha")
+        .expect("alpha summary");
+    assert_eq!(alpha_summary.description.as_deref(), Some("local app"));
+    assert_eq!(alpha_summary.tags, vec!["local".to_string()]);
+    assert_eq!(
+        alpha_summary.metadata,
+        serde_json::json!({"thread": "t-alpha"})
+    );
+
+    let alpha = api.prepare("alpha").expect("prepare alpha");
+    assert_eq!(alpha.name, "alpha");
+    assert_eq!(alpha.metadata, serde_json::json!({"thread": "t-alpha"}));
+    assert_eq!(alpha.config.binary, PathBuf::from("/bin/app-alpha"));
+    assert_eq!(
+        alpha.config.code_home.as_deref(),
+        Some(alpha_home.as_path())
+    );
+    assert_eq!(
+        alpha.config.current_dir.as_deref(),
+        Some(alpha_cwd.as_path())
+    );
+    assert!(alpha.config.mirror_stdio);
+    assert_eq!(alpha.config.startup_timeout, Duration::from_millis(4200));
+
+    let alpha_env: HashMap<OsString, OsString> = alpha.config.env.into_iter().collect();
+    assert_eq!(
+        alpha_env.get(&OsString::from("CODEX_HOME")),
+        Some(&alpha_home.as_os_str().to_os_string())
+    );
+    assert_eq!(
+        alpha_env.get(&OsString::from("DEFAULT_ONLY")),
+        Some(&OsString::from("base"))
+    );
+    assert_eq!(
+        alpha_env.get(&OsString::from("OVERRIDE_ME")),
+        Some(&OsString::from("runtime"))
+    );
+    assert_eq!(
+        alpha_env.get(&OsString::from("APP_RUNTIME_ENV")),
+        Some(&OsString::from("alpha"))
+    );
+
+    let beta = api.stdio_config("beta").expect("beta config");
+    assert_eq!(beta.binary, PathBuf::from("codex"));
+    assert_eq!(beta.code_home.as_deref(), Some(default_home.as_path()));
+    assert_eq!(beta.current_dir.as_deref(), Some(default_cwd.as_path()));
+    assert!(!beta.mirror_stdio);
+    assert_eq!(beta.startup_timeout, Duration::from_secs(3));
+
+    let beta_env: HashMap<OsString, OsString> = beta.env.into_iter().collect();
+    assert_eq!(
+        beta_env.get(&OsString::from("CODEX_HOME")),
+        Some(&default_home.as_os_str().to_os_string())
+    );
+    assert_eq!(
+        beta_env.get(&OsString::from("DEFAULT_ONLY")),
+        Some(&OsString::from("base"))
+    );
+    assert_eq!(
+        beta_env.get(&OsString::from("OVERRIDE_ME")),
+        Some(&OsString::from("base"))
+    );
+    assert_eq!(
+        beta_env.get(&OsString::from("APP_RUNTIME_ENV")),
+        Some(&OsString::from("beta"))
+    );
+
+    let beta_summary = available
+        .iter()
+        .find(|entry| entry.name == "beta")
+        .expect("beta summary");
+    assert_eq!(beta_summary.metadata, serde_json::json!({"resume": true}));
+
+    let after = fs::read_to_string(manager.config_path()).expect("read config after");
+    assert_eq!(before, after);
+}
+
+#[tokio::test]
+async fn app_runtime_lifecycle_starts_and_stops_without_mutation() {
+    let (config_dir, manager) = temp_config_manager();
+    let (_server_dir, server_path) = write_fake_app_server();
+    let code_home = config_dir.path().join("app-lifecycle-home");
+
+    let mut env_map = BTreeMap::new();
+    env_map.insert("APP_RUNTIME_LIFECYCLE".into(), "runtime-env".into());
+
+    let metadata = serde_json::json!({"resume_thread": "thread-lifecycle"});
+    manager
+        .add_app_runtime(AddAppRuntimeRequest {
+            name: "lifecycle".into(),
+            definition: AppRuntimeDefinition {
+                description: Some("app lifecycle".into()),
+                tags: vec!["app".into()],
+                env: env_map,
+                code_home: None,
+                current_dir: None,
+                mirror_stdio: Some(true),
+                startup_timeout_ms: Some(1500),
+                binary: None,
+                metadata: metadata.clone(),
+            },
+            overwrite: false,
+        })
+        .expect("add app runtime");
+
+    let defaults = StdioServerConfig {
+        binary: server_path.clone(),
+        code_home: Some(code_home.clone()),
+        current_dir: None,
+        env: vec![(
+            OsString::from("APP_RUNTIME_LIFECYCLE"),
+            OsString::from("default"),
+        )],
+        app_server_analytics_default_enabled: false,
+        mirror_stdio: false,
+        startup_timeout: Duration::from_secs(3),
+    };
+
+    let before = fs::read_to_string(manager.config_path()).expect("read config before");
+    let api = AppRuntimeApi::from_config(&manager, &defaults).expect("build api");
+    let client = test_client();
+
+    let runtime = api
+        .start("lifecycle", client.clone())
+        .await
+        .expect("start runtime");
+    assert_eq!(runtime.name, "lifecycle");
+    assert_eq!(runtime.metadata, metadata);
+
+    let env_values: HashMap<OsString, OsString> = runtime.config.env.iter().cloned().collect();
+    assert_eq!(
+        env_values.get(&OsString::from("CODEX_HOME")),
+        Some(&code_home.as_os_str().to_os_string())
+    );
+    assert_eq!(
+        env_values.get(&OsString::from("APP_RUNTIME_LIFECYCLE")),
+        Some(&OsString::from("runtime-env"))
+    );
+
+    let thread = runtime
+        .server
+        .thread_start(ThreadStartParams {
+            thread_id: None,
+            metadata: serde_json::json!({"from": "lifecycle"}),
+        })
+        .await
+        .expect("thread start");
+    let thread_response = time::timeout(Duration::from_secs(2), thread.response)
+        .await
+        .expect("thread response timeout")
+        .expect("recv thread response")
+        .expect("thread response ok");
+    let thread_id = thread_response
+        .get("thread_id")
+        .and_then(Value::as_str)
+        .unwrap_or_default()
+        .to_string();
+    assert!(!thread_id.is_empty());
+
+    runtime.stop().await.expect("shutdown runtime");
+
+    let after = fs::read_to_string(manager.config_path()).expect("read config after");
+    assert_eq!(before, after);
+
+    let prepared = api.prepare("lifecycle").expect("prepare after stop");
+    assert_eq!(prepared.metadata, metadata);
+}
+
+#[tokio::test]
+async fn app_runtime_api_not_found_errors() {
+    let api = AppRuntimeApi::new(Vec::new());
+    match api.prepare("missing") {
+        Err(AppRuntimeError::NotFound(name)) => assert_eq!(name, "missing"),
+        other => panic!("unexpected result: {other:?}"),
+    }
+
+    let client = test_client();
+    match api.start("missing", client).await {
+        Err(AppRuntimeError::NotFound(name)) => assert_eq!(name, "missing"),
+        other => panic!("unexpected start result: {other:?}"),
+    }
+}
+
+#[tokio::test]
+async fn app_runtime_pool_api_reuses_and_restarts_stdio() {
+    let (config_dir, manager) = temp_config_manager();
+    let (_server_dir, server_path) = write_fake_app_server();
+    let code_home = config_dir.path().join("app-pool-home");
+
+    let mut env_map = BTreeMap::new();
+    env_map.insert("APP_POOL_ENV".into(), "runtime".into());
+
+    let metadata = serde_json::json!({"resume_thread": "thread-pool"});
+    manager
+        .add_app_runtime(AddAppRuntimeRequest {
+            name: "pooled".into(),
+            definition: AppRuntimeDefinition {
+                description: Some("pooled app".into()),
+                tags: vec!["pool".into()],
+                env: env_map,
+                code_home: None,
+                current_dir: None,
+                mirror_stdio: Some(true),
+                startup_timeout_ms: Some(2000),
+                binary: None,
+                metadata: metadata.clone(),
+            },
+            overwrite: false,
+        })
+        .expect("add app runtime");
+
+    let defaults = StdioServerConfig {
+        binary: server_path.clone(),
+        code_home: Some(code_home.clone()),
+        current_dir: None,
+        env: vec![
+            (OsString::from("APP_POOL_ENV"), OsString::from("default")),
+            (OsString::from("POOL_ONLY"), OsString::from("base")),
+        ],
+        app_server_analytics_default_enabled: false,
+        mirror_stdio: false,
+        startup_timeout: Duration::from_secs(3),
+    };
+
+    let before = fs::read_to_string(manager.config_path()).expect("read config before");
+    let api = AppRuntimePoolApi::from_config(&manager, &defaults).expect("build pool api");
+    let client = test_client();
+
+    let available = api.available();
+    assert_eq!(available.len(), 1);
+    let pooled_summary = &available[0];
+    assert_eq!(pooled_summary.name, "pooled");
+    assert_eq!(pooled_summary.metadata, metadata);
+
+    let launcher = api.launcher("pooled").expect("pooled launcher");
+    assert_eq!(launcher.description.as_deref(), Some("pooled app"));
+    assert_eq!(launcher.metadata, metadata);
+
+    let launcher_config = launcher.config.clone();
+    assert_eq!(launcher_config.binary, server_path);
+    assert_eq!(
+        launcher_config.code_home.as_deref(),
+        Some(code_home.as_path())
+    );
+    assert_eq!(launcher_config.startup_timeout, Duration::from_secs(2));
+
+    let launcher_env: HashMap<OsString, OsString> = launcher_config.env.into_iter().collect();
+    assert_eq!(
+        launcher_env.get(&OsString::from("CODEX_HOME")),
+        Some(&code_home.as_os_str().to_os_string())
+    );
+    assert_eq!(
+        launcher_env.get(&OsString::from("POOL_ONLY")),
+        Some(&OsString::from("base"))
+    );
+    assert_eq!(
+        launcher_env.get(&OsString::from("APP_POOL_ENV")),
+        Some(&OsString::from("runtime"))
+    );
+
+    let stdio_config = api
+        .stdio_config("pooled")
+        .expect("pooled stdio config without starting");
+    assert_eq!(stdio_config.binary, server_path);
+    assert_eq!(stdio_config.code_home.as_deref(), Some(code_home.as_path()));
+    let stdio_env: HashMap<OsString, OsString> = stdio_config.env.into_iter().collect();
+    assert_eq!(
+        stdio_env.get(&OsString::from("POOL_ONLY")),
+        Some(&OsString::from("base"))
+    );
+    assert_eq!(
+        stdio_env.get(&OsString::from("CODEX_HOME")),
+        Some(&code_home.as_os_str().to_os_string())
+    );
+    assert_eq!(
+        stdio_env.get(&OsString::from("APP_POOL_ENV")),
+        Some(&OsString::from("runtime"))
+    );
+
+    assert!(api.running().await.is_empty());
+
+    let runtime = api
+        .start("pooled", client.clone())
+        .await
+        .expect("start pooled runtime");
+    assert_eq!(runtime.name, "pooled");
+    assert_eq!(runtime.metadata, metadata);
+
+    let env_values: HashMap<OsString, OsString> = runtime.config.env.iter().cloned().collect();
+    assert_eq!(
+        env_values.get(&OsString::from("CODEX_HOME")),
+        Some(&code_home.as_os_str().to_os_string())
+    );
+    assert_eq!(
+        env_values.get(&OsString::from("POOL_ONLY")),
+        Some(&OsString::from("base"))
+    );
+    assert_eq!(
+        env_values.get(&OsString::from("APP_POOL_ENV")),
+        Some(&OsString::from("runtime"))
+    );
+
+    let thread = runtime
+        .server
+        .thread_start(ThreadStartParams {
+            thread_id: None,
+            metadata: serde_json::json!({"from": "pool"}),
+        })
+        .await
+        .expect("thread start");
+    let response = time::timeout(Duration::from_secs(2), thread.response)
+        .await
+        .expect("thread response timeout")
+        .expect("recv thread response")
+        .expect("thread response ok");
+    let thread_id = response
+        .get("thread_id")
+        .and_then(Value::as_str)
+        .unwrap_or_default()
+        .to_string();
+    assert!(!thread_id.is_empty());
+
+    let running = api.running().await;
+    let running_summary = running
+        .iter()
+        .find(|summary| summary.name == "pooled")
+        .expect("running summary present");
+    assert_eq!(running_summary.metadata, metadata);
+
+    let reused = api
+        .start("pooled", client.clone())
+        .await
+        .expect("reuse pooled runtime");
+    assert!(Arc::ptr_eq(&runtime, &reused));
+
+    api.stop("pooled").await.expect("stop pooled runtime");
+    match api.stop("pooled").await {
+        Err(AppRuntimeError::NotFound(name)) => assert_eq!(name, "pooled"),
+        other => panic!("expected not found on second stop, got {other:?}"),
+    }
+
+    assert!(api.running().await.is_empty());
+
+    let restarted = api
+        .start("pooled", client)
+        .await
+        .expect("restart pooled runtime");
+    assert!(!Arc::ptr_eq(&runtime, &restarted));
+    assert_eq!(restarted.metadata, metadata);
+
+    let prepared = api.prepare("pooled").expect("prepare after restart");
+    assert_eq!(prepared.metadata, metadata);
+
+    let after = fs::read_to_string(manager.config_path()).expect("read config after");
+    assert_eq!(before, after);
+}
+
+#[tokio::test]
+async fn app_runtime_pool_api_stop_all_shuts_down_runtimes() {
+    let (config_dir, manager) = temp_config_manager();
+    let (_server_dir, server_path) = write_fake_app_server();
+    let code_home = config_dir.path().join("app-pool-stop-home");
+
+    let alpha_metadata = serde_json::json!({"resume_thread": "alpha"});
+    manager
+        .add_app_runtime(AddAppRuntimeRequest {
+            name: "alpha".into(),
+            definition: AppRuntimeDefinition {
+                description: Some("alpha runtime".into()),
+                tags: vec!["pool".into()],
+                env: BTreeMap::new(),
+                code_home: None,
+                current_dir: None,
+                mirror_stdio: Some(false),
+                startup_timeout_ms: Some(2000),
+                binary: None,
+                metadata: alpha_metadata.clone(),
+            },
+            overwrite: false,
+        })
+        .expect("add alpha runtime");
+
+    let beta_metadata = serde_json::json!({"resume_thread": "beta"});
+    manager
+        .add_app_runtime(AddAppRuntimeRequest {
+            name: "beta".into(),
+            definition: AppRuntimeDefinition {
+                description: Some("beta runtime".into()),
+                tags: vec!["pool".into()],
+                env: BTreeMap::new(),
+                code_home: None,
+                current_dir: None,
+                mirror_stdio: Some(false),
+                startup_timeout_ms: Some(2000),
+                binary: None,
+                metadata: beta_metadata.clone(),
+            },
+            overwrite: false,
+        })
+        .expect("add beta runtime");
+
+    let defaults = StdioServerConfig {
+        binary: server_path.clone(),
+        code_home: Some(code_home.clone()),
+        current_dir: None,
+        env: Vec::new(),
+        app_server_analytics_default_enabled: false,
+        mirror_stdio: false,
+        startup_timeout: Duration::from_secs(3),
+    };
+
+    let before = fs::read_to_string(manager.config_path()).expect("read config before");
+    let api = AppRuntimePoolApi::from_config(&manager, &defaults).expect("build pool api");
+    let client = test_client();
+
+    assert!(api.running().await.is_empty());
+
+    let alpha = api
+        .start("alpha", client.clone())
+        .await
+        .expect("start alpha runtime");
+    let beta = api
+        .start("beta", client.clone())
+        .await
+        .expect("start beta runtime");
+
+    assert_eq!(alpha.metadata, alpha_metadata);
+    assert_eq!(beta.metadata, beta_metadata);
+
+    let mut running = api.running().await;
+    running.sort_by(|a, b| a.name.cmp(&b.name));
+    assert_eq!(running.len(), 2);
+    assert_eq!(running[0].name, "alpha");
+    assert_eq!(running[0].metadata, alpha_metadata);
+    assert_eq!(running[1].name, "beta");
+    assert_eq!(running[1].metadata, beta_metadata);
+
+    let alpha_thread = alpha
+        .server
+        .thread_start(ThreadStartParams {
+            thread_id: None,
+            metadata: serde_json::json!({"from": "alpha"}),
+        })
+        .await
+        .expect("alpha thread start");
+    let _ = time::timeout(Duration::from_secs(2), alpha_thread.response)
+        .await
+        .expect("alpha thread response timeout")
+        .expect("alpha response recv")
+        .expect("alpha ok");
+
+    api.stop_all().await.expect("stop all runtimes");
+    assert!(api.running().await.is_empty());
+
+    let restarted_alpha = api
+        .start("alpha", client.clone())
+        .await
+        .expect("restart alpha");
+    assert!(!Arc::ptr_eq(&alpha, &restarted_alpha));
+    assert_eq!(restarted_alpha.metadata, alpha_metadata);
+
+    let restarted_beta = api.start("beta", client).await.expect("restart beta");
+    assert!(!Arc::ptr_eq(&beta, &restarted_beta));
+    assert_eq!(restarted_beta.metadata, beta_metadata);
+
+    let prepared_alpha = api.prepare("alpha").expect("prepare alpha");
+    assert_eq!(prepared_alpha.metadata, alpha_metadata);
+    let prepared_beta = api.prepare("beta").expect("prepare beta");
+    assert_eq!(prepared_beta.metadata, beta_metadata);
+
+    let after = fs::read_to_string(manager.config_path()).expect("read config after");
+    assert_eq!(before, after);
+}
+
+#[tokio::test]
+async fn runtime_manager_starts_and_stops_stdio() {
+    let (_dir, script) = write_env_probe_server("MCP_RUNTIME_ENV_E8");
+    let code_home = tempfile::tempdir().expect("code_home");
+
+    let defaults = StdioServerConfig {
+        binary: PathBuf::from("codex"),
+        code_home: Some(code_home.path().to_path_buf()),
+        current_dir: None,
+        env: vec![(
+            OsString::from("MCP_RUNTIME_ENV_E8"),
+            OsString::from("manager-ok"),
+        )],
+        app_server_analytics_default_enabled: false,
+        mirror_stdio: false,
+        startup_timeout: Duration::from_secs(5),
+    };
+
+    let runtime = McpRuntimeServer {
+        name: "env-probe".into(),
+        transport: McpRuntimeTransport::Stdio(StdioServerDefinition {
+            command: script.to_string_lossy().to_string(),
+            args: Vec::new(),
+            env: BTreeMap::new(),
+            timeout_ms: Some(1500),
+        }),
+        description: None,
+        tags: vec!["local".into()],
+        tools: Some(McpToolConfig {
+            enabled: vec!["tool-x".into()],
+            disabled: vec![],
+        }),
+    };
+
+    let launcher = runtime.into_launcher(&defaults);
+    let manager = McpRuntimeManager::new(vec![launcher]);
+
+    let mut handle = match manager.prepare("env-probe").expect("prepare stdio") {
+        McpRuntimeHandle::Stdio(handle) => handle,
+        other => panic!("expected stdio handle, got {other:?}"),
+    };
+
+    let mut reader = BufReader::new(handle.stdout_mut());
+    let mut line = String::new();
+    let _ = time::timeout(Duration::from_secs(2), reader.read_line(&mut line))
+        .await
+        .expect("read timeout")
+        .expect("read env line");
+    assert_eq!(line.trim(), "manager-ok");
+
+    let tools = handle.tools().expect("tool hints");
+    assert_eq!(tools.enabled, vec!["tool-x".to_string()]);
+
+    handle.stop().await.expect("stop server");
+}
+
+#[test]
+fn runtime_manager_propagates_tool_hints_for_http() {
+    let env_var = "MCP_HTTP_TOKEN_E8_HINTS";
+    env::set_var(env_var, "token-hints");
+
+    let mut http = StreamableHttpDefinition {
+        url: "https://example.test/hints".into(),
+        headers: BTreeMap::new(),
+        bearer_env_var: Some(env_var.to_string()),
+        connect_timeout_ms: Some(1200),
+        request_timeout_ms: Some(2400),
+    };
+    http.headers.insert("X-Test".into(), "true".into());
+
+    let runtime = McpRuntimeServer::from_definition(
+        "remote-http",
+        McpServerDefinition {
+            transport: McpTransport::StreamableHttp(http),
+            description: Some("http runtime".into()),
+            tags: vec!["http".into()],
+            tools: Some(McpToolConfig {
+                enabled: vec!["alpha".into()],
+                disabled: vec!["beta".into()],
+            }),
+        },
+    );
+
+    let defaults = StdioServerConfig {
+        binary: PathBuf::from("codex"),
+        code_home: None,
+        current_dir: None,
+        env: Vec::new(),
+        app_server_analytics_default_enabled: false,
+        mirror_stdio: false,
+        startup_timeout: Duration::from_secs(2),
+    };
+
+    let launcher = runtime.into_launcher(&defaults);
+    let manager = McpRuntimeManager::new(vec![launcher]);
+
+    let available = manager.available();
+    assert_eq!(available.len(), 1);
+    let summary = &available[0];
+    assert_eq!(summary.name, "remote-http");
+    assert_eq!(
+        summary.transport,
+        McpRuntimeSummaryTransport::StreamableHttp
+    );
+    let summary_tools = summary.tools.as_ref().expect("tool hints present");
+    assert_eq!(summary_tools.enabled, vec!["alpha".to_string()]);
+    assert_eq!(summary_tools.disabled, vec!["beta".to_string()]);
+
+    match manager.prepare("remote-http").expect("prepare http") {
+        McpRuntimeHandle::StreamableHttp(http_handle) => {
+            let tools = http_handle.tools.as_ref().expect("tool hints on handle");
+            assert_eq!(tools.enabled, vec!["alpha".to_string()]);
+            assert_eq!(tools.disabled, vec!["beta".to_string()]);
+            assert_eq!(
+                http_handle.connector.bearer_token.as_deref(),
+                Some("token-hints")
+            );
+        }
+        other => panic!("expected http handle, got {other:?}"),
+    }
+
+    env::remove_var(env_var);
+}
+
+#[test]
+fn http_connector_retrieval_is_non_destructive() {
+    let env_var = "MCP_HTTP_TOKEN_E8_REUSE";
+    env::set_var(env_var, "token-reuse");
+
+    let runtime = McpRuntimeServer::from_definition(
+        "remote-reuse",
+        McpServerDefinition {
+            transport: McpTransport::StreamableHttp(StreamableHttpDefinition {
+                url: "https://example.test/reuse".into(),
+                headers: BTreeMap::new(),
+                bearer_env_var: Some(env_var.to_string()),
+                connect_timeout_ms: Some(1500),
+                request_timeout_ms: Some(3200),
+            }),
+            description: None,
+            tags: vec!["http".into()],
+            tools: Some(McpToolConfig {
+                enabled: vec!["one".into()],
+                disabled: vec![],
+            }),
+        },
+    );
+
+    let defaults = StdioServerConfig {
+        binary: PathBuf::from("codex"),
+        code_home: None,
+        current_dir: None,
+        env: Vec::new(),
+        app_server_analytics_default_enabled: false,
+        mirror_stdio: false,
+        startup_timeout: Duration::from_secs(2),
+    };
+
+    let launcher = runtime.into_launcher(&defaults);
+    let manager = McpRuntimeManager::new(vec![launcher]);
+
+    let first = manager.prepare("remote-reuse").expect("first prepare");
+    let second = manager.prepare("remote-reuse").expect("second prepare");
+
+    let first_token = match first {
+        McpRuntimeHandle::StreamableHttp(handle) => handle.connector.bearer_token,
+        other => panic!("expected http handle, got {other:?}"),
+    };
+    let second_token = match second {
+        McpRuntimeHandle::StreamableHttp(handle) => handle.connector.bearer_token,
+        other => panic!("expected http handle, got {other:?}"),
+    };
+
+    assert_eq!(first_token.as_deref(), Some("token-reuse"));
+    assert_eq!(second_token.as_deref(), Some("token-reuse"));
+
+    let summary = manager
+        .available()
+        .into_iter()
+        .find(|s| s.name == "remote-reuse")
+        .expect("summary present");
+    assert_eq!(
+        summary.transport,
+        McpRuntimeSummaryTransport::StreamableHttp
+    );
+    let tools = summary.tools.as_ref().expect("tool hints preserved");
+    assert_eq!(tools.enabled, vec!["one".to_string()]);
+
+    env::remove_var(env_var);
+}
diff --git a/crates/codex/src/process.rs b/crates/codex/src/process.rs
new file mode 100644
index 0000000..b9b7975
--- /dev/null
+++ b/crates/codex/src/process.rs
@@ -0,0 +1,111 @@
+use std::{
+    io::{self, Write},
+    path::Path,
+    process::ExitStatus,
+    time::Duration,
+};
+
+use tokio::{
+    io::{AsyncRead, AsyncReadExt},
+    process::Command,
+    task,
+};
+
+use crate::CodexError;
+
+#[derive(Clone, Copy)]
+pub(crate) enum ConsoleTarget {
+    Stdout,
+    Stderr,
+}
+
+pub(crate) async fn tee_stream<R>(
+    mut reader: R,
+    target: ConsoleTarget,
+    mirror_console: bool,
+) -> Result<Vec<u8>, io::Error>
+where
+    R: AsyncRead + Unpin,
+{
+    let mut buffer = Vec::new();
+    let mut chunk = [0u8; 4096];
+    loop {
+        let n = reader.read(&mut chunk).await?;
+        if n == 0 {
+            break;
+        }
+        if mirror_console {
+            task::block_in_place(|| match target {
+                ConsoleTarget::Stdout => {
+                    let mut out = io::stdout();
+                    out.write_all(&chunk[..n])?;
+                    out.flush()
+                }
+                ConsoleTarget::Stderr => {
+                    let mut out = io::stderr();
+                    out.write_all(&chunk[..n])?;
+                    out.flush()
+                }
+            })?;
+        }
+        buffer.extend_from_slice(&chunk[..n]);
+    }
+    Ok(buffer)
+}
+
+pub(crate) fn spawn_with_retry(
+    command: &mut Command,
+    binary: &Path,
+) -> Result<tokio::process::Child, CodexError> {
+    let mut backoff = Duration::from_millis(2);
+    for attempt in 0..5 {
+        match command.spawn() {
+            Ok(child) => return Ok(child),
+            Err(source) => {
+                let is_busy = matches!(source.kind(), std::io::ErrorKind::ExecutableFileBusy)
+                    || source.raw_os_error() == Some(26);
+                if is_busy && attempt < 4 {
+                    std::thread::sleep(backoff);
+                    backoff = std::cmp::min(backoff * 2, Duration::from_millis(50));
+                    continue;
+                }
+                return Err(CodexError::Spawn {
+                    binary: binary.to_path_buf(),
+                    source,
+                });
+            }
+        }
+    }
+
+    unreachable!("spawn_with_retry should return before exhausting retries")
+}
+
+pub(crate) fn command_output_text(output: &CommandOutput) -> String {
+    let stdout = String::from_utf8_lossy(&output.stdout).into_owned();
+    let stderr = String::from_utf8_lossy(&output.stderr).into_owned();
+    let stdout = stdout.trim_end();
+    let stderr = stderr.trim_end();
+    if stdout.is_empty() {
+        stderr.to_string()
+    } else if stderr.is_empty() {
+        stdout.to_string()
+    } else {
+        format!("{stdout}\n{stderr}")
+    }
+}
+
+pub(crate) fn preferred_output_channel(output: &CommandOutput) -> String {
+    let stderr = String::from_utf8(output.stderr.clone()).unwrap_or_default();
+    let stdout = String::from_utf8(output.stdout.clone()).unwrap_or_default();
+    if stderr.trim().is_empty() {
+        stdout
+    } else {
+        stderr
+    }
+}
+
+pub(crate) struct CommandOutput {
+    pub(crate) status: ExitStatus,
+    pub(crate) stdout: Vec<u8>,
+    pub(crate) stderr: Vec<u8>,
+}
diff --git a/crates/codex/src/tests.rs b/crates/codex/src/tests.rs
new file mode 100644
index 0000000..e968684
--- /dev/null
+++ b/crates/codex/src/tests.rs
@@ -0,0 +1,3555 @@
+use super::*;
+use crate::auth::parse_login_success;
+use crate::builder::ResolvedCliOverrides;
+use crate::defaults::{
+    default_binary_path, default_rust_log_value, CODEX_BINARY_ENV, CODEX_HOME_ENV,
+    DEFAULT_RUST_LOG, DEFAULT_TIMEOUT, RUST_LOG_ENV,
+};
+use futures_util::{pin_mut, StreamExt};
+use semver::Version;
+use serde_json::json;
+use std::collections::HashMap;
+use std::env;
+use std::fs as std_fs;
+#[cfg(unix)]
+use std::os::unix::fs::PermissionsExt;
+use std::sync::OnceLock;
+use std::time::{Duration, SystemTime};
+use tokio::{
+    fs,
+    io::{AsyncBufReadExt, AsyncWriteExt, BufReader},
+};
+
+fn env_mutex() -> &'static tokio::sync::Mutex<()> {
+    static ENV_MUTEX: OnceLock<tokio::sync::Mutex<()>> = OnceLock::new();
+    ENV_MUTEX.get_or_init(|| tokio::sync::Mutex::new(()))
+}
+
+fn env_guard() -> tokio::sync::MutexGuard<'static, ()> {
+    env_mutex().blocking_lock()
+}
+
+async fn env_guard_async() -> tokio::sync::MutexGuard<'static, ()> {
+    env_mutex().lock().await
+}
+
+#[tokio::test]
+async fn json_stream_preserves_order_and_parses_tool_calls() {
+    let lines = [
+        r#"{"type":"thread.started","thread_id":"thread-1"}"#.to_string(),
+        serde_json::to_string(&json!({
+            "type": "item.started",
+            "thread_id": "thread-1",
+            "turn_id": "turn-1",
+            "item_id": "item-1",
+            "item_type": "mcp_tool_call",
+            "content": {
+                "server_name": "files",
+                "tool_name": "list",
+                "status": "running"
+            }
+        }))
+        .unwrap(),
+        serde_json::to_string(&json!({
+            "type": "item.delta",
+            "thread_id": "thread-1",
+            "turn_id": "turn-1",
+            "item_id": "item-1",
+            "item_type": "mcp_tool_call",
+            "delta": {
+                "result": {"paths": ["foo.rs"]},
+                "status": "completed"
+            }
+        }))
+        .unwrap(),
+    ];
+
+    let (mut writer, reader) = tokio::io::duplex(4096);
+    let (tx, rx) = mpsc::channel(8);
+    let forward_handle = tokio::spawn(crate::jsonl::forward_json_events(reader, tx, false, None));
+
+    for line in &lines {
+        writer.write_all(line.as_bytes()).await.unwrap();
+        writer.write_all(b"\n").await.unwrap();
+    }
+    writer.shutdown().await.unwrap();
+
+    let stream = crate::jsonl::EventChannelStream::new(rx, None);
+    pin_mut!(stream);
+    let events: Vec<_> = stream.collect().await;
+    forward_handle.await.unwrap().unwrap();
+
+    assert_eq!(events.len(), lines.len(), "events: {events:?}");
+
+    match &events[0] {
+        Ok(ThreadEvent::ThreadStarted(event)) => {
+            assert_eq!(event.thread_id, "thread-1");
+        }
+        other => panic!("unexpected first event: {other:?}"),
+    }
+
+    match &events[1] {
+        Ok(ThreadEvent::ItemStarted(envelope)) => {
+            assert_eq!(envelope.thread_id, "thread-1");
+            assert_eq!(envelope.turn_id, "turn-1");
+            match &envelope.item.payload {
+                ItemPayload::McpToolCall(state) => {
+                    assert_eq!(state.server_name, "files");
+                    assert_eq!(state.tool_name, "list");
+                    assert_eq!(state.status, ToolCallStatus::Running);
+                }
+                other => panic!("unexpected payload: {other:?}"),
+            }
+        }
+        other => panic!("unexpected second event: {other:?}"),
+    }
+
+    match &events[2] {
+        Ok(ThreadEvent::ItemDelta(delta)) => {
+            assert_eq!(delta.item_id, "item-1");
+            match &delta.delta {
+                ItemDeltaPayload::McpToolCall(call_delta) => {
+                    assert_eq!(call_delta.status, ToolCallStatus::Completed);
+                    let result = call_delta
+                        .result
+                        .as_ref()
+                        .expect("tool call delta result is captured");
+                    assert_eq!(result["paths"][0], "foo.rs");
+                }
+                other => panic!("unexpected delta payload: {other:?}"),
+            }
+        }
+        other => panic!("unexpected third event: {other:?}"),
+    }
+}
+
+#[tokio::test]
+async fn json_stream_propagates_parse_errors() {
+    let (mut writer, reader) = tokio::io::duplex(1024);
+    let (tx, rx) = mpsc::channel(4);
+    let forward_handle = tokio::spawn(crate::jsonl::forward_json_events(reader, tx, false, None));
+
+    writer
+        .write_all(br#"{"type":"thread.started","thread_id":"thread-err"}"#)
+        .await
+        .unwrap();
+    writer.write_all(b"\nthis is not json\n").await.unwrap();
+    writer.shutdown().await.unwrap();
+
+    let stream = crate::jsonl::EventChannelStream::new(rx, None);
+    pin_mut!(stream);
+    let events: Vec<_> = stream.collect().await;
+    forward_handle.await.unwrap().unwrap();
+
+    assert_eq!(events.len(), 2);
+    assert!(matches!(
+        events[0],
+        Ok(ThreadEvent::ThreadStarted(ThreadStarted { ref thread_id, .. }))
+            if thread_id == "thread-err"
+    ));
+    match &events[1] {
+        Err(ExecStreamError::Parse { line, .. }) => assert_eq!(line, "this is not json"),
+        other => panic!("expected parse error, got {other:?}"),
+    }
+}
+
+#[tokio::test]
+async fn json_stream_tees_logs_before_forwarding() {
+    let lines = [
+        r#"{"type":"thread.started","thread_id":"tee-thread"}"#.to_string(),
+        r#"{"type":"turn.started","thread_id":"tee-thread","turn_id":"turn-tee"}"#.to_string(),
+    ];
+
+    let dir = tempfile::tempdir().unwrap();
+    let log_path = dir.path().join("events.log");
+
+    let (mut writer, reader) = tokio::io::duplex(2048);
+    let (tx, rx) = mpsc::channel(4);
+    let log_sink = crate::jsonl::JsonLogSink::new(log_path.clone())
+        .await
+        .unwrap();
+    let forward_handle = tokio::spawn(crate::jsonl::forward_json_events(
+        reader,
+        tx,
+        false,
+        Some(log_sink),
+    ));
+
+    let stream = crate::jsonl::EventChannelStream::new(rx, None);
+    pin_mut!(stream);
+
+    writer.write_all(lines[0].as_bytes()).await.unwrap();
+    writer.write_all(b"\n").await.unwrap();
+
+    let first = stream.next().await.unwrap().unwrap();
+    assert!(matches!(first, ThreadEvent::ThreadStarted(_)));
+
+    let logged = fs::read_to_string(&log_path).await.unwrap();
+    assert_eq!(logged, format!("{}\n", lines[0]));
+
+    writer.write_all(lines[1].as_bytes()).await.unwrap();
+    writer.write_all(b"\n").await.unwrap();
+    writer.shutdown().await.unwrap();
+
+    let second = stream.next().await.unwrap().unwrap();
+    assert!(matches!(second, ThreadEvent::TurnStarted(_)));
+    assert!(stream.next().await.is_none());
+
+    forward_handle.await.unwrap().unwrap();
+
+    let final_log = fs::read_to_string(&log_path).await.unwrap();
+    assert_eq!(final_log, format!("{}\n{}\n", lines[0], lines[1]));
+}
+
+#[tokio::test]
+async fn json_event_log_captures_apply_diff_and_tool_payloads() {
+    let diff = "@@ -1 +1 @@\n-fn foo() {}\n+fn bar() {}";
+    let lines = vec![
+        r#"{"type":"thread.started","thread_id":"log-thread"}"#.to_string(),
+        serde_json::to_string(&json!({
+            "type": "item.started",
+            "thread_id": "log-thread",
+            "turn_id": "turn-log",
+            "item_id": "apply-1",
+            "item_type": "file_change",
+            "content": {
+                "path": "src/main.rs",
+                "change": "apply",
+                "diff": diff,
+                "stdout": "patched\n"
+            }
+        }))
+        .unwrap(),
+        serde_json::to_string(&json!({
+            "type": "item.delta",
+            "thread_id": "log-thread",
+            "turn_id": "turn-log",
+            "item_id": "apply-1",
+            "item_type": "file_change",
+            "delta": {
+                "diff": diff,
+                "stderr": "warning",
+                "exit_code": 2
+            }
+        }))
+        .unwrap(),
+        serde_json::to_string(&json!({
+            "type": "item.delta",
+            "thread_id": "log-thread",
+            "turn_id": "turn-log",
+            "item_id": "tool-1",
+            "item_type": "mcp_tool_call",
+            "delta": {
+                "result": {"paths": ["a.rs", "b.rs"]},
+                "status": "completed"
+            }
+        }))
+        .unwrap(),
+    ];
+
+    let dir = tempfile::tempdir().unwrap();
+    let log_path = dir.path().join("json.log");
+
+    let (mut writer, reader) = tokio::io::duplex(4096);
+    let (tx, rx) = mpsc::channel(8);
+    let log_sink = crate::jsonl::JsonLogSink::new(log_path.clone())
+        .await
+        .unwrap();
+    let forward_handle = tokio::spawn(crate::jsonl::forward_json_events(
+        reader,
+        tx,
+        false,
+        Some(log_sink),
+    ));
+
+    for line in &lines {
+        writer.write_all(line.as_bytes()).await.unwrap();
+        writer.write_all(b"\n").await.unwrap();
+    }
+    writer.shutdown().await.unwrap();
+
+    let stream = crate::jsonl::EventChannelStream::new(rx, None);
+    pin_mut!(stream);
+    let events: Vec<_> = stream.collect().await;
+    forward_handle.await.unwrap().unwrap();
+
+    assert_eq!(events.len(), lines.len());
+
+    let log_contents = fs::read_to_string(&log_path).await.unwrap();
+    assert_eq!(log_contents, lines.join("\n") + "\n");
+}
+
+#[tokio::test]
+async fn event_channel_stream_times_out_when_idle() {
+    let (_tx, rx) = mpsc::channel(1);
+    let stream = crate::jsonl::EventChannelStream::new(rx, Some(Duration::from_millis(5)));
+    pin_mut!(stream);
+
+    let next = stream.next().await;
+    match next {
+        Some(Err(ExecStreamError::IdleTimeout { idle_for })) => {
+            assert_eq!(idle_for, Duration::from_millis(5));
+        }
+        other => panic!("expected idle timeout, got {other:?}"),
+    }
+}
+
+fn write_executable(dir: &Path, name: &str, script: &str) -> PathBuf {
+    let path = dir.join(name);
+    std_fs::write(&path, script).unwrap();
+    let mut perms = std_fs::metadata(&path).unwrap().permissions();
+    #[cfg(unix)]
+    {
+        perms.set_mode(0o755);
+    }
+    std_fs::set_permissions(&path, perms).unwrap();
+    path
+}
+
+fn write_fake_codex(dir: &Path, script: &str) -> PathBuf {
+    write_executable(dir, "codex", script)
+}
+
+fn write_fake_bundled_codex(dir: &Path, platform: &str, script: &str) -> PathBuf {
+    write_executable(dir, bundled_binary_filename(platform), script)
+}
+
+#[test]
+fn resolve_bundled_binary_defaults_to_runtime_platform() {
+    let temp = tempfile::tempdir().unwrap();
+    let platform = default_bundled_platform_label();
+    let version = "1.2.3";
+    let version_dir = temp.path().join(&platform).join(version);
+    std_fs::create_dir_all(&version_dir).unwrap();
+    let binary = write_fake_bundled_codex(&version_dir, &platform, "#!/usr/bin/env bash\necho ok");
+
+    let resolved = resolve_bundled_binary(BundledBinarySpec {
+        bundle_root: temp.path(),
+        version,
+        platform: None,
+    })
+    .unwrap();
+
+    assert_eq!(resolved.platform, platform);
+    assert_eq!(resolved.version, version);
+    assert_eq!(resolved.binary_path, std_fs::canonicalize(&binary).unwrap());
+}
+
+#[test]
+fn resolve_bundled_binary_honors_platform_override() {
+    let temp = tempfile::tempdir().unwrap();
+    let platform = "windows-x64";
+    let version = "5.6.7";
+    let version_dir = temp.path().join(platform).join(version);
+    std_fs::create_dir_all(&version_dir).unwrap();
+    let binary = write_fake_bundled_codex(&version_dir, platform, "#!/usr/bin/env bash\necho win");
+
+    let resolved = resolve_bundled_binary(BundledBinarySpec {
+        bundle_root: temp.path(),
+        version,
+        platform: Some(platform),
+    })
+    .unwrap();
+
+    assert_eq!(resolved.platform, platform);
+    assert_eq!(resolved.version, version);
+    assert_eq!(resolved.binary_path, std_fs::canonicalize(&binary).unwrap());
+    assert_eq!(
+        resolved
+            .binary_path
+            .file_name()
+            .and_then(|name| name.to_str()),
+        Some("codex.exe")
+    );
+}
+
+#[test]
+fn resolve_bundled_binary_errors_when_binary_missing() {
+    let temp = tempfile::tempdir().unwrap();
+    let platform = default_bundled_platform_label();
+    let version = "0.0.1";
+    let version_dir = temp.path().join(&platform).join(version);
+    std_fs::create_dir_all(&version_dir).unwrap();
+
+    let err = resolve_bundled_binary(BundledBinarySpec {
+        bundle_root: temp.path(),
+        version,
+        platform: None,
+    })
+    .unwrap_err();
+
+    match err {
+        BundledBinaryError::BinaryUnreadable { binary, .. }
+        | BundledBinaryError::BinaryNotFile { binary }
+        | BundledBinaryError::BinaryNotExecutable { binary } => {
+            assert_eq!(binary, version_dir.join(bundled_binary_filename(&platform)));
+        }
+        other => panic!("unexpected error: {other:?}"),
+    }
+}
+
+#[test]
+fn resolve_bundled_binary_rejects_empty_version() {
+    let temp = tempfile::tempdir().unwrap();
+    let err = resolve_bundled_binary(BundledBinarySpec {
+        bundle_root: temp.path(),
+        version: "  ",
+        platform: None,
+    })
+    .unwrap_err();
+    assert!(matches!(err, BundledBinaryError::EmptyVersion));
+}
+
+#[cfg(unix)]
+#[tokio::test]
+async fn sandbox_maps_platform_flags_and_command() {
+    let dir = tempfile::tempdir().unwrap();
+    let script_path = write_fake_codex(
+        dir.path(),
+        r#"#!/usr/bin/env bash
+echo "$PWD"
+printf "%s\n" "$@"
+"#,
+    );
+
+    let client = CodexClient::builder()
+        .binary(&script_path)
+        .mirror_stdout(false)
+        .quiet(true)
+        .build();
+
+    let request = SandboxCommandRequest::new(
+        SandboxPlatform::Linux,
+        [OsString::from("echo"), OsString::from("hello world")],
+    )
+    .full_auto(true)
+    .log_denials(true)
+    .config_override("foo", "bar")
+    .enable_feature("alpha")
+    .disable_feature("beta");
+
+    let run = client.run_sandbox(request).await.unwrap();
+    let mut lines = run.stdout.lines();
+    let pwd = lines.next().unwrap();
+    assert_eq!(Path::new(pwd), env::current_dir().unwrap().as_path());
+
+    let args: Vec<_> = lines.map(str::to_string).collect();
+    assert!(!args.contains(&"--log-denials".to_string()));
+    assert_eq!(
+        args,
+        vec![
+            "sandbox",
+            "linux",
+            "--full-auto",
+            "--config",
+            "foo=bar",
+            "--enable",
+            "alpha",
+            "--disable",
+            "beta",
+            "--",
+            "echo",
+            "hello world"
+        ]
+    );
+    assert!(run.status.success());
+}
+
+#[cfg(unix)]
+#[tokio::test]
+async fn sandbox_includes_log_denials_on_macos() {
+    let dir = tempfile::tempdir().unwrap();
+    let script_path = write_fake_codex(
+        dir.path(),
+        r#"#!/usr/bin/env bash
+printf "%s\n" "$@"
+"#,
+    );
+
+    let client = CodexClient::builder()
+        .binary(&script_path)
+        .mirror_stdout(false)
+        .quiet(true)
+        .build();
+
+    let run = client
+        .run_sandbox(SandboxCommandRequest::new(SandboxPlatform::Macos, ["ls"]).log_denials(true))
+        .await
+        .unwrap();
+    let args: Vec<_> = run.stdout.lines().collect();
+    assert!(args.contains(&"--log-denials"));
+    assert_eq!(args[0], "sandbox");
+    assert_eq!(args[1], "macos");
+}
+
+#[cfg(unix)]
+#[tokio::test]
+async fn sandbox_honors_working_dir_precedence() {
+    let dir = tempfile::tempdir().unwrap();
+    let script_path = write_fake_codex(
+        dir.path(),
+        r#"#!/usr/bin/env bash
+echo "$PWD"
+"#,
+    );
+
+    let request_dir = dir.path().join("request_cwd");
+    let builder_dir = dir.path().join("builder_cwd");
+    std_fs::create_dir_all(&request_dir).unwrap();
+    std_fs::create_dir_all(&builder_dir).unwrap();
+
+    let client = CodexClient::builder()
+        .binary(&script_path)
+        .mirror_stdout(false)
+        .quiet(true)
+        .working_dir(&builder_dir)
+        .build();
+
+    let run_request = client
+        .run_sandbox(
+            SandboxCommandRequest::new(SandboxPlatform::Windows, ["echo", "cwd"])
+                .working_dir(&request_dir),
+        )
+        .await
+        .unwrap();
+    let request_pwd = run_request.stdout.lines().next().unwrap();
+    assert_eq!(Path::new(request_pwd), request_dir.as_path());
+
+    let run_builder = client
+        .run_sandbox(SandboxCommandRequest::new(
+            SandboxPlatform::Windows,
+            ["echo", "builder"],
+        ))
+        .await
+        .unwrap();
+    let builder_pwd = run_builder.stdout.lines().next().unwrap();
+    assert_eq!(Path::new(builder_pwd), builder_dir.as_path());
+
+    let client_default = CodexClient::builder()
+        .binary(&script_path)
+        .mirror_stdout(false)
+        .quiet(true)
+        .build();
+    let run_default = client_default
+        .run_sandbox(SandboxCommandRequest::new(
+            SandboxPlatform::Windows,
+            ["echo", "default"],
+        ))
+        .await
+        .unwrap();
+    let default_pwd = run_default.stdout.lines().next().unwrap();
+    assert_eq!(
+        Path::new(default_pwd),
+        env::current_dir().unwrap().as_path()
+    );
+}
+
+#[cfg(unix)]
+#[tokio::test]
+async fn sandbox_returns_non_zero_status_without_error() {
+    let dir = tempfile::tempdir().unwrap();
+    let script_path = write_fake_codex(
+        dir.path(),
+        r#"#!/usr/bin/env bash
+echo "failing"
+exit 7
+"#,
+    );
+
+    let client = CodexClient::builder()
+        .binary(&script_path)
+        .mirror_stdout(false)
+        .quiet(true)
+        .build();
+    let run = client
+        .run_sandbox(SandboxCommandRequest::new(
+            SandboxPlatform::Linux,
+            ["false"],
+        ))
+        .await
+        .unwrap();
+
+    assert!(!run.status.success());
+    assert_eq!(run.status.code(), Some(7));
+    assert_eq!(run.stdout.trim(), "failing");
+}
+
+#[cfg(unix)]
+#[tokio::test]
+async fn execpolicy_maps_policies_and_overrides() {
+    let dir = tempfile::tempdir().unwrap();
+    let script_path = dir.path().join("codex-execpolicy");
+    std_fs::write(
+        &script_path,
+        r#"#!/usr/bin/env bash
+printf "%s\n" "$PWD" "$@" 1>&2
+cat <<'JSON'
+{"match":{"decision":"prompt","rules":[{"name":"rule1","decision":"forbidden"}]}}
+JSON
+"#,
+    )
+    .unwrap();
+    let mut perms = std_fs::metadata(&script_path).unwrap().permissions();
+    perms.set_mode(0o755);
+    std_fs::set_permissions(&script_path, perms).unwrap();
+
+    let workdir = dir.path().join("workdir");
+    std_fs::create_dir_all(&workdir).unwrap();
+    let policy_one = dir.path().join("policy_a.codexpolicy");
+    let policy_two = dir.path().join("policy_b.codexpolicy");
+    std_fs::write(&policy_one, "").unwrap();
+    std_fs::write(&policy_two, "").unwrap();
+
+    let client = CodexClient::builder()
+        .binary(&script_path)
+        .mirror_stdout(false)
+        .quiet(true)
+        .working_dir(&workdir)
+        .approval_policy(ApprovalPolicy::OnRequest)
+        .build();
+
+    let result = client
+        .check_execpolicy(
+            ExecPolicyCheckRequest::new([
+                OsString::from("bash"),
+                OsString::from("-lc"),
+                OsString::from("echo ok"),
+            ])
+            .policies([&policy_one, &policy_two])
+            .pretty(true)
+            .profile("dev")
+            .config_override("features.execpolicy", "true"),
+        )
+        .await
+        .unwrap();
+
+    assert_eq!(result.decision(), Some(ExecPolicyDecision::Prompt));
+    let match_result = result.evaluation.match_result.unwrap();
+    assert_eq!(match_result.rules.len(), 1);
+    assert_eq!(match_result.rules[0].name.as_deref(), Some("rule1"));
+    assert_eq!(
+        match_result.rules[0].decision,
+        Some(ExecPolicyDecision::Forbidden)
+    );
+
+    let mut lines = result.stderr.lines();
+    let pwd = lines.next().unwrap();
+    assert_eq!(Path::new(pwd), workdir.as_path());
+
+    let args: Vec<_> = lines.map(str::to_string).collect();
+    assert_eq!(
+        args,
+        vec![
+            "execpolicy",
+            "check",
+            "--policy",
+            policy_one.to_string_lossy().as_ref(),
+            "--policy",
+            policy_two.to_string_lossy().as_ref(),
+            "--pretty",
+            "--config",
+            "features.execpolicy=true",
+            "--profile",
+            "dev",
+            "--ask-for-approval",
+            "on-request",
+            "--",
+            "bash",
+            "-lc",
+            "echo ok"
+        ]
+    );
+}
+
+#[tokio::test]
+async fn execpolicy_rejects_empty_command() {
+    let client = CodexClient::builder().build();
+    let request = ExecPolicyCheckRequest::new(Vec::<OsString>::new());
+    let err = client.check_execpolicy(request).await.unwrap_err();
+    assert!(matches!(err, CodexError::EmptyExecPolicyCommand));
+}
+
+#[cfg(unix)]
+#[tokio::test]
+async fn execpolicy_surfaces_parse_errors() {
+    let dir = tempfile::tempdir().unwrap();
+    let script_path = dir.path().join("codex-execpolicy-bad");
+    std_fs::write(
+        &script_path,
+        r#"#!/usr/bin/env bash
+echo "not-json"
+"#,
+    )
+    .unwrap();
+    let mut perms = std_fs::metadata(&script_path).unwrap().permissions();
+    perms.set_mode(0o755);
+    std_fs::set_permissions(&script_path, perms).unwrap();
+
+    let client = CodexClient::builder()
+        .binary(&script_path)
+        .mirror_stdout(false)
+        .quiet(true)
+        .build();
+
+    let err = client
+        .check_execpolicy(
+            ExecPolicyCheckRequest::new([OsString::from("echo"), OsString::from("noop")])
+                .policy(dir.path().join("policy.codexpolicy")),
+        )
+        .await
+        .unwrap_err();
+
+    match err {
+        CodexError::ExecPolicyParse { stdout, .. } => assert!(stdout.contains("not-json")),
+        other => panic!("expected ExecPolicyParse, got {other:?}"),
+    }
+}
+
+#[cfg(unix)]
+#[tokio::test]
+async fn features_list_maps_overrides_and_json_flag() {
+    let dir = tempfile::tempdir().unwrap();
+    let script_path = write_fake_codex(
+        dir.path(),
+        r#"#!/usr/bin/env bash
+echo "$PWD" 1>&2
+printf "%s\n" "$@" 1>&2
+cat <<'JSON'
+[{"name":"json-stream","stage":"stable","enabled":true},{"name":"cloud-exec","stage":"experimental","enabled":false}]
+JSON
+"#,
+    );
+
+    let workdir = dir.path().join("features-workdir");
+    std_fs::create_dir_all(&workdir).unwrap();
+
+    let client = CodexClient::builder()
+        .binary(&script_path)
+        .mirror_stdout(false)
+        .quiet(true)
+        .working_dir(&workdir)
+        .approval_policy(ApprovalPolicy::OnRequest)
+        .search(true)
+        .build();
+
+    let output = client
+        .list_features(
+            FeaturesListRequest::new()
+                .json(true)
+                .profile("dev")
+                .config_override("features.extras", "true"),
+        )
+        .await
+        .unwrap();
+
+    assert_eq!(output.format, FeaturesListFormat::Json);
+    assert_eq!(output.features.len(), 2);
+    assert_eq!(output.features[0].stage, Some(CodexFeatureStage::Stable));
+    assert!(output.features[0].enabled);
+    assert!(!output.features[1].enabled);
+
+    let mut lines = output.stderr.lines();
+    let pwd = lines.next().unwrap();
+    assert_eq!(Path::new(pwd), workdir.as_path());
+
+    let args: Vec<_> = lines.map(str::to_string).collect();
+    assert_eq!(
+        args,
+        vec![
+            "features",
+            "list",
+            "--config",
+            "features.extras=true",
+            "--profile",
+            "dev",
+            "--ask-for-approval",
+            "on-request",
+            "--search",
+            "--json"
+        ]
+    );
+}
+
+#[cfg(unix)]
+#[tokio::test]
+async fn supports_help_review_fork_resume_and_features_commands() {
+    let dir = tempfile::tempdir().unwrap();
+    let script_path = write_fake_codex(
+        dir.path(),
+        r#"#!/usr/bin/env bash
+printf "%s\n" "$@"
+"#,
+    );
+
+    let client = CodexClient::builder()
+        .binary(&script_path)
+        .mirror_stdout(false)
+        .quiet(true)
+        .build();
+
+    let features = client
+        .features(FeaturesCommandRequest::new())
+        .await
+        .unwrap();
+    assert_eq!(
+        features.stdout.lines().collect::<Vec<_>>(),
+        vec!["features"]
+    );
+
+    let help = client
+        .help(HelpCommandRequest::new(HelpScope::Root).command(["exec", "review"]))
+        .await
+        .unwrap();
+    assert_eq!(
+        help.stdout.lines().collect::<Vec<_>>(),
+        vec!["help", "exec", "review"]
+    );
+
+    let review = client
+        .review(
+            ReviewCommandRequest::new()
+                .base("main")
+                .commit("abc123")
+                .title("hello")
+                .uncommitted(true)
+                .prompt("please review"),
+        )
+        .await
+        .unwrap();
+    assert_eq!(
+        review.stdout.lines().collect::<Vec<_>>(),
+        vec![
+            "review",
+            "--base",
+            "main",
+            "--commit",
+            "abc123",
+            "--title",
+            "hello",
+            "--uncommitted",
+            "please review"
+        ]
+    );
+
+    let exec_review = client
+        .exec_review(
+            ExecReviewCommandRequest::new()
+                .base("main")
+                .commit("abc123")
+                .title("hello")
+                .uncommitted(true)
+                .json(true)
+                .prompt("please review"),
+        )
+        .await
+        .unwrap();
+    assert_eq!(
+        exec_review.stdout.lines().collect::<Vec<_>>(),
+        vec![
+            "exec",
+            "review",
+            "--base",
+            "main",
+            "--commit",
+            "abc123",
+            "--json",
+            "--skip-git-repo-check",
+            "--title",
+            "hello",
+            "--uncommitted",
+            "please review"
+        ]
+    );
+
+    let resume = client
+        .resume_session(
+            ResumeSessionRequest::new()
+                .all(true)
+                .last(true)
+                .session_id("sess-1")
+                .prompt("resume prompt"),
+        )
+        .await
+        .unwrap();
+    assert_eq!(
+        resume.stdout.lines().collect::<Vec<_>>(),
+        vec!["resume", "--all", "--last", "sess-1", "resume prompt"]
+    );
+
+    let fork = client
+        .fork_session(
+            ForkSessionRequest::new()
+                .all(true)
+                .last(true)
+                .session_id("sess-1")
+                .prompt("fork prompt"),
+        )
+        .await
+        .unwrap();
+    assert_eq!(
+        fork.stdout.lines().collect::<Vec<_>>(),
+        vec!["fork", "--all", "--last", "sess-1", "fork prompt"]
+    );
+}
+
+#[cfg(unix)]
+#[tokio::test]
+async fn cloud_list_parses_json_and_maps_args() {
+    let dir = tempfile::tempdir().unwrap();
+    let script_path = write_fake_codex(
+        dir.path(),
+        r#"#!/usr/bin/env bash
+printf "%s\n" "$@" 1>&2
+cat <<'JSON'
+{"tasks":[],"cursor":null}
+JSON
+"#,
+    );
+
+    let client = CodexClient::builder()
+        .binary(&script_path)
+        .mirror_stdout(false)
+        .quiet(true)
+        .build();
+
+    let output = client
+        .cloud_list(
+            CloudListRequest::new()
+                .json(true)
+                .env_id("env-1")
+                .limit(3)
+                .cursor("cur-1"),
+        )
+        .await
+        .unwrap();
+
+    assert_eq!(output.json, Some(json!({"tasks": [], "cursor": null})));
+    assert_eq!(
+        output.stderr.lines().collect::<Vec<_>>(),
+        vec!["cloud", "list", "--env", "env-1", "--limit", "3", "--cursor", "cur-1", "--json"]
+    );
+}
+
+#[cfg(unix)]
+#[tokio::test]
+async fn cloud_exec_maps_args_and_rejects_empty_env_id() {
+    let dir = tempfile::tempdir().unwrap();
+    let script_path = write_fake_codex(
+        dir.path(),
+        r#"#!/usr/bin/env bash
+printf "%s\n" "$@"
+"#,
+    );
+
+    let client = CodexClient::builder()
+        .binary(&script_path)
+        .mirror_stdout(false)
+        .quiet(true)
+        .build();
+
+    let output = client
+        .cloud_exec(
+            CloudExecRequest::new("env-1")
+                .attempts(2)
+                .branch("main")
+                .query("hello"),
+        )
+        .await
+        .unwrap();
+    assert_eq!(
+        output.stdout.lines().collect::<Vec<_>>(),
+        vec![
+            "cloud",
+            "exec",
+            "--env",
+            "env-1",
+            "--attempts",
+            "2",
+            "--branch",
+            "main",
+            "hello"
+        ]
+    );
+
+    let err = client
+        .cloud_exec(CloudExecRequest::new("  "))
+        .await
+        .unwrap_err();
+    assert!(matches!(err, CodexError::EmptyEnvId));
+}
+
+#[cfg(unix)]
+#[tokio::test]
+async fn mcp_list_get_and_add_map_args_and_parse_json() {
+    let dir = tempfile::tempdir().unwrap();
+    let script_path = write_fake_codex(
+        dir.path(),
+        r#"#!/usr/bin/env bash
+printf "%s\n" "$@" 1>&2
+cat <<'JSON'
+{"servers":[{"name":"files"}]}
+JSON
+"#,
+    );
+
+    let client = CodexClient::builder()
+        .binary(&script_path)
+        .mirror_stdout(false)
+        .quiet(true)
+        .build();
+
+    let list = client
+        .mcp_list(McpListRequest::new().json(true))
+        .await
+        .unwrap();
+    assert_eq!(list.json, Some(json!({"servers": [{"name": "files"}]})));
+    assert_eq!(
+        list.stderr.lines().collect::<Vec<_>>(),
+        vec!["mcp", "list", "--json"]
+    );
+
+    let get = client
+        .mcp_get(McpGetRequest::new("files").json(true))
+        .await
+        .unwrap();
+    assert_eq!(get.json, Some(json!({"servers": [{"name": "files"}]})));
+    assert_eq!(
+        get.stderr.lines().collect::<Vec<_>>(),
+        vec!["mcp", "get", "--json", "files"]
+    );
+}
+
+#[cfg(unix)]
+#[tokio::test]
+async fn mcp_add_maps_transports_and_validates_required_fields() {
+    let dir = tempfile::tempdir().unwrap();
+    let script_path = write_fake_codex(
+        dir.path(),
+        r#"#!/usr/bin/env bash
+printf "%s\n" "$@"
+"#,
+    );
+
+    let client = CodexClient::builder()
+        .binary(&script_path)
+        .mirror_stdout(false)
+        .quiet(true)
+        .build();
+
+    let stdio = client
+        .mcp_add(
+            McpAddRequest::stdio("files", vec![OsString::from("node"), OsString::from("srv")])
+                .env("TOKEN", "abc"),
+        )
+        .await
+        .unwrap();
+    assert_eq!(
+        stdio.stdout.lines().collect::<Vec<_>>(),
+        vec![
+            "mcp",
+            "add",
+            "files",
+            "--env",
+            "TOKEN=abc",
+            "--",
+            "node",
+            "srv"
+        ]
+    );
+
+    let http = client
+        .mcp_add(
+            McpAddRequest::streamable_http("http", "https://example.test")
+                .bearer_token_env_var("TOKEN_ENV"),
+        )
+        .await
+        .unwrap();
+    assert_eq!(
+        http.stdout.lines().collect::<Vec<_>>(),
+        vec![
+            "mcp",
+            "add",
+            "http",
+            "--url",
+            "https://example.test",
+            "--bearer-token-env-var",
+            "TOKEN_ENV"
+        ]
+    );
+
+    let err = client
+        .mcp_add(McpAddRequest::stdio("files", Vec::new()))
+        .await
+        .unwrap_err();
+    assert!(matches!(err, CodexError::EmptyMcpCommand));
+
+    let err = client
+        .mcp_add(McpAddRequest::streamable_http("bad", "  "))
+        .await
+        .unwrap_err();
+    assert!(matches!(err, CodexError::EmptyMcpUrl));
+}
+
+#[cfg(unix)]
+#[tokio::test]
+async fn app_server_codegen_maps_overrides_and_prettier() {
+    let dir = tempfile::tempdir().unwrap();
+    let script_path = write_fake_codex(
+        dir.path(),
+        r#"#!/usr/bin/env bash
+echo "$PWD"
+printf "%s\n" "$@"
+"#,
+    );
+
+    let workdir = dir.path().join("workdir");
+    std_fs::create_dir_all(&workdir).unwrap();
+    let out_dir = dir.path().join("out/ts");
+    let prettier = dir.path().join("bin/prettier.js");
+
+    let client = CodexClient::builder()
+        .binary(&script_path)
+        .mirror_stdout(false)
+        .quiet(true)
+        .working_dir(&workdir)
+        .approval_policy(ApprovalPolicy::OnRequest)
+        .search(true)
+        .build();
+
+    let result = client
+        .generate_app_server_bindings(
+            AppServerCodegenRequest::typescript(&out_dir)
+                .prettier(&prettier)
+                .profile("dev")
+                .config_override("features.codegen", "true"),
+        )
+        .await
+        .unwrap();
+
+    let mut lines = result.stdout.lines();
+    let pwd = lines.next().unwrap();
+    assert_eq!(Path::new(pwd), workdir.as_path());
+
+    let args: Vec<_> = lines.map(str::to_string).collect();
+    assert_eq!(
+        args,
+        vec![
+            "app-server",
+            "generate-ts",
+            "--out",
+            out_dir.to_string_lossy().as_ref(),
+            "--config",
+            "features.codegen=true",
+            "--profile",
+            "dev",
+            "--ask-for-approval",
+            "on-request",
+            "--search",
+            "--prettier",
+            prettier.to_string_lossy().as_ref(),
+        ]
+    );
+    assert!(out_dir.is_dir());
+    assert_eq!(result.out_dir, out_dir);
+    assert!(result.status.success());
+}
+
+#[cfg(unix)]
+#[tokio::test]
+async fn app_server_codegen_surfaces_non_zero_exit() {
+    let dir = tempfile::tempdir().unwrap();
+    let script_path = write_fake_codex(
+        dir.path(),
+        r#"#!/usr/bin/env bash
+echo "ts error"
+echo "bad format" 1>&2
+exit 5
+"#,
+    );
+
+    let client = CodexClient::builder()
+        .binary(&script_path)
+        .mirror_stdout(false)
+        .quiet(true)
+        .build();
+
+    let out_dir = dir.path().join("schema");
+    let err = client
+        .generate_app_server_bindings(AppServerCodegenRequest::json_schema(&out_dir))
+        .await
+        .unwrap_err();
+
+    match err {
+        CodexError::NonZeroExit { status, stderr } => {
+            assert_eq!(status.code(), Some(5));
+            assert!(stderr.contains("bad format"));
+        }
+        other => panic!("expected NonZeroExit, got {other:?}"),
+    }
+    assert!(out_dir.is_dir());
+}
+
+#[cfg(unix)]
+#[tokio::test]
+async fn responses_api_proxy_maps_flags_and_parses_server_info() {
+    let dir = tempfile::tempdir().unwrap();
+    let server_info = dir.path().join("server-info.json");
+    let script_path = write_fake_codex(
+        dir.path(),
+        r#"#!/usr/bin/env bash
+echo "$PWD"
+printf "%s\n" "$@"
+info_path=""
+while [[ $# -gt 0 ]]; do
+  if [[ $1 == "--server-info" ]]; then
+info_path=$2
+  fi
+  shift
+done
+read -r key || exit 1
+echo "key:${key}"
+if [[ -n "$info_path" ]]; then
+  printf '{"port":4567,"pid":1234}\n' > "$info_path"
+fi
+"#,
+    );
+
+    let workdir = dir.path().join("responses-workdir");
+    std_fs::create_dir_all(&workdir).unwrap();
+
+    let client = CodexClient::builder()
+        .binary(&script_path)
+        .mirror_stdout(false)
+        .quiet(true)
+        .working_dir(&workdir)
+        .build();
+
+    let mut proxy = client
+        .start_responses_api_proxy(
+            ResponsesApiProxyRequest::new("sk-test-123")
+                .port(8080)
+                .server_info(&server_info)
+                .http_shutdown(true)
+                .upstream_url("https://example.com/v1/responses"),
+        )
+        .await
+        .unwrap();
+
+    assert_eq!(
+        proxy.server_info_path.as_deref(),
+        Some(server_info.as_path())
+    );
+
+    let stdout = proxy.child.stdout.take().unwrap();
+    let mut lines = BufReader::new(stdout).lines();
+
+    let pwd = lines.next_line().await.unwrap().unwrap();
+    assert_eq!(Path::new(&pwd), workdir.as_path());
+
+    let mut args = Vec::new();
+    for _ in 0..8 {
+        args.push(lines.next_line().await.unwrap().unwrap());
+    }
+    assert_eq!(
+        args,
+        vec![
+            "responses-api-proxy",
+            "--port",
+            "8080",
+            "--server-info",
+            server_info.to_string_lossy().as_ref(),
+            "--http-shutdown",
+            "--upstream-url",
+            "https://example.com/v1/responses",
+        ]
+    );
+
+    let api_key_line = lines.next_line().await.unwrap().unwrap();
+    assert_eq!(api_key_line, "key:sk-test-123");
+
+    let info = proxy.read_server_info().await.unwrap().unwrap();
+    assert_eq!(info.port, 4567);
+    assert_eq!(info.pid, 1234);
+
+    let status = proxy.child.wait().await.unwrap();
+    assert!(status.success());
+}
+
+#[tokio::test]
+async fn responses_api_proxy_rejects_empty_api_key() {
+    let client = CodexClient::builder().build();
+    let err = client
+        .start_responses_api_proxy(ResponsesApiProxyRequest::new("  "))
+        .await
+        .unwrap_err();
+    assert!(matches!(err, CodexError::EmptyApiKey));
+}
+
+#[cfg(unix)]
+#[tokio::test]
+async fn stdio_to_uds_maps_args_and_pipes_stdio() {
+    let dir = tempfile::tempdir().unwrap();
+    let socket_path = dir.path().join("bridge.sock");
+    let script_path = write_fake_codex(
+        dir.path(),
+        r#"#!/usr/bin/env bash
+echo "$PWD"
+printf "%s\n" "$@"
+while read -r line; do
+  echo "relay:${line}"
+done
+"#,
+    );
+
+    let workdir = dir.path().join("uds-workdir");
+    std_fs::create_dir_all(&workdir).unwrap();
+
+    let client = CodexClient::builder()
+        .binary(&script_path)
+        .mirror_stdout(false)
+        .quiet(true)
+        .working_dir(&workdir)
+        .build();
+
+    let request = StdioToUdsRequest::new(&socket_path).working_dir(&workdir);
+    let mut child = match client.stdio_to_uds(request.clone()) {
+        Ok(child) => child,
+        Err(CodexError::Spawn { source, .. }) if source.raw_os_error() == Some(26) => {
+            time::sleep(Duration::from_millis(25)).await;
+            client.stdio_to_uds(request).unwrap()
+        }
+        Err(other) => panic!("unexpected spawn error: {other:?}"),
+    };
+
+    let stdout = child.stdout.take().unwrap();
+    let mut lines = BufReader::new(stdout).lines();
+
+    let pwd = lines.next_line().await.unwrap().unwrap();
+    assert_eq!(Path::new(&pwd), workdir.as_path());
+
+    let arg_one = lines.next_line().await.unwrap().unwrap();
+    let arg_two = lines.next_line().await.unwrap().unwrap();
+    assert_eq!(arg_one, "stdio-to-uds");
+    assert_eq!(arg_two, socket_path.to_string_lossy().as_ref());
+
+    let mut stdin = child.stdin.take().unwrap();
+    stdin.write_all(b"ping\n").await.unwrap();
+    stdin.shutdown().await.unwrap();
+    drop(stdin);
+
+    let echoed = lines.next_line().await.unwrap().unwrap();
+    assert_eq!(echoed, "relay:ping");
+
+    let status = time::timeout(Duration::from_secs(5), child.wait())
+        .await
+        .expect("stdio-to-uds wait timed out")
+        .unwrap();
+    assert!(status.success());
+}
+
+#[tokio::test]
+async fn stdio_to_uds_rejects_empty_socket_path() {
+    let client = CodexClient::builder().build();
+    let err = client
+        .stdio_to_uds(StdioToUdsRequest::new(PathBuf::new()))
+        .unwrap_err();
+    assert!(matches!(err, CodexError::EmptySocketPath));
+}
+
+#[tokio::test]
+async fn sandbox_rejects_empty_command() {
+    let client = CodexClient::builder().build();
+    let request = SandboxCommandRequest::new(SandboxPlatform::Linux, Vec::<OsString>::new());
+    let err = client.run_sandbox(request).await.unwrap_err();
+    assert!(matches!(err, CodexError::EmptySandboxCommand));
+}
+
+fn capabilities_with_version(raw_version: &str) -> CodexCapabilities {
+    CodexCapabilities {
+        cache_key: CapabilityCacheKey {
+            binary_path: PathBuf::from("codex"),
+        },
+        fingerprint: None,
+        version: Some(version::parse_version_output(raw_version)),
+        features: CodexFeatureFlags::default(),
+        probe_plan: CapabilityProbePlan::default(),
+        collected_at: SystemTime::now(),
+    }
+}
+
+fn capabilities_without_version() -> CodexCapabilities {
+    CodexCapabilities {
+        cache_key: CapabilityCacheKey {
+            binary_path: PathBuf::from("codex"),
+        },
+        fingerprint: None,
+        version: None,
+        features: CodexFeatureFlags::default(),
+        probe_plan: CapabilityProbePlan::default(),
+        collected_at: SystemTime::now(),
+    }
+}
+
+fn capabilities_with_feature_flags(features: CodexFeatureFlags) -> CodexCapabilities {
+    CodexCapabilities {
+        cache_key: CapabilityCacheKey {
+            binary_path: PathBuf::from("codex"),
+        },
+        fingerprint: None,
+        version: None,
+        features,
+        probe_plan: CapabilityProbePlan::default(),
+        collected_at: SystemTime::now(),
+    }
+}
+
+fn sample_capabilities_snapshot() -> CodexCapabilities {
+    CodexCapabilities {
+        cache_key: CapabilityCacheKey {
+            binary_path: PathBuf::from("/tmp/codex"),
+        },
+        fingerprint: Some(BinaryFingerprint {
+            canonical_path: Some(PathBuf::from("/tmp/codex")),
+            modified: Some(SystemTime::UNIX_EPOCH + Duration::from_secs(5)),
+            len: Some(1234),
+        }),
+        version: Some(CodexVersionInfo {
+            raw: "codex 3.4.5-beta (commit cafe)".to_string(),
+            semantic: Some((3, 4, 5)),
+            commit: Some("cafe".to_string()),
+            channel: CodexReleaseChannel::Beta,
+        }),
+        features: CodexFeatureFlags {
+            supports_features_list: true,
+            supports_output_schema: true,
+            supports_add_dir: false,
+            supports_mcp_login: true,
+        },
+        probe_plan: CapabilityProbePlan {
+            steps: vec![
+                CapabilityProbeStep::VersionFlag,
+                CapabilityProbeStep::FeaturesListJson,
+                CapabilityProbeStep::ManualOverride,
+            ],
+        },
+        collected_at: SystemTime::UNIX_EPOCH + Duration::from_secs(10),
+    }
+}
+
+fn sample_capability_overrides() -> CapabilityOverrides {
+    CapabilityOverrides {
+        snapshot: Some(sample_capabilities_snapshot()),
+        version: Some(version::parse_version_output("codex 9.9.9-nightly")),
+        features: CapabilityFeatureOverrides {
+            supports_features_list: Some(true),
+            supports_output_schema: Some(true),
+            supports_add_dir: Some(true),
+            supports_mcp_login: None,
+        },
+    }
+}
+
+fn capability_snapshot_with_metadata(
+    collected_at: SystemTime,
+    fingerprint: Option<BinaryFingerprint>,
+) -> CodexCapabilities {
+    CodexCapabilities {
+        cache_key: CapabilityCacheKey {
+            binary_path: PathBuf::from("/tmp/codex"),
+        },
+        fingerprint,
+        version: None,
+        features: CodexFeatureFlags::default(),
+        probe_plan: CapabilityProbePlan::default(),
+        collected_at,
+    }
+}
+
+#[test]
+fn builder_defaults_are_sane() {
+    let builder = CodexClient::builder();
+    assert!(builder.model.is_none());
+    assert_eq!(builder.timeout, DEFAULT_TIMEOUT);
+    assert_eq!(builder.color_mode, ColorMode::Never);
+    assert!(builder.codex_home.is_none());
+    assert!(builder.create_home_dirs);
+    assert!(builder.working_dir.is_none());
+    assert!(builder.images.is_empty());
+    assert!(!builder.json_output);
+    assert!(!builder.quiet);
+    assert!(builder.json_event_log.is_none());
+    assert!(builder.cli_overrides.config_overrides.is_empty());
+    assert!(!builder.cli_overrides.reasoning.has_overrides());
+    assert!(builder.cli_overrides.approval_policy.is_none());
+    assert!(builder.cli_overrides.sandbox_mode.is_none());
+    assert_eq!(
+        builder.cli_overrides.safety_override,
+        SafetyOverride::Inherit
+    );
+    assert!(builder.cli_overrides.cd.is_none());
+    assert!(builder.cli_overrides.local_provider.is_none());
+    assert_eq!(builder.cli_overrides.search, FlagState::Inherit);
+    assert!(builder.cli_overrides.auto_reasoning_defaults);
+    assert!(builder.capability_overrides.is_empty());
+    assert_eq!(
+        builder.capability_cache_policy,
+        CapabilityCachePolicy::PreferCache
+    );
+}
+
+#[test]
+fn builder_collects_images() {
+    let client = CodexClient::builder()
+        .image("foo.png")
+        .image("bar.jpg")
+        .build();
+    assert_eq!(client.images.len(), 2);
+    assert_eq!(client.images[0], PathBuf::from("foo.png"));
+    assert_eq!(client.images[1], PathBuf::from("bar.jpg"));
+}
+
+#[test]
+fn builder_sets_json_flag() {
+    let client = CodexClient::builder().json(true).build();
+    assert!(client.json_output);
+}
+
+#[test]
+fn builder_sets_json_event_log() {
+    let client = CodexClient::builder().json_event_log("events.log").build();
+    assert_eq!(client.json_event_log, Some(PathBuf::from("events.log")));
+}
+
+#[test]
+fn builder_sets_quiet_flag() {
+    let client = CodexClient::builder().quiet(true).build();
+    assert!(client.quiet);
+}
+
+#[test]
+fn builder_mirrors_stdout_by_default() {
+    let client = CodexClient::builder().build();
+    assert!(client.mirror_stdout);
+}
+
+#[test]
+fn builder_can_disable_stdout_mirroring() {
+    let client = CodexClient::builder().mirror_stdout(false).build();
+    assert!(!client.mirror_stdout);
+}
+
+#[test]
+fn builder_uses_env_binary_when_set() {
+    let _guard = env_guard();
+    let key = CODEX_BINARY_ENV;
+    let original = env::var_os(key);
+    env::set_var(key, "custom_codex");
+    let builder = CodexClient::builder();
+    assert_eq!(builder.binary, PathBuf::from("custom_codex"));
+    if let Some(value) = original {
+        env::set_var(key, value);
+    } else {
+        env::remove_var(key);
+    }
+}
+
+#[test]
+fn default_binary_falls_back_when_env_missing() {
+    let _guard = env_guard();
+    let key = CODEX_BINARY_ENV;
+    let original = env::var_os(key);
+    env::remove_var(key);
+
+    assert_eq!(default_binary_path(), PathBuf::from("codex"));
+
+    if let Some(value) = original {
+        env::set_var(key, value);
+    } else {
+        env::remove_var(key);
+    }
+}
+
+#[test]
+fn default_rust_log_is_error_when_unset() {
+    let _guard = env_guard();
+    let original = env::var_os("RUST_LOG");
+    env::remove_var("RUST_LOG");
+
+    assert_eq!(default_rust_log_value(), Some("error"));
+
+    if let Some(value) = original {
+        env::set_var("RUST_LOG", value);
+    } else {
+        env::remove_var("RUST_LOG");
+    }
+}
+
+#[test]
+fn default_rust_log_respects_existing_env() {
+    let _guard = env_guard();
+    let original = env::var_os("RUST_LOG");
+    env::set_var("RUST_LOG", "info");
+
+    assert_eq!(default_rust_log_value(), None);
+
+    if let Some(value) = original {
+        env::set_var("RUST_LOG", value);
+    } else {
+        env::remove_var("RUST_LOG");
+    }
+}
+
+#[test]
+fn command_env_sets_expected_overrides() {
+    let _guard = env_guard();
+    let rust_log_original = env::var_os(RUST_LOG_ENV);
+    env::remove_var(RUST_LOG_ENV);
+
+    let temp = tempfile::tempdir().unwrap();
+    let home = temp.path().join("codex_home");
+    let env_prep =
+        CommandEnvironment::new(PathBuf::from("/custom/codex"), Some(home.clone()), true);
+    let overrides = env_prep.environment_overrides().unwrap();
+    let map: HashMap<OsString, OsString> = overrides.into_iter().collect();
+
+    assert_eq!(
+        map.get(&OsString::from(CODEX_BINARY_ENV)),
+        Some(&OsString::from("/custom/codex"))
+    );
+    assert_eq!(
+        map.get(&OsString::from(CODEX_HOME_ENV)),
+        Some(&home.as_os_str().to_os_string())
+    );
+    assert_eq!(
+        map.get(&OsString::from(RUST_LOG_ENV)),
+        Some(&OsString::from(DEFAULT_RUST_LOG))
+    );
+
+    assert!(home.is_dir());
+    assert!(home.join("conversations").is_dir());
+    assert!(home.join("logs").is_dir());
+
+    match rust_log_original {
+        Some(value) => env::set_var(RUST_LOG_ENV, value),
+        None => env::remove_var(RUST_LOG_ENV),
+    }
+}
+
+#[test]
+fn command_env_applies_home_and_binary_per_command() {
+    let _guard = env_guard();
+    let binary_key = CODEX_BINARY_ENV;
+    let home_key = CODEX_HOME_ENV;
+    let rust_log_key = RUST_LOG_ENV;
+    let original_binary = env::var_os(binary_key);
+    let original_home = env::var_os(home_key);
+    let original_rust_log = env::var_os(rust_log_key);
+
+    env::set_var(binary_key, "/tmp/ignored_codex");
+    env::set_var(home_key, "/tmp/ambient_home");
+    env::remove_var(rust_log_key);
+
+    let temp = tempfile::tempdir().unwrap();
+    let home = temp.path().join("scoped_home");
+    let env_prep = CommandEnvironment::new(
+        PathBuf::from("/app/bundled/codex"),
+        Some(home.clone()),
+        true,
+    );
+
+    let mut command = Command::new("echo");
+    env_prep.apply(&mut command).unwrap();
+
+    let envs: HashMap<OsString, Option<OsString>> = command
+        .as_std()
+        .get_envs()
+        .map(|(key, value)| (key.to_os_string(), value.map(|v| v.to_os_string())))
+        .collect();
+
+    assert_eq!(
+        envs.get(&OsString::from(binary_key)),
+        Some(&Some(OsString::from("/app/bundled/codex")))
+    );
+    assert_eq!(
+        envs.get(&OsString::from(home_key)),
+        Some(&Some(home.as_os_str().to_os_string()))
+    );
+    assert_eq!(
+        envs.get(&OsString::from(rust_log_key)),
+        Some(&Some(OsString::from(DEFAULT_RUST_LOG)))
+    );
+    assert_eq!(
+        env::var_os(home_key),
+        Some(OsString::from("/tmp/ambient_home"))
+    );
+    assert!(home.is_dir());
+    assert!(home.join("conversations").is_dir());
+    assert!(home.join("logs").is_dir());
+
+    match original_binary {
+        Some(value) => env::set_var(binary_key, value),
+        None => env::remove_var(binary_key),
+    }
+    match original_home {
+        Some(value) => env::set_var(home_key, value),
+        None => env::remove_var(home_key),
+    }
+    match original_rust_log {
+        Some(value) => env::set_var(rust_log_key, value),
+        None => env::remove_var(rust_log_key),
+    }
+}
+
+#[cfg(unix)]
+#[tokio::test]
+async fn apply_and_diff_capture_outputs_and_status() {
+    let dir = tempfile::tempdir().unwrap();
+    let script_path = dir.path().join("codex");
+    std::fs::write(
+        &script_path,
+        r#"#!/usr/bin/env bash
+set -e
+cmd="$1"
+if [[ "$cmd" == "apply" ]]; then
+  echo "applied"
+  echo "apply-stderr" >&2
+  exit 0
+elif [[ "$cmd" == "cloud" && "${2:-}" == "diff" ]]; then
+  echo "diff-body"
+  echo "diff-stderr" >&2
+  exit 3
+else
+  echo "unknown $cmd" >&2
+  exit 99
+fi
+"#,
+    )
+    .unwrap();
+    let mut perms = std::fs::metadata(&script_path).unwrap().permissions();
+    perms.set_mode(0o755);
+    std::fs::set_permissions(&script_path, perms).unwrap();
+
+    let client = CodexClient::builder()
+        .binary(&script_path)
+        .mirror_stdout(false)
+        .quiet(true)
+        .build();
+
+    let apply = client.apply().await.unwrap();
+    assert!(apply.status.success());
+    assert_eq!(apply.stdout.trim(), "applied");
+    assert_eq!(apply.stderr.trim(), "apply-stderr");
+
+    let diff = client.diff().await.unwrap();
+    assert!(!diff.status.success());
+    assert_eq!(diff.status.code(), Some(3));
+    assert_eq!(diff.stdout.trim(), "diff-body");
+    assert_eq!(diff.stderr.trim(), "diff-stderr");
+}
+
+#[cfg(unix)]
+#[tokio::test]
+async fn apply_respects_rust_log_default() {
+    let _guard = env_guard_async().await;
+    let original = env::var_os("RUST_LOG");
+    env::remove_var("RUST_LOG");
+
+    let dir = tempfile::tempdir().unwrap();
+    let script_path = dir.path().join("codex-rust-log");
+    std::fs::write(
+        &script_path,
+        r#"#!/usr/bin/env bash
+echo "${RUST_LOG:-missing}"
+exit 0
+"#,
+    )
+    .unwrap();
+    let mut perms = std::fs::metadata(&script_path).unwrap().permissions();
+    perms.set_mode(0o755);
+    std::fs::set_permissions(&script_path, perms).unwrap();
+
+    let client = CodexClient::builder()
+        .binary(&script_path)
+        .mirror_stdout(false)
+        .quiet(true)
+        .build();
+
+    let apply = client.apply().await.unwrap();
+    assert_eq!(apply.stdout.trim(), "error");
+
+    if let Some(value) = original {
+        env::set_var("RUST_LOG", value);
+    } else {
+        env::remove_var("RUST_LOG");
+    }
+}
+
+#[test]
+fn command_env_respects_existing_rust_log() {
+    let _guard = env_guard();
+    let rust_log_original = env::var_os(RUST_LOG_ENV);
+    env::set_var(RUST_LOG_ENV, "trace");
+
+    let env_prep = CommandEnvironment::new(PathBuf::from("codex"), None, true);
+    let overrides = env_prep.environment_overrides().unwrap();
+    let map: HashMap<OsString, OsString> = overrides.into_iter().collect();
+
+    assert_eq!(
+        map.get(&OsString::from(CODEX_BINARY_ENV)),
+        Some(&OsString::from("codex"))
+    );
+    assert!(!map.contains_key(&OsString::from(RUST_LOG_ENV)));
+
+    match rust_log_original {
+        Some(value) => env::set_var(RUST_LOG_ENV, value),
+        None => env::remove_var(RUST_LOG_ENV),
+    }
+}
+
+#[test]
+fn command_env_can_skip_home_creation() {
+    let _guard = env_guard();
+    let rust_log_original = env::var_os(RUST_LOG_ENV);
+    env::remove_var(RUST_LOG_ENV);
+
+    let temp = tempfile::tempdir().unwrap();
+    let home = temp.path().join("codex_home");
+    let env_prep = CommandEnvironment::new(PathBuf::from("codex"), Some(home.clone()), false);
+    let overrides = env_prep.environment_overrides().unwrap();
+    let map: HashMap<OsString, OsString> = overrides.into_iter().collect();
+
+    assert!(!home.exists());
+    assert!(!home.join("conversations").exists());
+    assert!(!home.join("logs").exists());
+    assert_eq!(
+        map.get(&OsString::from(CODEX_HOME_ENV)),
+        Some(&home.as_os_str().to_os_string())
+    );
+
+    match rust_log_original {
+        Some(value) => env::set_var(RUST_LOG_ENV, value),
+        None => env::remove_var(RUST_LOG_ENV),
+    }
+}
+
+#[test]
+fn codex_home_layout_exposes_paths() {
+    let root = PathBuf::from("/tmp/codex_layout_root");
+    let layout = CodexHomeLayout::new(&root);
+
+    assert_eq!(layout.root(), root.as_path());
+    assert_eq!(layout.config_path(), root.join("config.toml"));
+    assert_eq!(layout.auth_path(), root.join("auth.json"));
+    assert_eq!(layout.credentials_path(), root.join(".credentials.json"));
+    assert_eq!(layout.history_path(), root.join("history.jsonl"));
+    assert_eq!(layout.conversations_dir(), root.join("conversations"));
+    assert_eq!(layout.logs_dir(), root.join("logs"));
+}
+
+#[test]
+fn codex_home_layout_respects_materialization_flag() {
+    let temp = tempfile::tempdir().unwrap();
+    let root = temp.path().join("codex_home_layout");
+    let layout = CodexHomeLayout::new(&root);
+
+    layout.materialize(false).unwrap();
+    assert!(!root.exists());
+
+    layout.materialize(true).unwrap();
+    assert!(root.is_dir());
+    assert!(layout.conversations_dir().is_dir());
+    assert!(layout.logs_dir().is_dir());
+}
+
+#[test]
+fn seed_auth_copies_files_and_creates_targets() {
+    let temp = tempfile::tempdir().unwrap();
+    let seed = temp.path().join("seed_home");
+    std::fs::create_dir_all(&seed).unwrap();
+    std::fs::write(seed.join("auth.json"), "auth").unwrap();
+    std::fs::write(seed.join(".credentials.json"), "creds").unwrap();
+
+    let target_root = temp.path().join("target_home");
+    let layout = CodexHomeLayout::new(&target_root);
+    let outcome = layout
+        .seed_auth_from(&seed, AuthSeedOptions::default())
+        .unwrap();
+
+    assert!(outcome.copied_auth);
+    assert!(outcome.copied_credentials);
+    assert_eq!(std::fs::read_to_string(layout.auth_path()).unwrap(), "auth");
+    assert_eq!(
+        std::fs::read_to_string(layout.credentials_path()).unwrap(),
+        "creds"
+    );
+}
+
+#[test]
+fn seed_auth_skips_optional_files() {
+    let temp = tempfile::tempdir().unwrap();
+    let seed = temp.path().join("seed_home");
+    std::fs::create_dir_all(&seed).unwrap();
+    std::fs::write(seed.join("auth.json"), "auth").unwrap();
+
+    let target_root = temp.path().join("target_home");
+    let layout = CodexHomeLayout::new(&target_root);
+    let outcome = layout
+        .seed_auth_from(&seed, AuthSeedOptions::default())
+        .unwrap();
+
+    assert!(outcome.copied_auth);
+    assert!(!outcome.copied_credentials);
+    assert_eq!(std::fs::read_to_string(layout.auth_path()).unwrap(), "auth");
+    assert!(!layout.credentials_path().exists());
+}
+
+#[test]
+fn seed_auth_errors_when_required_missing() {
+    let temp = tempfile::tempdir().unwrap();
+    let seed = temp.path().join("seed_home");
+    std::fs::create_dir_all(&seed).unwrap();
+
+    let target_root = temp.path().join("target_home");
+    let layout = CodexHomeLayout::new(&target_root);
+    let err = layout
+        .seed_auth_from(
+            &seed,
+            AuthSeedOptions {
+                require_auth: true,
+                require_credentials: true,
+                ..Default::default()
+            },
+        )
+        .unwrap_err();
+
+    match err {
+        AuthSeedError::SeedFileMissing { path } => {
+            assert!(path.ends_with("auth.json"), "{path:?}")
+        }
+        other => panic!("unexpected error: {other:?}"),
+    }
+}
+
+#[test]
+fn codex_client_returns_configured_home_layout() {
+    let temp = tempfile::tempdir().unwrap();
+    let root = temp.path().join("app_codex_home");
+    let client = CodexClient::builder().codex_home(&root).build();
+
+    let layout = client.codex_home_layout().expect("layout missing");
+    assert_eq!(layout.root(), root.as_path());
+    assert!(!root.exists());
+
+    let client_without_home = CodexClient::builder().build();
+    assert!(client_without_home.codex_home_layout().is_none());
+}
+
+#[test]
+fn parses_version_output_fields() {
+    let parsed = version::parse_version_output("codex v3.4.5-nightly (commit abc1234)");
+    assert_eq!(parsed.semantic, Some((3, 4, 5)));
+    assert_eq!(parsed.channel, CodexReleaseChannel::Nightly);
+    assert_eq!(parsed.commit.as_deref(), Some("abc1234"));
+    assert_eq!(
+        parsed.raw,
+        "codex v3.4.5-nightly (commit abc1234)".to_string()
+    );
+}
+
+#[test]
+fn update_advisory_detects_newer_release() {
+    let capabilities = capabilities_with_version("codex 1.0.0");
+    let latest = CodexLatestReleases {
+        stable: Some(Version::parse("1.1.0").unwrap()),
+        ..Default::default()
+    };
+    let advisory = update_advisory_from_capabilities(&capabilities, &latest);
+    assert_eq!(advisory.status, CodexUpdateStatus::UpdateRecommended);
+    assert!(advisory.is_update_recommended());
+    assert_eq!(
+        advisory
+            .latest_release
+            .as_ref()
+            .map(|release| release.version.clone()),
+        latest.stable
+    );
+}
+
+#[test]
+fn normalize_stream_infers_missing_thread_and_turn() {
+    let mut context = crate::jsonl::StreamContext::default();
+    // thread.started establishes thread context
+    let thread_line = r#"{"type":"thread.started","thread_id":"thread-1"}"#;
+    let thread_event = crate::jsonl::normalize_thread_event(thread_line, &mut context).unwrap();
+    match thread_event {
+        ThreadEvent::ThreadStarted(t) => assert_eq!(t.thread_id, "thread-1"),
+        other => panic!("unexpected event: {other:?}"),
+    }
+    // turn.started without thread_id should inherit
+    let turn_line = r#"{"type":"turn.started","turn_id":"turn-1"}"#;
+    let turn_event = crate::jsonl::normalize_thread_event(turn_line, &mut context).unwrap();
+    match turn_event {
+        ThreadEvent::TurnStarted(t) => {
+            assert_eq!(t.thread_id, "thread-1");
+            assert_eq!(t.turn_id, "turn-1");
+        }
+        other => panic!("unexpected event: {other:?}"),
+    }
+    // item.completed without ids should inherit both
+    let item_line =
+        r#"{"type":"item.completed","item":{"id":"msg-1","type":"agent_message","text":"hi"}}"#;
+    let item_event = crate::jsonl::normalize_thread_event(item_line, &mut context).unwrap();
+    match item_event {
+        ThreadEvent::ItemCompleted(item) => {
+            assert_eq!(item.turn_id, "turn-1");
+            assert_eq!(item.thread_id, "thread-1");
+            assert_eq!(item.item.item_id, "msg-1");
+        }
+        other => panic!("unexpected event: {other:?}"),
+    }
+}
+
+#[test]
+fn normalize_stream_errors_without_context() {
+    let mut context = crate::jsonl::StreamContext::default();
+    let line = r#"{"type":"turn.started"}"#;
+    let err = crate::jsonl::normalize_thread_event(line, &mut context).unwrap_err();
+    match err {
+        ExecStreamError::Normalize { .. } => {}
+        other => panic!("unexpected error: {other:?}"),
+    }
+}
+
+#[test]
+fn update_advisory_handles_unknown_local_version() {
+    let capabilities = capabilities_without_version();
+    let latest = CodexLatestReleases {
+        stable: Some(Version::parse("3.2.1").unwrap()),
+        ..Default::default()
+    };
+    let advisory = update_advisory_from_capabilities(&capabilities, &latest);
+    assert_eq!(advisory.status, CodexUpdateStatus::UnknownLocalVersion);
+    assert!(advisory.is_update_recommended());
+    assert!(advisory
+        .notes
+        .iter()
+        .any(|note| note.contains("could not be parsed")));
+}
+
+#[test]
+fn update_advisory_marks_up_to_date() {
+    let capabilities = capabilities_with_version("codex 2.0.1");
+    let latest = CodexLatestReleases {
+        stable: Some(Version::parse("2.0.1").unwrap()),
+        ..Default::default()
+    };
+    let advisory = update_advisory_from_capabilities(&capabilities, &latest);
+    assert_eq!(advisory.status, CodexUpdateStatus::UpToDate);
+    assert!(!advisory.is_update_recommended());
+}
+
+#[test]
+fn update_advisory_falls_back_when_channel_missing() {
+    let capabilities = capabilities_with_version("codex 2.0.0-beta");
+    let latest = CodexLatestReleases {
+        stable: Some(Version::parse("2.0.1").unwrap()),
+        ..Default::default()
+    };
+    let advisory = update_advisory_from_capabilities(&capabilities, &latest);
+    assert_eq!(advisory.comparison_channel, CodexReleaseChannel::Stable);
+    assert_eq!(advisory.status, CodexUpdateStatus::UpdateRecommended);
+    assert!(advisory
+        .notes
+        .iter()
+        .any(|note| note.contains("comparing against stable")));
+}
+
+#[test]
+fn update_advisory_handles_local_newer_than_known() {
+    let capabilities = capabilities_with_version("codex 2.0.0");
+    let latest = CodexLatestReleases {
+        stable: Some(Version::parse("1.9.9").unwrap()),
+        ..Default::default()
+    };
+    let advisory = update_advisory_from_capabilities(&capabilities, &latest);
+    assert_eq!(advisory.status, CodexUpdateStatus::LocalNewerThanKnown);
+    assert!(!advisory.is_update_recommended());
+    assert!(advisory
+        .notes
+        .iter()
+        .any(|note| note.contains("newer than provided")));
+}
+
+#[test]
+fn update_advisory_handles_missing_latest_metadata() {
+    let capabilities = capabilities_with_version("codex 1.0.0");
+    let latest = CodexLatestReleases::default();
+    let advisory = update_advisory_from_capabilities(&capabilities, &latest);
+    assert_eq!(advisory.status, CodexUpdateStatus::UnknownLatestVersion);
+    assert!(!advisory.is_update_recommended());
+    assert!(advisory
+        .notes
+        .iter()
+        .any(|note| note.contains("advisory unavailable")));
+}
+
+#[test]
+fn capability_snapshots_serialize_to_json_and_toml() {
+    let snapshot = sample_capabilities_snapshot();
+
+    let json = serialize_capabilities_snapshot(&snapshot, CapabilitySnapshotFormat::Json)
+        .expect("serialize json");
+    let parsed_json = deserialize_capabilities_snapshot(&json, CapabilitySnapshotFormat::Json)
+        .expect("parse json");
+    assert_eq!(parsed_json, snapshot);
+
+    let toml = serialize_capabilities_snapshot(&snapshot, CapabilitySnapshotFormat::Toml)
+        .expect("serialize toml");
+    let parsed_toml = deserialize_capabilities_snapshot(&toml, CapabilitySnapshotFormat::Toml)
+        .expect("parse toml");
+    assert_eq!(parsed_toml, snapshot);
+}
+
+#[test]
+fn capability_snapshots_and_overrides_round_trip_via_files() {
+    let snapshot = sample_capabilities_snapshot();
+    let overrides = sample_capability_overrides();
+    let temp = tempfile::tempdir().unwrap();
+
+    let snapshot_path = temp.path().join("capabilities.toml");
+    write_capabilities_snapshot(&snapshot_path, &snapshot, None).unwrap();
+    let loaded_snapshot = read_capabilities_snapshot(&snapshot_path, None).unwrap();
+    assert_eq!(loaded_snapshot, snapshot);
+
+    let overrides_path = temp.path().join("overrides.json");
+    write_capability_overrides(&overrides_path, &overrides, None).unwrap();
+    let loaded_overrides = read_capability_overrides(&overrides_path, None).unwrap();
+    assert_eq!(loaded_overrides, overrides);
+}
+
+#[test]
+fn capability_snapshot_match_checks_fingerprint() {
+    let temp = tempfile::tempdir().unwrap();
+    let script = "#!/bin/bash\necho ok";
+    let binary = write_fake_codex(temp.path(), script);
+    let cache_key = capability_cache_key(&binary);
+    let fingerprint = current_fingerprint(&cache_key);
+
+    let snapshot = CodexCapabilities {
+        cache_key: cache_key.clone(),
+        fingerprint: fingerprint.clone(),
+        version: None,
+        features: CodexFeatureFlags::default(),
+        probe_plan: CapabilityProbePlan::default(),
+        collected_at: SystemTime::UNIX_EPOCH,
+    };
+
+    assert!(capability_snapshot_matches_binary(&snapshot, &binary));
+    let mut missing_fingerprint = snapshot.clone();
+    missing_fingerprint.fingerprint = None;
+    assert!(!capability_snapshot_matches_binary(
+        &missing_fingerprint,
+        &binary
+    ));
+
+    std_fs::write(&binary, "#!/bin/bash\necho changed").unwrap();
+    let mut perms = std_fs::metadata(&binary).unwrap().permissions();
+    perms.set_mode(0o755);
+    std_fs::set_permissions(&binary, perms).unwrap();
+
+    assert!(!capability_snapshot_matches_binary(&snapshot, &binary));
+}
+
+#[test]
+fn capability_cache_entries_exposes_cache_state() {
+    let _guard = env_guard();
+    clear_capability_cache();
+
+    let temp = tempfile::tempdir().unwrap();
+    let binary = write_fake_codex(temp.path(), "#!/bin/bash\necho ok");
+    let cache_key = capability_cache_key(&binary);
+    let fingerprint = current_fingerprint(&cache_key);
+
+    let snapshot = CodexCapabilities {
+        cache_key: cache_key.clone(),
+        fingerprint: fingerprint.clone(),
+        version: Some(version::parse_version_output("codex 0.0.1")),
+        features: CodexFeatureFlags {
+            supports_features_list: true,
+            supports_output_schema: true,
+            supports_add_dir: false,
+            supports_mcp_login: false,
+        },
+        probe_plan: CapabilityProbePlan {
+            steps: vec![CapabilityProbeStep::VersionFlag],
+        },
+        collected_at: SystemTime::UNIX_EPOCH,
+    };
+
+    update_capability_cache(snapshot.clone());
+
+    let entries = capability_cache_entries();
+    assert!(entries.iter().any(|entry| entry.cache_key == cache_key));
+
+    let fetched = capability_cache_entry(&binary).expect("expected cache entry");
+    assert_eq!(fetched.cache_key, cache_key);
+    assert!(clear_capability_cache_entry(&binary));
+    assert!(capability_cache_entry(&binary).is_none());
+    assert!(capability_cache_entries().is_empty());
+    clear_capability_cache();
+}
+
+#[test]
+fn capability_ttl_decision_reuses_fresh_snapshot() {
+    let collected_at = SystemTime::UNIX_EPOCH + Duration::from_secs(10);
+    let snapshot = capability_snapshot_with_metadata(
+        collected_at,
+        Some(BinaryFingerprint {
+            canonical_path: Some(PathBuf::from("/tmp/codex")),
+            modified: Some(SystemTime::UNIX_EPOCH + Duration::from_secs(1)),
+            len: Some(123),
+        }),
+    );
+
+    let decision = capability_cache_ttl_decision(
+        Some(&snapshot),
+        Duration::from_secs(300),
+        SystemTime::UNIX_EPOCH + Duration::from_secs(100),
+    );
+    assert!(!decision.should_probe);
+    assert_eq!(decision.policy, CapabilityCachePolicy::PreferCache);
+}
+
+#[test]
+fn capability_ttl_decision_refreshes_after_ttl_with_fingerprint() {
+    let collected_at = SystemTime::UNIX_EPOCH + Duration::from_secs(1);
+    let snapshot = capability_snapshot_with_metadata(
+        collected_at,
+        Some(BinaryFingerprint {
+            canonical_path: Some(PathBuf::from("/tmp/codex")),
+            modified: Some(SystemTime::UNIX_EPOCH + Duration::from_secs(1)),
+            len: Some(321),
+        }),
+    );
+
+    let decision = capability_cache_ttl_decision(
+        Some(&snapshot),
+        Duration::from_secs(5),
+        SystemTime::UNIX_EPOCH + Duration::from_secs(10),
+    );
+    assert!(decision.should_probe);
+    assert_eq!(decision.policy, CapabilityCachePolicy::Refresh);
+}
+
+#[test]
+fn capability_ttl_decision_bypasses_when_metadata_missing() {
+    let collected_at = SystemTime::UNIX_EPOCH + Duration::from_secs(2);
+    let snapshot = capability_snapshot_with_metadata(collected_at, None);
+
+    let decision = capability_cache_ttl_decision(
+        Some(&snapshot),
+        Duration::from_secs(5),
+        SystemTime::UNIX_EPOCH + Duration::from_secs(10),
+    );
+    assert!(decision.should_probe);
+    assert_eq!(decision.policy, CapabilityCachePolicy::Bypass);
+}
+
+#[tokio::test]
+async fn probe_reprobes_when_metadata_missing() {
+    let _guard = env_guard_async().await;
+    clear_capability_cache();
+
+    let temp = tempfile::tempdir().unwrap();
+    let binary = temp.path().join("missing_codex");
+    let cache_key = capability_cache_key(&binary);
+
+    {
+        let mut cache = capability_cache().lock().unwrap();
+        cache.insert(
+            cache_key.clone(),
+            CodexCapabilities {
+                cache_key: cache_key.clone(),
+                fingerprint: None,
+                version: Some(version::parse_version_output("codex 9.9.9")),
+                features: CodexFeatureFlags {
+                    supports_features_list: true,
+                    supports_output_schema: true,
+                    supports_add_dir: true,
+                    supports_mcp_login: true,
+                },
+                probe_plan: CapabilityProbePlan::default(),
+                collected_at: SystemTime::UNIX_EPOCH,
+            },
+        );
+    }
+
+    let client = CodexClient::builder()
+        .binary(&binary)
+        .timeout(Duration::from_secs(1))
+        .build();
+
+    let capabilities = client.probe_capabilities().await;
+    assert!(!capabilities.features.supports_output_schema);
+    assert!(capabilities
+        .probe_plan
+        .steps
+        .contains(&CapabilityProbeStep::VersionFlag));
+
+    clear_capability_cache();
+}
+
+#[tokio::test]
+async fn probe_refresh_policy_forces_new_snapshot() {
+    let _guard = env_guard_async().await;
+    clear_capability_cache();
+
+    let temp = tempfile::tempdir().unwrap();
+    let log_path = temp.path().join("probe.log");
+    let script = format!(
+        r#"#!/bin/bash
+echo "$@" >> "{log}"
+if [[ "$1" == "--version" ]]; then
+  echo "codex 1.0.0"
+elif [[ "$1" == "features" && "$2" == "list" && "$3" == "--json" ]]; then
+  echo '{{"features":["output_schema"]}}'
+elif [[ "$1" == "features" && "$2" == "list" ]]; then
+  echo "output_schema"
+fi
+"#,
+        log = log_path.display()
+    );
+    let binary = write_fake_codex(temp.path(), &script);
+    let client = CodexClient::builder()
+        .binary(&binary)
+        .timeout(Duration::from_secs(5))
+        .build();
+
+    let first = client.probe_capabilities().await;
+    assert!(first.features.supports_output_schema);
+    let first_lines = std_fs::read_to_string(&log_path).unwrap().lines().count();
+    assert!(first_lines >= 2);
+
+    let refreshed = client
+        .probe_capabilities_with_policy(CapabilityCachePolicy::Refresh)
+        .await;
+    assert!(refreshed.features.supports_output_schema);
+    let refreshed_lines = std_fs::read_to_string(&log_path).unwrap().lines().count();
+    assert!(
+        refreshed_lines > first_lines,
+        "expected refresh policy to re-run probes"
+    );
+    clear_capability_cache();
+}
+
+#[tokio::test]
+async fn probe_bypass_policy_skips_cache_writes() {
+    let _guard = env_guard_async().await;
+    clear_capability_cache();
+
+    let temp = tempfile::tempdir().unwrap();
+    let script = r#"#!/bin/bash
+if [[ "$1" == "--version" ]]; then
+  echo "codex 1.0.0"
+elif [[ "$1" == "features" && "$2" == "list" && "$3" == "--json" ]]; then
+  echo '{"features":["output_schema"]}'
+elif [[ "$1" == "features" && "$2" == "list" ]]; then
+  echo "output_schema"
+fi
+"#;
+    let binary = write_fake_codex(temp.path(), script);
+
+    let client = CodexClient::builder()
+        .binary(&binary)
+        .timeout(Duration::from_secs(5))
+        .build();
+
+    let capabilities = client
+        .probe_capabilities_with_policy(CapabilityCachePolicy::Bypass)
+        .await;
+    assert!(capabilities.features.supports_output_schema);
+    assert!(capability_cache_entry(&binary).is_none());
+    clear_capability_cache();
+}
+
+#[test]
+fn parses_features_from_json_and_text() {
+    let json = r#"{"features":["output_schema","add_dir"],"mcp_login":true}"#;
+    let parsed_json = version::parse_features_from_json(json).unwrap();
+    assert!(parsed_json.supports_output_schema);
+    assert!(parsed_json.supports_add_dir);
+    assert!(parsed_json.supports_mcp_login);
+
+    let text = "Features: output-schema add-dir login --mcp";
+    let parsed_text = version::parse_features_from_text(text);
+    assert!(parsed_text.supports_output_schema);
+    assert!(parsed_text.supports_add_dir);
+    assert!(parsed_text.supports_mcp_login);
+}
+
+#[test]
+fn parses_feature_list_json_and_text_tables() {
+    let json = r#"{"features":[{"name":"json-stream","stage":"stable","enabled":true,"notes":"keep"},{"name":"cloud-exec","stage":"experimental","enabled":false}]}"#;
+    let (json_features, json_format) = version::parse_feature_list_output(json, true).unwrap();
+    assert_eq!(json_format, FeaturesListFormat::Json);
+    assert_eq!(json_features.len(), 2);
+    assert_eq!(json_features[0].name, "json-stream");
+    assert_eq!(json_features[0].stage, Some(CodexFeatureStage::Stable));
+    assert!(json_features[0].enabled);
+    assert!(json_features[0].extra.contains_key("notes"));
+    assert_eq!(
+        json_features[1].stage,
+        Some(CodexFeatureStage::Experimental)
+    );
+    assert!(!json_features[1].enabled);
+
+    let text = r#"
+Feature   Stage         Enabled
+json-stream stable      true
+	cloud-exec experimental false
+	"#;
+    let (text_features, text_format) = version::parse_feature_list_output(text, false).unwrap();
+    assert_eq!(text_format, FeaturesListFormat::Text);
+    assert_eq!(text_features.len(), 2);
+    assert_eq!(
+        text_features[1].stage,
+        Some(CodexFeatureStage::Experimental)
+    );
+    assert!(!text_features[1].enabled);
+
+    let (fallback_features, fallback_format) =
+        version::parse_feature_list_output(text, true).unwrap();
+    assert_eq!(fallback_format, FeaturesListFormat::Text);
+    assert_eq!(fallback_features.len(), 2);
+}
+
+#[test]
+fn parses_help_output_flags() {
+    let help =
+        "Usage: codex --output-schema ... add-dir ... login --mcp. See `codex features list`.";
+    let parsed = version::parse_help_output(help);
+    assert!(parsed.supports_output_schema);
+    assert!(parsed.supports_add_dir);
+    assert!(parsed.supports_mcp_login);
+    assert!(parsed.supports_features_list);
+}
+
+#[test]
+fn capability_guard_reports_detected_support() {
+    let flags = CodexFeatureFlags {
+        supports_features_list: true,
+        supports_output_schema: true,
+        supports_add_dir: true,
+        supports_mcp_login: true,
+    };
+    let capabilities = capabilities_with_feature_flags(flags);
+
+    let output_schema = capabilities.guard_output_schema();
+    assert_eq!(output_schema.support, CapabilitySupport::Supported);
+    assert!(output_schema.is_supported());
+
+    let add_dir = capabilities.guard_add_dir();
+    assert_eq!(add_dir.support, CapabilitySupport::Supported);
+    assert!(add_dir.is_supported());
+
+    let mcp_login = capabilities.guard_mcp_login();
+    assert_eq!(mcp_login.support, CapabilitySupport::Supported);
+
+    let features_list = capabilities.guard_features_list();
+    assert_eq!(features_list.support, CapabilitySupport::Supported);
+}
+
+#[test]
+fn capability_guard_marks_absent_feature_as_unsupported() {
+    let flags = CodexFeatureFlags {
+        supports_features_list: true,
+        supports_output_schema: false,
+        supports_add_dir: false,
+        supports_mcp_login: false,
+    };
+    let capabilities = capabilities_with_feature_flags(flags);
+
+    let output_schema = capabilities.guard_output_schema();
+    assert_eq!(output_schema.support, CapabilitySupport::Unsupported);
+    assert!(!output_schema.is_supported());
+    assert!(output_schema
+        .notes
+        .iter()
+        .any(|note| note.contains("features list")));
+
+    let mcp_login = capabilities.guard_mcp_login();
+    assert_eq!(mcp_login.support, CapabilitySupport::Unsupported);
+}
+
+#[test]
+fn capability_guard_returns_unknown_without_feature_list() {
+    let capabilities = capabilities_with_feature_flags(CodexFeatureFlags::default());
+
+    let add_dir = capabilities.guard_add_dir();
+    assert_eq!(add_dir.support, CapabilitySupport::Unknown);
+    assert!(add_dir.is_unknown());
+    assert!(add_dir
+        .notes
+        .iter()
+        .any(|note| note.contains("unknown") || note.contains("unavailable")));
+
+    let features_list = capabilities.guard_features_list();
+    assert_eq!(features_list.support, CapabilitySupport::Unknown);
+}
+
+#[tokio::test]
+async fn capability_snapshot_short_circuits_probes() {
+    let _guard = env_guard_async().await;
+    clear_capability_cache();
+
+    let temp = tempfile::tempdir().unwrap();
+    let log_path = temp.path().join("probe.log");
+    let script = format!(
+        r#"#!/bin/bash
+echo "$@" >> "{log}"
+exit 99
+"#,
+        log = log_path.display()
+    );
+    let binary = write_fake_codex(temp.path(), &script);
+
+    let snapshot = CodexCapabilities {
+        cache_key: CapabilityCacheKey {
+            binary_path: PathBuf::from("codex"),
+        },
+        fingerprint: None,
+        version: Some(version::parse_version_output("codex 9.9.9-custom")),
+        features: CodexFeatureFlags {
+            supports_features_list: true,
+            supports_output_schema: true,
+            supports_add_dir: false,
+            supports_mcp_login: true,
+        },
+        probe_plan: CapabilityProbePlan::default(),
+        collected_at: SystemTime::now(),
+    };
+
+    let client = CodexClient::builder()
+        .binary(&binary)
+        .capability_snapshot(snapshot)
+        .timeout(Duration::from_secs(5))
+        .build();
+
+    let capabilities = client.probe_capabilities().await;
+    assert_eq!(
+        capabilities.cache_key.binary_path,
+        std_fs::canonicalize(&binary).unwrap()
+    );
+    assert!(capabilities.fingerprint.is_some());
+    assert!(capabilities.features.supports_output_schema);
+    assert!(capabilities.features.supports_mcp_login);
+    assert_eq!(
+        capabilities.version.as_ref().and_then(|v| v.semantic),
+        Some((9, 9, 9))
+    );
+    assert!(capabilities
+        .probe_plan
+        .steps
+        .contains(&CapabilityProbeStep::ManualOverride));
+    assert!(!log_path.exists());
+}
+
+#[tokio::test]
+async fn capability_feature_overrides_apply_to_cached_entries() {
+    let _guard = env_guard_async().await;
+    clear_capability_cache();
+
+    let temp = tempfile::tempdir().unwrap();
+    let script = r#"#!/bin/bash
+if [[ "$1" == "--version" ]]; then
+  echo "codex 1.0.0"
+elif [[ "$1" == "features" && "$2" == "list" && "$3" == "--json" ]]; then
+  echo '{"features":[]}'
+elif [[ "$1" == "features" && "$2" == "list" ]]; then
+  echo "features list"
+elif [[ "$1" == "--help" ]]; then
+  echo "Usage: codex exec"
+fi
+"#;
+    let binary = write_fake_codex(temp.path(), script);
+
+    let base_client = CodexClient::builder()
+        .binary(&binary)
+        .timeout(Duration::from_secs(5))
+        .build();
+    let base_capabilities = base_client.probe_capabilities().await;
+    assert!(base_capabilities.features.supports_features_list);
+    assert!(!base_capabilities.features.supports_output_schema);
+
+    let overrides = CapabilityFeatureOverrides::enabling(CodexFeatureFlags {
+        supports_features_list: false,
+        supports_output_schema: true,
+        supports_add_dir: false,
+        supports_mcp_login: true,
+    });
+
+    let client = CodexClient::builder()
+        .binary(&binary)
+        .capability_feature_overrides(overrides)
+        .timeout(Duration::from_secs(5))
+        .build();
+
+    let capabilities = client.probe_capabilities().await;
+    assert!(capabilities.features.supports_output_schema);
+    assert!(capabilities.features.supports_mcp_login);
+    assert!(capabilities
+        .probe_plan
+        .steps
+        .contains(&CapabilityProbeStep::ManualOverride));
+    assert_eq!(
+        capabilities.guard_output_schema().support,
+        CapabilitySupport::Supported
+    );
+}
+
+#[tokio::test]
+async fn capability_version_override_replaces_probe_version() {
+    let _guard = env_guard_async().await;
+    clear_capability_cache();
+
+    let temp = tempfile::tempdir().unwrap();
+    let script = r#"#!/bin/bash
+if [[ "$1" == "--version" ]]; then
+  echo "codex 0.1.0"
+elif [[ "$1" == "features" && "$2" == "list" && "$3" == "--json" ]]; then
+  echo '{"features":["add_dir"]}'
+elif [[ "$1" == "features" && "$2" == "list" ]]; then
+  echo "add_dir"
+elif [[ "$1" == "--help" ]]; then
+  echo "Usage: codex add-dir"
+fi
+	"#;
+    let binary = write_fake_codex(temp.path(), script);
+    let version_override = version::parse_version_output("codex 9.9.9-nightly (commit beefcafe)");
+
+    let client = CodexClient::builder()
+        .binary(&binary)
+        .timeout(Duration::from_secs(5))
+        .capability_version_override(version_override)
+        .build();
+
+    let capabilities = client.probe_capabilities().await;
+    assert_eq!(
+        capabilities.version.as_ref().and_then(|v| v.semantic),
+        Some((9, 9, 9))
+    );
+    assert!(matches!(
+        capabilities.version.as_ref().map(|v| v.channel),
+        Some(CodexReleaseChannel::Nightly)
+    ));
+    assert!(capabilities.features.supports_add_dir);
+    assert!(capabilities
+        .probe_plan
+        .steps
+        .contains(&CapabilityProbeStep::ManualOverride));
+    assert_eq!(
+        capabilities.guard_add_dir().support,
+        CapabilitySupport::Supported
+    );
+}
+
+#[tokio::test]
+async fn exec_applies_guarded_flags_when_supported() {
+    let _guard = env_guard_async().await;
+    clear_capability_cache();
+
+    let temp = tempfile::tempdir().unwrap();
+    let log_path = temp.path().join("exec.log");
+    let script = format!(
+        r#"#!/bin/bash
+log="{log}"
+if [[ "$1" == "--version" ]]; then
+  echo "codex 1.2.3"
+elif [[ "$1" == "features" && "$2" == "list" && "$3" == "--json" ]]; then
+  echo '{{"features":["output_schema","add_dir","mcp_login"]}}'
+elif [[ "$1" == "features" && "$2" == "list" ]]; then
+  echo "output_schema add_dir login --mcp"
+elif [[ "$1" == "--help" ]]; then
+  echo "Usage: codex --output-schema add-dir login --mcp"
+elif [[ "$1" == "exec" ]]; then
+  echo "$@" >> "$log"
+  echo "ok"
+fi
+"#,
+        log = log_path.display()
+    );
+    let binary = write_fake_codex(temp.path(), &script);
+    let client = CodexClient::builder()
+        .binary(&binary)
+        .timeout(Duration::from_secs(5))
+        .add_dir("src")
+        .output_schema(true)
+        .quiet(true)
+        .mirror_stdout(false)
+        .build();
+
+    let response = client.send_prompt("hello").await.unwrap();
+    assert_eq!(response.trim(), "ok");
+
+    let logged = std_fs::read_to_string(&log_path).unwrap();
+    assert!(logged.contains("--add-dir"));
+    assert!(logged.contains("src"));
+    assert!(logged.contains("--output-schema"));
+}
+
+#[tokio::test]
+async fn exec_skips_guarded_flags_when_unknown() {
+    let _guard = env_guard_async().await;
+    clear_capability_cache();
+
+    let temp = tempfile::tempdir().unwrap();
+    let log_path = temp.path().join("exec.log");
+    let script = format!(
+        r#"#!/bin/bash
+log="{log}"
+if [[ "$1" == "--version" ]]; then
+  echo "codex 0.9.0"
+elif [[ "$1" == "features" && "$2" == "list" && "$3" == "--json" ]]; then
+  echo "feature list unavailable" >&2
+  exit 1
+elif [[ "$1" == "features" && "$2" == "list" ]]; then
+  echo "feature list unavailable" >&2
+  exit 1
+elif [[ "$1" == "--help" ]]; then
+  echo "Usage: codex exec"
+elif [[ "$1" == "exec" ]]; then
+  echo "$@" >> "$log"
+  echo "ok"
+fi
+"#,
+        log = log_path.display()
+    );
+    let binary = write_fake_codex(temp.path(), &script);
+    let client = CodexClient::builder()
+        .binary(&binary)
+        .timeout(Duration::from_secs(5))
+        .add_dir("src")
+        .output_schema(true)
+        .quiet(true)
+        .mirror_stdout(false)
+        .build();
+
+    let response = client.send_prompt("hello").await.unwrap();
+    assert_eq!(response.trim(), "ok");
+
+    let logged = std_fs::read_to_string(&log_path).unwrap();
+    assert!(!logged.contains("--add-dir"));
+    assert!(!logged.contains("--output-schema"));
+}
+
+#[tokio::test]
+async fn mcp_login_skips_when_unsupported() {
+    let _guard = env_guard_async().await;
+    clear_capability_cache();
+
+    let temp = tempfile::tempdir().unwrap();
+    let log_path = temp.path().join("login.log");
+    let script = format!(
+        r#"#!/bin/bash
+log="{log}"
+if [[ "$1" == "--version" ]]; then
+  echo "codex 1.0.0"
+elif [[ "$1" == "features" && "$2" == "list" && "$3" == "--json" ]]; then
+  echo '{{"features":["output_schema","add_dir"]}}'
+elif [[ "$1" == "features" && "$2" == "list" ]]; then
+  echo "output_schema add-dir"
+elif [[ "$1" == "--help" ]]; then
+  echo "Usage: codex exec"
+elif [[ "$1" == "login" ]]; then
+  echo "$@" >> "$log"
+  echo "login invoked"
+fi
+"#,
+        log = log_path.display()
+    );
+    let binary = write_fake_codex(temp.path(), &script);
+    let client = CodexClient::builder()
+        .binary(&binary)
+        .timeout(Duration::from_secs(5))
+        .build();
+
+    let login = client.spawn_mcp_login_process().await.unwrap();
+    assert!(login.is_none());
+    assert!(!log_path.exists());
+}
+
+#[tokio::test]
+async fn mcp_login_runs_when_supported() {
+    let _guard = env_guard_async().await;
+    clear_capability_cache();
+
+    let temp = tempfile::tempdir().unwrap();
+    let log_path = temp.path().join("login.log");
+    let script = format!(
+        r#"#!/bin/bash
+log="{log}"
+if [[ "$1" == "--version" ]]; then
+  echo "codex 2.0.0"
+elif [[ "$1" == "features" && "$2" == "list" && "$3" == "--json" ]]; then
+  echo '{{"features":["output_schema","add_dir"],"mcp_login":true}}'
+elif [[ "$1" == "features" && "$2" == "list" ]]; then
+  echo "output_schema add_dir login --mcp"
+elif [[ "$1" == "--help" ]]; then
+  echo "Usage: codex --output-schema add-dir login --mcp"
+elif [[ "$1" == "login" ]]; then
+  echo "$@" >> "$log"
+  echo "login invoked"
+fi
+"#,
+        log = log_path.display()
+    );
+    let binary = write_fake_codex(temp.path(), &script);
+    let client = CodexClient::builder()
+        .binary(&binary)
+        .timeout(Duration::from_secs(5))
+        .build();
+
+    let login = client
+        .spawn_mcp_login_process()
+        .await
+        .unwrap()
+        .expect("expected login child");
+    let output = login.wait_with_output().await.unwrap();
+    assert!(output.status.success());
+
+    let logged = std_fs::read_to_string(&log_path).unwrap();
+    assert!(logged.contains("login --mcp"));
+}
+
+#[tokio::test]
+async fn probe_capabilities_caches_and_invalidates() {
+    let _guard = env_guard_async().await;
+    clear_capability_cache();
+
+    let temp = tempfile::tempdir().unwrap();
+    let script_v1 = r#"#!/bin/bash
+if [[ "$1" == "--version" ]]; then
+  echo "codex 1.2.3-beta (commit cafe123)"
+elif [[ "$1" == "features" && "$2" == "list" && "$3" == "--json" ]]; then
+  echo '{"features":["output_schema","add_dir","mcp_login"]}'
+elif [[ "$1" == "features" && "$2" == "list" ]]; then
+  echo "output_schema add-dir login --mcp"
+elif [[ "$1" == "--help" ]]; then
+  echo "Usage: codex --output-schema add-dir login --mcp"
+fi
+"#;
+    let binary = write_fake_codex(temp.path(), script_v1);
+    let client = CodexClient::builder()
+        .binary(&binary)
+        .timeout(Duration::from_secs(5))
+        .build();
+
+    let first = client.probe_capabilities().await;
+    assert_eq!(
+        first.version.as_ref().and_then(|v| v.semantic),
+        Some((1, 2, 3))
+    );
+    assert_eq!(
+        first.version.as_ref().map(|v| v.channel),
+        Some(CodexReleaseChannel::Beta)
+    );
+    assert_eq!(
+        first.version.as_ref().and_then(|v| v.commit.as_deref()),
+        Some("cafe123")
+    );
+    assert!(first.features.supports_features_list);
+    assert!(first.features.supports_output_schema);
+    assert!(first.features.supports_add_dir);
+    assert!(first.features.supports_mcp_login);
+
+    let cached = client.probe_capabilities().await;
+    assert_eq!(cached, first);
+
+    let script_v2 = r#"#!/bin/bash
+if [[ "$1" == "--version" ]]; then
+  echo "codex 2.0.0 (commit deadbeef)"
+elif [[ "$1" == "features" && "$2" == "list" && "$3" == "--json" ]]; then
+  echo '{"features":["add_dir"]}'
+elif [[ "$1" == "features" && "$2" == "list" ]]; then
+  echo "add-dir"
+elif [[ "$1" == "--help" ]]; then
+  echo "Usage: codex add-dir"
+fi
+"#;
+    std_fs::write(&binary, script_v2).unwrap();
+    let mut perms = std_fs::metadata(&binary).unwrap().permissions();
+    perms.set_mode(0o755);
+    std_fs::set_permissions(&binary, perms).unwrap();
+
+    let refreshed = client.probe_capabilities().await;
+    assert_ne!(refreshed.version, first.version);
+    assert_eq!(
+        refreshed.version.as_ref().and_then(|v| v.semantic),
+        Some((2, 0, 0))
+    );
+    assert!(refreshed.features.supports_features_list);
+    assert!(refreshed.features.supports_add_dir);
+    assert!(!refreshed.features.supports_output_schema);
+    assert!(!refreshed.features.supports_mcp_login);
+    clear_capability_cache();
+}
+
+#[test]
+fn reasoning_config_by_model() {
+    assert_eq!(
+        reasoning_config_for(Some("gpt-5")).unwrap(),
+        DEFAULT_REASONING_CONFIG_GPT5
+    );
+    assert_eq!(
+        reasoning_config_for(Some("gpt-5.1-codex-max")).unwrap(),
+        DEFAULT_REASONING_CONFIG_GPT5_1
+    );
+    assert_eq!(
+        reasoning_config_for(Some("gpt-5-codex")).unwrap(),
+        DEFAULT_REASONING_CONFIG_GPT5_CODEX
+    );
+    assert!(reasoning_config_for(None).is_none());
+    assert!(reasoning_config_for(Some("gpt-4.1-mini")).is_none());
+}
+
+#[test]
+fn resolve_cli_overrides_respects_reasoning_defaults() {
+    let builder = CliOverrides::default();
+    let patch = CliOverridesPatch::default();
+
+    let resolved = resolve_cli_overrides(&builder, &patch, Some("gpt-5"));
+    let keys: Vec<_> = resolved
+        .config_overrides
+        .iter()
+        .map(|override_| override_.key.as_str())
+        .collect();
+    assert!(keys.contains(&"model_reasoning_effort"));
+    assert!(keys.contains(&"model_reasoning_summary"));
+    assert!(keys.contains(&"model_verbosity"));
+
+    let resolved_without_model = resolve_cli_overrides(&builder, &patch, None);
+    assert!(resolved_without_model.config_overrides.is_empty());
+}
+
+#[test]
+fn explicit_reasoning_overrides_disable_defaults() {
+    let mut builder = CliOverrides::default();
+    builder
+        .config_overrides
+        .push(ConfigOverride::new("model_reasoning_effort", "high"));
+
+    let resolved = resolve_cli_overrides(&builder, &CliOverridesPatch::default(), Some("gpt-5"));
+    assert_eq!(resolved.config_overrides.len(), 1);
+    assert_eq!(resolved.config_overrides[0].value, "high");
+}
+
+#[test]
+fn request_can_disable_auto_reasoning_defaults() {
+    let builder = CliOverrides::default();
+    let patch = CliOverridesPatch {
+        auto_reasoning_defaults: Some(false),
+        ..Default::default()
+    };
+
+    let resolved = resolve_cli_overrides(&builder, &patch, Some("gpt-5"));
+    assert!(resolved.config_overrides.is_empty());
+}
+
+#[test]
+fn request_config_overrides_follow_builder_order() {
+    let mut builder_overrides = CliOverrides {
+        auto_reasoning_defaults: false,
+        ..Default::default()
+    };
+    builder_overrides
+        .config_overrides
+        .push(ConfigOverride::new("foo", "bar"));
+
+    let mut patch = CliOverridesPatch::default();
+    patch
+        .config_overrides
+        .push(ConfigOverride::new("foo", "baz"));
+
+    let resolved = resolve_cli_overrides(&builder_overrides, &patch, None);
+    let values: Vec<_> = resolved
+        .config_overrides
+        .iter()
+        .map(|override_| override_.value.as_str())
+        .collect();
+    assert_eq!(values, vec!["bar", "baz"]);
+}
+
+#[test]
+fn request_search_override_can_disable_builder_flag() {
+    let builder_overrides = CliOverrides {
+        search: FlagState::Enable,
+        ..Default::default()
+    };
+
+    let patch = CliOverridesPatch {
+        search: FlagState::Disable,
+        ..Default::default()
+    };
+
+    let resolved = resolve_cli_overrides(&builder_overrides, &patch, None);
+    let args = cli_override_args(&resolved, true);
+    let args: Vec<_> = args
+        .iter()
+        .map(|arg| arg.to_string_lossy().into_owned())
+        .collect();
+    assert!(!args.contains(&"--search".to_string()));
+}
+
+#[test]
+fn request_profile_override_replaces_builder_value() {
+    let builder_overrides = CliOverrides {
+        profile: Some("builder".to_string()),
+        ..Default::default()
+    };
+
+    let patch = CliOverridesPatch {
+        profile: Some("request".to_string()),
+        ..Default::default()
+    };
+
+    let resolved = resolve_cli_overrides(&builder_overrides, &patch, None);
+    let args: Vec<_> = cli_override_args(&resolved, true)
+        .iter()
+        .map(|arg| arg.to_string_lossy().into_owned())
+        .collect();
+    assert!(args.windows(2).any(|window| {
+        window.first().map(String::as_str) == Some("--profile")
+            && window.get(1).map(String::as_str) == Some("request")
+    }));
+    assert!(!args.contains(&"builder".to_string()));
+}
+
+#[test]
+fn request_oss_override_can_disable_builder_flag() {
+    let builder_overrides = CliOverrides {
+        oss: FlagState::Enable,
+        ..Default::default()
+    };
+
+    let resolved = resolve_cli_overrides(&builder_overrides, &CliOverridesPatch::default(), None);
+    let args: Vec<_> = cli_override_args(&resolved, true)
+        .iter()
+        .map(|arg| arg.to_string_lossy().into_owned())
+        .collect();
+    assert!(args.contains(&"--oss".to_string()));
+
+    let patch = CliOverridesPatch {
+        oss: FlagState::Disable,
+        ..Default::default()
+    };
+    let resolved = resolve_cli_overrides(&builder_overrides, &patch, None);
+    let args: Vec<_> = cli_override_args(&resolved, true)
+        .iter()
+        .map(|arg| arg.to_string_lossy().into_owned())
+        .collect();
+    assert!(!args.contains(&"--oss".to_string()));
+}
+
+#[test]
+fn feature_toggles_merge_builder_and_request() {
+    let mut builder_overrides = CliOverrides::default();
+    builder_overrides
+        .feature_toggles
+        .enable
+        .push("builder-enable".to_string());
+    builder_overrides
+        .feature_toggles
+        .disable
+        .push("builder-disable".to_string());
+
+    let mut patch = CliOverridesPatch::default();
+    patch
+        .feature_toggles
+        .enable
+        .push("request-enable".to_string());
+    patch
+        .feature_toggles
+        .disable
+        .push("request-disable".to_string());
+
+    let resolved = resolve_cli_overrides(&builder_overrides, &patch, None);
+    let args: Vec<_> = cli_override_args(&resolved, true)
+        .iter()
+        .map(|arg| arg.to_string_lossy().into_owned())
+        .collect();
+
+    assert!(args.windows(2).any(|window| {
+        window.first().map(String::as_str) == Some("--enable")
+            && window.get(1).map(String::as_str) == Some("builder-enable")
+    }));
+    assert!(args.windows(2).any(|window| {
+        window.first().map(String::as_str) == Some("--enable")
+            && window.get(1).map(String::as_str) == Some("request-enable")
+    }));
+    assert!(args.windows(2).any(|window| {
+        window.first().map(String::as_str) == Some("--disable")
+            && window.get(1).map(String::as_str) == Some("builder-disable")
+    }));
+    assert!(args.windows(2).any(|window| {
+        window.first().map(String::as_str) == Some("--disable")
+            && window.get(1).map(String::as_str) == Some("request-disable")
+    }));
+}
+
+#[test]
+fn cli_override_args_apply_safety_precedence() {
+    let mut resolved = ResolvedCliOverrides {
+        config_overrides: Vec::new(),
+        feature_toggles: FeatureToggles::default(),
+        approval_policy: None,
+        sandbox_mode: None,
+        safety_override: SafetyOverride::FullAuto,
+        profile: None,
+        cd: None,
+        local_provider: None,
+        oss: false,
+        search: FlagState::Enable,
+    };
+    let args = cli_override_args(&resolved, true);
+    let args: Vec<_> = args
+        .iter()
+        .map(|value| value.to_string_lossy().into_owned())
+        .collect();
+    assert!(args.contains(&"--full-auto".to_string()));
+    assert!(args.contains(&"--search".to_string()));
+    assert!(!args.contains(&"--ask-for-approval".to_string()));
+
+    resolved.approval_policy = Some(ApprovalPolicy::OnRequest);
+    let args_with_policy = cli_override_args(&resolved, true);
+    let args_with_policy: Vec<_> = args_with_policy
+        .iter()
+        .map(|value| value.to_string_lossy().into_owned())
+        .collect();
+    assert!(!args_with_policy.contains(&"--full-auto".to_string()));
+    assert!(args_with_policy.contains(&"--ask-for-approval".to_string()));
+
+    let resolved = ResolvedCliOverrides {
+        config_overrides: vec![ConfigOverride::new("foo", "bar")],
+        feature_toggles: FeatureToggles::default(),
+        approval_policy: Some(ApprovalPolicy::OnRequest),
+        sandbox_mode: Some(SandboxMode::WorkspaceWrite),
+        safety_override: SafetyOverride::DangerouslyBypass,
+        profile: Some("team".to_string()),
+        cd: Some(PathBuf::from("/tmp/worktree")),
+        local_provider: Some(LocalProvider::Ollama),
+        oss: false,
+        search: FlagState::Enable,
+    };
+    let args = cli_override_args(&resolved, true);
+    let args: Vec<_> = args
+        .iter()
+        .map(|value| value.to_string_lossy().into_owned())
+        .collect();
+    assert!(args.contains(&"--config".to_string()));
+    assert!(args.contains(&"foo=bar".to_string()));
+    assert!(args.contains(&"--dangerously-bypass-approvals-and-sandbox".to_string()));
+    assert!(args.contains(&"--profile".to_string()));
+    assert!(args.contains(&"team".to_string()));
+    assert!(args.contains(&"--cd".to_string()));
+    assert!(args.contains(&"/tmp/worktree".to_string()));
+    assert!(args.contains(&"--local-provider".to_string()));
+    assert!(args.contains(&"ollama".to_string()));
+    assert!(args.contains(&"--search".to_string()));
+    assert!(!args.contains(&"--ask-for-approval".to_string()));
+    assert!(!args.contains(&"--sandbox".to_string()));
+
+    let args_without_search = cli_override_args(&resolved, false);
+    let args_without_search: Vec<_> = args_without_search
+        .iter()
+        .map(|value| value.to_string_lossy().into_owned())
+        .collect();
+    assert!(!args_without_search.contains(&"--search".to_string()));
+}
+
+#[tokio::test]
+async fn exec_applies_cli_overrides_and_request_patch() {
+    let _guard = env_guard_async().await;
+    clear_capability_cache();
+
+    let temp = tempfile::tempdir().unwrap();
+    let log_path = temp.path().join("exec.log");
+    let builder_cd = temp.path().join("builder-cd");
+    let request_cd = temp.path().join("request-cd");
+    let script = format!(
+        r#"#!/bin/bash
+echo "$@" >> "{log}"
+if [[ "$1" == "exec" ]]; then
+  echo "ok"
+fi
+"#,
+        log = log_path.display()
+    );
+    let binary = write_fake_codex(temp.path(), &script);
+    let client = CodexClient::builder()
+        .binary(&binary)
+        .timeout(Duration::from_secs(5))
+        .mirror_stdout(false)
+        .quiet(true)
+        .auto_reasoning_defaults(false)
+        .config_override("foo", "bar")
+        .reasoning_summary(ReasoningSummary::Concise)
+        .approval_policy(ApprovalPolicy::OnRequest)
+        .sandbox_mode(SandboxMode::WorkspaceWrite)
+        .cd(&builder_cd)
+        .local_provider(LocalProvider::Custom)
+        .oss(true)
+        .enable_feature("builder-on")
+        .disable_feature("builder-off")
+        .search(true)
+        .build();
+
+    let mut request = ExecRequest::new("list flags")
+        .config_override("extra", "value")
+        .oss(false)
+        .enable_feature("request-on")
+        .disable_feature("request-off")
+        .search(false);
+    request.overrides.cd = Some(request_cd.clone());
+    request.overrides.safety_override = Some(SafetyOverride::DangerouslyBypass);
+
+    let response = client.send_prompt_with(request).await.unwrap();
+    assert_eq!(response.trim(), "ok");
+
+    let logged = std_fs::read_to_string(&log_path).unwrap();
+    assert!(logged.contains("--config"));
+    assert!(logged.contains("foo=bar"));
+    assert!(logged.contains("extra=value"));
+    assert!(logged.contains("model_reasoning_summary=concise"));
+    assert!(logged.contains("--dangerously-bypass-approvals-and-sandbox"));
+    assert!(logged.contains(&request_cd.display().to_string()));
+    assert!(!logged.contains(&builder_cd.display().to_string()));
+    assert!(logged.contains("--local-provider"));
+    assert!(logged.contains("custom"));
+    assert!(logged.contains("--enable"));
+    assert!(logged.contains("builder-on"));
+    assert!(logged.contains("request-on"));
+    assert!(logged.contains("--disable"));
+    assert!(logged.contains("builder-off"));
+    assert!(logged.contains("request-off"));
+    assert!(!logged.contains("--oss"));
+    assert!(!logged.contains("--ask-for-approval"));
+    assert!(!logged.contains("--sandbox"));
+    assert!(!logged.contains("--search"));
+}
+
+#[tokio::test]
+async fn resume_applies_search_and_selector_overrides() {
+    let _guard = env_guard_async().await;
+    clear_capability_cache();
+
+    let temp = tempfile::tempdir().unwrap();
+    let log_path = temp.path().join("resume.log");
+    let builder_cd = temp.path().join("builder-cd");
+    let request_cd = temp.path().join("request-cd");
+    let script = format!(
+        r#"#!/bin/bash
+echo "$@" >> "{log}"
+if [[ "$1" == "exec" ]]; then
+  echo '{{"type":"thread.started","thread_id":"thread-1"}}'
+  echo '{{"type":"turn.started","thread_id":"thread-1","turn_id":"turn-1"}}'
+  echo '{{"type":"turn.completed","thread_id":"thread-1","turn_id":"turn-1"}}'
+fi
+"#,
+        log = log_path.display()
+    );
+    let binary = write_fake_codex(temp.path(), &script);
+    let client = CodexClient::builder()
+        .binary(&binary)
+        .timeout(Duration::from_secs(5))
+        .mirror_stdout(false)
+        .quiet(true)
+        .config_override("resume_hint", "enabled")
+        .approval_policy(ApprovalPolicy::OnRequest)
+        .sandbox_mode(SandboxMode::WorkspaceWrite)
+        .local_provider(LocalProvider::Ollama)
+        .cd(&builder_cd)
+        .search(true)
+        .build();
+
+    let request_last = ResumeRequest::last().prompt("continue");
+    let stream = client.stream_resume(request_last).await.unwrap();
+    let events: Vec<_> = stream.events.collect().await;
+    assert_eq!(events.len(), 3);
+    stream.completion.await.unwrap();
+
+    let mut request_all = ResumeRequest::all().prompt("summarize");
+    request_all.overrides.search = FlagState::Disable;
+    request_all.overrides.safety_override = Some(SafetyOverride::DangerouslyBypass);
+    request_all.overrides.cd = Some(request_cd.clone());
+    let stream_all = client.stream_resume(request_all).await.unwrap();
+    let _ = stream_all.events.collect::<Vec<_>>().await;
+    stream_all.completion.await.unwrap();
+
+    let logged: Vec<_> = std_fs::read_to_string(&log_path)
+        .unwrap()
+        .lines()
+        .map(str::to_string)
+        .collect();
+    assert!(logged.len() >= 2);
+
+    assert!(logged[0].contains("--last"));
+    assert!(logged[0].contains("--search"));
+    assert!(logged[0].contains("resume_hint=enabled"));
+    assert!(logged[0].contains("--ask-for-approval"));
+    assert!(logged[0].contains("--sandbox"));
+    assert!(logged[0].contains(&builder_cd.display().to_string()));
+    assert!(logged[0].contains("ollama"));
+
+    assert!(logged[1].contains("--all"));
+    assert!(logged[1].contains("--dangerously-bypass-approvals-and-sandbox"));
+    assert!(logged[1].contains(&request_cd.display().to_string()));
+    assert!(!logged[1].contains(&builder_cd.display().to_string()));
+    assert!(!logged[1].contains("--ask-for-approval"));
+    assert!(!logged[1].contains("--sandbox"));
+    assert!(!logged[1].contains("--search"));
+}
+
+#[tokio::test]
+async fn apply_respects_cli_overrides_without_search() {
+    let _guard = env_guard_async().await;
+    clear_capability_cache();
+
+    let temp = tempfile::tempdir().unwrap();
+    let log_path = temp.path().join("apply.log");
+    let script = format!(
+        r#"#!/bin/bash
+echo "$@" >> "{log}"
+if [[ "$1" == "apply" ]]; then
+  echo "applied"
+fi
+"#,
+        log = log_path.display()
+    );
+    let binary = write_fake_codex(temp.path(), &script);
+    let client = CodexClient::builder()
+        .binary(&binary)
+        .timeout(Duration::from_secs(5))
+        .mirror_stdout(false)
+        .quiet(true)
+        .cd(temp.path().join("apply-cd"))
+        .config_override("feature.toggle", "true")
+        .search(true)
+        .build();
+
+    let artifacts = client.apply().await.unwrap();
+    assert_eq!(artifacts.stdout.trim(), "applied");
+
+    let logged = std_fs::read_to_string(&log_path).unwrap();
+    assert!(logged.contains("--config"));
+    assert!(logged.contains("feature.toggle=true"));
+    assert!(logged.contains("apply-cd"));
+    assert!(!logged.contains("--search"));
+}
+
+#[test]
+fn color_mode_strings_are_stable() {
+    assert_eq!(ColorMode::Auto.as_str(), "auto");
+    assert_eq!(ColorMode::Always.as_str(), "always");
+    assert_eq!(ColorMode::Never.as_str(), "never");
+}
+
+#[tokio::test]
+async fn auth_helper_uses_app_scoped_home_without_mutating_env() {
+    let _guard = env_guard_async().await;
+    let temp = tempfile::tempdir().unwrap();
+    let log_path = temp.path().join("auth.log");
+    let app_home = temp.path().join("app-home");
+    let caller_home = temp.path().join("caller-home");
+    let previous_home = env::var("CODEX_HOME").ok();
+    env::set_var("CODEX_HOME", &caller_home);
+    env::set_var("AUTH_HELPER_LOG", &log_path);
+
+    let script = r#"#!/usr/bin/env bash
+set -e
+echo "args:$*" >> "$AUTH_HELPER_LOG"
+echo "CODEX_HOME=${CODEX_HOME:-missing}" >> "$AUTH_HELPER_LOG"
+if [[ "$1" == "login" && "$2" == "status" ]]; then
+  echo "Logged in using ChatGPT"
+  exit 0
+fi
+echo "Not logged in" >&2
+exit 1
+"#;
+    let binary = write_fake_codex(temp.path(), script);
+    let helper = AuthSessionHelper::with_client(
+        CodexClient::builder()
+            .binary(&binary)
+            .codex_home(&app_home)
+            .build(),
+    );
+
+    let status = helper.status().await.unwrap();
+    assert!(matches!(
+        status,
+        CodexAuthStatus::LoggedIn(CodexAuthMethod::ChatGpt)
+    ));
+
+    let logged = std_fs::read_to_string(&log_path).unwrap();
+    assert!(logged.contains("args:login status"));
+    assert!(logged.contains(&format!("CODEX_HOME={}", app_home.display())));
+
+    assert_eq!(
+        env::var("CODEX_HOME").unwrap(),
+        caller_home.display().to_string()
+    );
+
+    env::remove_var("AUTH_HELPER_LOG");
+    if let Some(previous) = previous_home {
+        env::set_var("CODEX_HOME", previous);
+    } else {
+        env::remove_var("CODEX_HOME");
+    }
+}
+
+#[tokio::test]
+async fn ensure_api_key_login_runs_when_logged_out() {
+    let _guard = env_guard_async().await;
+    let temp = tempfile::tempdir().unwrap();
+    let log_path = temp.path().join("login.log");
+    let state_path = temp.path().join("api-key-state");
+    let script = format!(
+        r#"#!/usr/bin/env bash
+set -e
+echo "$@" >> "{log}"
+if [[ "$1" == "login" && "$2" == "status" ]]; then
+  if [[ -f "{state}" ]]; then
+echo "Logged in using an API key - sk-already"
+exit 0
+  fi
+  echo "Not logged in" >&2
+  exit 1
+fi
+if [[ "$1" == "login" && "$2" == "--api-key" ]]; then
+  echo "Logged in using an API key - $3" > "{state}"
+  echo "Logged in using an API key - $3"
+  exit 0
+fi
+echo "unexpected args: $*" >&2
+exit 2
+"#,
+        log = log_path.display(),
+        state = state_path.display()
+    );
+    let binary = write_fake_codex(temp.path(), &script);
+    let helper = AuthSessionHelper::with_client(
+        CodexClient::builder()
+            .binary(&binary)
+            .codex_home(temp.path().join("app-home"))
+            .build(),
+    );
+
+    let status = helper.ensure_api_key_login("sk-test-key").await.unwrap();
+    match status {
+        CodexAuthStatus::LoggedIn(CodexAuthMethod::ApiKey { masked_key }) => {
+            assert_eq!(masked_key.as_deref(), Some("sk-test-key"));
+        }
+        other => panic!("unexpected status: {other:?}"),
+    }
+
+    let second = helper.ensure_api_key_login("sk-other").await.unwrap();
+    assert!(matches!(
+        second,
+        CodexAuthStatus::LoggedIn(CodexAuthMethod::ApiKey { .. })
+    ));
+
+    let log = std_fs::read_to_string(&log_path).unwrap();
+    assert!(log.contains("login status"));
+    assert!(log.contains("login --api-key sk-test-key"));
+    assert_eq!(
+        log.lines()
+            .filter(|line| line.contains("--api-key"))
+            .count(),
+        1
+    );
+}
+
+#[tokio::test]
+async fn ensure_chatgpt_login_launches_when_needed() {
+    let _guard = env_guard_async().await;
+    let temp = tempfile::tempdir().unwrap();
+    let log_path = temp.path().join("chatgpt.log");
+    let state_path = temp.path().join("chatgpt-state");
+    let script = format!(
+        r#"#!/usr/bin/env bash
+set -e
+echo "$@" >> "{log}"
+if [[ "$1" == "login" && "$2" == "status" ]]; then
+  if [[ -f "{state}" ]]; then
+echo "Logged in using ChatGPT"
+exit 0
+  fi
+  echo "Not logged in" >&2
+  exit 1
+fi
+if [[ "$1" == "login" && -z "$2" ]]; then
+  echo "Logged in using ChatGPT" > "{state}"
+  echo "Logged in using ChatGPT"
+  exit 0
+fi
+echo "unknown args: $*" >&2
+exit 2
+"#,
+        log = log_path.display(),
+        state = state_path.display()
+    );
+    let binary = write_fake_codex(temp.path(), &script);
+    let helper = AuthSessionHelper::with_client(
+        CodexClient::builder()
+            .binary(&binary)
+            .codex_home(temp.path().join("app-home"))
+            .build(),
+    );
+
+    let child = helper.ensure_chatgpt_login().await.unwrap();
+    let child = child.expect("expected ChatGPT login child");
+    let output = child.wait_with_output().await.unwrap();
+    let stdout = String::from_utf8_lossy(&output.stdout);
+    assert!(stdout.contains("Logged in using ChatGPT"));
+
+    let second = helper.ensure_chatgpt_login().await.unwrap();
+    assert!(second.is_none());
+
+    let log = std_fs::read_to_string(&log_path).unwrap();
+    assert!(log.lines().any(|line| line == "login"));
+    assert_eq!(log.lines().filter(|line| line == &"login").count(), 1);
+}
+
+#[test]
+fn parses_chatgpt_login() {
+    let message = "Logged in using ChatGPT";
+    let parsed = parse_login_success(message);
+    assert!(matches!(
+        parsed,
+        Some(CodexAuthStatus::LoggedIn(CodexAuthMethod::ChatGpt))
+    ));
+}
+
+#[test]
+fn parses_api_key_login() {
+    let message = "Logged in using an API key - sk-1234***abcd";
+    let parsed = parse_login_success(message);
+    match parsed {
+        Some(CodexAuthStatus::LoggedIn(CodexAuthMethod::ApiKey { masked_key })) => {
+            assert_eq!(masked_key.as_deref(), Some("sk-1234***abcd"));
+        }
+        other => panic!("unexpected status: {other:?}"),
+    }
+}
+
+#[test]
+fn parse_login_accepts_unknown_on_success() {
+    let message = "Authenticated";
+    assert!(parse_login_success(message).is_none());
+    let status = CodexAuthStatus::LoggedIn(CodexAuthMethod::Unknown {
+        raw: message.to_string(),
+    });
+    assert!(matches!(
+        status,
+        CodexAuthStatus::LoggedIn(CodexAuthMethod::Unknown { .. })
+    ));
+}
diff --git a/crates/codex/src/version.rs b/crates/codex/src/version.rs
new file mode 100644
index 0000000..134c1d3
--- /dev/null
+++ b/crates/codex/src/version.rs
@@ -0,0 +1,571 @@
+use std::collections::{BTreeMap, HashSet};
+
+use semver::{Prerelease, Version};
+use serde_json::Value;
+
+use crate::{
+    CodexCapabilities, CodexFeature, CodexFeatureFlags, CodexFeatureStage, CodexLatestReleases,
+    CodexRelease, CodexReleaseChannel, CodexUpdateAdvisory, CodexUpdateStatus, CodexVersionInfo,
+    FeaturesListFormat,
+};
+
+fn parse_semver_from_raw(raw: &str) -> Option<Version> {
+    for token in raw.split_whitespace() {
+        let candidate = token
+            .trim_matches(|c: char| matches!(c, '(' | ')' | ',' | ';'))
+            .trim_start_matches('v');
+        if let Ok(version) = Version::parse(candidate) {
+            return Some(version);
+        }
+    }
+    None
+}
+
+pub(super) fn parse_version_output(output: &str) -> CodexVersionInfo {
+    let raw = output.trim().to_string();
+    let parsed_version = parse_semver_from_raw(&raw);
+    let semantic = parsed_version
+        .as_ref()
+        .map(|version| (version.major, version.minor, version.patch));
+    let mut commit = extract_commit_hash(&raw);
+    if commit.is_none() {
+        for token in raw.split_whitespace() {
+            let candidate = token
+                .trim_matches(|c: char| matches!(c, '(' | ')' | ',' | ';'))
+                .trim_start_matches('v');
+            if let Some(cleaned) = cleaned_hex(candidate) {
+                commit = Some(cleaned);
+                break;
+            }
+        }
+    }
+    let channel = parsed_version
+        .as_ref()
+        .map(release_channel_for_version)
+        .unwrap_or_else(|| infer_release_channel(&raw));
+
+    CodexVersionInfo {
+        raw,
+        semantic,
+        commit,
+        channel,
+    }
+}
+
+fn release_channel_for_version(version: &Version) -> CodexReleaseChannel {
+    if version.pre.is_empty() {
+        CodexReleaseChannel::Stable
+    } else {
+        let prerelease = version.pre.as_str().to_ascii_lowercase();
+        if prerelease.contains("beta") {
+            CodexReleaseChannel::Beta
+        } else if prerelease.contains("nightly") {
+            CodexReleaseChannel::Nightly
+        } else {
+            CodexReleaseChannel::Custom
+        }
+    }
+}
+
+fn infer_release_channel(raw: &str) -> CodexReleaseChannel {
+    let lower = raw.to_ascii_lowercase();
+    if lower.contains("beta") {
+        CodexReleaseChannel::Beta
+    } else if lower.contains("nightly") {
+        CodexReleaseChannel::Nightly
+    } else {
+        CodexReleaseChannel::Custom
+    }
+}
+
+fn codex_semver(info: &CodexVersionInfo) -> Option<Version> {
+    if let Some(parsed) = parse_semver_from_raw(&info.raw) {
+        return Some(parsed);
+    }
+    let (major, minor, patch) = info.semantic?;
+    let mut version = Version::new(major, minor, patch);
+    if version.pre.is_empty() {
+        match info.channel {
+            CodexReleaseChannel::Beta => {
+                version.pre = Prerelease::new("beta").ok()?;
+            }
+            CodexReleaseChannel::Nightly => {
+                version.pre = Prerelease::new("nightly").ok()?;
+            }
+            CodexReleaseChannel::Stable | CodexReleaseChannel::Custom => {}
+        }
+    }
+    Some(version)
+}
+
+fn codex_release_from_info(info: &CodexVersionInfo) -> Option<CodexRelease> {
+    let version = codex_semver(info)?;
+    Some(CodexRelease {
+        channel: info.channel,
+        version,
+    })
+}
+
+fn extract_commit_hash(raw: &str) -> Option<String> {
+    let tokens: Vec<&str> = raw.split_whitespace().collect();
+    for window in tokens.windows(2) {
+        if window[0].eq_ignore_ascii_case("commit") {
+            if let Some(cleaned) = cleaned_hex(window[1]) {
+                return Some(cleaned);
+            }
+        }
+    }
+
+    for token in tokens {
+        if let Some(cleaned) = cleaned_hex(token) {
+            return Some(cleaned);
+        }
+    }
+    None
+}
+
+fn cleaned_hex(token: &str) -> Option<String> {
+    let trimmed = token
+        .trim_matches(|c: char| matches!(c, '(' | ')' | ',' | ';'))
+        .trim_start_matches("commit")
+        .trim_start_matches(':')
+        .trim_start_matches('g');
+    if trimmed.len() >= 7 && trimmed.chars().all(|c| c.is_ascii_hexdigit()) {
+        Some(trimmed.to_string())
+    } else {
+        None
+    }
+}
+
+pub(super) fn parse_features_from_json(output: &str) -> Option<CodexFeatureFlags> {
+    let parsed: Value = serde_json::from_str(output).ok()?;
+    let mut tokens = HashSet::new();
+    collect_feature_tokens(&parsed, &mut tokens);
+    if tokens.is_empty() {
+        return None;
+    }
+
+    let mut flags = CodexFeatureFlags::default();
+    for token in tokens {
+        apply_feature_token(&mut flags, &token);
+    }
+    Some(flags)
+}
+
+fn collect_feature_tokens(value: &Value, tokens: &mut HashSet<String>) {
+    match value {
+        Value::String(value) => {
+            if !value.trim().is_empty() {
+                tokens.insert(value.clone());
+            }
+        }
+        Value::Array(items) => {
+            for item in items {
+                collect_feature_tokens(item, tokens);
+            }
+        }
+        Value::Object(map) => {
+            for (key, value) in map {
+                if let Value::Bool(true) = value {
+                    tokens.insert(key.clone());
+                }
+                collect_feature_tokens(value, tokens);
+            }
+        }
+        _ => {}
+    }
+}
+
+pub(super) fn parse_features_from_text(output: &str) -> CodexFeatureFlags {
+    let mut flags = CodexFeatureFlags::default();
+    let lower = output.to_ascii_lowercase();
+    if lower.contains("features list") {
+        flags.supports_features_list = true;
+    }
+    if lower.contains("--output-schema") || lower.contains("output schema") {
+        flags.supports_output_schema = true;
+    }
+    if lower.contains("add-dir") || lower.contains("add dir") {
+        flags.supports_add_dir = true;
+    }
+    if lower.contains("login --mcp") || lower.contains("mcp login") {
+        flags.supports_mcp_login = true;
+    }
+    if lower.contains("login") && lower.contains("mcp") {
+        flags.supports_mcp_login = true;
+    }
+
+    for token in lower
+        .split(|c: char| c.is_ascii_whitespace() || c == ',' || c == ';' || c == '|')
+        .filter(|token| !token.is_empty())
+    {
+        apply_feature_token(&mut flags, token);
+    }
+    flags
+}
+
+pub(super) fn parse_help_output(output: &str) -> CodexFeatureFlags {
+    let mut flags = parse_features_from_text(output);
+    let lower = output.to_ascii_lowercase();
+    if lower.contains("features list") {
+        flags.supports_features_list = true;
+    }
+    flags
+}
+
+pub(super) fn merge_feature_flags(target: &mut CodexFeatureFlags, update: CodexFeatureFlags) {
+    target.supports_features_list |= update.supports_features_list;
+    target.supports_output_schema |= update.supports_output_schema;
+    target.supports_add_dir |= update.supports_add_dir;
+    target.supports_mcp_login |= update.supports_mcp_login;
+}
+
+pub(super) fn detected_feature_flags(flags: &CodexFeatureFlags) -> bool {
+    flags.supports_output_schema || flags.supports_add_dir || flags.supports_mcp_login
+}
+
+pub(super) fn should_run_help_fallback(flags: &CodexFeatureFlags) -> bool {
+    !flags.supports_features_list
+        || !flags.supports_output_schema
+        || !flags.supports_add_dir
+        || !flags.supports_mcp_login
+}
+
+fn normalize_feature_token(token: &str) -> String {
+    token
+        .chars()
+        .map(|c| {
+            if c.is_ascii_alphanumeric() {
+                c.to_ascii_lowercase()
+            } else {
+                '_'
+            }
+        })
+        .collect()
+}
+
+fn apply_feature_token(flags: &mut CodexFeatureFlags, token: &str) {
+    let normalized = normalize_feature_token(token);
+    let compact = normalized.replace('_', "");
+    if normalized.contains("features_list") || compact.contains("featureslist") {
+        flags.supports_features_list = true;
+    }
+    if normalized.contains("output_schema") || compact.contains("outputschema") {
+        flags.supports_output_schema = true;
+    }
+    if normalized.contains("add_dir") || compact.contains("adddir") {
+        flags.supports_add_dir = true;
+    }
+    if normalized.contains("mcp_login")
+        || (normalized.contains("login") && normalized.contains("mcp"))
+    {
+        flags.supports_mcp_login = true;
+    }
+}
+
+pub(super) fn parse_feature_list_output(
+    stdout: &str,
+    prefer_json: bool,
+) -> Result<(Vec<CodexFeature>, FeaturesListFormat), String> {
+    let trimmed = stdout.trim();
+    if trimmed.is_empty() {
+        return Err("features list output was empty".to_string());
+    }
+
+    if prefer_json {
+        if let Some(features) = parse_feature_list_json(trimmed) {
+            if !features.is_empty() {
+                return Ok((features, FeaturesListFormat::Json));
+            }
+        }
+        if let Some(features) = parse_feature_list_text(trimmed) {
+            if !features.is_empty() {
+                return Ok((features, FeaturesListFormat::Text));
+            }
+        }
+    } else {
+        if let Some(features) = parse_feature_list_text(trimmed) {
+            if !features.is_empty() {
+                return Ok((features, FeaturesListFormat::Text));
+            }
+        }
+        if let Some(features) = parse_feature_list_json(trimmed) {
+            if !features.is_empty() {
+                return Ok((features, FeaturesListFormat::Json));
+            }
+        }
+    }
+
+    Err("could not parse JSON or text feature rows".to_string())
+}
+
+fn parse_feature_list_json(output: &str) -> Option<Vec<CodexFeature>> {
+    let parsed: Value = serde_json::from_str(output).ok()?;
+    parse_feature_list_json_value(&parsed)
+}
+
+fn parse_feature_list_json_value(value: &Value) -> Option<Vec<CodexFeature>> {
+    match value {
+        Value::Array(items) => Some(
+            items
+                .iter()
+                .filter_map(|item| match item {
+                    Value::Object(map) => feature_from_json_fields(None, map),
+                    Value::String(name) => Some(CodexFeature {
+                        name: name.clone(),
+                        stage: None,
+                        enabled: true,
+                        extra: BTreeMap::new(),
+                    }),
+                    _ => None,
+                })
+                .collect(),
+        ),
+        Value::Object(map) => {
+            if let Some(features) = map.get("features") {
+                return parse_feature_list_json_value(features);
+            }
+            if map.contains_key("name") || map.contains_key("enabled") || map.contains_key("stage")
+            {
+                return feature_from_json_fields(None, map).map(|feature| vec![feature]);
+            }
+            Some(
+                map.iter()
+                    .filter_map(|(name, value)| match value {
+                        Value::Object(inner) => {
+                            feature_from_json_fields(Some(name.as_str()), inner)
+                        }
+                        Value::Bool(flag) => Some(CodexFeature {
+                            name: name.clone(),
+                            stage: None,
+                            enabled: *flag,
+                            extra: BTreeMap::new(),
+                        }),
+                        Value::String(flag) => parse_feature_enabled_str(flag)
+                            .map(|enabled| CodexFeature {
+                                name: name.clone(),
+                                stage: None,
+                                enabled,
+                                extra: BTreeMap::new(),
+                            })
+                            .or_else(|| {
+                                Some(CodexFeature {
+                                    name: name.clone(),
+                                    stage: Some(CodexFeatureStage::parse(flag)),
+                                    enabled: true,
+                                    extra: BTreeMap::new(),
+                                })
+                            }),
+                        _ => None,
+                    })
+                    .collect(),
+            )
+        }
+        _ => None,
+    }
+}
+
+fn parse_feature_list_text(output: &str) -> Option<Vec<CodexFeature>> {
+    let mut features = Vec::new();
+    for line in output.lines() {
+        let trimmed = line.trim();
+        if trimmed.is_empty() {
+            continue;
+        }
+        if trimmed
+            .chars()
+            .all(|c| matches!(c, '-' | '=' | '+' | '*' | '|'))
+        {
+            continue;
+        }
+
+        let tokens: Vec<&str> = trimmed.split_whitespace().collect();
+        if tokens.len() < 3 {
+            continue;
+        }
+        if tokens[0].eq_ignore_ascii_case("feature")
+            && tokens[1].eq_ignore_ascii_case("stage")
+            && tokens[2].eq_ignore_ascii_case("enabled")
+        {
+            continue;
+        }
+
+        let enabled_token = tokens.last().copied().unwrap_or_default();
+        let enabled = match parse_feature_enabled_str(enabled_token) {
+            Some(value) => value,
+            None => continue,
+        };
+        let stage_token = tokens.get(tokens.len() - 2).copied().unwrap_or_default();
+        let name = tokens[..tokens.len() - 2].join(" ");
+        if name.is_empty() {
+            continue;
+        }
+        let stage = (!stage_token.is_empty()).then(|| CodexFeatureStage::parse(stage_token));
+        features.push(CodexFeature {
+            name,
+            stage,
+            enabled,
+            extra: BTreeMap::new(),
+        });
+    }
+
+    if features.is_empty() {
+        None
+    } else {
+        Some(features)
+    }
+}
+
+fn parse_feature_enabled_value(value: &Value) -> Option<bool> {
+    match value {
+        Value::Bool(flag) => Some(*flag),
+        Value::String(raw) => parse_feature_enabled_str(raw),
+        _ => None,
+    }
+}
+
+fn parse_feature_enabled_str(raw: &str) -> Option<bool> {
+    match raw.trim().to_ascii_lowercase().as_str() {
+        "true" | "yes" | "y" | "on" | "1" | "enabled" => Some(true),
+        "false" | "no" | "n" | "off" | "0" | "disabled" => Some(false),
+        _ => None,
+    }
+}
+
+fn feature_from_json_fields(
+    name_hint: Option<&str>,
+    map: &serde_json::Map<String, Value>,
+) -> Option<CodexFeature> {
+    let name = map
+        .get("name")
+        .and_then(Value::as_str)
+        .map(str::to_string)
+        .or_else(|| name_hint.map(str::to_string))?;
+    let enabled = map
+        .get("enabled")
+        .and_then(parse_feature_enabled_value)
+        .or_else(|| map.get("value").and_then(parse_feature_enabled_value))?;
+    let stage = map
+        .get("stage")
+        .or_else(|| map.get("status"))
+        .and_then(Value::as_str)
+        .map(CodexFeatureStage::parse);
+
+    let mut extra = BTreeMap::new();
+    for (key, value) in map {
+        if matches!(
+            key.as_str(),
+            "name" | "stage" | "status" | "enabled" | "value"
+        ) {
+            continue;
+        }
+        extra.insert(key.clone(), value.clone());
+    }
+
+    Some(CodexFeature {
+        name,
+        stage,
+        enabled,
+        extra,
+    })
+}
+
+/// Computes an update advisory for a previously probed binary.
+///
+/// Callers that already have a [`CodexCapabilities`] snapshot can use this
+/// helper to avoid re-running `codex --version`. Provide a [`CodexLatestReleases`]
+/// table sourced from your preferred distribution channel.
+pub fn update_advisory_from_capabilities(
+    capabilities: &CodexCapabilities,
+    latest_releases: &CodexLatestReleases,
+) -> CodexUpdateAdvisory {
+    let local_release = capabilities
+        .version
+        .as_ref()
+        .and_then(codex_release_from_info);
+    let preferred_channel = local_release
+        .as_ref()
+        .map(|release| release.channel)
+        .unwrap_or(CodexReleaseChannel::Stable);
+    let (latest_release, comparison_channel, fell_back) =
+        latest_releases.select_for_channel(preferred_channel);
+    let mut notes = Vec::new();
+
+    if fell_back {
+        notes.push(format!(
+            "No latest {preferred_channel} release provided; comparing against {comparison_channel}."
+        ));
+    }
+
+    let status = match (local_release.as_ref(), latest_release.as_ref()) {
+        (None, None) => CodexUpdateStatus::UnknownLatestVersion,
+        (None, Some(_)) => CodexUpdateStatus::UnknownLocalVersion,
+        (Some(_), None) => CodexUpdateStatus::UnknownLatestVersion,
+        (Some(local), Some(latest)) => {
+            if local.version < latest.version {
+                CodexUpdateStatus::UpdateRecommended
+            } else if local.version > latest.version {
+                CodexUpdateStatus::LocalNewerThanKnown
+            } else {
+                CodexUpdateStatus::UpToDate
+            }
+        }
+    };
+
+    match status {
+        CodexUpdateStatus::UpdateRecommended => {
+            if let (Some(local), Some(latest)) = (local_release.as_ref(), latest_release.as_ref()) {
+                notes.push(format!(
+                    "Local codex {local_version} is behind latest {comparison_channel} {latest_version}.",
+                    local_version = local.version,
+                    latest_version = latest.version
+                ));
+            }
+        }
+        CodexUpdateStatus::LocalNewerThanKnown => {
+            if let Some(local) = local_release.as_ref() {
+                let known = latest_release
+                    .as_ref()
+                    .map(|release| release.version.to_string())
+                    .unwrap_or_else(|| "unknown".to_string());
+                notes.push(format!(
+                    "Local codex {local_version} is newer than provided {comparison_channel} metadata (latest table: {known}).",
+                    local_version = local.version
+                ));
+            }
+        }
+        CodexUpdateStatus::UnknownLocalVersion => {
+            if let Some(latest) = latest_release.as_ref() {
+                notes.push(format!(
+                    "Latest known {comparison_channel} release is {latest_version}; local version could not be parsed.",
+                    latest_version = latest.version
+                ));
+            } else {
+                notes.push(
+                    "Local version could not be parsed and no latest release was provided."
+                        .to_string(),
+                );
+            }
+        }
+        CodexUpdateStatus::UnknownLatestVersion => notes.push(
+            "No latest Codex release information provided; update advisory unavailable."
+                .to_string(),
+        ),
+        CodexUpdateStatus::UpToDate => {
+            if let Some(latest) = latest_release.as_ref() {
+                notes.push(format!(
+                    "Local codex matches latest {comparison_channel} release {latest_version}.",
+                    latest_version = latest.version
+                ));
+            }
+        }
+    }
+
+    CodexUpdateAdvisory {
+        local_release,
+        latest_release,
+        comparison_channel,
+        status,
+        notes,
+    }
+}
diff --git a/crates/xtask/src/codex_validate.rs b/crates/xtask/src/codex_validate.rs
index f54656c..6da3ab3 100644
--- a/crates/xtask/src/codex_validate.rs
+++ b/crates/xtask/src/codex_validate.rs
@@ -11,10 +11,14 @@ use semver::Version;
 use serde_json::{json, Value};
 use thiserror::Error;
 
+mod current;
+mod fix_mode;
 mod models;
+mod pointer_consistency;
 mod pointers;
 mod report_invariants;
 mod schema;
+mod versions;
 mod wrapper_coverage;
 use models::{
     IuSortKey, ParityExclusionUnit, ParityExclusionsIndex, PointerRead, PointerValue,
@@ -213,7 +217,7 @@ fn run_inner(args: Args) -> Result<Vec<Violation>, FatalError> {
     };
 
     if matches!(args.mode, Mode::Fix) {
-        apply_fix_mode(&ctx)?;
+        fix_mode::apply_fix_mode(&ctx)?;
     }
 
     let mut violations = Vec::<Violation>::new();
@@ -225,16 +229,21 @@ fn run_inner(args: Args) -> Result<Vec<Violation>, FatalError> {
 
     // 2) Version set to validate.
     let versions_to_validate =
-        compute_versions_to_validate(&mut ctx, &mut violations, &pointer_values);
+        versions::compute_versions_to_validate(&mut ctx, &mut violations, &pointer_values);
 
     // 3) Per-version required files (+ schemas).
     let mut version_metadata = BTreeMap::<String, Value>::new();
     for version in &versions_to_validate {
-        validate_version_bundle(&mut ctx, &mut violations, version, &mut version_metadata);
+        versions::validate_version_bundle(
+            &mut ctx,
+            &mut violations,
+            version,
+            &mut version_metadata,
+        );
     }
 
     // 4) current.json invariants.
-    validate_current_json(
+    current::validate_current_json(
         &mut ctx,
         &mut violations,
         pointer_values.latest_validated.as_deref(),
@@ -244,7 +253,12 @@ fn run_inner(args: Args) -> Result<Vec<Violation>, FatalError> {
     wrapper_coverage::validate_wrapper_coverage(&mut ctx, &mut violations);
 
     // 6) Pointer  version metadata consistency (requires parsed metadata).
-    validate_pointer_consistency(&ctx, &mut violations, &pointer_values, &version_metadata);
+    pointer_consistency::validate_pointer_consistency(
+        &ctx,
+        &mut violations,
+        &pointer_values,
+        &version_metadata,
+    );
 
     violations.sort_by(|a, b| {
         a.sort_key()
@@ -258,729 +272,6 @@ fn run_inner(args: Args) -> Result<Vec<Violation>, FatalError> {
     Ok(violations)
 }
 
-fn apply_fix_mode(ctx: &ValidateCtx) -> Result<(), FatalError> {
-    // 1) Create missing pointer files under pointers/ for every expected target.
-    for target in &ctx.expected_targets {
-        for dir in ["pointers/latest_supported", "pointers/latest_validated"] {
-            let path = ctx.root.join(dir).join(format!("{target}.txt"));
-            if path.exists() {
-                continue;
-            }
-            fs::create_dir_all(path.parent().unwrap_or(&ctx.root))?;
-            fs::write(&path, b"none\n")?;
-        }
-    }
-
-    // 2) Normalize pointer formatting (single line + trailing newline).
-    for target in &ctx.expected_targets {
-        for dir in ["pointers/latest_supported", "pointers/latest_validated"] {
-            let path = ctx.root.join(dir).join(format!("{target}.txt"));
-            pointers::normalize_single_line_file(&path)?;
-        }
-    }
-    pointers::normalize_single_line_file(&ctx.root.join("latest_validated.txt"))?;
-    pointers::normalize_single_line_file(&ctx.root.join("min_supported.txt"))?;
-
-    // 3) Normalize current.json to match snapshots/<latest_validated>/union.json (if possible).
-    let latest_validated = match pointers::read_pointer_file(
-        &ctx.root.join("latest_validated.txt"),
-        &ctx.stable_semver_re,
-        false,
-    ) {
-        Ok(PointerRead::Value(PointerValue::Version(ver))) => Some(ver.to_string()),
-        _ => None,
-    };
-
-    if let Some(version) = latest_validated {
-        let union_path = ctx.root.join("snapshots").join(&version).join("union.json");
-        if union_path.is_file() {
-            let bytes = fs::read(&union_path)?;
-            fs::write(ctx.root.join("current.json"), bytes)?;
-        }
-    }
-
-    Ok(())
-}
-
-fn compute_versions_to_validate(
-    ctx: &mut ValidateCtx,
-    violations: &mut Vec<Violation>,
-    pointers: &PointerValues,
-) -> Vec<String> {
-    let mut versions = BTreeSet::<Version>::new();
-
-    for v in pointers
-        .min_supported
-        .iter()
-        .chain(pointers.latest_validated.iter())
-    {
-        if let Some(ver) = parse_stable_version(v, &ctx.stable_semver_re) {
-            versions.insert(ver);
-        }
-    }
-    for (_target, v) in pointers
-        .by_target_latest_supported
-        .iter()
-        .chain(pointers.by_target_latest_validated.iter())
-    {
-        if let Some(v) = v {
-            if let Some(ver) = parse_stable_version(v, &ctx.stable_semver_re) {
-                versions.insert(ver);
-            }
-        }
-    }
-
-    let versions_dir = ctx.root.join("versions");
-    match fs::read_dir(&versions_dir) {
-        Ok(read_dir) => {
-            let mut entries = read_dir
-                .filter_map(|e| e.ok())
-                .filter_map(|e| {
-                    let path = e.path();
-                    if path.extension().and_then(|x| x.to_str()) != Some("json") {
-                        return None;
-                    }
-                    let stem = path.file_stem()?.to_str()?.to_string();
-                    Some((stem, path))
-                })
-                .collect::<Vec<_>>();
-            entries.sort_by(|a, b| a.0.cmp(&b.0));
-            for (stem, path) in entries {
-                match parse_stable_version(&stem, &ctx.stable_semver_re) {
-                    Some(ver) => {
-                        versions.insert(ver);
-                    }
-                    None => violations.push(Violation {
-                        code: "VERSION_FILE_INVALID_NAME",
-                        path: rel_path(&ctx.root, &path),
-                        json_pointer: None,
-                        message: format!(
-                            "versions/<version>.json filename must be a strict stable semver (got {stem})"
-                        ),
-                        unit: Some("versions"),
-                        command_path: None,
-                        key_or_name: Some(stem),
-                        field: Some("filename"),
-                        target_triple: None,
-                        details: None,
-                    }),
-                }
-            }
-        }
-        Err(e) if e.kind() == io::ErrorKind::NotFound => {}
-        Err(e) => {
-            violations.push(Violation {
-                code: "VERSIONS_DIR_UNREADABLE",
-                path: rel_path(&ctx.root, &versions_dir),
-                json_pointer: None,
-                message: format!("failed to read versions directory: {e}"),
-                unit: Some("versions"),
-                command_path: None,
-                key_or_name: None,
-                field: None,
-                target_triple: None,
-                details: None,
-            });
-        }
-    }
-
-    versions.into_iter().map(|v| v.to_string()).collect()
-}
-
-fn validate_version_bundle(
-    ctx: &mut ValidateCtx,
-    violations: &mut Vec<Violation>,
-    version: &str,
-    version_metadata: &mut BTreeMap<String, Value>,
-) {
-    let version_path = ctx.root.join("versions").join(format!("{version}.json"));
-    match schema::read_json_file(
-        &ctx.root,
-        &version_path,
-        violations,
-        "VERSION_METADATA_INVALID_JSON",
-    ) {
-        Some(value) => {
-            schema::schema_validate(
-                ctx,
-                violations,
-                &ctx.version_schema,
-                &value,
-                &version_path,
-                "VERSION_METADATA_SCHEMA_INVALID",
-            );
-            validate_version_metadata_validation_sets(
-                ctx,
-                violations,
-                version,
-                &value,
-                &version_path,
-            );
-            version_metadata.insert(version.to_string(), value);
-        }
-        None => {
-            if !version_path.exists() {
-                violations.push(Violation {
-                    code: "VERSION_METADATA_MISSING",
-                    path: rel_path(&ctx.root, &version_path),
-                    json_pointer: None,
-                    message: format!("missing required file: versions/{version}.json"),
-                    unit: Some("versions"),
-                    command_path: None,
-                    key_or_name: Some(version.to_string()),
-                    field: Some("versions"),
-                    target_triple: None,
-                    details: None,
-                });
-            }
-        }
-    }
-
-    let union_path = ctx.root.join("snapshots").join(version).join("union.json");
-    let union_value = match schema::read_json_file(
-        &ctx.root,
-        &union_path,
-        violations,
-        "UNION_INVALID_JSON",
-    ) {
-        Some(value) => {
-            schema::schema_validate(
-                ctx,
-                violations,
-                &ctx.schema,
-                &value,
-                &union_path,
-                "UNION_SCHEMA_INVALID",
-            );
-            if !is_union_snapshot(&value) {
-                violations.push(Violation {
-                    code: "UNION_WRONG_KIND",
-                    path: rel_path(&ctx.root, &union_path),
-                    json_pointer: Some("/snapshot_schema_version".to_string()),
-                    message: "snapshots/<version>/union.json must be an UpstreamSnapshotUnionV2 (snapshot_schema_version=2, mode=union)".to_string(),
-                    unit: Some("snapshots"),
-                    command_path: None,
-                    key_or_name: Some(version.to_string()),
-                    field: Some("union"),
-                    target_triple: None,
-                    details: None,
-                });
-            }
-            Some(value)
-        }
-        None => {
-            if !union_path.exists() {
-                violations.push(Violation {
-                    code: "UNION_MISSING",
-                    path: rel_path(&ctx.root, &union_path),
-                    json_pointer: None,
-                    message: format!("missing required file: snapshots/{version}/union.json"),
-                    unit: Some("snapshots"),
-                    command_path: None,
-                    key_or_name: Some(version.to_string()),
-                    field: Some("union"),
-                    target_triple: None,
-                    details: None,
-                });
-            }
-            None
-        }
-    };
-
-    let inputs = union_value
-        .as_ref()
-        .and_then(|u| u.get("inputs"))
-        .and_then(Value::as_array)
-        .cloned()
-        .unwrap_or_default();
-
-    let mut input_targets = Vec::<String>::new();
-    for input in &inputs {
-        if let Some(t) = input.get("target_triple").and_then(Value::as_str) {
-            input_targets.push(t.to_string());
-        }
-    }
-
-    for target in &input_targets {
-        let per_target_path = ctx
-            .root
-            .join("snapshots")
-            .join(version)
-            .join(format!("{target}.json"));
-        match schema::read_json_file(
-            &ctx.root,
-            &per_target_path,
-            violations,
-            "SNAPSHOT_INVALID_JSON",
-        ) {
-            Some(value) => {
-                schema::schema_validate(
-                    ctx,
-                    violations,
-                    &ctx.schema,
-                    &value,
-                    &per_target_path,
-                    "SNAPSHOT_SCHEMA_INVALID",
-                );
-                if !is_per_target_snapshot(&value) {
-                    violations.push(Violation {
-                        code: "SNAPSHOT_WRONG_KIND",
-                        path: rel_path(&ctx.root, &per_target_path),
-                        json_pointer: Some("/snapshot_schema_version".to_string()),
-                        message: "snapshots/<version>/<target_triple>.json must be an UpstreamSnapshotV1 (snapshot_schema_version=1)".to_string(),
-                        unit: Some("snapshots"),
-                        command_path: None,
-                        key_or_name: Some(target.to_string()),
-                        field: Some("per_target"),
-                        target_triple: Some(target.to_string()),
-                        details: None,
-                    });
-                }
-            }
-            None => {
-                if per_target_path.exists() {
-                    continue;
-                }
-                violations.push(Violation {
-                    code: "SNAPSHOT_MISSING",
-                    path: rel_path(&ctx.root, &per_target_path),
-                    json_pointer: None,
-                    message: format!(
-                        "missing required file: snapshots/{version}/{target}.json (referenced by union.inputs[])"
-                    ),
-                    unit: Some("snapshots"),
-                    command_path: None,
-                    key_or_name: Some(target.to_string()),
-                    field: Some("per_target"),
-                    target_triple: Some(target.to_string()),
-                    details: None,
-                });
-            }
-        }
-    }
-
-    // Reports are required depending on version status.
-    let status = version_metadata
-        .get(version)
-        .and_then(|v| v.get("status"))
-        .and_then(Value::as_str)
-        .unwrap_or("unknown");
-
-    let require_reports = matches!(status, "reported" | "validated" | "supported");
-    let reports_dir = ctx.root.join("reports").join(version);
-    let any_report = reports_dir.join("coverage.any.json");
-    if require_reports {
-        report_invariants::require_report(ctx, violations, version, "any", None, &any_report);
-    } else {
-        report_invariants::validate_report_if_present(ctx, violations, &any_report);
-    }
-
-    for target in &input_targets {
-        let per_target = reports_dir.join(format!("coverage.{target}.json"));
-        if require_reports {
-            report_invariants::require_report(
-                ctx,
-                violations,
-                version,
-                "per_target",
-                Some(target.as_str()),
-                &per_target,
-            );
-        } else {
-            report_invariants::validate_report_if_present(ctx, violations, &per_target);
-        }
-    }
-
-    let complete = union_value
-        .as_ref()
-        .and_then(|u| u.get("complete"))
-        .and_then(Value::as_bool)
-        .unwrap_or(false);
-    if complete {
-        let all_report = reports_dir.join("coverage.all.json");
-        if require_reports {
-            report_invariants::require_report(ctx, violations, version, "all", None, &all_report);
-        } else {
-            report_invariants::validate_report_if_present(ctx, violations, &all_report);
-        }
-    }
-}
-
-fn validate_current_json(
-    ctx: &mut ValidateCtx,
-    violations: &mut Vec<Violation>,
-    latest_validated: Option<&str>,
-) {
-    let current_path = ctx.root.join("current.json");
-    let current_value = match schema::read_json_file(
-        &ctx.root,
-        &current_path,
-        violations,
-        "CURRENT_INVALID_JSON",
-    ) {
-        Some(v) => {
-            schema::schema_validate(
-                ctx,
-                violations,
-                &ctx.schema,
-                &v,
-                &current_path,
-                "CURRENT_SCHEMA_INVALID",
-            );
-            if !is_union_snapshot(&v) {
-                violations.push(Violation {
-                    code: "CURRENT_WRONG_KIND",
-                    path: rel_path(&ctx.root, &current_path),
-                    json_pointer: Some("/snapshot_schema_version".to_string()),
-                    message: "current.json must be an UpstreamSnapshotUnionV2 (snapshot_schema_version=2, mode=union)".to_string(),
-                    unit: Some("current_json"),
-                    command_path: None,
-                    key_or_name: None,
-                    field: Some("current"),
-                    target_triple: None,
-                    details: None,
-                });
-            }
-            Some(v)
-        }
-        None => {
-            if current_path.exists() {
-                return;
-            }
-            violations.push(Violation {
-                code: "CURRENT_MISSING",
-                path: rel_path(&ctx.root, &current_path),
-                json_pointer: None,
-                message: "missing required file: current.json".to_string(),
-                unit: Some("current_json"),
-                command_path: None,
-                key_or_name: None,
-                field: Some("current"),
-                target_triple: None,
-                details: None,
-            });
-            None
-        }
-    };
-
-    let Some(latest_validated) = latest_validated else {
-        return;
-    };
-    let union_path = ctx
-        .root
-        .join("snapshots")
-        .join(latest_validated)
-        .join("union.json");
-
-    if current_path.is_file() && union_path.is_file() {
-        if let (Ok(a), Ok(b)) = (fs::read(&current_path), fs::read(&union_path)) {
-            if a != b {
-                violations.push(Violation {
-                    code: "CURRENT_JSON_NOT_EQUAL_UNION",
-                    path: rel_path(&ctx.root, &current_path),
-                    json_pointer: None,
-                    message: format!(
-                        "current.json must be byte-for-byte identical to snapshots/{latest_validated}/union.json"
-                    ),
-                    unit: Some("current_json"),
-                    command_path: None,
-                    key_or_name: Some(latest_validated.to_string()),
-                    field: Some("identity"),
-                    target_triple: None,
-                    details: None,
-                });
-            }
-        }
-    }
-
-    // current.json semantic version invariants use the required target's input.binary.semantic_version.
-    let Some(current_value) = current_value else {
-        return;
-    };
-    let required_target = ctx.required_target.clone();
-    let required_input = current_value
-        .get("inputs")
-        .and_then(Value::as_array)
-        .and_then(|inputs| {
-            inputs.iter().find(|i| {
-                i.get("target_triple")
-                    .and_then(Value::as_str)
-                    .is_some_and(|t| t == required_target.as_str())
-            })
-        });
-    let Some(required_input) = required_input else {
-        violations.push(Violation {
-            code: "CURRENT_JSON_MISSING_REQUIRED_TARGET",
-            path: rel_path(&ctx.root, &current_path),
-            json_pointer: Some("/inputs".to_string()),
-            message: format!("current.json.inputs[] missing required_target={required_target}"),
-            unit: Some("current_json"),
-            command_path: None,
-            key_or_name: Some(required_target.clone()),
-            field: Some("inputs"),
-            target_triple: Some(required_target),
-            details: None,
-        });
-        return;
-    };
-    let semantic_version = required_input
-        .get("binary")
-        .and_then(|b| b.get("semantic_version"))
-        .and_then(Value::as_str);
-    if semantic_version != Some(latest_validated) {
-        violations.push(Violation {
-            code: "CURRENT_JSON_SEMVER_MISMATCH",
-            path: rel_path(&ctx.root, &current_path),
-            json_pointer: Some("/inputs/*/binary/semantic_version".to_string()),
-            message: format!(
-                "current.json required_target binary.semantic_version must equal latest_validated.txt (expected {latest_validated}, got {})",
-                semantic_version.unwrap_or("<missing>")
-            ),
-            unit: Some("current_json"),
-            command_path: None,
-            key_or_name: Some(required_target.clone()),
-            field: Some("semantic_version"),
-            target_triple: Some(required_target),
-            details: None,
-        });
-    }
-}
-
-fn intersect(a: &BTreeSet<String>, b: &BTreeSet<String>) -> BTreeSet<String> {
-    a.intersection(b).cloned().collect()
-}
-
-fn validate_version_metadata_validation_sets(
-    ctx: &ValidateCtx,
-    violations: &mut Vec<Violation>,
-    version: &str,
-    meta: &Value,
-    path: &Path,
-) {
-    let Some(validation) = meta.get("validation") else {
-        return;
-    };
-
-    let expected = ctx
-        .expected_targets
-        .iter()
-        .cloned()
-        .collect::<BTreeSet<_>>();
-
-    let passed = validation
-        .get("passed_targets")
-        .and_then(Value::as_array)
-        .map(|arr| {
-            arr.iter()
-                .filter_map(Value::as_str)
-                .map(|s| s.to_string())
-                .collect::<BTreeSet<_>>()
-        })
-        .unwrap_or_default();
-    let failed = validation
-        .get("failed_targets")
-        .and_then(Value::as_array)
-        .map(|arr| {
-            arr.iter()
-                .filter_map(Value::as_str)
-                .map(|s| s.to_string())
-                .collect::<BTreeSet<_>>()
-        })
-        .unwrap_or_default();
-    let skipped = validation
-        .get("skipped_targets")
-        .and_then(Value::as_array)
-        .map(|arr| {
-            arr.iter()
-                .filter_map(Value::as_str)
-                .map(|s| s.to_string())
-                .collect::<BTreeSet<_>>()
-        })
-        .unwrap_or_default();
-
-    let overlaps = [
-        (
-            "passed_targets",
-            "failed_targets",
-            intersect(&passed, &failed),
-        ),
-        (
-            "passed_targets",
-            "skipped_targets",
-            intersect(&passed, &skipped),
-        ),
-        (
-            "failed_targets",
-            "skipped_targets",
-            intersect(&failed, &skipped),
-        ),
-    ];
-    for (a, b, inter) in overlaps {
-        if inter.is_empty() {
-            continue;
-        }
-        violations.push(Violation {
-            code: "VALIDATION_TARGET_SETS_OVERLAP",
-            path: rel_path(&ctx.root, path),
-            json_pointer: Some("/validation".to_string()),
-            message: format!(
-                "versions/{version}.json validation target sets overlap ({a}  {b} = {:?})",
-                inter.iter().collect::<Vec<_>>()
-            ),
-            unit: Some("versions"),
-            command_path: None,
-            key_or_name: Some(version.to_string()),
-            field: Some("validation"),
-            target_triple: None,
-            details: Some(json!({
-                "overlap": inter.into_iter().collect::<Vec<_>>(),
-                "a": a,
-                "b": b,
-            })),
-        });
-    }
-
-    for t in passed.iter().chain(failed.iter()).chain(skipped.iter()) {
-        if expected.contains(t) {
-            continue;
-        }
-        violations.push(Violation {
-            code: "VALIDATION_TARGET_NOT_EXPECTED",
-            path: rel_path(&ctx.root, path),
-            json_pointer: Some("/validation".to_string()),
-            message: format!(
-                "versions/{version}.json validation includes unexpected target_triple={t} (not in RULES.json.union.expected_targets)"
-            ),
-            unit: Some("versions"),
-            command_path: None,
-            key_or_name: Some(version.to_string()),
-            field: Some("validation"),
-            target_triple: Some(t.to_string()),
-            details: None,
-        });
-    }
-
-    let required = ctx.required_target.as_str();
-    let count = (passed.contains(required) as u8)
-        + (failed.contains(required) as u8)
-        + (skipped.contains(required) as u8);
-    if count != 1 {
-        violations.push(Violation {
-            code: "VALIDATION_REQUIRED_TARGET_NOT_EXPLICIT",
-            path: rel_path(&ctx.root, path),
-            json_pointer: Some("/validation".to_string()),
-            message: format!(
-                "versions/{version}.json validation must include required_target={} in exactly one of passed_targets/failed_targets/skipped_targets",
-                ctx.required_target
-            ),
-            unit: Some("versions"),
-            command_path: None,
-            key_or_name: Some(version.to_string()),
-            field: Some("validation"),
-            target_triple: Some(ctx.required_target.clone()),
-            details: Some(json!({
-                "required_target": ctx.required_target,
-                "passed": passed.contains(required),
-                "failed": failed.contains(required),
-                "skipped": skipped.contains(required),
-            })),
-        });
-    }
-}
-
-fn validate_pointer_consistency(
-    ctx: &ValidateCtx,
-    violations: &mut Vec<Violation>,
-    pointers: &PointerValues,
-    version_metadata: &BTreeMap<String, Value>,
-) {
-    for (target, v) in &pointers.by_target_latest_supported {
-        let Some(version) = v.as_deref() else {
-            continue;
-        };
-        let meta = version_metadata.get(version);
-        if meta.is_none() {
-            continue;
-        }
-        let supported_targets = meta
-            .and_then(|m| m.get("coverage"))
-            .and_then(|c| c.get("supported_targets"))
-            .and_then(Value::as_array)
-            .map(|arr| {
-                arr.iter()
-                    .filter_map(Value::as_str)
-                    .map(|s| s.to_string())
-                    .collect::<BTreeSet<_>>()
-            })
-            .unwrap_or_default();
-        if !supported_targets.contains(target) {
-            violations.push(Violation {
-                code: "POINTER_INCONSISTENT_WITH_VERSION_METADATA",
-                path: rel_path(&ctx.root, &ctx.root.join("versions").join(format!("{version}.json"))),
-                json_pointer: Some("/coverage/supported_targets".to_string()),
-                message: format!(
-                    "pointers/latest_supported/{target}.txt={version} requires versions/{version}.json.coverage.supported_targets to include target_triple={target}"
-                ),
-                unit: Some("pointers"),
-                command_path: None,
-                key_or_name: Some(target.clone()),
-                field: Some("latest_supported"),
-                target_triple: Some(target.clone()),
-                details: None,
-            });
-        }
-    }
-
-    for (target, v) in &pointers.by_target_latest_validated {
-        let Some(version) = v.as_deref() else {
-            continue;
-        };
-        let meta = version_metadata.get(version);
-        if meta.is_none() {
-            continue;
-        }
-        let supported_targets = meta
-            .and_then(|m| m.get("coverage"))
-            .and_then(|c| c.get("supported_targets"))
-            .and_then(Value::as_array)
-            .map(|arr| {
-                arr.iter()
-                    .filter_map(Value::as_str)
-                    .map(|s| s.to_string())
-                    .collect::<BTreeSet<_>>()
-            })
-            .unwrap_or_default();
-        let passed_targets = meta
-            .and_then(|m| m.get("validation"))
-            .and_then(|v| v.get("passed_targets"))
-            .and_then(Value::as_array)
-            .map(|arr| {
-                arr.iter()
-                    .filter_map(Value::as_str)
-                    .map(|s| s.to_string())
-                    .collect::<BTreeSet<_>>()
-            })
-            .unwrap_or_default();
-
-        if !supported_targets.contains(target) || !passed_targets.contains(target) {
-            violations.push(Violation {
-                code: "POINTER_INCONSISTENT_WITH_VERSION_METADATA",
-                path: rel_path(&ctx.root, &ctx.root.join("versions").join(format!("{version}.json"))),
-                json_pointer: Some("/validation/passed_targets".to_string()),
-                message: format!(
-                    "pointers/latest_validated/{target}.txt={version} requires versions/{version}.json.coverage.supported_targets and versions/{version}.json.validation.passed_targets to include target_triple={target}"
-                ),
-                unit: Some("pointers"),
-                command_path: None,
-                key_or_name: Some(target.clone()),
-                field: Some("latest_validated"),
-                target_triple: Some(target.clone()),
-                details: None,
-            });
-        }
-    }
-}
-
 fn parse_stable_version(s: &str, stable_semver_re: &Regex) -> Option<Version> {
     models::parse_stable_version(s, stable_semver_re)
 }
diff --git a/crates/xtask/src/codex_validate/current.rs b/crates/xtask/src/codex_validate/current.rs
new file mode 100644
index 0000000..697f12d
--- /dev/null
+++ b/crates/xtask/src/codex_validate/current.rs
@@ -0,0 +1,145 @@
+use std::fs;
+
+use serde_json::Value;
+
+use super::{is_union_snapshot, rel_path, schema, ValidateCtx, Violation};
+
+pub(super) fn validate_current_json(
+    ctx: &mut ValidateCtx,
+    violations: &mut Vec<Violation>,
+    latest_validated: Option<&str>,
+) {
+    let current_path = ctx.root.join("current.json");
+    let current_value = match schema::read_json_file(
+        &ctx.root,
+        &current_path,
+        violations,
+        "CURRENT_INVALID_JSON",
+    ) {
+        Some(v) => {
+            schema::schema_validate(
+                ctx,
+                violations,
+                &ctx.schema,
+                &v,
+                &current_path,
+                "CURRENT_SCHEMA_INVALID",
+            );
+            if !is_union_snapshot(&v) {
+                violations.push(Violation {
+                    code: "CURRENT_WRONG_KIND",
+                    path: rel_path(&ctx.root, &current_path),
+                    json_pointer: Some("/snapshot_schema_version".to_string()),
+                    message: "current.json must be an UpstreamSnapshotUnionV2 (snapshot_schema_version=2, mode=union)".to_string(),
+                    unit: Some("current_json"),
+                    command_path: None,
+                    key_or_name: None,
+                    field: Some("current"),
+                    target_triple: None,
+                    details: None,
+                });
+            }
+            Some(v)
+        }
+        None => {
+            if current_path.exists() {
+                return;
+            }
+            violations.push(Violation {
+                code: "CURRENT_MISSING",
+                path: rel_path(&ctx.root, &current_path),
+                json_pointer: None,
+                message: "missing required file: current.json".to_string(),
+                unit: Some("current_json"),
+                command_path: None,
+                key_or_name: None,
+                field: Some("current"),
+                target_triple: None,
+                details: None,
+            });
+            None
+        }
+    };
+
+    let Some(latest_validated) = latest_validated else {
+        return;
+    };
+    let union_path = ctx
+        .root
+        .join("snapshots")
+        .join(latest_validated)
+        .join("union.json");
+
+    if current_path.is_file() && union_path.is_file() {
+        if let (Ok(a), Ok(b)) = (fs::read(&current_path), fs::read(&union_path)) {
+            if a != b {
+                violations.push(Violation {
+                    code: "CURRENT_JSON_NOT_EQUAL_UNION",
+                    path: rel_path(&ctx.root, &current_path),
+                    json_pointer: None,
+                    message: format!(
+                        "current.json must be byte-for-byte identical to snapshots/{latest_validated}/union.json"
+                    ),
+                    unit: Some("current_json"),
+                    command_path: None,
+                    key_or_name: Some(latest_validated.to_string()),
+                    field: Some("identity"),
+                    target_triple: None,
+                    details: None,
+                });
+            }
+        }
+    }
+
+    // current.json semantic version invariants use the required target's input.binary.semantic_version.
+    let Some(current_value) = current_value else {
+        return;
+    };
+    let required_target = ctx.required_target.clone();
+    let required_input = current_value
+        .get("inputs")
+        .and_then(Value::as_array)
+        .and_then(|inputs| {
+            inputs.iter().find(|i| {
+                i.get("target_triple")
+                    .and_then(Value::as_str)
+                    .is_some_and(|t| t == required_target.as_str())
+            })
+        });
+    let Some(required_input) = required_input else {
+        violations.push(Violation {
+            code: "CURRENT_JSON_MISSING_REQUIRED_TARGET",
+            path: rel_path(&ctx.root, &current_path),
+            json_pointer: Some("/inputs".to_string()),
+            message: format!("current.json.inputs[] missing required_target={required_target}"),
+            unit: Some("current_json"),
+            command_path: None,
+            key_or_name: Some(required_target.clone()),
+            field: Some("inputs"),
+            target_triple: Some(required_target),
+            details: None,
+        });
+        return;
+    };
+    let semantic_version = required_input
+        .get("binary")
+        .and_then(|b| b.get("semantic_version"))
+        .and_then(Value::as_str);
+    if semantic_version != Some(latest_validated) {
+        violations.push(Violation {
+            code: "CURRENT_JSON_SEMVER_MISMATCH",
+            path: rel_path(&ctx.root, &current_path),
+            json_pointer: Some("/inputs/*/binary/semantic_version".to_string()),
+            message: format!(
+                "current.json required_target binary.semantic_version must equal latest_validated.txt (expected {latest_validated}, got {})",
+                semantic_version.unwrap_or("<missing>")
+            ),
+            unit: Some("current_json"),
+            command_path: None,
+            key_or_name: Some(required_target.clone()),
+            field: Some("semantic_version"),
+            target_triple: Some(required_target),
+            details: None,
+        });
+    }
+}
diff --git a/crates/xtask/src/codex_validate/fix_mode.rs b/crates/xtask/src/codex_validate/fix_mode.rs
new file mode 100644
index 0000000..845b6d6
--- /dev/null
+++ b/crates/xtask/src/codex_validate/fix_mode.rs
@@ -0,0 +1,47 @@
+use std::fs;
+
+use super::{pointers, FatalError, PointerRead, PointerValue, ValidateCtx};
+
+pub(super) fn apply_fix_mode(ctx: &ValidateCtx) -> Result<(), FatalError> {
+    // 1) Create missing pointer files under pointers/ for every expected target.
+    for target in &ctx.expected_targets {
+        for dir in ["pointers/latest_supported", "pointers/latest_validated"] {
+            let path = ctx.root.join(dir).join(format!("{target}.txt"));
+            if path.exists() {
+                continue;
+            }
+            fs::create_dir_all(path.parent().unwrap_or(&ctx.root))?;
+            fs::write(&path, b"none\n")?;
+        }
+    }
+
+    // 2) Normalize pointer formatting (single line + trailing newline).
+    for target in &ctx.expected_targets {
+        for dir in ["pointers/latest_supported", "pointers/latest_validated"] {
+            let path = ctx.root.join(dir).join(format!("{target}.txt"));
+            pointers::normalize_single_line_file(&path)?;
+        }
+    }
+    pointers::normalize_single_line_file(&ctx.root.join("latest_validated.txt"))?;
+    pointers::normalize_single_line_file(&ctx.root.join("min_supported.txt"))?;
+
+    // 3) Normalize current.json to match snapshots/<latest_validated>/union.json (if possible).
+    let latest_validated = match pointers::read_pointer_file(
+        &ctx.root.join("latest_validated.txt"),
+        &ctx.stable_semver_re,
+        false,
+    ) {
+        Ok(PointerRead::Value(PointerValue::Version(ver))) => Some(ver.to_string()),
+        _ => None,
+    };
+
+    if let Some(version) = latest_validated {
+        let union_path = ctx.root.join("snapshots").join(&version).join("union.json");
+        if union_path.is_file() {
+            let bytes = fs::read(&union_path)?;
+            fs::write(ctx.root.join("current.json"), bytes)?;
+        }
+    }
+
+    Ok(())
+}
diff --git a/crates/xtask/src/codex_validate/pointer_consistency.rs b/crates/xtask/src/codex_validate/pointer_consistency.rs
new file mode 100644
index 0000000..24b5c8e
--- /dev/null
+++ b/crates/xtask/src/codex_validate/pointer_consistency.rs
@@ -0,0 +1,98 @@
+use std::collections::{BTreeMap, BTreeSet};
+
+use serde_json::Value;
+
+use super::{rel_path, PointerValues, ValidateCtx, Violation};
+
+pub(super) fn validate_pointer_consistency(
+    ctx: &ValidateCtx,
+    violations: &mut Vec<Violation>,
+    pointers: &PointerValues,
+    version_metadata: &BTreeMap<String, Value>,
+) {
+    for (target, v) in &pointers.by_target_latest_supported {
+        let Some(version) = v.as_deref() else {
+            continue;
+        };
+        let meta = version_metadata.get(version);
+        if meta.is_none() {
+            continue;
+        }
+        let supported_targets = meta
+            .and_then(|m| m.get("coverage"))
+            .and_then(|c| c.get("supported_targets"))
+            .and_then(Value::as_array)
+            .map(|arr| {
+                arr.iter()
+                    .filter_map(Value::as_str)
+                    .map(|s| s.to_string())
+                    .collect::<BTreeSet<_>>()
+            })
+            .unwrap_or_default();
+        if !supported_targets.contains(target) {
+            violations.push(Violation {
+                code: "POINTER_INCONSISTENT_WITH_VERSION_METADATA",
+                path: rel_path(&ctx.root, &ctx.root.join("versions").join(format!("{version}.json"))),
+                json_pointer: Some("/coverage/supported_targets".to_string()),
+                message: format!(
+                    "pointers/latest_supported/{target}.txt={version} requires versions/{version}.json.coverage.supported_targets to include target_triple={target}"
+                ),
+                unit: Some("pointers"),
+                command_path: None,
+                key_or_name: Some(target.clone()),
+                field: Some("latest_supported"),
+                target_triple: Some(target.clone()),
+                details: None,
+            });
+        }
+    }
+
+    for (target, v) in &pointers.by_target_latest_validated {
+        let Some(version) = v.as_deref() else {
+            continue;
+        };
+        let meta = version_metadata.get(version);
+        if meta.is_none() {
+            continue;
+        }
+        let supported_targets = meta
+            .and_then(|m| m.get("coverage"))
+            .and_then(|c| c.get("supported_targets"))
+            .and_then(Value::as_array)
+            .map(|arr| {
+                arr.iter()
+                    .filter_map(Value::as_str)
+                    .map(|s| s.to_string())
+                    .collect::<BTreeSet<_>>()
+            })
+            .unwrap_or_default();
+        let passed_targets = meta
+            .and_then(|m| m.get("validation"))
+            .and_then(|v| v.get("passed_targets"))
+            .and_then(Value::as_array)
+            .map(|arr| {
+                arr.iter()
+                    .filter_map(Value::as_str)
+                    .map(|s| s.to_string())
+                    .collect::<BTreeSet<_>>()
+            })
+            .unwrap_or_default();
+
+        if !supported_targets.contains(target) || !passed_targets.contains(target) {
+            violations.push(Violation {
+                code: "POINTER_INCONSISTENT_WITH_VERSION_METADATA",
+                path: rel_path(&ctx.root, &ctx.root.join("versions").join(format!("{version}.json"))),
+                json_pointer: Some("/validation/passed_targets".to_string()),
+                message: format!(
+                    "pointers/latest_validated/{target}.txt={version} requires versions/{version}.json.coverage.supported_targets and versions/{version}.json.validation.passed_targets to include target_triple={target}"
+                ),
+                unit: Some("pointers"),
+                command_path: None,
+                key_or_name: Some(target.clone()),
+                field: Some("latest_validated"),
+                target_triple: Some(target.clone()),
+                details: None,
+            });
+        }
+    }
+}
diff --git a/crates/xtask/src/codex_validate/versions.rs b/crates/xtask/src/codex_validate/versions.rs
new file mode 100644
index 0000000..4933a89
--- /dev/null
+++ b/crates/xtask/src/codex_validate/versions.rs
@@ -0,0 +1,459 @@
+use std::{
+    collections::{BTreeMap, BTreeSet},
+    fs, io,
+    path::Path,
+};
+
+use semver::Version;
+use serde_json::{json, Value};
+
+use super::{
+    is_per_target_snapshot, is_union_snapshot, parse_stable_version, rel_path, report_invariants,
+    schema, PointerValues, ValidateCtx, Violation,
+};
+
+pub(super) fn compute_versions_to_validate(
+    ctx: &mut ValidateCtx,
+    violations: &mut Vec<Violation>,
+    pointers: &PointerValues,
+) -> Vec<String> {
+    let mut versions = BTreeSet::<Version>::new();
+
+    for v in pointers
+        .min_supported
+        .iter()
+        .chain(pointers.latest_validated.iter())
+    {
+        if let Some(ver) = parse_stable_version(v, &ctx.stable_semver_re) {
+            versions.insert(ver);
+        }
+    }
+    for (_target, v) in pointers
+        .by_target_latest_supported
+        .iter()
+        .chain(pointers.by_target_latest_validated.iter())
+    {
+        if let Some(v) = v {
+            if let Some(ver) = parse_stable_version(v, &ctx.stable_semver_re) {
+                versions.insert(ver);
+            }
+        }
+    }
+
+    let versions_dir = ctx.root.join("versions");
+    match fs::read_dir(&versions_dir) {
+        Ok(read_dir) => {
+            let mut entries = read_dir
+                .filter_map(|e| e.ok())
+                .filter_map(|e| {
+                    let path = e.path();
+                    if path.extension().and_then(|x| x.to_str()) != Some("json") {
+                        return None;
+                    }
+                    let stem = path.file_stem()?.to_str()?.to_string();
+                    Some((stem, path))
+                })
+                .collect::<Vec<_>>();
+            entries.sort_by(|a, b| a.0.cmp(&b.0));
+            for (stem, path) in entries {
+                match parse_stable_version(&stem, &ctx.stable_semver_re) {
+                    Some(ver) => {
+                        versions.insert(ver);
+                    }
+                    None => violations.push(Violation {
+                        code: "VERSION_FILE_INVALID_NAME",
+                        path: rel_path(&ctx.root, &path),
+                        json_pointer: None,
+                        message: format!(
+                            "versions/<version>.json filename must be a strict stable semver (got {stem})"
+                        ),
+                        unit: Some("versions"),
+                        command_path: None,
+                        key_or_name: Some(stem),
+                        field: Some("filename"),
+                        target_triple: None,
+                        details: None,
+                    }),
+                }
+            }
+        }
+        Err(e) if e.kind() == io::ErrorKind::NotFound => {}
+        Err(e) => {
+            violations.push(Violation {
+                code: "VERSIONS_DIR_UNREADABLE",
+                path: rel_path(&ctx.root, &versions_dir),
+                json_pointer: None,
+                message: format!("failed to read versions directory: {e}"),
+                unit: Some("versions"),
+                command_path: None,
+                key_or_name: None,
+                field: None,
+                target_triple: None,
+                details: None,
+            });
+        }
+    }
+
+    versions.into_iter().map(|v| v.to_string()).collect()
+}
+
+pub(super) fn validate_version_bundle(
+    ctx: &mut ValidateCtx,
+    violations: &mut Vec<Violation>,
+    version: &str,
+    version_metadata: &mut BTreeMap<String, Value>,
+) {
+    let version_path = ctx.root.join("versions").join(format!("{version}.json"));
+    match schema::read_json_file(
+        &ctx.root,
+        &version_path,
+        violations,
+        "VERSION_METADATA_INVALID_JSON",
+    ) {
+        Some(value) => {
+            schema::schema_validate(
+                ctx,
+                violations,
+                &ctx.version_schema,
+                &value,
+                &version_path,
+                "VERSION_METADATA_SCHEMA_INVALID",
+            );
+            validate_version_metadata_validation_sets(
+                ctx,
+                violations,
+                version,
+                &value,
+                &version_path,
+            );
+            version_metadata.insert(version.to_string(), value);
+        }
+        None => {
+            if !version_path.exists() {
+                violations.push(Violation {
+                    code: "VERSION_METADATA_MISSING",
+                    path: rel_path(&ctx.root, &version_path),
+                    json_pointer: None,
+                    message: format!("missing required file: versions/{version}.json"),
+                    unit: Some("versions"),
+                    command_path: None,
+                    key_or_name: Some(version.to_string()),
+                    field: Some("versions"),
+                    target_triple: None,
+                    details: None,
+                });
+            }
+        }
+    }
+
+    let union_path = ctx.root.join("snapshots").join(version).join("union.json");
+    let union_value = match schema::read_json_file(
+        &ctx.root,
+        &union_path,
+        violations,
+        "UNION_INVALID_JSON",
+    ) {
+        Some(value) => {
+            schema::schema_validate(
+                ctx,
+                violations,
+                &ctx.schema,
+                &value,
+                &union_path,
+                "UNION_SCHEMA_INVALID",
+            );
+            if !is_union_snapshot(&value) {
+                violations.push(Violation {
+                    code: "UNION_WRONG_KIND",
+                    path: rel_path(&ctx.root, &union_path),
+                    json_pointer: Some("/snapshot_schema_version".to_string()),
+                    message: "snapshots/<version>/union.json must be an UpstreamSnapshotUnionV2 (snapshot_schema_version=2, mode=union)".to_string(),
+                    unit: Some("snapshots"),
+                    command_path: None,
+                    key_or_name: Some(version.to_string()),
+                    field: Some("union"),
+                    target_triple: None,
+                    details: None,
+                });
+            }
+            Some(value)
+        }
+        None => {
+            if !union_path.exists() {
+                violations.push(Violation {
+                    code: "UNION_MISSING",
+                    path: rel_path(&ctx.root, &union_path),
+                    json_pointer: None,
+                    message: format!("missing required file: snapshots/{version}/union.json"),
+                    unit: Some("snapshots"),
+                    command_path: None,
+                    key_or_name: Some(version.to_string()),
+                    field: Some("union"),
+                    target_triple: None,
+                    details: None,
+                });
+            }
+            None
+        }
+    };
+
+    let inputs = union_value
+        .as_ref()
+        .and_then(|u| u.get("inputs"))
+        .and_then(Value::as_array)
+        .cloned()
+        .unwrap_or_default();
+
+    let mut input_targets = Vec::<String>::new();
+    for input in &inputs {
+        if let Some(t) = input.get("target_triple").and_then(Value::as_str) {
+            input_targets.push(t.to_string());
+        }
+    }
+
+    for target in &input_targets {
+        let per_target_path = ctx
+            .root
+            .join("snapshots")
+            .join(version)
+            .join(format!("{target}.json"));
+        match schema::read_json_file(
+            &ctx.root,
+            &per_target_path,
+            violations,
+            "SNAPSHOT_INVALID_JSON",
+        ) {
+            Some(value) => {
+                schema::schema_validate(
+                    ctx,
+                    violations,
+                    &ctx.schema,
+                    &value,
+                    &per_target_path,
+                    "SNAPSHOT_SCHEMA_INVALID",
+                );
+                if !is_per_target_snapshot(&value) {
+                    violations.push(Violation {
+                        code: "SNAPSHOT_WRONG_KIND",
+                        path: rel_path(&ctx.root, &per_target_path),
+                        json_pointer: Some("/snapshot_schema_version".to_string()),
+                        message: "snapshots/<version>/<target_triple>.json must be an UpstreamSnapshotV1 (snapshot_schema_version=1)".to_string(),
+                        unit: Some("snapshots"),
+                        command_path: None,
+                        key_or_name: Some(target.to_string()),
+                        field: Some("per_target"),
+                        target_triple: Some(target.to_string()),
+                        details: None,
+                    });
+                }
+            }
+            None => {
+                if per_target_path.exists() {
+                    continue;
+                }
+                violations.push(Violation {
+                    code: "SNAPSHOT_MISSING",
+                    path: rel_path(&ctx.root, &per_target_path),
+                    json_pointer: None,
+                    message: format!(
+                        "missing required file: snapshots/{version}/{target}.json (referenced by union.inputs[])"
+                    ),
+                    unit: Some("snapshots"),
+                    command_path: None,
+                    key_or_name: Some(target.to_string()),
+                    field: Some("per_target"),
+                    target_triple: Some(target.to_string()),
+                    details: None,
+                });
+            }
+        }
+    }
+
+    // Reports are required depending on version status.
+    let status = version_metadata
+        .get(version)
+        .and_then(|v| v.get("status"))
+        .and_then(Value::as_str)
+        .unwrap_or("unknown");
+
+    let require_reports = matches!(status, "reported" | "validated" | "supported");
+    let reports_dir = ctx.root.join("reports").join(version);
+    let any_report = reports_dir.join("coverage.any.json");
+    if require_reports {
+        report_invariants::require_report(ctx, violations, version, "any", None, &any_report);
+    } else {
+        report_invariants::validate_report_if_present(ctx, violations, &any_report);
+    }
+
+    for target in &input_targets {
+        let per_target = reports_dir.join(format!("coverage.{target}.json"));
+        if require_reports {
+            report_invariants::require_report(
+                ctx,
+                violations,
+                version,
+                "per_target",
+                Some(target.as_str()),
+                &per_target,
+            );
+        } else {
+            report_invariants::validate_report_if_present(ctx, violations, &per_target);
+        }
+    }
+
+    let complete = union_value
+        .as_ref()
+        .and_then(|u| u.get("complete"))
+        .and_then(Value::as_bool)
+        .unwrap_or(false);
+    if complete {
+        let all_report = reports_dir.join("coverage.all.json");
+        if require_reports {
+            report_invariants::require_report(ctx, violations, version, "all", None, &all_report);
+        } else {
+            report_invariants::validate_report_if_present(ctx, violations, &all_report);
+        }
+    }
+}
+
+fn intersect(a: &BTreeSet<String>, b: &BTreeSet<String>) -> BTreeSet<String> {
+    a.intersection(b).cloned().collect()
+}
+
+fn validate_version_metadata_validation_sets(
+    ctx: &ValidateCtx,
+    violations: &mut Vec<Violation>,
+    version: &str,
+    meta: &Value,
+    path: &Path,
+) {
+    let Some(validation) = meta.get("validation") else {
+        return;
+    };
+
+    let expected = ctx
+        .expected_targets
+        .iter()
+        .cloned()
+        .collect::<BTreeSet<_>>();
+
+    let passed = validation
+        .get("passed_targets")
+        .and_then(Value::as_array)
+        .map(|arr| {
+            arr.iter()
+                .filter_map(Value::as_str)
+                .map(|s| s.to_string())
+                .collect::<BTreeSet<_>>()
+        })
+        .unwrap_or_default();
+    let failed = validation
+        .get("failed_targets")
+        .and_then(Value::as_array)
+        .map(|arr| {
+            arr.iter()
+                .filter_map(Value::as_str)
+                .map(|s| s.to_string())
+                .collect::<BTreeSet<_>>()
+        })
+        .unwrap_or_default();
+    let skipped = validation
+        .get("skipped_targets")
+        .and_then(Value::as_array)
+        .map(|arr| {
+            arr.iter()
+                .filter_map(Value::as_str)
+                .map(|s| s.to_string())
+                .collect::<BTreeSet<_>>()
+        })
+        .unwrap_or_default();
+
+    let overlaps = [
+        (
+            "passed_targets",
+            "failed_targets",
+            intersect(&passed, &failed),
+        ),
+        (
+            "passed_targets",
+            "skipped_targets",
+            intersect(&passed, &skipped),
+        ),
+        (
+            "failed_targets",
+            "skipped_targets",
+            intersect(&failed, &skipped),
+        ),
+    ];
+    for (a, b, inter) in overlaps {
+        if inter.is_empty() {
+            continue;
+        }
+        violations.push(Violation {
+            code: "VALIDATION_TARGET_SETS_OVERLAP",
+            path: rel_path(&ctx.root, path),
+            json_pointer: Some("/validation".to_string()),
+            message: format!(
+                "versions/{version}.json validation target sets overlap ({a}  {b} = {:?})",
+                inter.iter().collect::<Vec<_>>()
+            ),
+            unit: Some("versions"),
+            command_path: None,
+            key_or_name: Some(version.to_string()),
+            field: Some("validation"),
+            target_triple: None,
+            details: Some(json!({
+                "overlap": inter.into_iter().collect::<Vec<_>>(),
+                "a": a,
+                "b": b,
+            })),
+        });
+    }
+
+    for t in passed.iter().chain(failed.iter()).chain(skipped.iter()) {
+        if expected.contains(t) {
+            continue;
+        }
+        violations.push(Violation {
+            code: "VALIDATION_TARGET_NOT_EXPECTED",
+            path: rel_path(&ctx.root, path),
+            json_pointer: Some("/validation".to_string()),
+            message: format!(
+                "versions/{version}.json validation includes unexpected target_triple={t} (not in RULES.json.union.expected_targets)"
+            ),
+            unit: Some("versions"),
+            command_path: None,
+            key_or_name: Some(version.to_string()),
+            field: Some("validation"),
+            target_triple: Some(t.to_string()),
+            details: None,
+        });
+    }
+
+    let required = ctx.required_target.as_str();
+    let count = (passed.contains(required) as u8)
+        + (failed.contains(required) as u8)
+        + (skipped.contains(required) as u8);
+    if count != 1 {
+        violations.push(Violation {
+            code: "VALIDATION_REQUIRED_TARGET_NOT_EXPLICIT",
+            path: rel_path(&ctx.root, path),
+            json_pointer: Some("/validation".to_string()),
+            message: format!(
+                "versions/{version}.json validation must include required_target={} in exactly one of passed_targets/failed_targets/skipped_targets",
+                ctx.required_target
+            ),
+            unit: Some("versions"),
+            command_path: None,
+            key_or_name: Some(version.to_string()),
+            field: Some("validation"),
+            target_triple: Some(ctx.required_target.clone()),
+            details: Some(json!({
+                "required_target": ctx.required_target,
+                "passed": passed.contains(required),
+                "failed": failed.contains(required),
+                "skipped": skipped.contains(required),
+            })),
+        });
+    }
+}
