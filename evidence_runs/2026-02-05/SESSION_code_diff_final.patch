diff --git a/crates/codex/src/builder/cli_overrides.rs b/crates/codex/src/builder/cli_overrides.rs
new file mode 100644
index 0000000..f1604c6
--- /dev/null
+++ b/crates/codex/src/builder/cli_overrides.rs
@@ -0,0 +1,204 @@
+use std::{ffi::OsString, path::PathBuf};
+
+use tokio::process::Command;
+
+use super::{
+    ApprovalPolicy, CliOverrides, CliOverridesPatch, ConfigOverride, FeatureToggles, FlagState,
+    LocalProvider, SafetyOverride, SandboxMode,
+};
+
+pub(super) const DEFAULT_REASONING_CONFIG_GPT5: &[(&str, &str)] = &[
+    ("model_reasoning_effort", "medium"),
+    ("model_reasoning_summary", "auto"),
+    ("model_verbosity", "low"),
+];
+
+pub(super) const DEFAULT_REASONING_CONFIG_GPT5_CODEX: &[(&str, &str)] = &[
+    ("model_reasoning_effort", "medium"),
+    ("model_reasoning_summary", "auto"),
+    ("model_verbosity", "low"),
+];
+
+pub(super) const DEFAULT_REASONING_CONFIG_GPT5_1: &[(&str, &str)] = &[
+    ("model_reasoning_effort", "medium"),
+    ("model_reasoning_summary", "auto"),
+    ("model_verbosity", "low"),
+];
+
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub(crate) struct ResolvedCliOverrides {
+    pub(crate) config_overrides: Vec<ConfigOverride>,
+    pub(crate) feature_toggles: FeatureToggles,
+    pub(crate) approval_policy: Option<ApprovalPolicy>,
+    pub(crate) sandbox_mode: Option<SandboxMode>,
+    pub(crate) safety_override: SafetyOverride,
+    pub(crate) profile: Option<String>,
+    pub(crate) cd: Option<PathBuf>,
+    pub(crate) local_provider: Option<LocalProvider>,
+    pub(crate) oss: bool,
+    pub(crate) search: FlagState,
+}
+
+impl ResolvedCliOverrides {
+    fn search_enabled(&self) -> bool {
+        matches!(self.search, FlagState::Enable)
+    }
+}
+
+pub(super) fn reasoning_config_for(
+    model: Option<&str>,
+) -> Option<&'static [(&'static str, &'static str)]> {
+    let name = model.map(|value| value.to_ascii_lowercase())?;
+    match name.as_str() {
+        name if name.starts_with("gpt-5.1-codex") => Some(DEFAULT_REASONING_CONFIG_GPT5_1),
+        name if name.starts_with("gpt-5.1") => Some(DEFAULT_REASONING_CONFIG_GPT5_1),
+        "gpt-5-codex" => Some(DEFAULT_REASONING_CONFIG_GPT5_CODEX),
+        name if name.starts_with("gpt-5") => Some(DEFAULT_REASONING_CONFIG_GPT5),
+        _ => None,
+    }
+}
+
+fn has_reasoning_config_override(overrides: &[ConfigOverride]) -> bool {
+    overrides.iter().any(ConfigOverride::is_reasoning_key)
+}
+
+pub(super) fn resolve_cli_overrides(
+    builder: &CliOverrides,
+    patch: &CliOverridesPatch,
+    model: Option<&str>,
+) -> ResolvedCliOverrides {
+    let auto_reasoning_defaults = patch
+        .auto_reasoning_defaults
+        .unwrap_or(builder.auto_reasoning_defaults);
+
+    let has_reasoning_overrides = builder.reasoning.has_overrides()
+        || patch.reasoning.has_overrides()
+        || has_reasoning_config_override(&builder.config_overrides)
+        || has_reasoning_config_override(&patch.config_overrides);
+
+    let mut config_overrides = Vec::new();
+    if auto_reasoning_defaults && !has_reasoning_overrides {
+        if let Some(defaults) = reasoning_config_for(model) {
+            for (key, value) in defaults {
+                config_overrides.push(ConfigOverride::new(*key, *value));
+            }
+        }
+    }
+
+    config_overrides.extend(builder.config_overrides.clone());
+    builder.reasoning.append_overrides(&mut config_overrides);
+    config_overrides.extend(patch.config_overrides.clone());
+    patch.reasoning.append_overrides(&mut config_overrides);
+
+    let approval_policy = patch.approval_policy.or(builder.approval_policy);
+    let sandbox_mode = patch.sandbox_mode.or(builder.sandbox_mode);
+    let safety_override = patch.safety_override.unwrap_or(builder.safety_override);
+    let profile = patch.profile.clone().or_else(|| builder.profile.clone());
+    let cd = patch.cd.clone().or_else(|| builder.cd.clone());
+    let local_provider = patch.local_provider.or(builder.local_provider);
+    let search = match patch.search {
+        FlagState::Inherit => builder.search,
+        other => other,
+    };
+    let oss = match patch.oss {
+        FlagState::Inherit => builder.oss,
+        other => other,
+    };
+    let mut feature_toggles = builder.feature_toggles.clone();
+    feature_toggles
+        .enable
+        .extend(patch.feature_toggles.enable.iter().cloned());
+    feature_toggles
+        .disable
+        .extend(patch.feature_toggles.disable.iter().cloned());
+
+    ResolvedCliOverrides {
+        config_overrides,
+        feature_toggles,
+        approval_policy,
+        sandbox_mode,
+        safety_override,
+        profile,
+        cd,
+        local_provider,
+        oss: matches!(oss, FlagState::Enable),
+        search,
+    }
+}
+
+pub(super) fn cli_override_args(
+    resolved: &ResolvedCliOverrides,
+    include_search: bool,
+) -> Vec<OsString> {
+    let mut args = Vec::new();
+    for config in &resolved.config_overrides {
+        args.push(OsString::from("--config"));
+        args.push(OsString::from(format!("{}={}", config.key, config.value)));
+    }
+
+    for feature in &resolved.feature_toggles.enable {
+        args.push(OsString::from("--enable"));
+        args.push(OsString::from(feature));
+    }
+
+    for feature in &resolved.feature_toggles.disable {
+        args.push(OsString::from("--disable"));
+        args.push(OsString::from(feature));
+    }
+
+    if let Some(profile) = &resolved.profile {
+        args.push(OsString::from("--profile"));
+        args.push(OsString::from(profile));
+    }
+
+    match resolved.safety_override {
+        SafetyOverride::DangerouslyBypass => {
+            args.push(OsString::from("--dangerously-bypass-approvals-and-sandbox"));
+        }
+        other => {
+            if let Some(policy) = resolved.approval_policy {
+                args.push(OsString::from("--ask-for-approval"));
+                args.push(OsString::from(policy.as_str()));
+            }
+
+            if let Some(mode) = resolved.sandbox_mode {
+                args.push(OsString::from("--sandbox"));
+                args.push(OsString::from(mode.as_str()));
+            } else if resolved.approval_policy.is_none()
+                && matches!(other, SafetyOverride::FullAuto)
+            {
+                args.push(OsString::from("--full-auto"));
+            }
+        }
+    }
+
+    if let Some(cd) = &resolved.cd {
+        args.push(OsString::from("--cd"));
+        args.push(cd.as_os_str().to_os_string());
+    }
+
+    if let Some(provider) = resolved.local_provider {
+        args.push(OsString::from("--local-provider"));
+        args.push(OsString::from(provider.as_str()));
+    }
+
+    if resolved.oss {
+        args.push(OsString::from("--oss"));
+    }
+
+    if include_search && resolved.search_enabled() {
+        args.push(OsString::from("--search"));
+    }
+
+    args
+}
+
+pub(super) fn apply_cli_overrides(
+    command: &mut Command,
+    resolved: &ResolvedCliOverrides,
+    include_search: bool,
+) {
+    for arg in cli_override_args(resolved, include_search) {
+        command.arg(arg);
+    }
+}
diff --git a/crates/codex/src/builder.rs b/crates/codex/src/builder/mod.rs
similarity index 52%
rename from crates/codex/src/builder.rs
rename to crates/codex/src/builder/mod.rs
index afb6530..c69d160 100644
--- a/crates/codex/src/builder.rs
+++ b/crates/codex/src/builder/mod.rs
@@ -1,26 +1,62 @@
-use std::{ffi::OsString, path::PathBuf, time::Duration};
+use std::{path::PathBuf, time::Duration};
 
-use tokio::process::Command;
+#[cfg(test)]
+use std::ffi::OsString;
 
 use crate::home::CommandEnvironment;
+use tokio::process::Command;
+
+mod cli_overrides;
+mod types;
 
-pub(super) const DEFAULT_REASONING_CONFIG_GPT5: &[(&str, &str)] = &[
-    ("model_reasoning_effort", "medium"),
-    ("model_reasoning_summary", "auto"),
-    ("model_verbosity", "low"),
-];
+pub use types::{
+    ApprovalPolicy, CliOverrides, CliOverridesPatch, ColorMode, ConfigOverride, FeatureToggles,
+    FlagState, LocalProvider, ModelVerbosity, ReasoningEffort, ReasoningOverrides,
+    ReasoningSummary, ReasoningSummaryFormat, SafetyOverride, SandboxMode,
+};
 
-pub(super) const DEFAULT_REASONING_CONFIG_GPT5_CODEX: &[(&str, &str)] = &[
-    ("model_reasoning_effort", "medium"),
-    ("model_reasoning_summary", "auto"),
-    ("model_verbosity", "low"),
-];
+pub(super) type ResolvedCliOverrides = cli_overrides::ResolvedCliOverrides;
+
+#[cfg(test)]
+pub(super) const DEFAULT_REASONING_CONFIG_GPT5: &[(&str, &str)] =
+    cli_overrides::DEFAULT_REASONING_CONFIG_GPT5;
+#[cfg(test)]
+pub(super) const DEFAULT_REASONING_CONFIG_GPT5_CODEX: &[(&str, &str)] =
+    cli_overrides::DEFAULT_REASONING_CONFIG_GPT5_CODEX;
+#[cfg(test)]
+pub(super) const DEFAULT_REASONING_CONFIG_GPT5_1: &[(&str, &str)] =
+    cli_overrides::DEFAULT_REASONING_CONFIG_GPT5_1;
+
+#[cfg(test)]
+pub(super) fn reasoning_config_for(
+    model: Option<&str>,
+) -> Option<&'static [(&'static str, &'static str)]> {
+    cli_overrides::reasoning_config_for(model)
+}
+
+pub(super) fn resolve_cli_overrides(
+    builder: &CliOverrides,
+    patch: &CliOverridesPatch,
+    model: Option<&str>,
+) -> ResolvedCliOverrides {
+    cli_overrides::resolve_cli_overrides(builder, patch, model)
+}
 
-pub(super) const DEFAULT_REASONING_CONFIG_GPT5_1: &[(&str, &str)] = &[
-    ("model_reasoning_effort", "medium"),
-    ("model_reasoning_summary", "auto"),
-    ("model_verbosity", "low"),
-];
+#[cfg(test)]
+pub(super) fn cli_override_args(
+    resolved: &ResolvedCliOverrides,
+    include_search: bool,
+) -> Vec<OsString> {
+    cli_overrides::cli_override_args(resolved, include_search)
+}
+
+pub(super) fn apply_cli_overrides(
+    command: &mut Command,
+    resolved: &ResolvedCliOverrides,
+    include_search: bool,
+) {
+    cli_overrides::apply_cli_overrides(command, resolved, include_search);
+}
 
 /// Builder for [`crate::CodexClient`].
 ///
@@ -427,497 +463,3 @@ impl Default for CodexClientBuilder {
         }
     }
 }
-
-/// ANSI color behavior for `codex exec` output.
-#[derive(Clone, Copy, Debug, Eq, PartialEq)]
-pub enum ColorMode {
-    /// Match upstream defaults: use color codes when stdout/stderr look like terminals.
-    Auto,
-    /// Force colorful output even when piping.
-    Always,
-    /// Fully disable ANSI sequences for deterministic parsing/logging (default).
-    Never,
-}
-
-impl ColorMode {
-    pub(super) const fn as_str(self) -> &'static str {
-        match self {
-            ColorMode::Auto => "auto",
-            ColorMode::Always => "always",
-            ColorMode::Never => "never",
-        }
-    }
-}
-
-/// Approval policy used by `--ask-for-approval`.
-#[derive(Clone, Copy, Debug, Eq, PartialEq)]
-pub enum ApprovalPolicy {
-    Untrusted,
-    OnFailure,
-    OnRequest,
-    Never,
-}
-
-impl ApprovalPolicy {
-    const fn as_str(self) -> &'static str {
-        match self {
-            ApprovalPolicy::Untrusted => "untrusted",
-            ApprovalPolicy::OnFailure => "on-failure",
-            ApprovalPolicy::OnRequest => "on-request",
-            ApprovalPolicy::Never => "never",
-        }
-    }
-}
-
-/// Sandbox isolation level.
-#[derive(Clone, Copy, Debug, Eq, PartialEq)]
-pub enum SandboxMode {
-    ReadOnly,
-    WorkspaceWrite,
-    DangerFullAccess,
-}
-
-impl SandboxMode {
-    const fn as_str(self) -> &'static str {
-        match self {
-            SandboxMode::ReadOnly => "read-only",
-            SandboxMode::WorkspaceWrite => "workspace-write",
-            SandboxMode::DangerFullAccess => "danger-full-access",
-        }
-    }
-}
-
-/// Safety overrides that collapse approval/sandbox behavior.
-#[derive(Clone, Copy, Debug, Default, Eq, PartialEq)]
-pub enum SafetyOverride {
-    #[default]
-    Inherit,
-    FullAuto,
-    DangerouslyBypass,
-}
-
-/// Local provider selection for OSS backends.
-#[derive(Clone, Copy, Debug, Eq, PartialEq)]
-pub enum LocalProvider {
-    LmStudio,
-    Ollama,
-    Custom,
-}
-
-impl LocalProvider {
-    const fn as_str(self) -> &'static str {
-        match self {
-            LocalProvider::LmStudio => "lmstudio",
-            LocalProvider::Ollama => "ollama",
-            LocalProvider::Custom => "custom",
-        }
-    }
-}
-
-/// Three-state flag used when requests can override builder defaults.
-#[derive(Clone, Copy, Debug, Default, Eq, PartialEq)]
-pub enum FlagState {
-    #[default]
-    Inherit,
-    Enable,
-    Disable,
-}
-
-/// Feature toggles forwarded to `--enable/--disable`.
-#[derive(Clone, Debug, Default, Eq, PartialEq)]
-pub struct FeatureToggles {
-    pub enable: Vec<String>,
-    pub disable: Vec<String>,
-}
-
-/// Config values for `model_reasoning_effort`.
-#[derive(Clone, Copy, Debug, Eq, PartialEq)]
-pub enum ReasoningEffort {
-    Minimal,
-    Low,
-    Medium,
-    High,
-}
-
-impl ReasoningEffort {
-    const fn as_str(self) -> &'static str {
-        match self {
-            ReasoningEffort::Minimal => "minimal",
-            ReasoningEffort::Low => "low",
-            ReasoningEffort::Medium => "medium",
-            ReasoningEffort::High => "high",
-        }
-    }
-}
-
-/// Config values for `model_reasoning_summary`.
-#[derive(Clone, Copy, Debug, Eq, PartialEq)]
-pub enum ReasoningSummary {
-    Auto,
-    Concise,
-    Detailed,
-    None,
-}
-
-impl ReasoningSummary {
-    const fn as_str(self) -> &'static str {
-        match self {
-            ReasoningSummary::Auto => "auto",
-            ReasoningSummary::Concise => "concise",
-            ReasoningSummary::Detailed => "detailed",
-            ReasoningSummary::None => "none",
-        }
-    }
-}
-
-/// Config values for `model_verbosity`.
-#[derive(Clone, Copy, Debug, Eq, PartialEq)]
-pub enum ModelVerbosity {
-    Low,
-    Medium,
-    High,
-}
-
-impl ModelVerbosity {
-    const fn as_str(self) -> &'static str {
-        match self {
-            ModelVerbosity::Low => "low",
-            ModelVerbosity::Medium => "medium",
-            ModelVerbosity::High => "high",
-        }
-    }
-}
-
-/// Config values for `model_reasoning_summary_format`.
-#[derive(Clone, Copy, Debug, Eq, PartialEq)]
-pub enum ReasoningSummaryFormat {
-    None,
-    Experimental,
-}
-
-impl ReasoningSummaryFormat {
-    const fn as_str(self) -> &'static str {
-        match self {
-            ReasoningSummaryFormat::None => "none",
-            ReasoningSummaryFormat::Experimental => "experimental",
-        }
-    }
-}
-
-/// Represents a single `--config key=value` override.
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub struct ConfigOverride {
-    pub key: String,
-    pub value: String,
-}
-
-impl ConfigOverride {
-    pub fn new(key: impl Into<String>, value: impl Into<String>) -> Self {
-        Self {
-            key: key.into(),
-            value: value.into(),
-        }
-    }
-
-    pub fn from_raw(raw: impl Into<String>) -> Self {
-        let raw = raw.into();
-        let (key, value) = raw
-            .split_once('=')
-            .map(|(key, value)| (key.to_string(), value.to_string()))
-            .unwrap_or_else(|| (raw.clone(), String::new()));
-        ConfigOverride { key, value }
-    }
-
-    fn is_reasoning_key(&self) -> bool {
-        REASONING_CONFIG_KEYS.contains(&self.key.as_str())
-    }
-}
-
-/// Structured reasoning overrides converted into config entries.
-#[derive(Clone, Debug, Default, Eq, PartialEq)]
-pub struct ReasoningOverrides {
-    pub effort: Option<ReasoningEffort>,
-    pub summary: Option<ReasoningSummary>,
-    pub verbosity: Option<ModelVerbosity>,
-    pub summary_format: Option<ReasoningSummaryFormat>,
-    pub supports_summaries: Option<bool>,
-}
-
-impl ReasoningOverrides {
-    pub(super) fn has_overrides(&self) -> bool {
-        self.effort.is_some()
-            || self.summary.is_some()
-            || self.verbosity.is_some()
-            || self.summary_format.is_some()
-            || self.supports_summaries.is_some()
-    }
-
-    fn append_overrides(&self, configs: &mut Vec<ConfigOverride>) {
-        if let Some(value) = self.effort {
-            configs.push(ConfigOverride::new(
-                "model_reasoning_effort",
-                value.as_str(),
-            ));
-        }
-        if let Some(value) = self.summary {
-            configs.push(ConfigOverride::new(
-                "model_reasoning_summary",
-                value.as_str(),
-            ));
-        }
-        if let Some(value) = self.verbosity {
-            configs.push(ConfigOverride::new("model_verbosity", value.as_str()));
-        }
-        if let Some(value) = self.summary_format {
-            configs.push(ConfigOverride::new(
-                "model_reasoning_summary_format",
-                value.as_str(),
-            ));
-        }
-        if let Some(value) = self.supports_summaries {
-            configs.push(ConfigOverride::new(
-                "model_supports_reasoning_summaries",
-                value.to_string(),
-            ));
-        }
-    }
-}
-
-/// Builder-scoped CLI overrides.
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub struct CliOverrides {
-    pub config_overrides: Vec<ConfigOverride>,
-    pub feature_toggles: FeatureToggles,
-    pub reasoning: ReasoningOverrides,
-    pub approval_policy: Option<ApprovalPolicy>,
-    pub sandbox_mode: Option<SandboxMode>,
-    pub safety_override: SafetyOverride,
-    pub profile: Option<String>,
-    pub cd: Option<PathBuf>,
-    pub local_provider: Option<LocalProvider>,
-    pub oss: FlagState,
-    pub search: FlagState,
-    pub auto_reasoning_defaults: bool,
-}
-
-impl Default for CliOverrides {
-    fn default() -> Self {
-        Self {
-            config_overrides: Vec::new(),
-            feature_toggles: FeatureToggles::default(),
-            reasoning: ReasoningOverrides::default(),
-            approval_policy: None,
-            sandbox_mode: None,
-            safety_override: SafetyOverride::Inherit,
-            profile: None,
-            cd: None,
-            local_provider: None,
-            oss: FlagState::Inherit,
-            search: FlagState::Inherit,
-            auto_reasoning_defaults: true,
-        }
-    }
-}
-
-/// Request-level overlay of builder overrides.
-#[derive(Clone, Debug, Default, Eq, PartialEq)]
-pub struct CliOverridesPatch {
-    pub config_overrides: Vec<ConfigOverride>,
-    pub feature_toggles: FeatureToggles,
-    pub reasoning: ReasoningOverrides,
-    pub approval_policy: Option<ApprovalPolicy>,
-    pub sandbox_mode: Option<SandboxMode>,
-    pub safety_override: Option<SafetyOverride>,
-    pub profile: Option<String>,
-    pub cd: Option<PathBuf>,
-    pub local_provider: Option<LocalProvider>,
-    pub oss: FlagState,
-    pub search: FlagState,
-    pub auto_reasoning_defaults: Option<bool>,
-}
-
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub(super) struct ResolvedCliOverrides {
-    pub(super) config_overrides: Vec<ConfigOverride>,
-    pub(super) feature_toggles: FeatureToggles,
-    pub(super) approval_policy: Option<ApprovalPolicy>,
-    pub(super) sandbox_mode: Option<SandboxMode>,
-    pub(super) safety_override: SafetyOverride,
-    pub(super) profile: Option<String>,
-    pub(super) cd: Option<PathBuf>,
-    pub(super) local_provider: Option<LocalProvider>,
-    pub(super) oss: bool,
-    pub(super) search: FlagState,
-}
-
-impl ResolvedCliOverrides {
-    fn search_enabled(&self) -> bool {
-        matches!(self.search, FlagState::Enable)
-    }
-}
-
-const REASONING_CONFIG_KEYS: &[&str] = &[
-    "model_reasoning_effort",
-    "model_reasoning_summary",
-    "model_verbosity",
-    "model_reasoning_summary_format",
-    "model_supports_reasoning_summaries",
-];
-
-pub(super) fn reasoning_config_for(
-    model: Option<&str>,
-) -> Option<&'static [(&'static str, &'static str)]> {
-    let name = model.map(|value| value.to_ascii_lowercase())?;
-    match name.as_str() {
-        name if name.starts_with("gpt-5.1-codex") => Some(DEFAULT_REASONING_CONFIG_GPT5_1),
-        name if name.starts_with("gpt-5.1") => Some(DEFAULT_REASONING_CONFIG_GPT5_1),
-        "gpt-5-codex" => Some(DEFAULT_REASONING_CONFIG_GPT5_CODEX),
-        name if name.starts_with("gpt-5") => Some(DEFAULT_REASONING_CONFIG_GPT5),
-        _ => None,
-    }
-}
-
-fn has_reasoning_config_override(overrides: &[ConfigOverride]) -> bool {
-    overrides.iter().any(ConfigOverride::is_reasoning_key)
-}
-
-pub(super) fn resolve_cli_overrides(
-    builder: &CliOverrides,
-    patch: &CliOverridesPatch,
-    model: Option<&str>,
-) -> ResolvedCliOverrides {
-    let auto_reasoning_defaults = patch
-        .auto_reasoning_defaults
-        .unwrap_or(builder.auto_reasoning_defaults);
-
-    let has_reasoning_overrides = builder.reasoning.has_overrides()
-        || patch.reasoning.has_overrides()
-        || has_reasoning_config_override(&builder.config_overrides)
-        || has_reasoning_config_override(&patch.config_overrides);
-
-    let mut config_overrides = Vec::new();
-    if auto_reasoning_defaults && !has_reasoning_overrides {
-        if let Some(defaults) = reasoning_config_for(model) {
-            for (key, value) in defaults {
-                config_overrides.push(ConfigOverride::new(*key, *value));
-            }
-        }
-    }
-
-    config_overrides.extend(builder.config_overrides.clone());
-    builder.reasoning.append_overrides(&mut config_overrides);
-    config_overrides.extend(patch.config_overrides.clone());
-    patch.reasoning.append_overrides(&mut config_overrides);
-
-    let approval_policy = patch.approval_policy.or(builder.approval_policy);
-    let sandbox_mode = patch.sandbox_mode.or(builder.sandbox_mode);
-    let safety_override = patch.safety_override.unwrap_or(builder.safety_override);
-    let profile = patch.profile.clone().or_else(|| builder.profile.clone());
-    let cd = patch.cd.clone().or_else(|| builder.cd.clone());
-    let local_provider = patch.local_provider.or(builder.local_provider);
-    let search = match patch.search {
-        FlagState::Inherit => builder.search,
-        other => other,
-    };
-    let oss = match patch.oss {
-        FlagState::Inherit => builder.oss,
-        other => other,
-    };
-    let mut feature_toggles = builder.feature_toggles.clone();
-    feature_toggles
-        .enable
-        .extend(patch.feature_toggles.enable.iter().cloned());
-    feature_toggles
-        .disable
-        .extend(patch.feature_toggles.disable.iter().cloned());
-
-    ResolvedCliOverrides {
-        config_overrides,
-        feature_toggles,
-        approval_policy,
-        sandbox_mode,
-        safety_override,
-        profile,
-        cd,
-        local_provider,
-        oss: matches!(oss, FlagState::Enable),
-        search,
-    }
-}
-
-pub(super) fn cli_override_args(
-    resolved: &ResolvedCliOverrides,
-    include_search: bool,
-) -> Vec<OsString> {
-    let mut args = Vec::new();
-    for config in &resolved.config_overrides {
-        args.push(OsString::from("--config"));
-        args.push(OsString::from(format!("{}={}", config.key, config.value)));
-    }
-
-    for feature in &resolved.feature_toggles.enable {
-        args.push(OsString::from("--enable"));
-        args.push(OsString::from(feature));
-    }
-
-    for feature in &resolved.feature_toggles.disable {
-        args.push(OsString::from("--disable"));
-        args.push(OsString::from(feature));
-    }
-
-    if let Some(profile) = &resolved.profile {
-        args.push(OsString::from("--profile"));
-        args.push(OsString::from(profile));
-    }
-
-    match resolved.safety_override {
-        SafetyOverride::DangerouslyBypass => {
-            args.push(OsString::from("--dangerously-bypass-approvals-and-sandbox"));
-        }
-        other => {
-            if let Some(policy) = resolved.approval_policy {
-                args.push(OsString::from("--ask-for-approval"));
-                args.push(OsString::from(policy.as_str()));
-            }
-
-            if let Some(mode) = resolved.sandbox_mode {
-                args.push(OsString::from("--sandbox"));
-                args.push(OsString::from(mode.as_str()));
-            } else if resolved.approval_policy.is_none()
-                && matches!(other, SafetyOverride::FullAuto)
-            {
-                args.push(OsString::from("--full-auto"));
-            }
-        }
-    }
-
-    if let Some(cd) = &resolved.cd {
-        args.push(OsString::from("--cd"));
-        args.push(cd.as_os_str().to_os_string());
-    }
-
-    if let Some(provider) = resolved.local_provider {
-        args.push(OsString::from("--local-provider"));
-        args.push(OsString::from(provider.as_str()));
-    }
-
-    if resolved.oss {
-        args.push(OsString::from("--oss"));
-    }
-
-    if include_search && resolved.search_enabled() {
-        args.push(OsString::from("--search"));
-    }
-
-    args
-}
-
-pub(super) fn apply_cli_overrides(
-    command: &mut Command,
-    resolved: &ResolvedCliOverrides,
-    include_search: bool,
-) {
-    for arg in cli_override_args(resolved, include_search) {
-        command.arg(arg);
-    }
-}
diff --git a/crates/codex/src/builder/types.rs b/crates/codex/src/builder/types.rs
new file mode 100644
index 0000000..aecc3b1
--- /dev/null
+++ b/crates/codex/src/builder/types.rs
@@ -0,0 +1,317 @@
+use std::path::PathBuf;
+
+const REASONING_CONFIG_KEYS: &[&str] = &[
+    "model_reasoning_effort",
+    "model_reasoning_summary",
+    "model_verbosity",
+    "model_reasoning_summary_format",
+    "model_supports_reasoning_summaries",
+];
+
+/// ANSI color behavior for `codex exec` output.
+#[derive(Clone, Copy, Debug, Eq, PartialEq)]
+pub enum ColorMode {
+    /// Match upstream defaults: use color codes when stdout/stderr look like terminals.
+    Auto,
+    /// Force colorful output even when piping.
+    Always,
+    /// Fully disable ANSI sequences for deterministic parsing/logging (default).
+    Never,
+}
+
+impl ColorMode {
+    pub(crate) const fn as_str(self) -> &'static str {
+        match self {
+            ColorMode::Auto => "auto",
+            ColorMode::Always => "always",
+            ColorMode::Never => "never",
+        }
+    }
+}
+
+/// Approval policy used by `--ask-for-approval`.
+#[derive(Clone, Copy, Debug, Eq, PartialEq)]
+pub enum ApprovalPolicy {
+    Untrusted,
+    OnFailure,
+    OnRequest,
+    Never,
+}
+
+impl ApprovalPolicy {
+    pub(super) const fn as_str(self) -> &'static str {
+        match self {
+            ApprovalPolicy::Untrusted => "untrusted",
+            ApprovalPolicy::OnFailure => "on-failure",
+            ApprovalPolicy::OnRequest => "on-request",
+            ApprovalPolicy::Never => "never",
+        }
+    }
+}
+
+/// Sandbox isolation level.
+#[derive(Clone, Copy, Debug, Eq, PartialEq)]
+pub enum SandboxMode {
+    ReadOnly,
+    WorkspaceWrite,
+    DangerFullAccess,
+}
+
+impl SandboxMode {
+    pub(super) const fn as_str(self) -> &'static str {
+        match self {
+            SandboxMode::ReadOnly => "read-only",
+            SandboxMode::WorkspaceWrite => "workspace-write",
+            SandboxMode::DangerFullAccess => "danger-full-access",
+        }
+    }
+}
+
+/// Safety overrides that collapse approval/sandbox behavior.
+#[derive(Clone, Copy, Debug, Default, Eq, PartialEq)]
+pub enum SafetyOverride {
+    #[default]
+    Inherit,
+    FullAuto,
+    DangerouslyBypass,
+}
+
+/// Local provider selection for OSS backends.
+#[derive(Clone, Copy, Debug, Eq, PartialEq)]
+pub enum LocalProvider {
+    LmStudio,
+    Ollama,
+    Custom,
+}
+
+impl LocalProvider {
+    pub(super) const fn as_str(self) -> &'static str {
+        match self {
+            LocalProvider::LmStudio => "lmstudio",
+            LocalProvider::Ollama => "ollama",
+            LocalProvider::Custom => "custom",
+        }
+    }
+}
+
+/// Three-state flag used when requests can override builder defaults.
+#[derive(Clone, Copy, Debug, Default, Eq, PartialEq)]
+pub enum FlagState {
+    #[default]
+    Inherit,
+    Enable,
+    Disable,
+}
+
+/// Feature toggles forwarded to `--enable/--disable`.
+#[derive(Clone, Debug, Default, Eq, PartialEq)]
+pub struct FeatureToggles {
+    pub enable: Vec<String>,
+    pub disable: Vec<String>,
+}
+
+/// Config values for `model_reasoning_effort`.
+#[derive(Clone, Copy, Debug, Eq, PartialEq)]
+pub enum ReasoningEffort {
+    Minimal,
+    Low,
+    Medium,
+    High,
+}
+
+impl ReasoningEffort {
+    pub(super) const fn as_str(self) -> &'static str {
+        match self {
+            ReasoningEffort::Minimal => "minimal",
+            ReasoningEffort::Low => "low",
+            ReasoningEffort::Medium => "medium",
+            ReasoningEffort::High => "high",
+        }
+    }
+}
+
+/// Config values for `model_reasoning_summary`.
+#[derive(Clone, Copy, Debug, Eq, PartialEq)]
+pub enum ReasoningSummary {
+    Auto,
+    Concise,
+    Detailed,
+    None,
+}
+
+impl ReasoningSummary {
+    pub(super) const fn as_str(self) -> &'static str {
+        match self {
+            ReasoningSummary::Auto => "auto",
+            ReasoningSummary::Concise => "concise",
+            ReasoningSummary::Detailed => "detailed",
+            ReasoningSummary::None => "none",
+        }
+    }
+}
+
+/// Config values for `model_verbosity`.
+#[derive(Clone, Copy, Debug, Eq, PartialEq)]
+pub enum ModelVerbosity {
+    Low,
+    Medium,
+    High,
+}
+
+impl ModelVerbosity {
+    pub(super) const fn as_str(self) -> &'static str {
+        match self {
+            ModelVerbosity::Low => "low",
+            ModelVerbosity::Medium => "medium",
+            ModelVerbosity::High => "high",
+        }
+    }
+}
+
+/// Config values for `model_reasoning_summary_format`.
+#[derive(Clone, Copy, Debug, Eq, PartialEq)]
+pub enum ReasoningSummaryFormat {
+    None,
+    Experimental,
+}
+
+impl ReasoningSummaryFormat {
+    pub(super) const fn as_str(self) -> &'static str {
+        match self {
+            ReasoningSummaryFormat::None => "none",
+            ReasoningSummaryFormat::Experimental => "experimental",
+        }
+    }
+}
+
+/// Represents a single `--config key=value` override.
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub struct ConfigOverride {
+    pub key: String,
+    pub value: String,
+}
+
+impl ConfigOverride {
+    pub fn new(key: impl Into<String>, value: impl Into<String>) -> Self {
+        Self {
+            key: key.into(),
+            value: value.into(),
+        }
+    }
+
+    pub fn from_raw(raw: impl Into<String>) -> Self {
+        let raw = raw.into();
+        let (key, value) = raw
+            .split_once('=')
+            .map(|(key, value)| (key.to_string(), value.to_string()))
+            .unwrap_or_else(|| (raw.clone(), String::new()));
+        ConfigOverride { key, value }
+    }
+
+    pub(super) fn is_reasoning_key(&self) -> bool {
+        REASONING_CONFIG_KEYS.contains(&self.key.as_str())
+    }
+}
+
+/// Structured reasoning overrides converted into config entries.
+#[derive(Clone, Debug, Default, Eq, PartialEq)]
+pub struct ReasoningOverrides {
+    pub effort: Option<ReasoningEffort>,
+    pub summary: Option<ReasoningSummary>,
+    pub verbosity: Option<ModelVerbosity>,
+    pub summary_format: Option<ReasoningSummaryFormat>,
+    pub supports_summaries: Option<bool>,
+}
+
+impl ReasoningOverrides {
+    pub(crate) fn has_overrides(&self) -> bool {
+        self.effort.is_some()
+            || self.summary.is_some()
+            || self.verbosity.is_some()
+            || self.summary_format.is_some()
+            || self.supports_summaries.is_some()
+    }
+
+    pub(super) fn append_overrides(&self, configs: &mut Vec<ConfigOverride>) {
+        if let Some(value) = self.effort {
+            configs.push(ConfigOverride::new(
+                "model_reasoning_effort",
+                value.as_str(),
+            ));
+        }
+        if let Some(value) = self.summary {
+            configs.push(ConfigOverride::new(
+                "model_reasoning_summary",
+                value.as_str(),
+            ));
+        }
+        if let Some(value) = self.verbosity {
+            configs.push(ConfigOverride::new("model_verbosity", value.as_str()));
+        }
+        if let Some(value) = self.summary_format {
+            configs.push(ConfigOverride::new(
+                "model_reasoning_summary_format",
+                value.as_str(),
+            ));
+        }
+        if let Some(value) = self.supports_summaries {
+            configs.push(ConfigOverride::new(
+                "model_supports_reasoning_summaries",
+                value.to_string(),
+            ));
+        }
+    }
+}
+
+/// Builder-scoped CLI overrides.
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub struct CliOverrides {
+    pub config_overrides: Vec<ConfigOverride>,
+    pub feature_toggles: FeatureToggles,
+    pub reasoning: ReasoningOverrides,
+    pub approval_policy: Option<ApprovalPolicy>,
+    pub sandbox_mode: Option<SandboxMode>,
+    pub safety_override: SafetyOverride,
+    pub profile: Option<String>,
+    pub cd: Option<PathBuf>,
+    pub local_provider: Option<LocalProvider>,
+    pub oss: FlagState,
+    pub search: FlagState,
+    pub auto_reasoning_defaults: bool,
+}
+
+impl Default for CliOverrides {
+    fn default() -> Self {
+        Self {
+            config_overrides: Vec::new(),
+            feature_toggles: FeatureToggles::default(),
+            reasoning: ReasoningOverrides::default(),
+            approval_policy: None,
+            sandbox_mode: None,
+            safety_override: SafetyOverride::Inherit,
+            profile: None,
+            cd: None,
+            local_provider: None,
+            oss: FlagState::Inherit,
+            search: FlagState::Inherit,
+            auto_reasoning_defaults: true,
+        }
+    }
+}
+
+/// Request-level overlay of builder overrides.
+#[derive(Clone, Debug, Default, Eq, PartialEq)]
+pub struct CliOverridesPatch {
+    pub config_overrides: Vec<ConfigOverride>,
+    pub feature_toggles: FeatureToggles,
+    pub reasoning: ReasoningOverrides,
+    pub approval_policy: Option<ApprovalPolicy>,
+    pub sandbox_mode: Option<SandboxMode>,
+    pub safety_override: Option<SafetyOverride>,
+    pub profile: Option<String>,
+    pub cd: Option<PathBuf>,
+    pub local_provider: Option<LocalProvider>,
+    pub oss: FlagState,
+    pub search: FlagState,
+    pub auto_reasoning_defaults: Option<bool>,
+}
diff --git a/crates/codex/src/bundled_binary.rs b/crates/codex/src/bundled_binary.rs
new file mode 100644
index 0000000..6ff209c
--- /dev/null
+++ b/crates/codex/src/bundled_binary.rs
@@ -0,0 +1,232 @@
+use std::{
+    env, fs as std_fs,
+    path::{Path, PathBuf},
+};
+
+#[cfg(unix)]
+use std::os::unix::fs::PermissionsExt;
+
+use thiserror::Error;
+
+/// Specification for resolving an app-bundled Codex binary.
+///
+/// Callers supply a bundle root plus the pinned version they expect. Platform
+/// defaults to the current target triple label (e.g., `darwin-arm64` or
+/// `linux-x64`) but can be overridden when hosts manage their own layout.
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub struct BundledBinarySpec<'a> {
+    /// Root containing `<platform>/<version>/codex` slices managed by the host.
+    pub bundle_root: &'a Path,
+    /// Pinned Codex version directory to resolve (semantic version or channel/build id).
+    pub version: &'a str,
+    /// Optional platform label override; defaults to [`default_bundled_platform_label`].
+    pub platform: Option<&'a str>,
+}
+
+/// Resolved bundled Codex binary details.
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub struct BundledBinary {
+    /// Canonicalized path to the bundled Codex binary (`codex` or `codex.exe`).
+    pub binary_path: PathBuf,
+    /// Platform slice resolved under the bundle root.
+    pub platform: String,
+    /// Version slice resolved under the platform directory.
+    pub version: String,
+}
+
+/// Errors that may occur while resolving a bundled Codex binary.
+#[derive(Debug, Error)]
+pub enum BundledBinaryError {
+    #[error("bundled Codex version cannot be empty")]
+    EmptyVersion,
+    #[error("bundled Codex platform label cannot be empty")]
+    EmptyPlatform,
+    #[error("bundle root `{bundle_root}` does not exist or is unreadable")]
+    BundleRootUnreadable {
+        bundle_root: PathBuf,
+        #[source]
+        source: std::io::Error,
+    },
+    #[error("bundle root `{bundle_root}` is not a directory")]
+    BundleRootNotDirectory { bundle_root: PathBuf },
+    #[error("bundle platform directory `{platform_dir}` for `{platform}` does not exist or is unreadable")]
+    PlatformUnreadable {
+        platform: String,
+        platform_dir: PathBuf,
+        #[source]
+        source: std::io::Error,
+    },
+    #[error("bundle platform directory `{platform_dir}` for `{platform}` is not a directory")]
+    PlatformNotDirectory {
+        platform: String,
+        platform_dir: PathBuf,
+    },
+    #[error(
+        "bundle version directory `{version_dir}` for `{version}` does not exist or is unreadable"
+    )]
+    VersionUnreadable {
+        version: String,
+        version_dir: PathBuf,
+        #[source]
+        source: std::io::Error,
+    },
+    #[error("bundle version directory `{version_dir}` for `{version}` is not a directory")]
+    VersionNotDirectory {
+        version: String,
+        version_dir: PathBuf,
+    },
+    #[error("bundled Codex binary `{binary}` is missing or unreadable")]
+    BinaryUnreadable {
+        binary: PathBuf,
+        #[source]
+        source: std::io::Error,
+    },
+    #[error("bundled Codex binary `{binary}` is not a file")]
+    BinaryNotFile { binary: PathBuf },
+    #[error("bundled Codex binary `{binary}` is not executable")]
+    BinaryNotExecutable { binary: PathBuf },
+    #[error("failed to canonicalize bundled Codex binary `{path}`: {source}")]
+    Canonicalize {
+        path: PathBuf,
+        #[source]
+        source: std::io::Error,
+    },
+}
+
+/// Resolves a bundled Codex binary under `<bundle_root>/<platform>/<version>/`.
+///
+/// The helper never consults `PATH` or `CODEX_BINARY`; missing slices are hard
+/// errors. The resolved path is canonicalized and should be passed to
+/// [`CodexClientBuilder::binary`] to keep behavior isolated from any global
+/// Codex install.
+pub fn resolve_bundled_binary(
+    spec: BundledBinarySpec<'_>,
+) -> Result<BundledBinary, BundledBinaryError> {
+    let platform = match spec.platform {
+        Some(label) => {
+            super::normalize_non_empty(label).ok_or(BundledBinaryError::EmptyPlatform)?
+        }
+        None => default_bundled_platform_label(),
+    };
+    let version =
+        super::normalize_non_empty(spec.version).ok_or(BundledBinaryError::EmptyVersion)?;
+
+    require_directory(
+        spec.bundle_root,
+        |source| BundledBinaryError::BundleRootUnreadable {
+            bundle_root: spec.bundle_root.to_path_buf(),
+            source,
+        },
+        || BundledBinaryError::BundleRootNotDirectory {
+            bundle_root: spec.bundle_root.to_path_buf(),
+        },
+    )?;
+
+    let platform_dir = spec.bundle_root.join(&platform);
+    require_directory(
+        &platform_dir,
+        |source| BundledBinaryError::PlatformUnreadable {
+            platform: platform.clone(),
+            platform_dir: platform_dir.clone(),
+            source,
+        },
+        || BundledBinaryError::PlatformNotDirectory {
+            platform: platform.clone(),
+            platform_dir: platform_dir.clone(),
+        },
+    )?;
+
+    let version_dir = platform_dir.join(&version);
+    require_directory(
+        &version_dir,
+        |source| BundledBinaryError::VersionUnreadable {
+            version: version.clone(),
+            version_dir: version_dir.clone(),
+            source,
+        },
+        || BundledBinaryError::VersionNotDirectory {
+            version: version.clone(),
+            version_dir: version_dir.clone(),
+        },
+    )?;
+
+    let binary_path = version_dir.join(bundled_binary_filename(&platform));
+    let metadata =
+        std_fs::metadata(&binary_path).map_err(|source| BundledBinaryError::BinaryUnreadable {
+            binary: binary_path.clone(),
+            source,
+        })?;
+    if !metadata.is_file() {
+        return Err(BundledBinaryError::BinaryNotFile {
+            binary: binary_path.clone(),
+        });
+    }
+    ensure_executable(&metadata, &binary_path)?;
+
+    let canonical =
+        std_fs::canonicalize(&binary_path).map_err(|source| BundledBinaryError::Canonicalize {
+            path: binary_path.clone(),
+            source,
+        })?;
+
+    Ok(BundledBinary {
+        binary_path: canonical,
+        platform,
+        version,
+    })
+}
+
+/// Default bundled platform label for the current target (e.g., `darwin-arm64`, `linux-x64`, `windows-x64`).
+pub fn default_bundled_platform_label() -> String {
+    let os = match env::consts::OS {
+        "macos" => "darwin",
+        other => other,
+    };
+    let arch = match env::consts::ARCH {
+        "x86_64" => "x64",
+        "aarch64" => "arm64",
+        other => other,
+    };
+    format!("{os}-{arch}")
+}
+
+fn require_directory(
+    path: &Path,
+    on_read_error: impl FnOnce(std::io::Error) -> BundledBinaryError,
+    on_wrong_type: impl FnOnce() -> BundledBinaryError,
+) -> Result<(), BundledBinaryError> {
+    let metadata = std_fs::metadata(path).map_err(on_read_error)?;
+    if !metadata.is_dir() {
+        return Err(on_wrong_type());
+    }
+    Ok(())
+}
+
+fn ensure_executable(metadata: &std_fs::Metadata, binary: &Path) -> Result<(), BundledBinaryError> {
+    if binary_is_executable(metadata) {
+        return Ok(());
+    }
+    Err(BundledBinaryError::BinaryNotExecutable {
+        binary: binary.to_path_buf(),
+    })
+}
+
+fn binary_is_executable(metadata: &std_fs::Metadata) -> bool {
+    #[cfg(unix)]
+    {
+        metadata.permissions().mode() & 0o111 != 0
+    }
+    #[cfg(not(unix))]
+    {
+        // Windows does not use executable bits; existence is sufficient.
+        true
+    }
+}
+
+pub(super) fn bundled_binary_filename(platform: &str) -> &'static str {
+    if platform.to_ascii_lowercase().contains("windows") {
+        "codex.exe"
+    } else {
+        "codex"
+    }
+}
diff --git a/crates/codex/src/cli/app_server.rs b/crates/codex/src/cli/app_server.rs
new file mode 100644
index 0000000..f0c2ff0
--- /dev/null
+++ b/crates/codex/src/cli/app_server.rs
@@ -0,0 +1,140 @@
+use crate::{CliOverridesPatch, ConfigOverride, FlagState};
+use std::{path::PathBuf, process::ExitStatus};
+
+/// Target for app-server code generation.
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub enum AppServerCodegenTarget {
+    /// Emits TypeScript bindings for the app-server protocol. Optionally formats the output with Prettier.
+    TypeScript { prettier: Option<PathBuf> },
+    /// Emits a JSON schema bundle for the app-server protocol.
+    JsonSchema,
+}
+
+impl AppServerCodegenTarget {
+    pub(crate) fn subcommand(&self) -> &'static str {
+        match self {
+            AppServerCodegenTarget::TypeScript { .. } => "generate-ts",
+            AppServerCodegenTarget::JsonSchema => "generate-json-schema",
+        }
+    }
+
+    pub(crate) fn prettier(&self) -> Option<&PathBuf> {
+        match self {
+            AppServerCodegenTarget::TypeScript { prettier } => prettier.as_ref(),
+            AppServerCodegenTarget::JsonSchema => None,
+        }
+    }
+}
+
+/// Request for `codex app-server generate-ts` or `generate-json-schema`.
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub struct AppServerCodegenRequest {
+    /// Codegen target and optional Prettier path (TypeScript only).
+    pub target: AppServerCodegenTarget,
+    /// Output directory passed to `--out`; created if missing.
+    pub out_dir: PathBuf,
+    /// Per-call CLI overrides layered on top of the builder.
+    pub overrides: CliOverridesPatch,
+}
+
+impl AppServerCodegenRequest {
+    /// Generates TypeScript bindings into `out_dir`.
+    pub fn typescript(out_dir: impl Into<PathBuf>) -> Self {
+        Self {
+            target: AppServerCodegenTarget::TypeScript { prettier: None },
+            out_dir: out_dir.into(),
+            overrides: CliOverridesPatch::default(),
+        }
+    }
+
+    /// Generates a JSON schema bundle into `out_dir`.
+    pub fn json_schema(out_dir: impl Into<PathBuf>) -> Self {
+        Self {
+            target: AppServerCodegenTarget::JsonSchema,
+            out_dir: out_dir.into(),
+            overrides: CliOverridesPatch::default(),
+        }
+    }
+
+    /// Formats TypeScript output with the provided Prettier executable (no-op for JSON schema).
+    pub fn prettier(mut self, prettier: impl Into<PathBuf>) -> Self {
+        if let AppServerCodegenTarget::TypeScript { prettier: slot } = &mut self.target {
+            *slot = Some(prettier.into());
+        }
+        self
+    }
+
+    /// Replaces the default CLI overrides for this request.
+    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
+        self.overrides = overrides;
+        self
+    }
+
+    /// Adds a `--config key=value` override for this request.
+    pub fn config_override(mut self, key: impl Into<String>, value: impl Into<String>) -> Self {
+        self.overrides
+            .config_overrides
+            .push(ConfigOverride::new(key, value));
+        self
+    }
+
+    /// Adds a raw `--config key=value` override without validation.
+    pub fn config_override_raw(mut self, raw: impl Into<String>) -> Self {
+        self.overrides
+            .config_overrides
+            .push(ConfigOverride::from_raw(raw));
+        self
+    }
+
+    /// Sets the config profile (`--profile`) for this request.
+    pub fn profile(mut self, profile: impl Into<String>) -> Self {
+        let profile = profile.into();
+        self.overrides.profile = (!profile.trim().is_empty()).then_some(profile);
+        self
+    }
+
+    /// Requests the CLI `--oss` flag for this codegen call.
+    pub fn oss(mut self, enable: bool) -> Self {
+        self.overrides.oss = if enable {
+            FlagState::Enable
+        } else {
+            FlagState::Disable
+        };
+        self
+    }
+
+    /// Adds a `--enable <feature>` toggle for this codegen call.
+    pub fn enable_feature(mut self, name: impl Into<String>) -> Self {
+        self.overrides.feature_toggles.enable.push(name.into());
+        self
+    }
+
+    /// Adds a `--disable <feature>` toggle for this codegen call.
+    pub fn disable_feature(mut self, name: impl Into<String>) -> Self {
+        self.overrides.feature_toggles.disable.push(name.into());
+        self
+    }
+
+    /// Controls whether `--search` is passed through to Codex.
+    pub fn search(mut self, enable: bool) -> Self {
+        self.overrides.search = if enable {
+            FlagState::Enable
+        } else {
+            FlagState::Disable
+        };
+        self
+    }
+}
+
+/// Captured output from app-server codegen commands.
+#[derive(Clone, Debug)]
+pub struct AppServerCodegenOutput {
+    /// Exit status returned by the subcommand.
+    pub status: ExitStatus,
+    /// Captured stdout (mirrored to the console when `mirror_stdout` is true).
+    pub stdout: String,
+    /// Captured stderr (mirrored unless `quiet` is set).
+    pub stderr: String,
+    /// Output directory passed to `--out`.
+    pub out_dir: PathBuf,
+}
diff --git a/crates/codex/src/cli/cloud.rs b/crates/codex/src/cli/cloud.rs
new file mode 100644
index 0000000..cb51168
--- /dev/null
+++ b/crates/codex/src/cli/cloud.rs
@@ -0,0 +1,158 @@
+use crate::CliOverridesPatch;
+use serde_json::Value;
+use std::process::ExitStatus;
+
+/// Request for `codex cloud` (overview/help).
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub struct CloudOverviewRequest {
+    pub overrides: CliOverridesPatch,
+}
+
+impl CloudOverviewRequest {
+    pub fn new() -> Self {
+        Self {
+            overrides: CliOverridesPatch::default(),
+        }
+    }
+
+    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
+        self.overrides = overrides;
+        self
+    }
+}
+
+impl Default for CloudOverviewRequest {
+    fn default() -> Self {
+        Self::new()
+    }
+}
+
+/// Request for `codex cloud list`.
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub struct CloudListRequest {
+    pub json: bool,
+    pub env_id: Option<String>,
+    pub limit: Option<u32>,
+    pub cursor: Option<String>,
+    pub overrides: CliOverridesPatch,
+}
+
+impl CloudListRequest {
+    pub fn new() -> Self {
+        Self {
+            json: false,
+            env_id: None,
+            limit: None,
+            cursor: None,
+            overrides: CliOverridesPatch::default(),
+        }
+    }
+
+    pub fn json(mut self, enable: bool) -> Self {
+        self.json = enable;
+        self
+    }
+
+    pub fn env_id(mut self, env_id: impl Into<String>) -> Self {
+        let env_id = env_id.into();
+        self.env_id = (!env_id.trim().is_empty()).then_some(env_id);
+        self
+    }
+
+    pub fn limit(mut self, limit: u32) -> Self {
+        self.limit = Some(limit);
+        self
+    }
+
+    pub fn cursor(mut self, cursor: impl Into<String>) -> Self {
+        let cursor = cursor.into();
+        self.cursor = (!cursor.trim().is_empty()).then_some(cursor);
+        self
+    }
+
+    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
+        self.overrides = overrides;
+        self
+    }
+}
+
+impl Default for CloudListRequest {
+    fn default() -> Self {
+        Self::new()
+    }
+}
+
+/// Output from `codex cloud list`.
+#[derive(Clone, Debug, PartialEq)]
+pub struct CloudListOutput {
+    pub status: ExitStatus,
+    pub stdout: String,
+    pub stderr: String,
+    /// Parsed JSON output when `--json` was requested.
+    pub json: Option<Value>,
+}
+
+/// Request for `codex cloud status <TASK_ID>`.
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub struct CloudStatusRequest {
+    pub task_id: String,
+    pub overrides: CliOverridesPatch,
+}
+
+impl CloudStatusRequest {
+    pub fn new(task_id: impl Into<String>) -> Self {
+        Self {
+            task_id: task_id.into(),
+            overrides: CliOverridesPatch::default(),
+        }
+    }
+
+    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
+        self.overrides = overrides;
+        self
+    }
+}
+
+/// Request for `codex cloud exec`.
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub struct CloudExecRequest {
+    pub env_id: String,
+    pub query: Option<String>,
+    pub attempts: Option<u32>,
+    pub branch: Option<String>,
+    pub overrides: CliOverridesPatch,
+}
+
+impl CloudExecRequest {
+    pub fn new(env_id: impl Into<String>) -> Self {
+        Self {
+            env_id: env_id.into(),
+            query: None,
+            attempts: None,
+            branch: None,
+            overrides: CliOverridesPatch::default(),
+        }
+    }
+
+    pub fn query(mut self, query: impl Into<String>) -> Self {
+        let query = query.into();
+        self.query = (!query.trim().is_empty()).then_some(query);
+        self
+    }
+
+    pub fn attempts(mut self, attempts: u32) -> Self {
+        self.attempts = Some(attempts);
+        self
+    }
+
+    pub fn branch(mut self, branch: impl Into<String>) -> Self {
+        let branch = branch.into();
+        self.branch = (!branch.trim().is_empty()).then_some(branch);
+        self
+    }
+
+    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
+        self.overrides = overrides;
+        self
+    }
+}
diff --git a/crates/codex/src/cli/exec.rs b/crates/codex/src/cli/exec.rs
new file mode 100644
index 0000000..00c9049
--- /dev/null
+++ b/crates/codex/src/cli/exec.rs
@@ -0,0 +1,70 @@
+use crate::{CliOverridesPatch, ConfigOverride, FlagState};
+
+/// Options configuring a single exec request.
+#[derive(Clone, Debug)]
+pub struct ExecRequest {
+    pub prompt: String,
+    pub overrides: CliOverridesPatch,
+}
+
+impl ExecRequest {
+    pub fn new(prompt: impl Into<String>) -> Self {
+        Self {
+            prompt: prompt.into(),
+            overrides: CliOverridesPatch::default(),
+        }
+    }
+
+    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
+        self.overrides = overrides;
+        self
+    }
+
+    pub fn config_override(mut self, key: impl Into<String>, value: impl Into<String>) -> Self {
+        self.overrides
+            .config_overrides
+            .push(ConfigOverride::new(key, value));
+        self
+    }
+
+    pub fn config_override_raw(mut self, raw: impl Into<String>) -> Self {
+        self.overrides
+            .config_overrides
+            .push(ConfigOverride::from_raw(raw));
+        self
+    }
+
+    pub fn profile(mut self, profile: impl Into<String>) -> Self {
+        let profile = profile.into();
+        self.overrides.profile = (!profile.trim().is_empty()).then_some(profile);
+        self
+    }
+
+    pub fn oss(mut self, enable: bool) -> Self {
+        self.overrides.oss = if enable {
+            FlagState::Enable
+        } else {
+            FlagState::Disable
+        };
+        self
+    }
+
+    pub fn enable_feature(mut self, name: impl Into<String>) -> Self {
+        self.overrides.feature_toggles.enable.push(name.into());
+        self
+    }
+
+    pub fn disable_feature(mut self, name: impl Into<String>) -> Self {
+        self.overrides.feature_toggles.disable.push(name.into());
+        self
+    }
+
+    pub fn search(mut self, enable: bool) -> Self {
+        self.overrides.search = if enable {
+            FlagState::Enable
+        } else {
+            FlagState::Disable
+        };
+        self
+    }
+}
diff --git a/crates/codex/src/cli/features.rs b/crates/codex/src/cli/features.rs
new file mode 100644
index 0000000..fdb1a55
--- /dev/null
+++ b/crates/codex/src/cli/features.rs
@@ -0,0 +1,223 @@
+use crate::{CliOverridesPatch, ConfigOverride, FlagState};
+use serde::{Deserialize, Serialize};
+use serde_json::Value;
+use std::{collections::BTreeMap, process::ExitStatus};
+
+/// Stage labels reported by `codex features list`.
+#[derive(Clone, Debug, Eq, PartialEq, Serialize, Deserialize)]
+#[serde(from = "String", into = "String")]
+pub enum CodexFeatureStage {
+    Experimental,
+    Beta,
+    Stable,
+    Deprecated,
+    Removed,
+    Unknown(String),
+}
+
+impl CodexFeatureStage {
+    pub(crate) fn parse(raw: &str) -> Self {
+        let normalized = raw.trim();
+        match normalized.to_ascii_lowercase().as_str() {
+            "experimental" => CodexFeatureStage::Experimental,
+            "beta" => CodexFeatureStage::Beta,
+            "stable" => CodexFeatureStage::Stable,
+            "deprecated" => CodexFeatureStage::Deprecated,
+            "removed" => CodexFeatureStage::Removed,
+            _ => CodexFeatureStage::Unknown(normalized.to_string()),
+        }
+    }
+
+    /// Returns the normalized label for this stage.
+    pub fn as_str(&self) -> &str {
+        match self {
+            CodexFeatureStage::Experimental => "experimental",
+            CodexFeatureStage::Beta => "beta",
+            CodexFeatureStage::Stable => "stable",
+            CodexFeatureStage::Deprecated => "deprecated",
+            CodexFeatureStage::Removed => "removed",
+            CodexFeatureStage::Unknown(label) => label.as_str(),
+        }
+    }
+}
+
+impl From<String> for CodexFeatureStage {
+    fn from(value: String) -> Self {
+        CodexFeatureStage::parse(&value)
+    }
+}
+
+impl From<CodexFeatureStage> for String {
+    fn from(stage: CodexFeatureStage) -> Self {
+        String::from(&stage)
+    }
+}
+
+impl From<&CodexFeatureStage> for String {
+    fn from(stage: &CodexFeatureStage) -> Self {
+        stage.as_str().to_string()
+    }
+}
+
+/// Single feature entry reported by `codex features list`.
+#[derive(Clone, Debug, Eq, PartialEq, Serialize, Deserialize)]
+pub struct CodexFeature {
+    /// Feature name as reported by the CLI.
+    pub name: String,
+    /// Feature stage (experimental/beta/stable/deprecated/removed) when provided.
+    #[serde(default, skip_serializing_if = "Option::is_none")]
+    pub stage: Option<CodexFeatureStage>,
+    /// Whether the feature is enabled for the current config/profile.
+    pub enabled: bool,
+    /// Unrecognized fields from JSON output are preserved here.
+    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
+    pub extra: BTreeMap<String, Value>,
+}
+
+impl CodexFeature {
+    /// Convenience helper mirroring the `enabled` flag.
+    pub const fn is_enabled(&self) -> bool {
+        self.enabled
+    }
+}
+
+/// Format used to parse `codex features list` output.
+#[derive(Clone, Copy, Debug, Eq, PartialEq)]
+pub enum FeaturesListFormat {
+    Json,
+    Text,
+}
+
+/// Parsed output from `codex features list`.
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub struct FeaturesListOutput {
+    /// Exit status returned by the subcommand.
+    pub status: ExitStatus,
+    /// Captured stdout (mirrored to the console when `mirror_stdout` is true).
+    pub stdout: String,
+    /// Captured stderr (mirrored unless `quiet` is set).
+    pub stderr: String,
+    /// Parsed feature entries.
+    pub features: Vec<CodexFeature>,
+    /// Indicates whether JSON or text parsing was used.
+    pub format: FeaturesListFormat,
+}
+
+/// Request for `codex features list`.
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub struct FeaturesListRequest {
+    /// Request JSON output via `--json` (falls back to text parsing when JSON is absent).
+    pub json: bool,
+    /// Per-call CLI overrides layered on top of the builder.
+    pub overrides: CliOverridesPatch,
+}
+
+impl FeaturesListRequest {
+    /// Creates a request with JSON disabled by default for compatibility with older binaries.
+    pub fn new() -> Self {
+        Self {
+            json: false,
+            overrides: CliOverridesPatch::default(),
+        }
+    }
+
+    /// Controls whether `--json` is passed to `codex features list`.
+    pub fn json(mut self, enable: bool) -> Self {
+        self.json = enable;
+        self
+    }
+
+    /// Replaces the default CLI overrides for this request.
+    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
+        self.overrides = overrides;
+        self
+    }
+
+    /// Adds a `--config key=value` override for this request.
+    pub fn config_override(mut self, key: impl Into<String>, value: impl Into<String>) -> Self {
+        self.overrides
+            .config_overrides
+            .push(ConfigOverride::new(key, value));
+        self
+    }
+
+    /// Adds a raw `--config key=value` override without validation.
+    pub fn config_override_raw(mut self, raw: impl Into<String>) -> Self {
+        self.overrides
+            .config_overrides
+            .push(ConfigOverride::from_raw(raw));
+        self
+    }
+
+    /// Sets the config profile (`--profile`) for this request.
+    pub fn profile(mut self, profile: impl Into<String>) -> Self {
+        let profile = profile.into();
+        self.overrides.profile = (!profile.trim().is_empty()).then_some(profile);
+        self
+    }
+
+    /// Requests the CLI `--oss` flag for this call.
+    pub fn oss(mut self, enable: bool) -> Self {
+        self.overrides.oss = if enable {
+            FlagState::Enable
+        } else {
+            FlagState::Disable
+        };
+        self
+    }
+
+    /// Adds a `--enable <feature>` toggle for this call.
+    pub fn enable_feature(mut self, name: impl Into<String>) -> Self {
+        self.overrides.feature_toggles.enable.push(name.into());
+        self
+    }
+
+    /// Adds a `--disable <feature>` toggle for this call.
+    pub fn disable_feature(mut self, name: impl Into<String>) -> Self {
+        self.overrides.feature_toggles.disable.push(name.into());
+        self
+    }
+
+    /// Controls whether `--search` is passed through to Codex.
+    pub fn search(mut self, enable: bool) -> Self {
+        self.overrides.search = if enable {
+            FlagState::Enable
+        } else {
+            FlagState::Disable
+        };
+        self
+    }
+}
+
+impl Default for FeaturesListRequest {
+    fn default() -> Self {
+        Self::new()
+    }
+}
+
+/// Request for `codex features`.
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub struct FeaturesCommandRequest {
+    /// Per-call CLI overrides layered on top of the builder.
+    pub overrides: CliOverridesPatch,
+}
+
+impl FeaturesCommandRequest {
+    pub fn new() -> Self {
+        Self {
+            overrides: CliOverridesPatch::default(),
+        }
+    }
+
+    /// Replaces the default CLI overrides for this request.
+    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
+        self.overrides = overrides;
+        self
+    }
+}
+
+impl Default for FeaturesCommandRequest {
+    fn default() -> Self {
+        Self::new()
+    }
+}
diff --git a/crates/codex/src/cli/help.rs b/crates/codex/src/cli/help.rs
new file mode 100644
index 0000000..87e6f91
--- /dev/null
+++ b/crates/codex/src/cli/help.rs
@@ -0,0 +1,65 @@
+use crate::CliOverridesPatch;
+
+/// Selector for `codex help`-style command families.
+#[derive(Clone, Copy, Debug, Eq, PartialEq)]
+pub enum HelpScope {
+    Root,
+    Exec,
+    Features,
+    Login,
+    AppServer,
+    Sandbox,
+    Cloud,
+    Mcp,
+}
+
+impl HelpScope {
+    pub(crate) fn argv_prefix(&self) -> &'static [&'static str] {
+        match self {
+            HelpScope::Root => &["help"],
+            HelpScope::Exec => &["exec", "help"],
+            HelpScope::Features => &["features", "help"],
+            HelpScope::Login => &["login", "help"],
+            HelpScope::AppServer => &["app-server", "help"],
+            HelpScope::Sandbox => &["sandbox", "help"],
+            HelpScope::Cloud => &["cloud", "help"],
+            HelpScope::Mcp => &["mcp", "help"],
+        }
+    }
+}
+
+/// Request for `codex <scope> help [COMMAND]...`.
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub struct HelpCommandRequest {
+    pub scope: HelpScope,
+    /// Optional command path components appended after `help` (variadic upstream).
+    pub command: Vec<String>,
+    /// Per-call CLI overrides layered on top of the builder.
+    pub overrides: CliOverridesPatch,
+}
+
+impl HelpCommandRequest {
+    pub fn new(scope: HelpScope) -> Self {
+        Self {
+            scope,
+            command: Vec::new(),
+            overrides: CliOverridesPatch::default(),
+        }
+    }
+
+    /// Appends one or more command tokens to the help invocation.
+    pub fn command<I, S>(mut self, tokens: I) -> Self
+    where
+        I: IntoIterator<Item = S>,
+        S: Into<String>,
+    {
+        self.command.extend(tokens.into_iter().map(Into::into));
+        self
+    }
+
+    /// Replaces the default CLI overrides for this request.
+    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
+        self.overrides = overrides;
+        self
+    }
+}
diff --git a/crates/codex/src/cli/mcp.rs b/crates/codex/src/cli/mcp.rs
new file mode 100644
index 0000000..20e120a
--- /dev/null
+++ b/crates/codex/src/cli/mcp.rs
@@ -0,0 +1,245 @@
+use crate::CliOverridesPatch;
+use serde_json::Value;
+use std::{ffi::OsString, process::ExitStatus};
+
+/// Request for `codex mcp` (overview/help).
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub struct McpOverviewRequest {
+    pub overrides: CliOverridesPatch,
+}
+
+impl McpOverviewRequest {
+    pub fn new() -> Self {
+        Self {
+            overrides: CliOverridesPatch::default(),
+        }
+    }
+
+    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
+        self.overrides = overrides;
+        self
+    }
+}
+
+impl Default for McpOverviewRequest {
+    fn default() -> Self {
+        Self::new()
+    }
+}
+
+/// Request for `codex mcp list`.
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub struct McpListRequest {
+    pub json: bool,
+    pub overrides: CliOverridesPatch,
+}
+
+impl McpListRequest {
+    pub fn new() -> Self {
+        Self {
+            json: false,
+            overrides: CliOverridesPatch::default(),
+        }
+    }
+
+    pub fn json(mut self, enable: bool) -> Self {
+        self.json = enable;
+        self
+    }
+
+    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
+        self.overrides = overrides;
+        self
+    }
+}
+
+impl Default for McpListRequest {
+    fn default() -> Self {
+        Self::new()
+    }
+}
+
+/// Output from `codex mcp list`.
+#[derive(Clone, Debug, PartialEq)]
+pub struct McpListOutput {
+    pub status: ExitStatus,
+    pub stdout: String,
+    pub stderr: String,
+    pub json: Option<Value>,
+}
+
+/// Request for `codex mcp get <NAME>`.
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub struct McpGetRequest {
+    pub name: String,
+    pub json: bool,
+    pub overrides: CliOverridesPatch,
+}
+
+impl McpGetRequest {
+    pub fn new(name: impl Into<String>) -> Self {
+        Self {
+            name: name.into(),
+            json: false,
+            overrides: CliOverridesPatch::default(),
+        }
+    }
+
+    pub fn json(mut self, enable: bool) -> Self {
+        self.json = enable;
+        self
+    }
+
+    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
+        self.overrides = overrides;
+        self
+    }
+}
+
+/// Transport for `codex mcp add`.
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub enum McpAddTransport {
+    Stdio {
+        env: Vec<(String, String)>,
+        command: Vec<OsString>,
+    },
+    StreamableHttp {
+        url: String,
+        bearer_token_env_var: Option<String>,
+    },
+}
+
+/// Request for `codex mcp add`.
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub struct McpAddRequest {
+    pub name: String,
+    pub transport: McpAddTransport,
+    pub overrides: CliOverridesPatch,
+}
+
+impl McpAddRequest {
+    pub fn stdio(name: impl Into<String>, command: Vec<OsString>) -> Self {
+        Self {
+            name: name.into(),
+            transport: McpAddTransport::Stdio {
+                env: Vec::new(),
+                command,
+            },
+            overrides: CliOverridesPatch::default(),
+        }
+    }
+
+    pub fn streamable_http(name: impl Into<String>, url: impl Into<String>) -> Self {
+        Self {
+            name: name.into(),
+            transport: McpAddTransport::StreamableHttp {
+                url: url.into(),
+                bearer_token_env_var: None,
+            },
+            overrides: CliOverridesPatch::default(),
+        }
+    }
+
+    pub fn env(mut self, key: impl Into<String>, value: impl Into<String>) -> Self {
+        if let McpAddTransport::Stdio { env, .. } = &mut self.transport {
+            env.push((key.into(), value.into()));
+        }
+        self
+    }
+
+    pub fn bearer_token_env_var(mut self, env_var: impl Into<String>) -> Self {
+        if let McpAddTransport::StreamableHttp {
+            bearer_token_env_var,
+            ..
+        } = &mut self.transport
+        {
+            let env_var = env_var.into();
+            *bearer_token_env_var = (!env_var.trim().is_empty()).then_some(env_var);
+        }
+        self
+    }
+
+    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
+        self.overrides = overrides;
+        self
+    }
+}
+
+/// Request for `codex mcp remove <NAME>`.
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub struct McpRemoveRequest {
+    pub name: String,
+    pub overrides: CliOverridesPatch,
+}
+
+impl McpRemoveRequest {
+    pub fn new(name: impl Into<String>) -> Self {
+        Self {
+            name: name.into(),
+            overrides: CliOverridesPatch::default(),
+        }
+    }
+
+    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
+        self.overrides = overrides;
+        self
+    }
+}
+
+/// Request for `codex mcp logout <NAME>`.
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub struct McpLogoutRequest {
+    pub name: String,
+    pub overrides: CliOverridesPatch,
+}
+
+impl McpLogoutRequest {
+    pub fn new(name: impl Into<String>) -> Self {
+        Self {
+            name: name.into(),
+            overrides: CliOverridesPatch::default(),
+        }
+    }
+
+    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
+        self.overrides = overrides;
+        self
+    }
+}
+
+/// Request for `codex mcp login <NAME>` (OAuth).
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub struct McpOauthLoginRequest {
+    pub name: String,
+    pub scopes: Vec<String>,
+    pub overrides: CliOverridesPatch,
+}
+
+impl McpOauthLoginRequest {
+    pub fn new(name: impl Into<String>) -> Self {
+        Self {
+            name: name.into(),
+            scopes: Vec::new(),
+            overrides: CliOverridesPatch::default(),
+        }
+    }
+
+    pub fn scopes<I, S>(mut self, scopes: I) -> Self
+    where
+        I: IntoIterator<Item = S>,
+        S: Into<String>,
+    {
+        self.scopes.extend(
+            scopes
+                .into_iter()
+                .map(|s| s.into())
+                .filter(|s| !s.trim().is_empty()),
+        );
+        self
+    }
+
+    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
+        self.overrides = overrides;
+        self
+    }
+}
diff --git a/crates/codex/src/cli/mod.rs b/crates/codex/src/cli/mod.rs
new file mode 100644
index 0000000..252b76d
--- /dev/null
+++ b/crates/codex/src/cli/mod.rs
@@ -0,0 +1,33 @@
+mod app_server;
+mod cloud;
+mod exec;
+mod features;
+mod help;
+mod mcp;
+mod responses_api_proxy;
+mod review;
+mod sandbox;
+mod session;
+mod stdio_to_uds;
+
+pub use app_server::{AppServerCodegenOutput, AppServerCodegenRequest, AppServerCodegenTarget};
+pub use cloud::{
+    CloudExecRequest, CloudListOutput, CloudListRequest, CloudOverviewRequest, CloudStatusRequest,
+};
+pub use exec::ExecRequest;
+pub use features::{
+    CodexFeature, CodexFeatureStage, FeaturesCommandRequest, FeaturesListFormat,
+    FeaturesListOutput, FeaturesListRequest,
+};
+pub use help::{HelpCommandRequest, HelpScope};
+pub use mcp::{
+    McpAddRequest, McpAddTransport, McpGetRequest, McpListOutput, McpListRequest, McpLogoutRequest,
+    McpOauthLoginRequest, McpOverviewRequest, McpRemoveRequest,
+};
+pub use responses_api_proxy::{
+    ResponsesApiProxyHandle, ResponsesApiProxyInfo, ResponsesApiProxyRequest,
+};
+pub use review::{ExecReviewCommandRequest, ReviewCommandRequest};
+pub use sandbox::{SandboxCommandRequest, SandboxPlatform, SandboxRun};
+pub use session::{ForkSessionRequest, ResumeSessionRequest};
+pub use stdio_to_uds::StdioToUdsRequest;
diff --git a/crates/codex/src/cli/responses_api_proxy.rs b/crates/codex/src/cli/responses_api_proxy.rs
new file mode 100644
index 0000000..32c6d82
--- /dev/null
+++ b/crates/codex/src/cli/responses_api_proxy.rs
@@ -0,0 +1,119 @@
+use crate::CodexError;
+use serde::{Deserialize, Serialize};
+use serde_json::Value;
+use std::{collections::BTreeMap, path::PathBuf};
+use tokio::fs;
+
+/// Request for `codex responses-api-proxy`.
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub struct ResponsesApiProxyRequest {
+    /// API key to write to stdin on startup.
+    pub api_key: String,
+    /// Optional port to bind; falls back to an OS-assigned ephemeral port when omitted.
+    pub port: Option<u16>,
+    /// Optional path passed to `--server-info` for `{port,pid}` JSON output.
+    pub server_info_path: Option<PathBuf>,
+    /// Enables the HTTP shutdown endpoint (`GET /shutdown`).
+    pub http_shutdown: bool,
+    /// Optional upstream URL passed to `--upstream-url` (defaults to `https://api.openai.com/v1/responses`).
+    pub upstream_url: Option<String>,
+}
+
+impl ResponsesApiProxyRequest {
+    /// Creates a request with the API key provided via stdin.
+    pub fn new(api_key: impl Into<String>) -> Self {
+        Self {
+            api_key: api_key.into(),
+            port: None,
+            server_info_path: None,
+            http_shutdown: false,
+            upstream_url: None,
+        }
+    }
+
+    /// Sets the listening port (`--port`).
+    pub fn port(mut self, port: u16) -> Self {
+        self.port = Some(port);
+        self
+    }
+
+    /// Writes `{port,pid}` JSON to the provided path via `--server-info`.
+    pub fn server_info(mut self, path: impl Into<PathBuf>) -> Self {
+        self.server_info_path = Some(path.into());
+        self
+    }
+
+    /// Enables the `--http-shutdown` flag (GET /shutdown).
+    pub fn http_shutdown(mut self, enable: bool) -> Self {
+        self.http_shutdown = enable;
+        self
+    }
+
+    /// Overrides the upstream responses endpoint URL.
+    pub fn upstream_url(mut self, url: impl Into<String>) -> Self {
+        let url = url.into();
+        self.upstream_url = (!url.trim().is_empty()).then_some(url);
+        self
+    }
+}
+
+/// Running responses proxy process and metadata.
+#[derive(Debug)]
+pub struct ResponsesApiProxyHandle {
+    /// Spawned `codex responses-api-proxy` child (inherits kill-on-drop).
+    pub child: tokio::process::Child,
+    /// Optional `--server-info` path that may contain `{port,pid}` JSON.
+    pub server_info_path: Option<PathBuf>,
+}
+
+impl ResponsesApiProxyHandle {
+    /// Reads and parses the `{port,pid}` JSON written by `--server-info`.
+    ///
+    /// Returns `Ok(None)` when no server info path was configured.
+    pub async fn read_server_info(&self) -> Result<Option<ResponsesApiProxyInfo>, CodexError> {
+        let Some(path) = &self.server_info_path else {
+            return Ok(None);
+        };
+
+        const MAX_ATTEMPTS: usize = 10;
+        const BACKOFF_MS: u64 = 25;
+
+        for attempt in 0..MAX_ATTEMPTS {
+            match fs::read_to_string(path).await {
+                Ok(contents) => match serde_json::from_str::<ResponsesApiProxyInfo>(&contents) {
+                    Ok(info) => return Ok(Some(info)),
+                    Err(source) => {
+                        if attempt + 1 == MAX_ATTEMPTS {
+                            return Err(CodexError::ResponsesApiProxyInfoParse {
+                                path: path.clone(),
+                                source,
+                            });
+                        }
+                    }
+                },
+                Err(source) => {
+                    let is_missing = source.kind() == std::io::ErrorKind::NotFound;
+                    if !is_missing || attempt + 1 == MAX_ATTEMPTS {
+                        return Err(CodexError::ResponsesApiProxyInfoRead {
+                            path: path.clone(),
+                            source,
+                        });
+                    }
+                }
+            }
+
+            tokio::time::sleep(std::time::Duration::from_millis(BACKOFF_MS)).await;
+        }
+
+        unreachable!("read_server_info loop must return by MAX_ATTEMPTS")
+    }
+}
+
+/// Parsed `{port,pid}` emitted by `codex responses-api-proxy --server-info`.
+#[derive(Clone, Debug, Eq, PartialEq, Serialize, Deserialize)]
+pub struct ResponsesApiProxyInfo {
+    pub port: u16,
+    pub pid: u32,
+    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
+    pub extra: BTreeMap<String, Value>,
+}
diff --git a/crates/codex/src/cli/review.rs b/crates/codex/src/cli/review.rs
new file mode 100644
index 0000000..55ec539
--- /dev/null
+++ b/crates/codex/src/cli/review.rs
@@ -0,0 +1,145 @@
+use crate::CliOverridesPatch;
+
+/// Request for `codex review [OPTIONS] [PROMPT]`.
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub struct ReviewCommandRequest {
+    pub prompt: Option<String>,
+    pub base: Option<String>,
+    pub commit: Option<String>,
+    pub title: Option<String>,
+    pub uncommitted: bool,
+    /// Per-call CLI overrides layered on top of the builder.
+    pub overrides: CliOverridesPatch,
+}
+
+impl ReviewCommandRequest {
+    pub fn new() -> Self {
+        Self {
+            prompt: None,
+            base: None,
+            commit: None,
+            title: None,
+            uncommitted: false,
+            overrides: CliOverridesPatch::default(),
+        }
+    }
+
+    pub fn prompt(mut self, prompt: impl Into<String>) -> Self {
+        let prompt = prompt.into();
+        self.prompt = (!prompt.trim().is_empty()).then_some(prompt);
+        self
+    }
+
+    pub fn base(mut self, branch: impl Into<String>) -> Self {
+        let branch = branch.into();
+        self.base = (!branch.trim().is_empty()).then_some(branch);
+        self
+    }
+
+    pub fn commit(mut self, sha: impl Into<String>) -> Self {
+        let sha = sha.into();
+        self.commit = (!sha.trim().is_empty()).then_some(sha);
+        self
+    }
+
+    pub fn title(mut self, title: impl Into<String>) -> Self {
+        let title = title.into();
+        self.title = (!title.trim().is_empty()).then_some(title);
+        self
+    }
+
+    pub fn uncommitted(mut self, enable: bool) -> Self {
+        self.uncommitted = enable;
+        self
+    }
+
+    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
+        self.overrides = overrides;
+        self
+    }
+}
+
+impl Default for ReviewCommandRequest {
+    fn default() -> Self {
+        Self::new()
+    }
+}
+
+/// Request for `codex exec review [OPTIONS] [PROMPT]`.
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub struct ExecReviewCommandRequest {
+    pub prompt: Option<String>,
+    pub base: Option<String>,
+    pub commit: Option<String>,
+    pub title: Option<String>,
+    pub uncommitted: bool,
+    pub json: bool,
+    pub skip_git_repo_check: bool,
+    /// Per-call CLI overrides layered on top of the builder.
+    pub overrides: CliOverridesPatch,
+}
+
+impl ExecReviewCommandRequest {
+    pub fn new() -> Self {
+        Self {
+            prompt: None,
+            base: None,
+            commit: None,
+            title: None,
+            uncommitted: false,
+            json: false,
+            skip_git_repo_check: true,
+            overrides: CliOverridesPatch::default(),
+        }
+    }
+
+    pub fn prompt(mut self, prompt: impl Into<String>) -> Self {
+        let prompt = prompt.into();
+        self.prompt = (!prompt.trim().is_empty()).then_some(prompt);
+        self
+    }
+
+    pub fn base(mut self, branch: impl Into<String>) -> Self {
+        let branch = branch.into();
+        self.base = (!branch.trim().is_empty()).then_some(branch);
+        self
+    }
+
+    pub fn commit(mut self, sha: impl Into<String>) -> Self {
+        let sha = sha.into();
+        self.commit = (!sha.trim().is_empty()).then_some(sha);
+        self
+    }
+
+    pub fn title(mut self, title: impl Into<String>) -> Self {
+        let title = title.into();
+        self.title = (!title.trim().is_empty()).then_some(title);
+        self
+    }
+
+    pub fn uncommitted(mut self, enable: bool) -> Self {
+        self.uncommitted = enable;
+        self
+    }
+
+    pub fn json(mut self, enable: bool) -> Self {
+        self.json = enable;
+        self
+    }
+
+    pub fn skip_git_repo_check(mut self, enable: bool) -> Self {
+        self.skip_git_repo_check = enable;
+        self
+    }
+
+    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
+        self.overrides = overrides;
+        self
+    }
+}
+
+impl Default for ExecReviewCommandRequest {
+    fn default() -> Self {
+        Self::new()
+    }
+}
diff --git a/crates/codex/src/cli/sandbox.rs b/crates/codex/src/cli/sandbox.rs
new file mode 100644
index 0000000..f23ab1a
--- /dev/null
+++ b/crates/codex/src/cli/sandbox.rs
@@ -0,0 +1,103 @@
+use crate::{ConfigOverride, FeatureToggles};
+use std::{ffi::OsString, path::PathBuf, process::ExitStatus};
+
+/// Sandbox platform variant; maps to platform subcommands of `codex sandbox`.
+#[derive(Clone, Copy, Debug, Eq, PartialEq)]
+pub enum SandboxPlatform {
+    Macos,
+    Linux,
+    Windows,
+}
+
+impl SandboxPlatform {
+    pub(crate) fn subcommand(self) -> &'static str {
+        match self {
+            SandboxPlatform::Macos => "macos",
+            SandboxPlatform::Linux => "linux",
+            SandboxPlatform::Windows => "windows",
+        }
+    }
+}
+
+/// Request to run an arbitrary command inside a Codex-provided sandbox.
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub struct SandboxCommandRequest {
+    /// Target platform subcommand; maps to `macos` (alias `seatbelt`), `linux` (alias `landlock`), or `windows`.
+    pub platform: SandboxPlatform,
+    /// Trailing command arguments to execute. Must be non-empty to avoid the upstream CLI panic.
+    pub command: Vec<OsString>,
+    /// Request the workspace-write sandbox preset (`--full-auto`).
+    pub full_auto: bool,
+    /// Stream macOS sandbox denials after the child process exits (no-op on other platforms).
+    pub log_denials: bool,
+    /// Additional `--config key=value` overrides to pass through.
+    pub config_overrides: Vec<ConfigOverride>,
+    /// Feature toggles forwarded to `--enable`/`--disable`.
+    pub feature_toggles: FeatureToggles,
+    /// Working directory for the spawned command; falls back to the builder value, then the current process directory.
+    pub working_dir: Option<PathBuf>,
+}
+
+impl SandboxCommandRequest {
+    pub fn new<I, S>(platform: SandboxPlatform, command: I) -> Self
+    where
+        I: IntoIterator<Item = S>,
+        S: Into<OsString>,
+    {
+        Self {
+            platform,
+            command: command.into_iter().map(Into::into).collect(),
+            full_auto: false,
+            log_denials: false,
+            config_overrides: Vec::new(),
+            feature_toggles: FeatureToggles::default(),
+            working_dir: None,
+        }
+    }
+
+    pub fn full_auto(mut self, enable: bool) -> Self {
+        self.full_auto = enable;
+        self
+    }
+
+    pub fn log_denials(mut self, enable: bool) -> Self {
+        self.log_denials = enable;
+        self
+    }
+
+    pub fn config_override(mut self, key: impl Into<String>, value: impl Into<String>) -> Self {
+        self.config_overrides.push(ConfigOverride::new(key, value));
+        self
+    }
+
+    pub fn config_override_raw(mut self, raw: impl Into<String>) -> Self {
+        self.config_overrides.push(ConfigOverride::from_raw(raw));
+        self
+    }
+
+    pub fn enable_feature(mut self, name: impl Into<String>) -> Self {
+        self.feature_toggles.enable.push(name.into());
+        self
+    }
+
+    pub fn disable_feature(mut self, name: impl Into<String>) -> Self {
+        self.feature_toggles.disable.push(name.into());
+        self
+    }
+
+    pub fn working_dir(mut self, dir: impl Into<PathBuf>) -> Self {
+        self.working_dir = Some(dir.into());
+        self
+    }
+}
+
+/// Captured output from `codex sandbox <platform>`.
+#[derive(Clone, Debug)]
+pub struct SandboxRun {
+    /// Exit status returned by the inner command (mirrors the sandbox helper).
+    pub status: ExitStatus,
+    /// Captured stdout (mirrored to the console when `mirror_stdout` is true).
+    pub stdout: String,
+    /// Captured stderr (mirrored unless `quiet` is set).
+    pub stderr: String,
+}
diff --git a/crates/codex/src/cli/session.rs b/crates/codex/src/cli/session.rs
new file mode 100644
index 0000000..fcef5e0
--- /dev/null
+++ b/crates/codex/src/cli/session.rs
@@ -0,0 +1,113 @@
+use crate::CliOverridesPatch;
+
+/// Request for `codex resume [OPTIONS] [SESSION_ID] [PROMPT]`.
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub struct ResumeSessionRequest {
+    pub session_id: Option<String>,
+    pub prompt: Option<String>,
+    pub all: bool,
+    pub last: bool,
+    /// Per-call CLI overrides layered on top of the builder.
+    pub overrides: CliOverridesPatch,
+}
+
+impl ResumeSessionRequest {
+    pub fn new() -> Self {
+        Self {
+            session_id: None,
+            prompt: None,
+            all: false,
+            last: false,
+            overrides: CliOverridesPatch::default(),
+        }
+    }
+
+    pub fn session_id(mut self, session_id: impl Into<String>) -> Self {
+        let session_id = session_id.into();
+        self.session_id = (!session_id.trim().is_empty()).then_some(session_id);
+        self
+    }
+
+    pub fn prompt(mut self, prompt: impl Into<String>) -> Self {
+        let prompt = prompt.into();
+        self.prompt = (!prompt.trim().is_empty()).then_some(prompt);
+        self
+    }
+
+    pub fn all(mut self, enable: bool) -> Self {
+        self.all = enable;
+        self
+    }
+
+    pub fn last(mut self, enable: bool) -> Self {
+        self.last = enable;
+        self
+    }
+
+    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
+        self.overrides = overrides;
+        self
+    }
+}
+
+impl Default for ResumeSessionRequest {
+    fn default() -> Self {
+        Self::new()
+    }
+}
+
+/// Request for `codex fork [OPTIONS] [SESSION_ID] [PROMPT]`.
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub struct ForkSessionRequest {
+    pub session_id: Option<String>,
+    pub prompt: Option<String>,
+    pub all: bool,
+    pub last: bool,
+    /// Per-call CLI overrides layered on top of the builder.
+    pub overrides: CliOverridesPatch,
+}
+
+impl ForkSessionRequest {
+    pub fn new() -> Self {
+        Self {
+            session_id: None,
+            prompt: None,
+            all: false,
+            last: false,
+            overrides: CliOverridesPatch::default(),
+        }
+    }
+
+    pub fn session_id(mut self, session_id: impl Into<String>) -> Self {
+        let session_id = session_id.into();
+        self.session_id = (!session_id.trim().is_empty()).then_some(session_id);
+        self
+    }
+
+    pub fn prompt(mut self, prompt: impl Into<String>) -> Self {
+        let prompt = prompt.into();
+        self.prompt = (!prompt.trim().is_empty()).then_some(prompt);
+        self
+    }
+
+    pub fn all(mut self, enable: bool) -> Self {
+        self.all = enable;
+        self
+    }
+
+    pub fn last(mut self, enable: bool) -> Self {
+        self.last = enable;
+        self
+    }
+
+    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
+        self.overrides = overrides;
+        self
+    }
+}
+
+impl Default for ForkSessionRequest {
+    fn default() -> Self {
+        Self::new()
+    }
+}
diff --git a/crates/codex/src/cli/stdio_to_uds.rs b/crates/codex/src/cli/stdio_to_uds.rs
new file mode 100644
index 0000000..31c9b84
--- /dev/null
+++ b/crates/codex/src/cli/stdio_to_uds.rs
@@ -0,0 +1,25 @@
+use std::path::PathBuf;
+
+/// Request for `codex stdio-to-uds <SOCKET_PATH>`.
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub struct StdioToUdsRequest {
+    /// Path to the Unix domain socket to connect to.
+    pub socket_path: PathBuf,
+    /// Optional working directory override for the spawned process.
+    pub working_dir: Option<PathBuf>,
+}
+
+impl StdioToUdsRequest {
+    pub fn new(socket_path: impl Into<PathBuf>) -> Self {
+        Self {
+            socket_path: socket_path.into(),
+            working_dir: None,
+        }
+    }
+
+    /// Sets the working directory used to resolve the socket path.
+    pub fn working_dir(mut self, dir: impl Into<PathBuf>) -> Self {
+        self.working_dir = Some(dir.into());
+        self
+    }
+}
diff --git a/crates/codex/src/events.rs b/crates/codex/src/events.rs
new file mode 100644
index 0000000..4c6f08c
--- /dev/null
+++ b/crates/codex/src/events.rs
@@ -0,0 +1,414 @@
+use serde::{Deserialize, Serialize};
+use serde_json::Value;
+use std::collections::BTreeMap;
+use std::path::PathBuf;
+
+/// Single JSONL event emitted by `codex exec --json`.
+///
+/// Each line on stdout maps to a [`ThreadEvent`] with lifecycle edges:
+/// - `thread.started` is emitted once per invocation.
+/// - `turn.started` begins the turn associated with the provided prompt.
+/// - one or more `item.*` events stream output and tool activity.
+/// - `turn.completed` or `turn.failed` closes the stream; `error` captures transport-level failures.
+///
+/// Item variants mirror the upstream `item_type` field: `agent_message`, `reasoning`,
+/// `command_execution`, `file_change`, `mcp_tool_call`, `web_search`, `todo_list`, and `error`.
+/// Unknown or future fields are preserved in `extra` maps to keep the parser forward-compatible.
+#[derive(Clone, Debug, Deserialize, Serialize)]
+#[serde(tag = "type")]
+pub enum ThreadEvent {
+    #[serde(rename = "thread.started", alias = "thread.resumed")]
+    ThreadStarted(ThreadStarted),
+    #[serde(rename = "turn.started")]
+    TurnStarted(TurnStarted),
+    #[serde(rename = "turn.completed")]
+    TurnCompleted(TurnCompleted),
+    #[serde(rename = "turn.failed")]
+    TurnFailed(TurnFailed),
+    #[serde(rename = "item.started", alias = "item.created")]
+    ItemStarted(ItemEnvelope<ItemSnapshot>),
+    #[serde(rename = "item.delta", alias = "item.updated")]
+    ItemDelta(ItemDelta),
+    #[serde(rename = "item.completed")]
+    ItemCompleted(ItemEnvelope<ItemSnapshot>),
+    #[serde(rename = "item.failed")]
+    ItemFailed(ItemEnvelope<ItemFailure>),
+    #[serde(rename = "error")]
+    Error(EventError),
+}
+
+/// Marks the start of a new thread.
+#[derive(Clone, Debug, Deserialize, Serialize)]
+pub struct ThreadStarted {
+    pub thread_id: String,
+    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
+    pub extra: BTreeMap<String, Value>,
+}
+
+/// Indicates the CLI accepted a new turn within a thread.
+#[derive(Clone, Debug, Deserialize, Serialize)]
+pub struct TurnStarted {
+    pub thread_id: String,
+    pub turn_id: String,
+    /// Original input text when upstream echoes it; may be omitted for security reasons.
+    #[serde(default, skip_serializing_if = "Option::is_none")]
+    pub input_text: Option<String>,
+    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
+    pub extra: BTreeMap<String, Value>,
+}
+
+/// Reports a completed turn.
+#[derive(Clone, Debug, Deserialize, Serialize)]
+pub struct TurnCompleted {
+    pub thread_id: String,
+    pub turn_id: String,
+    /// Identifier of the last output item when provided by the CLI.
+    #[serde(default, skip_serializing_if = "Option::is_none")]
+    pub last_item_id: Option<String>,
+    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
+    pub extra: BTreeMap<String, Value>,
+}
+
+/// Indicates a turn-level failure.
+#[derive(Clone, Debug, Deserialize, Serialize)]
+pub struct TurnFailed {
+    pub thread_id: String,
+    pub turn_id: String,
+    pub error: EventError,
+    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
+    pub extra: BTreeMap<String, Value>,
+}
+
+/// Shared wrapper for item events that always include thread/turn context.
+#[derive(Clone, Debug, Deserialize, Serialize)]
+pub struct ItemEnvelope<T> {
+    pub thread_id: String,
+    pub turn_id: String,
+    #[serde(flatten)]
+    pub item: T,
+}
+
+/// Snapshot of an item at start/completion time.
+#[derive(Clone, Debug, Deserialize, Serialize)]
+pub struct ItemSnapshot {
+    #[serde(rename = "item_id", alias = "id")]
+    pub item_id: String,
+    #[serde(default, skip_serializing_if = "Option::is_none")]
+    pub index: Option<u32>,
+    #[serde(default)]
+    pub status: ItemStatus,
+    #[serde(flatten)]
+    pub payload: ItemPayload,
+    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
+    pub extra: BTreeMap<String, Value>,
+}
+
+/// Streaming delta describing the next piece of an item.
+#[derive(Clone, Debug, Deserialize, Serialize)]
+pub struct ItemDelta {
+    pub thread_id: String,
+    pub turn_id: String,
+    #[serde(rename = "item_id", alias = "id")]
+    pub item_id: String,
+    #[serde(default, skip_serializing_if = "Option::is_none")]
+    pub index: Option<u32>,
+    #[serde(flatten)]
+    pub delta: ItemDeltaPayload,
+    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
+    pub extra: BTreeMap<String, Value>,
+}
+
+/// Terminal item failure event.
+#[derive(Clone, Debug, Deserialize, Serialize)]
+pub struct ItemFailure {
+    #[serde(rename = "item_id", alias = "id")]
+    pub item_id: String,
+    #[serde(default, skip_serializing_if = "Option::is_none")]
+    pub index: Option<u32>,
+    pub error: EventError,
+    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
+    pub extra: BTreeMap<String, Value>,
+}
+
+/// Fully-typed item payload for start/completed events.
+#[derive(Clone, Debug, Deserialize, Serialize)]
+#[serde(tag = "item_type", content = "content", rename_all = "snake_case")]
+pub enum ItemPayload {
+    AgentMessage(TextContent),
+    Reasoning(TextContent),
+    CommandExecution(CommandExecutionState),
+    FileChange(FileChangeState),
+    McpToolCall(McpToolCallState),
+    WebSearch(WebSearchState),
+    TodoList(TodoListState),
+    Error(EventError),
+}
+
+/// Delta form of an item payload. Each delta should be applied in order to reconstruct the item.
+#[derive(Clone, Debug, Deserialize, Serialize)]
+#[serde(tag = "item_type", content = "delta", rename_all = "snake_case")]
+pub enum ItemDeltaPayload {
+    AgentMessage(TextDelta),
+    Reasoning(TextDelta),
+    CommandExecution(CommandExecutionDelta),
+    FileChange(FileChangeDelta),
+    McpToolCall(McpToolCallDelta),
+    WebSearch(WebSearchDelta),
+    TodoList(TodoListDelta),
+    Error(EventError),
+}
+
+/// Item status supplied by the CLI for bookkeeping.
+#[derive(Clone, Debug, Default, Deserialize, Serialize, Eq, PartialEq)]
+#[serde(rename_all = "snake_case")]
+pub enum ItemStatus {
+    #[default]
+    InProgress,
+    Completed,
+    Failed,
+    #[serde(other)]
+    Unknown,
+}
+
+/// Human-readable content emitted by the agent.
+#[derive(Clone, Debug, Deserialize, Serialize)]
+pub struct TextContent {
+    pub text: String,
+    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
+    pub extra: BTreeMap<String, Value>,
+}
+
+/// Incremental content fragment for streaming items.
+#[derive(Clone, Debug, Deserialize, Serialize)]
+pub struct TextDelta {
+    #[serde(rename = "text_delta", alias = "text")]
+    pub text_delta: String,
+    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
+    pub extra: BTreeMap<String, Value>,
+}
+
+/// Snapshot of a command execution, including accumulated stdout/stderr.
+#[derive(Clone, Debug, Deserialize, Serialize)]
+pub struct CommandExecutionState {
+    pub command: String,
+    #[serde(default, skip_serializing_if = "Option::is_none")]
+    pub exit_code: Option<i32>,
+    #[serde(
+        default,
+        skip_serializing_if = "String::is_empty",
+        alias = "aggregated_output",
+        alias = "output"
+    )]
+    pub stdout: String,
+    #[serde(
+        default,
+        skip_serializing_if = "String::is_empty",
+        alias = "error_output",
+        alias = "err"
+    )]
+    pub stderr: String,
+    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
+    pub extra: BTreeMap<String, Value>,
+}
+
+/// Streaming delta for command execution.
+#[derive(Clone, Debug, Deserialize, Serialize)]
+pub struct CommandExecutionDelta {
+    #[serde(
+        default,
+        skip_serializing_if = "String::is_empty",
+        alias = "aggregated_output",
+        alias = "output"
+    )]
+    pub stdout: String,
+    #[serde(
+        default,
+        skip_serializing_if = "String::is_empty",
+        alias = "error_output",
+        alias = "err"
+    )]
+    pub stderr: String,
+    #[serde(default, skip_serializing_if = "Option::is_none")]
+    pub exit_code: Option<i32>,
+    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
+    pub extra: BTreeMap<String, Value>,
+}
+
+/// File change or diff applied by the agent.
+#[derive(Clone, Debug, Deserialize, Serialize)]
+pub struct FileChangeState {
+    #[serde(alias = "file_path")]
+    pub path: PathBuf,
+    #[serde(default, skip_serializing_if = "Option::is_none")]
+    pub change: Option<FileChangeKind>,
+    #[serde(default, skip_serializing_if = "Option::is_none", alias = "patch")]
+    pub diff: Option<String>,
+    #[serde(default, skip_serializing_if = "Option::is_none")]
+    pub exit_code: Option<i32>,
+    #[serde(
+        default,
+        skip_serializing_if = "String::is_empty",
+        alias = "aggregated_output",
+        alias = "output"
+    )]
+    pub stdout: String,
+    #[serde(
+        default,
+        skip_serializing_if = "String::is_empty",
+        alias = "error_output",
+        alias = "err"
+    )]
+    pub stderr: String,
+    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
+    pub extra: BTreeMap<String, Value>,
+}
+
+/// Streaming delta describing a file change.
+#[derive(Clone, Debug, Deserialize, Serialize)]
+pub struct FileChangeDelta {
+    #[serde(default, skip_serializing_if = "Option::is_none", alias = "patch")]
+    pub diff: Option<String>,
+    #[serde(
+        default,
+        skip_serializing_if = "String::is_empty",
+        alias = "aggregated_output",
+        alias = "output"
+    )]
+    pub stdout: String,
+    #[serde(
+        default,
+        skip_serializing_if = "String::is_empty",
+        alias = "error_output",
+        alias = "err"
+    )]
+    pub stderr: String,
+    #[serde(default, skip_serializing_if = "Option::is_none")]
+    pub exit_code: Option<i32>,
+    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
+    pub extra: BTreeMap<String, Value>,
+}
+
+/// Type of file operation being reported.
+#[derive(Clone, Copy, Debug, Deserialize, Serialize, Eq, PartialEq)]
+#[serde(rename_all = "snake_case")]
+pub enum FileChangeKind {
+    Apply,
+    Diff,
+    #[serde(other)]
+    Unknown,
+}
+
+/// State of an MCP tool call.
+#[derive(Clone, Debug, Deserialize, Serialize)]
+pub struct McpToolCallState {
+    #[serde(alias = "server")]
+    pub server_name: String,
+    #[serde(alias = "tool")]
+    pub tool_name: String,
+    #[serde(default, skip_serializing_if = "Option::is_none")]
+    pub arguments: Option<Value>,
+    #[serde(default, skip_serializing_if = "Option::is_none")]
+    pub result: Option<Value>,
+    #[serde(default)]
+    pub status: ToolCallStatus,
+    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
+    pub extra: BTreeMap<String, Value>,
+}
+
+/// Streaming delta for MCP tool call output.
+#[derive(Clone, Debug, Deserialize, Serialize)]
+pub struct McpToolCallDelta {
+    #[serde(default, skip_serializing_if = "Option::is_none")]
+    pub result: Option<Value>,
+    #[serde(default)]
+    pub status: ToolCallStatus,
+    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
+    pub extra: BTreeMap<String, Value>,
+}
+
+/// Lifecycle state for a tool call.
+#[derive(Clone, Debug, Default, Deserialize, Serialize, Eq, PartialEq)]
+#[serde(rename_all = "snake_case")]
+pub enum ToolCallStatus {
+    #[default]
+    Pending,
+    Running,
+    Completed,
+    Failed,
+    #[serde(other)]
+    Unknown,
+}
+
+/// Details of a web search step.
+#[derive(Clone, Debug, Deserialize, Serialize)]
+pub struct WebSearchState {
+    pub query: String,
+    #[serde(default, skip_serializing_if = "Option::is_none")]
+    pub results: Option<Value>,
+    #[serde(default)]
+    pub status: WebSearchStatus,
+    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
+    pub extra: BTreeMap<String, Value>,
+}
+
+/// Streaming delta for search results.
+#[derive(Clone, Debug, Deserialize, Serialize)]
+pub struct WebSearchDelta {
+    #[serde(default, skip_serializing_if = "Option::is_none")]
+    pub results: Option<Value>,
+    #[serde(default)]
+    pub status: WebSearchStatus,
+    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
+    pub extra: BTreeMap<String, Value>,
+}
+
+/// Search progress indicator.
+#[derive(Clone, Debug, Default, Deserialize, Serialize, Eq, PartialEq)]
+#[serde(rename_all = "snake_case")]
+pub enum WebSearchStatus {
+    #[default]
+    Pending,
+    Running,
+    Completed,
+    Failed,
+    #[serde(other)]
+    Unknown,
+}
+
+/// Checklist maintained by the agent.
+#[derive(Clone, Debug, Deserialize, Serialize)]
+pub struct TodoListState {
+    #[serde(default, skip_serializing_if = "Vec::is_empty")]
+    pub items: Vec<TodoItem>,
+    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
+    pub extra: BTreeMap<String, Value>,
+}
+
+/// Streaming delta for todo list mutations.
+#[derive(Clone, Debug, Deserialize, Serialize)]
+pub struct TodoListDelta {
+    #[serde(default, skip_serializing_if = "Vec::is_empty")]
+    pub items: Vec<TodoItem>,
+    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
+    pub extra: BTreeMap<String, Value>,
+}
+
+/// Single todo item.
+#[derive(Clone, Debug, Deserialize, Serialize)]
+pub struct TodoItem {
+    pub title: String,
+    #[serde(default)]
+    pub completed: bool,
+    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
+    pub extra: BTreeMap<String, Value>,
+}
+
+/// Error payload shared by turn/item failures.
+#[derive(Clone, Debug, Deserialize, Serialize)]
+pub struct EventError {
+    pub message: String,
+    #[serde(default, skip_serializing_if = "Option::is_none")]
+    pub code: Option<String>,
+    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
+    pub extra: BTreeMap<String, Value>,
+}
diff --git a/crates/codex/src/exec.rs b/crates/codex/src/exec.rs
new file mode 100644
index 0000000..bf520c0
--- /dev/null
+++ b/crates/codex/src/exec.rs
@@ -0,0 +1,817 @@
+use std::{
+    env,
+    ffi::OsString,
+    future::Future,
+    path::{Path, PathBuf},
+    pin::Pin,
+    process::ExitStatus,
+    time::{Duration, SystemTime, UNIX_EPOCH},
+};
+
+use futures_core::Stream;
+use thiserror::Error;
+use tokio::{fs, io::AsyncWriteExt, process::Command, sync::mpsc, time};
+use tracing::debug;
+
+use crate::{
+    builder::{apply_cli_overrides, resolve_cli_overrides},
+    capabilities::{guard_is_supported, log_guard_skip},
+    jsonl,
+    process::{spawn_with_retry, tee_stream, ConsoleTarget},
+    ApplyDiffArtifacts, CliOverridesPatch, CodexClient, CodexError, ConfigOverride, ExecRequest,
+    FlagState, ResumeSessionRequest, ThreadEvent,
+};
+
+impl CodexClient {
+    /// Sends `prompt` to `codex exec` and returns its stdout (the final agent message) on success.
+    ///
+    /// When `.json(true)` is enabled the CLI emits JSONL events (`thread.started` or
+    /// `thread.resumed`, `turn.started`/`turn.completed`/`turn.failed`,
+    /// `item.created`/`item.updated`, or `error`). The stream is mirrored to stdout unless
+    /// `.mirror_stdout(false)`; the returned string contains the buffered lines for offline
+    /// parsing. For per-event handling, see `crates/codex/examples/stream_events.rs`.
+    ///
+    /// ```rust,no_run
+    /// use codex::CodexClient;
+    /// # #[tokio::main]
+    /// # async fn main() -> Result<(), Box<dyn std::error::Error>> {
+    /// let client = CodexClient::builder().json(true).mirror_stdout(false).build();
+    /// let jsonl = client.send_prompt("Stream repo status").await?;
+    /// println!("{jsonl}");
+    /// # Ok(()) }
+    /// ```
+    pub async fn send_prompt(&self, prompt: impl AsRef<str>) -> Result<String, CodexError> {
+        self.send_prompt_with(ExecRequest::new(prompt.as_ref()))
+            .await
+    }
+
+    /// Sends an exec request with per-call CLI overrides.
+    pub async fn send_prompt_with(&self, request: ExecRequest) -> Result<String, CodexError> {
+        if request.prompt.trim().is_empty() {
+            return Err(CodexError::EmptyPrompt);
+        }
+
+        self.invoke_codex_exec(request).await
+    }
+
+    /// Streams structured JSONL events from `codex exec --json`.
+    ///
+    /// Respects `mirror_stdout` (raw JSON echoing) and tees raw lines to `json_event_log` when
+    /// configured on the builder or request. Returns an [`ExecStream`] with both the parsed event
+    /// stream and a completion future that reports `--output-last-message`/schema paths.
+    pub async fn stream_exec(
+        &self,
+        request: ExecStreamRequest,
+    ) -> Result<ExecStream, ExecStreamError> {
+        self.stream_exec_with_overrides(request, CliOverridesPatch::default())
+            .await
+    }
+
+    /// Streams JSONL events with per-request CLI overrides.
+    pub async fn stream_exec_with_overrides(
+        &self,
+        request: ExecStreamRequest,
+        overrides: CliOverridesPatch,
+    ) -> Result<ExecStream, ExecStreamError> {
+        if request.prompt.trim().is_empty() {
+            return Err(CodexError::EmptyPrompt.into());
+        }
+
+        let ExecStreamRequest {
+            prompt,
+            idle_timeout,
+            output_last_message,
+            output_schema,
+            json_event_log,
+        } = request;
+
+        let dir_ctx = self.directory_context()?;
+        let dir_path = dir_ctx.path().to_path_buf();
+        let last_message_path =
+            output_last_message.unwrap_or_else(|| unique_temp_path("codex_last_message_", "txt"));
+        let needs_capabilities = output_schema.is_some() || !self.add_dirs.is_empty();
+        let capabilities = if needs_capabilities {
+            Some(self.probe_capabilities().await)
+        } else {
+            None
+        };
+        let resolved_overrides =
+            resolve_cli_overrides(&self.cli_overrides, &overrides, self.model.as_deref());
+
+        let mut command = Command::new(self.command_env.binary_path());
+        command
+            .arg("exec")
+            .arg("--color")
+            .arg(self.color_mode.as_str())
+            .arg("--skip-git-repo-check")
+            .arg("--json")
+            .stdout(std::process::Stdio::piped())
+            .stderr(std::process::Stdio::piped())
+            .stdin(std::process::Stdio::piped())
+            .kill_on_drop(true)
+            .current_dir(&dir_path);
+
+        apply_cli_overrides(&mut command, &resolved_overrides, true);
+
+        if let Some(model) = &self.model {
+            command.arg("--model").arg(model);
+        }
+
+        if let Some(capabilities) = &capabilities {
+            if !self.add_dirs.is_empty() {
+                let guard = capabilities.guard_add_dir();
+                if guard_is_supported(&guard) {
+                    for dir in &self.add_dirs {
+                        command.arg("--add-dir").arg(dir);
+                    }
+                } else {
+                    log_guard_skip(&guard);
+                }
+            }
+        }
+
+        for image in &self.images {
+            command.arg("--image").arg(image);
+        }
+
+        command.arg("--output-last-message").arg(&last_message_path);
+
+        if let Some(schema_path) = &output_schema {
+            if let Some(capabilities) = &capabilities {
+                let guard = capabilities.guard_output_schema();
+                if guard_is_supported(&guard) {
+                    command.arg("--output-schema").arg(schema_path);
+                } else {
+                    log_guard_skip(&guard);
+                }
+            } else {
+                command.arg("--output-schema").arg(schema_path);
+            }
+        }
+
+        self.command_env.apply(&mut command)?;
+
+        let mut child = spawn_with_retry(&mut command, self.command_env.binary_path())?;
+
+        {
+            let mut stdin = child.stdin.take().ok_or(CodexError::StdinUnavailable)?;
+            if let Err(source) = stdin.write_all(prompt.as_bytes()).await {
+                if source.kind() != std::io::ErrorKind::BrokenPipe {
+                    return Err(CodexError::StdinWrite(source).into());
+                }
+            }
+            if let Err(source) = stdin.write_all(b"\n").await {
+                if source.kind() != std::io::ErrorKind::BrokenPipe {
+                    return Err(CodexError::StdinWrite(source).into());
+                }
+            }
+            if let Err(source) = stdin.shutdown().await {
+                if source.kind() != std::io::ErrorKind::BrokenPipe {
+                    return Err(CodexError::StdinWrite(source).into());
+                }
+            }
+        }
+
+        let stdout = child.stdout.take().ok_or(CodexError::StdoutUnavailable)?;
+        let stderr = child.stderr.take().ok_or(CodexError::StderrUnavailable)?;
+
+        let (tx, rx) = mpsc::channel(32);
+        let json_log = jsonl::prepare_json_log(
+            json_event_log
+                .or_else(|| self.json_event_log.clone())
+                .filter(|path| !path.as_os_str().is_empty()),
+        )
+        .await?;
+        let stdout_task = tokio::spawn(jsonl::forward_json_events(
+            stdout,
+            tx,
+            self.mirror_stdout,
+            json_log,
+        ));
+        let stderr_task = tokio::spawn(tee_stream(stderr, ConsoleTarget::Stderr, !self.quiet));
+
+        let events = jsonl::EventChannelStream::new(rx, idle_timeout);
+        let timeout = self.timeout;
+        let schema_path = output_schema.clone();
+        let completion = Box::pin(async move {
+            let _dir_ctx = dir_ctx;
+            let wait_task = async move {
+                let status = child
+                    .wait()
+                    .await
+                    .map_err(|source| CodexError::Wait { source })?;
+                let stdout_result = stdout_task.await.map_err(CodexError::Join)?;
+                stdout_result?;
+                let stderr_bytes = stderr_task
+                    .await
+                    .map_err(CodexError::Join)?
+                    .map_err(CodexError::CaptureIo)?;
+                if !status.success() {
+                    return Err(CodexError::NonZeroExit {
+                        status,
+                        stderr: String::from_utf8(stderr_bytes).unwrap_or_default(),
+                    }
+                    .into());
+                }
+                let last_message = read_last_message(&last_message_path).await;
+                Ok(ExecCompletion {
+                    status,
+                    last_message_path: Some(last_message_path),
+                    last_message,
+                    schema_path,
+                })
+            };
+
+            if timeout.is_zero() {
+                wait_task.await
+            } else {
+                match time::timeout(timeout, wait_task).await {
+                    Ok(result) => result,
+                    Err(_) => Err(CodexError::Timeout { timeout }.into()),
+                }
+            }
+        });
+
+        Ok(ExecStream {
+            events: Box::pin(events),
+            completion,
+        })
+    }
+
+    /// Streams structured events from `codex exec --json resume ...`.
+    pub async fn stream_resume(
+        &self,
+        request: ResumeRequest,
+    ) -> Result<ExecStream, ExecStreamError> {
+        if let Some(prompt) = &request.prompt {
+            if prompt.trim().is_empty() {
+                return Err(CodexError::EmptyPrompt.into());
+            }
+        }
+
+        let ResumeRequest {
+            selector,
+            prompt,
+            idle_timeout,
+            output_last_message,
+            output_schema,
+            json_event_log,
+            overrides,
+        } = request;
+
+        let dir_ctx = self.directory_context()?;
+        let dir_path = dir_ctx.path().to_path_buf();
+        let last_message_path =
+            output_last_message.unwrap_or_else(|| unique_temp_path("codex_last_message_", "txt"));
+        let needs_capabilities = output_schema.is_some() || !self.add_dirs.is_empty();
+        let capabilities = if needs_capabilities {
+            Some(self.probe_capabilities().await)
+        } else {
+            None
+        };
+        let resolved_overrides =
+            resolve_cli_overrides(&self.cli_overrides, &overrides, self.model.as_deref());
+
+        let mut command = Command::new(self.command_env.binary_path());
+        command
+            .arg("exec")
+            .arg("--color")
+            .arg(self.color_mode.as_str())
+            .arg("--skip-git-repo-check")
+            .arg("--json")
+            .stdout(std::process::Stdio::piped())
+            .stderr(std::process::Stdio::piped())
+            .stdin(std::process::Stdio::piped())
+            .kill_on_drop(true)
+            .current_dir(&dir_path);
+
+        apply_cli_overrides(&mut command, &resolved_overrides, true);
+
+        if let Some(model) = &self.model {
+            command.arg("--model").arg(model);
+        }
+
+        if let Some(capabilities) = &capabilities {
+            if !self.add_dirs.is_empty() {
+                let guard = capabilities.guard_add_dir();
+                if guard_is_supported(&guard) {
+                    for dir in &self.add_dirs {
+                        command.arg("--add-dir").arg(dir);
+                    }
+                } else {
+                    log_guard_skip(&guard);
+                }
+            }
+        }
+
+        for image in &self.images {
+            command.arg("--image").arg(image);
+        }
+
+        command.arg("--output-last-message").arg(&last_message_path);
+
+        if let Some(schema_path) = &output_schema {
+            if let Some(capabilities) = &capabilities {
+                let guard = capabilities.guard_output_schema();
+                if guard_is_supported(&guard) {
+                    command.arg("--output-schema").arg(schema_path);
+                } else {
+                    log_guard_skip(&guard);
+                }
+            } else {
+                command.arg("--output-schema").arg(schema_path);
+            }
+        }
+
+        command.arg("resume");
+
+        match selector {
+            ResumeSelector::Id(id) => {
+                command.arg(id);
+            }
+            ResumeSelector::Last => {
+                command.arg("--last");
+            }
+            ResumeSelector::All => {
+                command.arg("--all");
+            }
+        }
+
+        if prompt.is_some() {
+            // `codex exec resume` reads the follow-up prompt from stdin when `-` is supplied.
+            command.arg("-");
+        }
+
+        self.command_env.apply(&mut command)?;
+
+        let mut child = spawn_with_retry(&mut command, self.command_env.binary_path())?;
+
+        if let Some(prompt) = &prompt {
+            let mut stdin = child.stdin.take().ok_or(CodexError::StdinUnavailable)?;
+            if let Err(source) = stdin.write_all(prompt.as_bytes()).await {
+                if source.kind() != std::io::ErrorKind::BrokenPipe {
+                    return Err(CodexError::StdinWrite(source).into());
+                }
+            }
+            if let Err(source) = stdin.write_all(b"\n").await {
+                if source.kind() != std::io::ErrorKind::BrokenPipe {
+                    return Err(CodexError::StdinWrite(source).into());
+                }
+            }
+            if let Err(source) = stdin.shutdown().await {
+                if source.kind() != std::io::ErrorKind::BrokenPipe {
+                    return Err(CodexError::StdinWrite(source).into());
+                }
+            }
+        } else {
+            let _ = child.stdin.take();
+        }
+
+        let stdout = child.stdout.take().ok_or(CodexError::StdoutUnavailable)?;
+        let stderr = child.stderr.take().ok_or(CodexError::StderrUnavailable)?;
+
+        let (tx, rx) = mpsc::channel(32);
+        let json_log = jsonl::prepare_json_log(
+            json_event_log
+                .or_else(|| self.json_event_log.clone())
+                .filter(|path| !path.as_os_str().is_empty()),
+        )
+        .await?;
+        let stdout_task = tokio::spawn(jsonl::forward_json_events(
+            stdout,
+            tx,
+            self.mirror_stdout,
+            json_log,
+        ));
+        let stderr_task = tokio::spawn(tee_stream(stderr, ConsoleTarget::Stderr, !self.quiet));
+
+        let events = jsonl::EventChannelStream::new(rx, idle_timeout);
+        let timeout = self.timeout;
+        let schema_path = output_schema.clone();
+        let completion = Box::pin(async move {
+            let _dir_ctx = dir_ctx;
+            let wait_task = async move {
+                let status = child
+                    .wait()
+                    .await
+                    .map_err(|source| CodexError::Wait { source })?;
+                let stdout_result = stdout_task.await.map_err(CodexError::Join)?;
+                stdout_result?;
+                let stderr_bytes = stderr_task
+                    .await
+                    .map_err(CodexError::Join)?
+                    .map_err(CodexError::CaptureIo)?;
+                if !status.success() {
+                    return Err(CodexError::NonZeroExit {
+                        status,
+                        stderr: String::from_utf8(stderr_bytes).unwrap_or_default(),
+                    }
+                    .into());
+                }
+                let last_message = read_last_message(&last_message_path).await;
+                Ok(ExecCompletion {
+                    status,
+                    last_message_path: Some(last_message_path),
+                    last_message,
+                    schema_path,
+                })
+            };
+
+            if timeout.is_zero() {
+                wait_task.await
+            } else {
+                match time::timeout(timeout, wait_task).await {
+                    Ok(result) => result,
+                    Err(_) => Err(CodexError::Timeout { timeout }.into()),
+                }
+            }
+        });
+
+        Ok(ExecStream {
+            events: Box::pin(events),
+            completion,
+        })
+    }
+
+    /// Runs `codex resume [OPTIONS] [SESSION_ID] [PROMPT]` and returns captured output.
+    pub async fn resume_session(
+        &self,
+        request: ResumeSessionRequest,
+    ) -> Result<ApplyDiffArtifacts, CodexError> {
+        if matches!(request.prompt.as_deref(), Some(prompt) if prompt.trim().is_empty()) {
+            return Err(CodexError::EmptyPrompt);
+        }
+
+        let mut args = vec![OsString::from("resume")];
+        if request.all {
+            args.push(OsString::from("--all"));
+        }
+        if request.last {
+            args.push(OsString::from("--last"));
+        }
+        if let Some(session_id) = request.session_id {
+            if !session_id.trim().is_empty() {
+                args.push(OsString::from(session_id));
+            }
+        }
+        if let Some(prompt) = request.prompt {
+            if !prompt.trim().is_empty() {
+                args.push(OsString::from(prompt));
+            }
+        }
+
+        self.run_simple_command_with_overrides(args, request.overrides)
+            .await
+    }
+
+    async fn invoke_codex_exec(&self, request: ExecRequest) -> Result<String, CodexError> {
+        let ExecRequest { prompt, overrides } = request;
+        let dir_ctx = self.directory_context()?;
+        let needs_capabilities = self.output_schema || !self.add_dirs.is_empty();
+        let capabilities = if needs_capabilities {
+            Some(self.probe_capabilities().await)
+        } else {
+            None
+        };
+
+        let resolved_overrides =
+            resolve_cli_overrides(&self.cli_overrides, &overrides, self.model.as_deref());
+        let mut command = Command::new(self.command_env.binary_path());
+        command
+            .arg("exec")
+            .arg("--color")
+            .arg(self.color_mode.as_str())
+            .arg("--skip-git-repo-check")
+            .stdout(std::process::Stdio::piped())
+            .stderr(std::process::Stdio::piped())
+            .kill_on_drop(true)
+            .current_dir(dir_ctx.path());
+
+        apply_cli_overrides(&mut command, &resolved_overrides, true);
+
+        let send_prompt_via_stdin = self.json_output;
+        if !send_prompt_via_stdin {
+            command.arg(&prompt);
+        }
+        let stdin_mode = if send_prompt_via_stdin {
+            std::process::Stdio::piped()
+        } else {
+            std::process::Stdio::null()
+        };
+        command.stdin(stdin_mode);
+
+        if let Some(model) = &self.model {
+            command.arg("--model").arg(model);
+        }
+
+        if let Some(capabilities) = &capabilities {
+            if self.output_schema {
+                let guard = capabilities.guard_output_schema();
+                if guard_is_supported(&guard) {
+                    command.arg("--output-schema");
+                } else {
+                    log_guard_skip(&guard);
+                }
+            }
+
+            if !self.add_dirs.is_empty() {
+                let guard = capabilities.guard_add_dir();
+                if guard_is_supported(&guard) {
+                    for dir in &self.add_dirs {
+                        command.arg("--add-dir").arg(dir);
+                    }
+                } else {
+                    log_guard_skip(&guard);
+                }
+            }
+        }
+
+        for image in &self.images {
+            command.arg("--image").arg(image);
+        }
+
+        if self.json_output {
+            command.arg("--json");
+        }
+
+        self.command_env.apply(&mut command)?;
+
+        let mut child = spawn_with_retry(&mut command, self.command_env.binary_path())?;
+
+        if send_prompt_via_stdin {
+            let mut stdin = child.stdin.take().ok_or(CodexError::StdinUnavailable)?;
+            if let Err(source) = stdin.write_all(prompt.as_bytes()).await {
+                if source.kind() != std::io::ErrorKind::BrokenPipe {
+                    return Err(CodexError::StdinWrite(source));
+                }
+            }
+            if let Err(source) = stdin.write_all(b"\n").await {
+                if source.kind() != std::io::ErrorKind::BrokenPipe {
+                    return Err(CodexError::StdinWrite(source));
+                }
+            }
+            if let Err(source) = stdin.shutdown().await {
+                if source.kind() != std::io::ErrorKind::BrokenPipe {
+                    return Err(CodexError::StdinWrite(source));
+                }
+            }
+        } else {
+            let _ = child.stdin.take();
+        }
+
+        let stdout = child.stdout.take().ok_or(CodexError::StdoutUnavailable)?;
+        let stderr = child.stderr.take().ok_or(CodexError::StderrUnavailable)?;
+
+        let stdout_task = tokio::spawn(tee_stream(
+            stdout,
+            ConsoleTarget::Stdout,
+            self.mirror_stdout,
+        ));
+        let stderr_task = tokio::spawn(tee_stream(stderr, ConsoleTarget::Stderr, !self.quiet));
+
+        let wait_task = async move {
+            let status = child
+                .wait()
+                .await
+                .map_err(|source| CodexError::Wait { source })?;
+            let stdout_bytes = stdout_task
+                .await
+                .map_err(CodexError::Join)?
+                .map_err(CodexError::CaptureIo)?;
+            let stderr_bytes = stderr_task
+                .await
+                .map_err(CodexError::Join)?
+                .map_err(CodexError::CaptureIo)?;
+            Ok::<_, CodexError>((status, stdout_bytes, stderr_bytes))
+        };
+
+        let (status, stdout_bytes, stderr_bytes) = if self.timeout.is_zero() {
+            wait_task.await?
+        } else {
+            match time::timeout(self.timeout, wait_task).await {
+                Ok(result) => result?,
+                Err(_) => {
+                    return Err(CodexError::Timeout {
+                        timeout: self.timeout,
+                    });
+                }
+            }
+        };
+
+        let stderr_string = String::from_utf8(stderr_bytes).unwrap_or_default();
+        if !status.success() {
+            return Err(CodexError::NonZeroExit {
+                status,
+                stderr: stderr_string,
+            });
+        }
+
+        let primary_output = if self.json_output && stdout_bytes.is_empty() {
+            stderr_string
+        } else {
+            String::from_utf8(stdout_bytes)?
+        };
+        let trimmed = if self.json_output {
+            primary_output
+        } else {
+            primary_output.trim().to_string()
+        };
+        debug!(
+            binary = ?self.command_env.binary_path(),
+            bytes = trimmed.len(),
+            "received Codex output"
+        );
+        Ok(trimmed)
+    }
+}
+
+/// Options configuring a streaming exec invocation.
+#[derive(Clone, Debug)]
+pub struct ExecStreamRequest {
+    /// User prompt that will be forwarded to `codex exec`.
+    pub prompt: String,
+    /// Per-event idle timeout. If no JSON lines arrive before the duration elapses,
+    /// [`ExecStreamError::IdleTimeout`] is returned.
+    pub idle_timeout: Option<Duration>,
+    /// Optional file path passed through to `--output-last-message`. When unset, the wrapper
+    /// will request a temporary path and return it in [`ExecCompletion::last_message_path`].
+    pub output_last_message: Option<PathBuf>,
+    /// Optional file path passed through to `--output-schema` so clients can persist the schema
+    /// describing the item envelope structure seen during the run.
+    pub output_schema: Option<PathBuf>,
+    /// Optional file path that receives a tee of every raw JSONL event line as it streams in.
+    /// Appends to existing files, flushes each line, and creates parent directories. Overrides
+    /// [`CodexClientBuilder::json_event_log`] for this request when provided.
+    pub json_event_log: Option<PathBuf>,
+}
+
+/// Selector for `codex resume` targets.
+#[derive(Clone, Debug, Eq, PartialEq)]
+pub enum ResumeSelector {
+    Id(String),
+    Last,
+    All,
+}
+
+/// Options configuring a streaming resume invocation.
+#[derive(Clone, Debug)]
+pub struct ResumeRequest {
+    pub selector: ResumeSelector,
+    pub prompt: Option<String>,
+    pub idle_timeout: Option<Duration>,
+    pub output_last_message: Option<PathBuf>,
+    pub output_schema: Option<PathBuf>,
+    pub json_event_log: Option<PathBuf>,
+    pub overrides: CliOverridesPatch,
+}
+
+impl ResumeRequest {
+    pub fn new(selector: ResumeSelector) -> Self {
+        Self {
+            selector,
+            prompt: None,
+            idle_timeout: None,
+            output_last_message: None,
+            output_schema: None,
+            json_event_log: None,
+            overrides: CliOverridesPatch::default(),
+        }
+    }
+
+    pub fn with_id(id: impl Into<String>) -> Self {
+        Self::new(ResumeSelector::Id(id.into()))
+    }
+
+    pub fn last() -> Self {
+        Self::new(ResumeSelector::Last)
+    }
+
+    pub fn all() -> Self {
+        Self::new(ResumeSelector::All)
+    }
+
+    pub fn prompt(mut self, prompt: impl Into<String>) -> Self {
+        self.prompt = Some(prompt.into());
+        self
+    }
+
+    pub fn idle_timeout(mut self, idle_timeout: Duration) -> Self {
+        self.idle_timeout = Some(idle_timeout);
+        self
+    }
+
+    pub fn config_override(mut self, key: impl Into<String>, value: impl Into<String>) -> Self {
+        self.overrides
+            .config_overrides
+            .push(ConfigOverride::new(key, value));
+        self
+    }
+
+    pub fn config_override_raw(mut self, raw: impl Into<String>) -> Self {
+        self.overrides
+            .config_overrides
+            .push(ConfigOverride::from_raw(raw));
+        self
+    }
+
+    pub fn profile(mut self, profile: impl Into<String>) -> Self {
+        let profile = profile.into();
+        self.overrides.profile = (!profile.trim().is_empty()).then_some(profile);
+        self
+    }
+
+    pub fn oss(mut self, enable: bool) -> Self {
+        self.overrides.oss = if enable {
+            FlagState::Enable
+        } else {
+            FlagState::Disable
+        };
+        self
+    }
+
+    pub fn enable_feature(mut self, name: impl Into<String>) -> Self {
+        self.overrides.feature_toggles.enable.push(name.into());
+        self
+    }
+
+    pub fn disable_feature(mut self, name: impl Into<String>) -> Self {
+        self.overrides.feature_toggles.disable.push(name.into());
+        self
+    }
+
+    pub fn search(mut self, enable: bool) -> Self {
+        self.overrides.search = if enable {
+            FlagState::Enable
+        } else {
+            FlagState::Disable
+        };
+        self
+    }
+}
+
+/// Ergonomic container for the streaming surface; produced by `stream_exec` (implemented in D2).
+///
+/// `events` yields parsed [`ThreadEvent`] values as soon as each JSONL line arrives from the CLI.
+/// `completion` resolves once the Codex process exits and is the place to surface `--output-last-message`
+/// and `--output-schema` paths after streaming finishes.
+pub struct ExecStream {
+    pub events: DynThreadEventStream,
+    pub completion: DynExecCompletion,
+}
+
+/// Type-erased stream of events from the Codex CLI.
+pub type DynThreadEventStream =
+    Pin<Box<dyn Stream<Item = Result<ThreadEvent, ExecStreamError>> + Send>>;
+
+/// Type-erased completion future that resolves when streaming stops.
+pub type DynExecCompletion =
+    Pin<Box<dyn Future<Output = Result<ExecCompletion, ExecStreamError>> + Send>>;
+
+/// Summary returned when the codex child process exits.
+#[derive(Clone, Debug)]
+pub struct ExecCompletion {
+    pub status: ExitStatus,
+    /// Path that codex wrote when `--output-last-message` was enabled. The wrapper may eagerly
+    /// read the file and populate `last_message` when feasible.
+    pub last_message_path: Option<PathBuf>,
+    pub last_message: Option<String>,
+    /// Path to the JSON schema requested via `--output-schema`, if provided by the caller.
+    pub schema_path: Option<PathBuf>,
+}
+
+/// Errors that may occur while consuming the JSONL stream.
+#[derive(Debug, Error)]
+pub enum ExecStreamError {
+    #[error(transparent)]
+    Codex(#[from] CodexError),
+    #[error("failed to parse codex JSONL event: {source}: `{line}`")]
+    Parse {
+        line: String,
+        #[source]
+        source: serde_json::Error,
+    },
+    #[error("codex JSONL event missing required context: {message}: `{line}`")]
+    Normalize { line: String, message: String },
+    #[error("codex JSON stream idle for {idle_for:?}")]
+    IdleTimeout { idle_for: Duration },
+    #[error("codex JSON stream closed unexpectedly")]
+    ChannelClosed,
+}
+
+async fn read_last_message(path: &Path) -> Option<String> {
+    (fs::read_to_string(path).await).ok()
+}
+
+fn unique_temp_path(prefix: &str, extension: &str) -> PathBuf {
+    let mut path = env::temp_dir();
+    let timestamp = SystemTime::now()
+        .duration_since(UNIX_EPOCH)
+        .unwrap_or_else(|_| Duration::from_secs(0))
+        .as_nanos();
+    path.push(format!(
+        "{prefix}{timestamp}_{}.{}",
+        std::process::id(),
+        extension
+    ));
+    path
+}
diff --git a/crates/codex/src/lib.rs b/crates/codex/src/lib.rs
index 08e80ed..66fee60 100644
--- a/crates/codex/src/lib.rs
+++ b/crates/codex/src/lib.rs
@@ -69,10 +69,15 @@
 
 mod apply_diff;
 mod builder;
+mod bundled_binary;
+mod cli;
+mod events;
+mod exec;
 mod execpolicy;
 mod home;
 pub mod jsonl;
 pub mod mcp;
+mod process;
 pub mod wrapper_coverage_manifest;
 
 pub use apply_diff::{ApplyDiffArtifacts, CloudApplyRequest, CloudDiffRequest};
@@ -81,6 +86,31 @@ pub use builder::{
     FeatureToggles, FlagState, LocalProvider, ModelVerbosity, ReasoningEffort, ReasoningOverrides,
     ReasoningSummary, ReasoningSummaryFormat, SafetyOverride, SandboxMode,
 };
+pub use bundled_binary::{
+    default_bundled_platform_label, resolve_bundled_binary, BundledBinary, BundledBinaryError,
+    BundledBinarySpec,
+};
+pub use cli::{
+    AppServerCodegenOutput, AppServerCodegenRequest, AppServerCodegenTarget, CloudExecRequest,
+    CloudListOutput, CloudListRequest, CloudOverviewRequest, CloudStatusRequest, CodexFeature,
+    CodexFeatureStage, ExecRequest, ExecReviewCommandRequest, FeaturesCommandRequest,
+    FeaturesListFormat, FeaturesListOutput, FeaturesListRequest, ForkSessionRequest,
+    HelpCommandRequest, HelpScope, McpAddRequest, McpAddTransport, McpGetRequest, McpListOutput,
+    McpListRequest, McpLogoutRequest, McpOauthLoginRequest, McpOverviewRequest, McpRemoveRequest,
+    ResponsesApiProxyHandle, ResponsesApiProxyInfo, ResponsesApiProxyRequest, ResumeSessionRequest,
+    ReviewCommandRequest, SandboxCommandRequest, SandboxPlatform, SandboxRun, StdioToUdsRequest,
+};
+pub use events::{
+    CommandExecutionDelta, CommandExecutionState, EventError, FileChangeDelta, FileChangeKind,
+    FileChangeState, ItemDelta, ItemDeltaPayload, ItemEnvelope, ItemFailure, ItemPayload,
+    ItemSnapshot, ItemStatus, McpToolCallDelta, McpToolCallState, TextContent, TextDelta,
+    ThreadEvent, ThreadStarted, TodoItem, TodoListDelta, TodoListState, ToolCallStatus,
+    TurnCompleted, TurnFailed, TurnStarted, WebSearchDelta, WebSearchState, WebSearchStatus,
+};
+pub use exec::{
+    DynExecCompletion, DynThreadEventStream, ExecCompletion, ExecStream, ExecStreamError,
+    ExecStreamRequest, ResumeRequest, ResumeSelector,
+};
 pub use execpolicy::{
     ExecPolicyCheckRequest, ExecPolicyCheckResult, ExecPolicyDecision, ExecPolicyEvaluation,
     ExecPolicyMatch, ExecPolicyNoMatch, ExecPolicyRuleMatch,
@@ -92,36 +122,27 @@ pub use jsonl::{
 };
 
 use std::{
-    collections::{BTreeMap, HashSet},
     env,
     ffi::{OsStr, OsString},
     fs as std_fs,
-    future::Future,
-    io::{self as stdio, Write},
     path::{Path, PathBuf},
-    pin::Pin,
     process::ExitStatus,
-    time::{Duration, SystemTime, UNIX_EPOCH},
+    time::{Duration, SystemTime},
 };
 
 use builder::{apply_cli_overrides, resolve_cli_overrides};
-use futures_core::Stream;
 use home::CommandEnvironment;
-use semver::{Prerelease, Version};
-use serde::{Deserialize, Serialize};
-use serde_json::Value;
-#[cfg(unix)]
-use std::os::unix::fs::PermissionsExt;
+use process::{
+    command_output_text, preferred_output_channel, spawn_with_retry, tee_stream, CommandOutput,
+    ConsoleTarget,
+};
 use tempfile::TempDir;
 use thiserror::Error;
-use tokio::{
-    fs,
-    io::{AsyncRead, AsyncReadExt, AsyncWriteExt},
-    process::Command,
-    sync::mpsc,
-    task, time,
-};
-use tracing::{debug, warn};
+use tokio::{io::AsyncWriteExt, process::Command, time};
+use tracing::warn;
+
+#[cfg(test)]
+use tokio::sync::mpsc;
 
 const DEFAULT_TIMEOUT: Duration = Duration::from_secs(120);
 const CODEX_BINARY_ENV: &str = "CODEX_BINARY";
@@ -135,233 +156,20 @@ use builder::{
     DEFAULT_REASONING_CONFIG_GPT5_1, DEFAULT_REASONING_CONFIG_GPT5_CODEX,
 };
 
-/// Specification for resolving an app-bundled Codex binary.
-///
-/// Callers supply a bundle root plus the pinned version they expect. Platform
-/// defaults to the current target triple label (e.g., `darwin-arm64` or
-/// `linux-x64`) but can be overridden when hosts manage their own layout.
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub struct BundledBinarySpec<'a> {
-    /// Root containing `<platform>/<version>/codex` slices managed by the host.
-    pub bundle_root: &'a Path,
-    /// Pinned Codex version directory to resolve (semantic version or channel/build id).
-    pub version: &'a str,
-    /// Optional platform label override; defaults to [`default_bundled_platform_label`].
-    pub platform: Option<&'a str>,
-}
-
-/// Resolved bundled Codex binary details.
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub struct BundledBinary {
-    /// Canonicalized path to the bundled Codex binary (`codex` or `codex.exe`).
-    pub binary_path: PathBuf,
-    /// Platform slice resolved under the bundle root.
-    pub platform: String,
-    /// Version slice resolved under the platform directory.
-    pub version: String,
-}
-
-/// Errors that may occur while resolving a bundled Codex binary.
-#[derive(Debug, Error)]
-pub enum BundledBinaryError {
-    #[error("bundled Codex version cannot be empty")]
-    EmptyVersion,
-    #[error("bundled Codex platform label cannot be empty")]
-    EmptyPlatform,
-    #[error("bundle root `{bundle_root}` does not exist or is unreadable")]
-    BundleRootUnreadable {
-        bundle_root: PathBuf,
-        #[source]
-        source: std::io::Error,
-    },
-    #[error("bundle root `{bundle_root}` is not a directory")]
-    BundleRootNotDirectory { bundle_root: PathBuf },
-    #[error("bundle platform directory `{platform_dir}` for `{platform}` does not exist or is unreadable")]
-    PlatformUnreadable {
-        platform: String,
-        platform_dir: PathBuf,
-        #[source]
-        source: std::io::Error,
-    },
-    #[error("bundle platform directory `{platform_dir}` for `{platform}` is not a directory")]
-    PlatformNotDirectory {
-        platform: String,
-        platform_dir: PathBuf,
-    },
-    #[error(
-        "bundle version directory `{version_dir}` for `{version}` does not exist or is unreadable"
-    )]
-    VersionUnreadable {
-        version: String,
-        version_dir: PathBuf,
-        #[source]
-        source: std::io::Error,
-    },
-    #[error("bundle version directory `{version_dir}` for `{version}` is not a directory")]
-    VersionNotDirectory {
-        version: String,
-        version_dir: PathBuf,
-    },
-    #[error("bundled Codex binary `{binary}` is missing or unreadable")]
-    BinaryUnreadable {
-        binary: PathBuf,
-        #[source]
-        source: std::io::Error,
-    },
-    #[error("bundled Codex binary `{binary}` is not a file")]
-    BinaryNotFile { binary: PathBuf },
-    #[error("bundled Codex binary `{binary}` is not executable")]
-    BinaryNotExecutable { binary: PathBuf },
-    #[error("failed to canonicalize bundled Codex binary `{path}`: {source}")]
-    Canonicalize {
-        path: PathBuf,
-        #[source]
-        source: std::io::Error,
-    },
-}
-
-/// Resolves a bundled Codex binary under `<bundle_root>/<platform>/<version>/`.
-///
-/// The helper never consults `PATH` or `CODEX_BINARY`; missing slices are hard
-/// errors. The resolved path is canonicalized and should be passed to
-/// [`CodexClientBuilder::binary`] to keep behavior isolated from any global
-/// Codex install.
-pub fn resolve_bundled_binary(
-    spec: BundledBinarySpec<'_>,
-) -> Result<BundledBinary, BundledBinaryError> {
-    let platform = match spec.platform {
-        Some(label) => normalize_non_empty(label).ok_or(BundledBinaryError::EmptyPlatform)?,
-        None => default_bundled_platform_label(),
-    };
-    let version = normalize_non_empty(spec.version).ok_or(BundledBinaryError::EmptyVersion)?;
-
-    require_directory(
-        spec.bundle_root,
-        |source| BundledBinaryError::BundleRootUnreadable {
-            bundle_root: spec.bundle_root.to_path_buf(),
-            source,
-        },
-        || BundledBinaryError::BundleRootNotDirectory {
-            bundle_root: spec.bundle_root.to_path_buf(),
-        },
-    )?;
-
-    let platform_dir = spec.bundle_root.join(&platform);
-    require_directory(
-        &platform_dir,
-        |source| BundledBinaryError::PlatformUnreadable {
-            platform: platform.clone(),
-            platform_dir: platform_dir.clone(),
-            source,
-        },
-        || BundledBinaryError::PlatformNotDirectory {
-            platform: platform.clone(),
-            platform_dir: platform_dir.clone(),
-        },
-    )?;
-
-    let version_dir = platform_dir.join(&version);
-    require_directory(
-        &version_dir,
-        |source| BundledBinaryError::VersionUnreadable {
-            version: version.clone(),
-            version_dir: version_dir.clone(),
-            source,
-        },
-        || BundledBinaryError::VersionNotDirectory {
-            version: version.clone(),
-            version_dir: version_dir.clone(),
-        },
-    )?;
-
-    let binary_path = version_dir.join(bundled_binary_filename(&platform));
-    let metadata =
-        std_fs::metadata(&binary_path).map_err(|source| BundledBinaryError::BinaryUnreadable {
-            binary: binary_path.clone(),
-            source,
-        })?;
-    if !metadata.is_file() {
-        return Err(BundledBinaryError::BinaryNotFile {
-            binary: binary_path.clone(),
-        });
-    }
-    ensure_executable(&metadata, &binary_path)?;
-
-    let canonical =
-        std_fs::canonicalize(&binary_path).map_err(|source| BundledBinaryError::Canonicalize {
-            path: binary_path.clone(),
-            source,
-        })?;
-
-    Ok(BundledBinary {
-        binary_path: canonical,
-        platform,
-        version,
-    })
-}
-
-/// Default bundled platform label for the current target (e.g., `darwin-arm64`, `linux-x64`, `windows-x64`).
-pub fn default_bundled_platform_label() -> String {
-    let os = match env::consts::OS {
-        "macos" => "darwin",
-        other => other,
-    };
-    let arch = match env::consts::ARCH {
-        "x86_64" => "x64",
-        "aarch64" => "arm64",
-        other => other,
-    };
-    format!("{os}-{arch}")
-}
-
-fn require_directory(
-    path: &Path,
-    on_read_error: impl FnOnce(std::io::Error) -> BundledBinaryError,
-    on_wrong_type: impl FnOnce() -> BundledBinaryError,
-) -> Result<(), BundledBinaryError> {
-    let metadata = std_fs::metadata(path).map_err(on_read_error)?;
-    if !metadata.is_dir() {
-        return Err(on_wrong_type());
-    }
-    Ok(())
-}
-
-fn ensure_executable(metadata: &std_fs::Metadata, binary: &Path) -> Result<(), BundledBinaryError> {
-    if binary_is_executable(metadata) {
-        return Ok(());
-    }
-    Err(BundledBinaryError::BinaryNotExecutable {
-        binary: binary.to_path_buf(),
-    })
-}
-
-fn binary_is_executable(metadata: &std_fs::Metadata) -> bool {
-    #[cfg(unix)]
-    {
-        metadata.permissions().mode() & 0o111 != 0
-    }
-    #[cfg(not(unix))]
-    {
-        // Windows does not use executable bits; existence is sufficient.
-        true
-    }
-}
-
-fn bundled_binary_filename(platform: &str) -> &'static str {
-    if platform.to_ascii_lowercase().contains("windows") {
-        "codex.exe"
-    } else {
-        "codex"
-    }
-}
-
 fn normalize_non_empty(value: &str) -> Option<String> {
     let trimmed = value.trim();
     (!trimmed.is_empty()).then_some(trimmed.to_string())
 }
 
+#[cfg(test)]
+fn bundled_binary_filename(platform: &str) -> &'static str {
+    bundled_binary::bundled_binary_filename(platform)
+}
+
 mod capabilities;
+mod version;
 pub use capabilities::*;
+pub use version::update_advisory_from_capabilities;
 
 /// High-level client for interacting with `codex exec`.
 ///
@@ -499,416 +307,6 @@ impl CodexClient {
         self.command_env.codex_home_layout()
     }
 
-    /// Sends `prompt` to `codex exec` and returns its stdout (the final agent message) on success.
-    ///
-    /// When `.json(true)` is enabled the CLI emits JSONL events (`thread.started` or
-    /// `thread.resumed`, `turn.started`/`turn.completed`/`turn.failed`,
-    /// `item.created`/`item.updated`, or `error`). The stream is mirrored to stdout unless
-    /// `.mirror_stdout(false)`; the returned string contains the buffered lines for offline
-    /// parsing. For per-event handling, see `crates/codex/examples/stream_events.rs`.
-    ///
-    /// ```rust,no_run
-    /// use codex::CodexClient;
-    /// # #[tokio::main]
-    /// # async fn main() -> Result<(), Box<dyn std::error::Error>> {
-    /// let client = CodexClient::builder().json(true).mirror_stdout(false).build();
-    /// let jsonl = client.send_prompt("Stream repo status").await?;
-    /// println!("{jsonl}");
-    /// # Ok(()) }
-    /// ```
-    pub async fn send_prompt(&self, prompt: impl AsRef<str>) -> Result<String, CodexError> {
-        self.send_prompt_with(ExecRequest::new(prompt.as_ref()))
-            .await
-    }
-
-    /// Sends an exec request with per-call CLI overrides.
-    pub async fn send_prompt_with(&self, request: ExecRequest) -> Result<String, CodexError> {
-        if request.prompt.trim().is_empty() {
-            return Err(CodexError::EmptyPrompt);
-        }
-
-        self.invoke_codex_exec(request).await
-    }
-
-    /// Streams structured JSONL events from `codex exec --json`.
-    ///
-    /// Respects `mirror_stdout` (raw JSON echoing) and tees raw lines to `json_event_log` when
-    /// configured on the builder or request. Returns an [`ExecStream`] with both the parsed event
-    /// stream and a completion future that reports `--output-last-message`/schema paths.
-    pub async fn stream_exec(
-        &self,
-        request: ExecStreamRequest,
-    ) -> Result<ExecStream, ExecStreamError> {
-        self.stream_exec_with_overrides(request, CliOverridesPatch::default())
-            .await
-    }
-
-    /// Streams JSONL events with per-request CLI overrides.
-    pub async fn stream_exec_with_overrides(
-        &self,
-        request: ExecStreamRequest,
-        overrides: CliOverridesPatch,
-    ) -> Result<ExecStream, ExecStreamError> {
-        if request.prompt.trim().is_empty() {
-            return Err(CodexError::EmptyPrompt.into());
-        }
-
-        let ExecStreamRequest {
-            prompt,
-            idle_timeout,
-            output_last_message,
-            output_schema,
-            json_event_log,
-        } = request;
-
-        let dir_ctx = self.directory_context()?;
-        let dir_path = dir_ctx.path().to_path_buf();
-        let last_message_path =
-            output_last_message.unwrap_or_else(|| unique_temp_path("codex_last_message_", "txt"));
-        let needs_capabilities = output_schema.is_some() || !self.add_dirs.is_empty();
-        let capabilities = if needs_capabilities {
-            Some(self.probe_capabilities().await)
-        } else {
-            None
-        };
-        let resolved_overrides =
-            resolve_cli_overrides(&self.cli_overrides, &overrides, self.model.as_deref());
-
-        let mut command = Command::new(self.command_env.binary_path());
-        command
-            .arg("exec")
-            .arg("--color")
-            .arg(self.color_mode.as_str())
-            .arg("--skip-git-repo-check")
-            .arg("--json")
-            .stdout(std::process::Stdio::piped())
-            .stderr(std::process::Stdio::piped())
-            .stdin(std::process::Stdio::piped())
-            .kill_on_drop(true)
-            .current_dir(&dir_path);
-
-        apply_cli_overrides(&mut command, &resolved_overrides, true);
-
-        if let Some(model) = &self.model {
-            command.arg("--model").arg(model);
-        }
-
-        if let Some(capabilities) = &capabilities {
-            if !self.add_dirs.is_empty() {
-                let guard = capabilities.guard_add_dir();
-                if guard_is_supported(&guard) {
-                    for dir in &self.add_dirs {
-                        command.arg("--add-dir").arg(dir);
-                    }
-                } else {
-                    log_guard_skip(&guard);
-                }
-            }
-        }
-
-        for image in &self.images {
-            command.arg("--image").arg(image);
-        }
-
-        command.arg("--output-last-message").arg(&last_message_path);
-
-        if let Some(schema_path) = &output_schema {
-            if let Some(capabilities) = &capabilities {
-                let guard = capabilities.guard_output_schema();
-                if guard_is_supported(&guard) {
-                    command.arg("--output-schema").arg(schema_path);
-                } else {
-                    log_guard_skip(&guard);
-                }
-            } else {
-                command.arg("--output-schema").arg(schema_path);
-            }
-        }
-
-        self.command_env.apply(&mut command)?;
-
-        let mut child = spawn_with_retry(&mut command, self.command_env.binary_path())?;
-
-        {
-            let mut stdin = child.stdin.take().ok_or(CodexError::StdinUnavailable)?;
-            if let Err(source) = stdin.write_all(prompt.as_bytes()).await {
-                if source.kind() != std::io::ErrorKind::BrokenPipe {
-                    return Err(CodexError::StdinWrite(source).into());
-                }
-            }
-            if let Err(source) = stdin.write_all(b"\n").await {
-                if source.kind() != std::io::ErrorKind::BrokenPipe {
-                    return Err(CodexError::StdinWrite(source).into());
-                }
-            }
-            if let Err(source) = stdin.shutdown().await {
-                if source.kind() != std::io::ErrorKind::BrokenPipe {
-                    return Err(CodexError::StdinWrite(source).into());
-                }
-            }
-        }
-
-        let stdout = child.stdout.take().ok_or(CodexError::StdoutUnavailable)?;
-        let stderr = child.stderr.take().ok_or(CodexError::StderrUnavailable)?;
-
-        let (tx, rx) = mpsc::channel(32);
-        let json_log = jsonl::prepare_json_log(
-            json_event_log
-                .or_else(|| self.json_event_log.clone())
-                .filter(|path| !path.as_os_str().is_empty()),
-        )
-        .await?;
-        let stdout_task = tokio::spawn(jsonl::forward_json_events(
-            stdout,
-            tx,
-            self.mirror_stdout,
-            json_log,
-        ));
-        let stderr_task = tokio::spawn(tee_stream(stderr, ConsoleTarget::Stderr, !self.quiet));
-
-        let events = jsonl::EventChannelStream::new(rx, idle_timeout);
-        let timeout = self.timeout;
-        let schema_path = output_schema.clone();
-        let completion = Box::pin(async move {
-            let _dir_ctx = dir_ctx;
-            let wait_task = async move {
-                let status = child
-                    .wait()
-                    .await
-                    .map_err(|source| CodexError::Wait { source })?;
-                let stdout_result = stdout_task.await.map_err(CodexError::Join)?;
-                stdout_result?;
-                let stderr_bytes = stderr_task
-                    .await
-                    .map_err(CodexError::Join)?
-                    .map_err(CodexError::CaptureIo)?;
-                if !status.success() {
-                    return Err(CodexError::NonZeroExit {
-                        status,
-                        stderr: String::from_utf8(stderr_bytes).unwrap_or_default(),
-                    }
-                    .into());
-                }
-                let last_message = read_last_message(&last_message_path).await;
-                Ok(ExecCompletion {
-                    status,
-                    last_message_path: Some(last_message_path),
-                    last_message,
-                    schema_path,
-                })
-            };
-
-            if timeout.is_zero() {
-                wait_task.await
-            } else {
-                match time::timeout(timeout, wait_task).await {
-                    Ok(result) => result,
-                    Err(_) => Err(CodexError::Timeout { timeout }.into()),
-                }
-            }
-        });
-
-        Ok(ExecStream {
-            events: Box::pin(events),
-            completion,
-        })
-    }
-
-    /// Streams structured events from `codex exec --json resume ...`.
-    pub async fn stream_resume(
-        &self,
-        request: ResumeRequest,
-    ) -> Result<ExecStream, ExecStreamError> {
-        if let Some(prompt) = &request.prompt {
-            if prompt.trim().is_empty() {
-                return Err(CodexError::EmptyPrompt.into());
-            }
-        }
-
-        let ResumeRequest {
-            selector,
-            prompt,
-            idle_timeout,
-            output_last_message,
-            output_schema,
-            json_event_log,
-            overrides,
-        } = request;
-
-        let dir_ctx = self.directory_context()?;
-        let dir_path = dir_ctx.path().to_path_buf();
-        let last_message_path =
-            output_last_message.unwrap_or_else(|| unique_temp_path("codex_last_message_", "txt"));
-        let needs_capabilities = output_schema.is_some() || !self.add_dirs.is_empty();
-        let capabilities = if needs_capabilities {
-            Some(self.probe_capabilities().await)
-        } else {
-            None
-        };
-        let resolved_overrides =
-            resolve_cli_overrides(&self.cli_overrides, &overrides, self.model.as_deref());
-
-        let mut command = Command::new(self.command_env.binary_path());
-        command
-            .arg("exec")
-            .arg("--color")
-            .arg(self.color_mode.as_str())
-            .arg("--skip-git-repo-check")
-            .arg("--json")
-            .stdout(std::process::Stdio::piped())
-            .stderr(std::process::Stdio::piped())
-            .stdin(std::process::Stdio::piped())
-            .kill_on_drop(true)
-            .current_dir(&dir_path);
-
-        apply_cli_overrides(&mut command, &resolved_overrides, true);
-
-        if let Some(model) = &self.model {
-            command.arg("--model").arg(model);
-        }
-
-        if let Some(capabilities) = &capabilities {
-            if !self.add_dirs.is_empty() {
-                let guard = capabilities.guard_add_dir();
-                if guard_is_supported(&guard) {
-                    for dir in &self.add_dirs {
-                        command.arg("--add-dir").arg(dir);
-                    }
-                } else {
-                    log_guard_skip(&guard);
-                }
-            }
-        }
-
-        for image in &self.images {
-            command.arg("--image").arg(image);
-        }
-
-        command.arg("--output-last-message").arg(&last_message_path);
-
-        if let Some(schema_path) = &output_schema {
-            if let Some(capabilities) = &capabilities {
-                let guard = capabilities.guard_output_schema();
-                if guard_is_supported(&guard) {
-                    command.arg("--output-schema").arg(schema_path);
-                } else {
-                    log_guard_skip(&guard);
-                }
-            } else {
-                command.arg("--output-schema").arg(schema_path);
-            }
-        }
-
-        command.arg("resume");
-
-        match selector {
-            ResumeSelector::Id(id) => {
-                command.arg(id);
-            }
-            ResumeSelector::Last => {
-                command.arg("--last");
-            }
-            ResumeSelector::All => {
-                command.arg("--all");
-            }
-        }
-
-        if prompt.is_some() {
-            // `codex exec resume` reads the follow-up prompt from stdin when `-` is supplied.
-            command.arg("-");
-        }
-
-        self.command_env.apply(&mut command)?;
-
-        let mut child = spawn_with_retry(&mut command, self.command_env.binary_path())?;
-
-        if let Some(prompt) = &prompt {
-            let mut stdin = child.stdin.take().ok_or(CodexError::StdinUnavailable)?;
-            if let Err(source) = stdin.write_all(prompt.as_bytes()).await {
-                if source.kind() != std::io::ErrorKind::BrokenPipe {
-                    return Err(CodexError::StdinWrite(source).into());
-                }
-            }
-            if let Err(source) = stdin.write_all(b"\n").await {
-                if source.kind() != std::io::ErrorKind::BrokenPipe {
-                    return Err(CodexError::StdinWrite(source).into());
-                }
-            }
-            if let Err(source) = stdin.shutdown().await {
-                if source.kind() != std::io::ErrorKind::BrokenPipe {
-                    return Err(CodexError::StdinWrite(source).into());
-                }
-            }
-        } else {
-            let _ = child.stdin.take();
-        }
-
-        let stdout = child.stdout.take().ok_or(CodexError::StdoutUnavailable)?;
-        let stderr = child.stderr.take().ok_or(CodexError::StderrUnavailable)?;
-
-        let (tx, rx) = mpsc::channel(32);
-        let json_log = jsonl::prepare_json_log(
-            json_event_log
-                .or_else(|| self.json_event_log.clone())
-                .filter(|path| !path.as_os_str().is_empty()),
-        )
-        .await?;
-        let stdout_task = tokio::spawn(jsonl::forward_json_events(
-            stdout,
-            tx,
-            self.mirror_stdout,
-            json_log,
-        ));
-        let stderr_task = tokio::spawn(tee_stream(stderr, ConsoleTarget::Stderr, !self.quiet));
-
-        let events = jsonl::EventChannelStream::new(rx, idle_timeout);
-        let timeout = self.timeout;
-        let schema_path = output_schema.clone();
-        let completion = Box::pin(async move {
-            let _dir_ctx = dir_ctx;
-            let wait_task = async move {
-                let status = child
-                    .wait()
-                    .await
-                    .map_err(|source| CodexError::Wait { source })?;
-                let stdout_result = stdout_task.await.map_err(CodexError::Join)?;
-                stdout_result?;
-                let stderr_bytes = stderr_task
-                    .await
-                    .map_err(CodexError::Join)?
-                    .map_err(CodexError::CaptureIo)?;
-                if !status.success() {
-                    return Err(CodexError::NonZeroExit {
-                        status,
-                        stderr: String::from_utf8(stderr_bytes).unwrap_or_default(),
-                    }
-                    .into());
-                }
-                let last_message = read_last_message(&last_message_path).await;
-                Ok(ExecCompletion {
-                    status,
-                    last_message_path: Some(last_message_path),
-                    last_message,
-                    schema_path,
-                })
-            };
-
-            if timeout.is_zero() {
-                wait_task.await
-            } else {
-                match time::timeout(timeout, wait_task).await {
-                    Ok(result) => result,
-                    Err(_) => Err(CodexError::Timeout { timeout }.into()),
-                }
-            }
-        });
-
-        Ok(ExecStream {
-            events: Box::pin(events),
-            completion,
-        })
-    }
-
     /// Spawns a `codex login` session using the default ChatGPT OAuth flow.
     ///
     /// The returned child inherits `kill_on_drop` so abandoning the handle cleans up the login helper.
@@ -1393,7 +791,7 @@ impl CodexClient {
         let stdout_string = String::from_utf8(stdout_bytes)?;
         let stderr_string = String::from_utf8(stderr_bytes)?;
         let (features, format) =
-            parse_feature_list_output(&stdout_string, json).map_err(|reason| {
+            version::parse_feature_list_output(&stdout_string, json).map_err(|reason| {
                 CodexError::FeatureListParse {
                     reason,
                     stdout: stdout_string.clone(),
@@ -1522,16 +920,16 @@ impl CodexClient {
             .await
     }
 
-    /// Runs `codex resume [OPTIONS] [SESSION_ID] [PROMPT]` and returns captured output.
-    pub async fn resume_session(
+    /// Runs `codex fork [OPTIONS] [SESSION_ID] [PROMPT]` and returns captured output.
+    pub async fn fork_session(
         &self,
-        request: ResumeSessionRequest,
+        request: ForkSessionRequest,
     ) -> Result<ApplyDiffArtifacts, CodexError> {
         if matches!(request.prompt.as_deref(), Some(prompt) if prompt.trim().is_empty()) {
             return Err(CodexError::EmptyPrompt);
         }
 
-        let mut args = vec![OsString::from("resume")];
+        let mut args = vec![OsString::from("fork")];
         if request.all {
             args.push(OsString::from("--all"));
         }
@@ -1553,41 +951,10 @@ impl CodexClient {
             .await
     }
 
-    /// Runs `codex fork [OPTIONS] [SESSION_ID] [PROMPT]` and returns captured output.
-    pub async fn fork_session(
+    /// Runs `codex cloud --help` and returns captured output.
+    pub async fn cloud_overview(
         &self,
-        request: ForkSessionRequest,
-    ) -> Result<ApplyDiffArtifacts, CodexError> {
-        if matches!(request.prompt.as_deref(), Some(prompt) if prompt.trim().is_empty()) {
-            return Err(CodexError::EmptyPrompt);
-        }
-
-        let mut args = vec![OsString::from("fork")];
-        if request.all {
-            args.push(OsString::from("--all"));
-        }
-        if request.last {
-            args.push(OsString::from("--last"));
-        }
-        if let Some(session_id) = request.session_id {
-            if !session_id.trim().is_empty() {
-                args.push(OsString::from(session_id));
-            }
-        }
-        if let Some(prompt) = request.prompt {
-            if !prompt.trim().is_empty() {
-                args.push(OsString::from(prompt));
-            }
-        }
-
-        self.run_simple_command_with_overrides(args, request.overrides)
-            .await
-    }
-
-    /// Runs `codex cloud --help` and returns captured output.
-    pub async fn cloud_overview(
-        &self,
-        request: CloudOverviewRequest,
+        request: CloudOverviewRequest,
     ) -> Result<ApplyDiffArtifacts, CodexError> {
         self.run_simple_command_with_overrides(
             vec![OsString::from("cloud"), OsString::from("--help")],
@@ -2260,7 +1627,7 @@ impl CodexClient {
                 }
                 let text = command_output_text(&output);
                 if !text.trim().is_empty() {
-                    version = Some(parse_version_output(&text));
+                    version = Some(version::parse_version_output(&text));
                 }
             }
             Err(error) => warn!(
@@ -2286,13 +1653,13 @@ impl CodexClient {
                     features.supports_features_list = true;
                 }
                 let text = command_output_text(&output);
-                if let Some(parsed) = parse_features_from_json(&text) {
-                    merge_feature_flags(&mut features, parsed);
-                    parsed_features = detected_feature_flags(&features);
+                if let Some(parsed) = version::parse_features_from_json(&text) {
+                    version::merge_feature_flags(&mut features, parsed);
+                    parsed_features = version::detected_feature_flags(&features);
                 } else if !text.is_empty() {
-                    let parsed = parse_features_from_text(&text);
-                    merge_feature_flags(&mut features, parsed);
-                    parsed_features = detected_feature_flags(&features);
+                    let parsed = version::parse_features_from_text(&text);
+                    version::merge_feature_flags(&mut features, parsed);
+                    parsed_features = version::detected_feature_flags(&features);
                 }
             }
             Err(error) => warn!(
@@ -2317,8 +1684,8 @@ impl CodexClient {
                         features.supports_features_list = true;
                     }
                     let text = command_output_text(&output);
-                    let parsed = parse_features_from_text(&text);
-                    merge_feature_flags(&mut features, parsed);
+                    let parsed = version::parse_features_from_text(&text);
+                    version::merge_feature_flags(&mut features, parsed);
                 }
                 Err(error) => warn!(
                     ?error,
@@ -2328,7 +1695,7 @@ impl CodexClient {
             }
         }
 
-        if should_run_help_fallback(&features) {
+        if version::should_run_help_fallback(&features) {
             plan.steps.push(CapabilityProbeStep::HelpFallback);
             match self.run_basic_command(["--help"]).await {
                 Ok(output) => {
@@ -2340,8 +1707,8 @@ impl CodexClient {
                         );
                     }
                     let text = command_output_text(&output);
-                    let parsed = parse_help_output(&text);
-                    merge_feature_flags(&mut features, parsed);
+                    let parsed = version::parse_help_output(&text);
+                    version::merge_feature_flags(&mut features, parsed);
                 }
                 Err(error) => warn!(
                     ?error,
@@ -2378,166 +1745,6 @@ impl CodexClient {
         update_advisory_from_capabilities(&capabilities, latest_releases)
     }
 
-    async fn invoke_codex_exec(&self, request: ExecRequest) -> Result<String, CodexError> {
-        let ExecRequest { prompt, overrides } = request;
-        let dir_ctx = self.directory_context()?;
-        let needs_capabilities = self.output_schema || !self.add_dirs.is_empty();
-        let capabilities = if needs_capabilities {
-            Some(self.probe_capabilities().await)
-        } else {
-            None
-        };
-
-        let resolved_overrides =
-            resolve_cli_overrides(&self.cli_overrides, &overrides, self.model.as_deref());
-        let mut command = Command::new(self.command_env.binary_path());
-        command
-            .arg("exec")
-            .arg("--color")
-            .arg(self.color_mode.as_str())
-            .arg("--skip-git-repo-check")
-            .stdout(std::process::Stdio::piped())
-            .stderr(std::process::Stdio::piped())
-            .kill_on_drop(true)
-            .current_dir(dir_ctx.path());
-
-        apply_cli_overrides(&mut command, &resolved_overrides, true);
-
-        let send_prompt_via_stdin = self.json_output;
-        if !send_prompt_via_stdin {
-            command.arg(&prompt);
-        }
-        let stdin_mode = if send_prompt_via_stdin {
-            std::process::Stdio::piped()
-        } else {
-            std::process::Stdio::null()
-        };
-        command.stdin(stdin_mode);
-
-        if let Some(model) = &self.model {
-            command.arg("--model").arg(model);
-        }
-
-        if let Some(capabilities) = &capabilities {
-            if self.output_schema {
-                let guard = capabilities.guard_output_schema();
-                if guard_is_supported(&guard) {
-                    command.arg("--output-schema");
-                } else {
-                    log_guard_skip(&guard);
-                }
-            }
-
-            if !self.add_dirs.is_empty() {
-                let guard = capabilities.guard_add_dir();
-                if guard_is_supported(&guard) {
-                    for dir in &self.add_dirs {
-                        command.arg("--add-dir").arg(dir);
-                    }
-                } else {
-                    log_guard_skip(&guard);
-                }
-            }
-        }
-
-        for image in &self.images {
-            command.arg("--image").arg(image);
-        }
-
-        if self.json_output {
-            command.arg("--json");
-        }
-
-        self.command_env.apply(&mut command)?;
-
-        let mut child = spawn_with_retry(&mut command, self.command_env.binary_path())?;
-
-        if send_prompt_via_stdin {
-            let mut stdin = child.stdin.take().ok_or(CodexError::StdinUnavailable)?;
-            if let Err(source) = stdin.write_all(prompt.as_bytes()).await {
-                if source.kind() != std::io::ErrorKind::BrokenPipe {
-                    return Err(CodexError::StdinWrite(source));
-                }
-            }
-            if let Err(source) = stdin.write_all(b"\n").await {
-                if source.kind() != std::io::ErrorKind::BrokenPipe {
-                    return Err(CodexError::StdinWrite(source));
-                }
-            }
-            if let Err(source) = stdin.shutdown().await {
-                if source.kind() != std::io::ErrorKind::BrokenPipe {
-                    return Err(CodexError::StdinWrite(source));
-                }
-            }
-        } else {
-            let _ = child.stdin.take();
-        }
-
-        let stdout = child.stdout.take().ok_or(CodexError::StdoutUnavailable)?;
-        let stderr = child.stderr.take().ok_or(CodexError::StderrUnavailable)?;
-
-        let stdout_task = tokio::spawn(tee_stream(
-            stdout,
-            ConsoleTarget::Stdout,
-            self.mirror_stdout,
-        ));
-        let stderr_task = tokio::spawn(tee_stream(stderr, ConsoleTarget::Stderr, !self.quiet));
-
-        let wait_task = async move {
-            let status = child
-                .wait()
-                .await
-                .map_err(|source| CodexError::Wait { source })?;
-            let stdout_bytes = stdout_task
-                .await
-                .map_err(CodexError::Join)?
-                .map_err(CodexError::CaptureIo)?;
-            let stderr_bytes = stderr_task
-                .await
-                .map_err(CodexError::Join)?
-                .map_err(CodexError::CaptureIo)?;
-            Ok::<_, CodexError>((status, stdout_bytes, stderr_bytes))
-        };
-
-        let (status, stdout_bytes, stderr_bytes) = if self.timeout.is_zero() {
-            wait_task.await?
-        } else {
-            match time::timeout(self.timeout, wait_task).await {
-                Ok(result) => result?,
-                Err(_) => {
-                    return Err(CodexError::Timeout {
-                        timeout: self.timeout,
-                    });
-                }
-            }
-        };
-
-        let stderr_string = String::from_utf8(stderr_bytes).unwrap_or_default();
-        if !status.success() {
-            return Err(CodexError::NonZeroExit {
-                status,
-                stderr: stderr_string,
-            });
-        }
-
-        let primary_output = if self.json_output && stdout_bytes.is_empty() {
-            stderr_string
-        } else {
-            String::from_utf8(stdout_bytes)?
-        };
-        let trimmed = if self.json_output {
-            primary_output
-        } else {
-            primary_output.trim().to_string()
-        };
-        debug!(
-            binary = ?self.command_env.binary_path(),
-            bytes = trimmed.len(),
-            "received Codex output"
-        );
-        Ok(trimmed)
-    }
-
     fn directory_context(&self) -> Result<DirectoryContext, CodexError> {
         if let Some(dir) = &self.working_dir {
             return Ok(DirectoryContext::Fixed(dir.clone()));
@@ -2700,33 +1907,6 @@ impl Default for CodexClient {
     }
 }
 
-fn spawn_with_retry(
-    command: &mut Command,
-    binary: &Path,
-) -> Result<tokio::process::Child, CodexError> {
-    let mut backoff = Duration::from_millis(2);
-    for attempt in 0..5 {
-        match command.spawn() {
-            Ok(child) => return Ok(child),
-            Err(source) => {
-                let is_busy = matches!(source.kind(), std::io::ErrorKind::ExecutableFileBusy)
-                    || source.raw_os_error() == Some(26);
-                if is_busy && attempt < 4 {
-                    std::thread::sleep(backoff);
-                    backoff = std::cmp::min(backoff * 2, Duration::from_millis(50));
-                    continue;
-                }
-                return Err(CodexError::Spawn {
-                    binary: binary.to_path_buf(),
-                    source,
-                });
-            }
-        }
-    }
-
-    unreachable!("spawn_with_retry should return before exhausting retries")
-}
-
 /// Errors that may occur while invoking the Codex CLI.
 #[derive(Debug, Error)]
 pub enum CodexError {
@@ -2796,2018 +1976,35 @@ pub enum CodexError {
     EmptySocketPath,
     #[error("failed to create temporary working directory: {0}")]
     TempDir(#[source] std::io::Error),
-    #[error("failed to resolve working directory: {source}")]
-    WorkingDirectory {
-        #[source]
-        source: std::io::Error,
-    },
-    #[error("failed to prepare app-server output directory `{path}`: {source}")]
-    PrepareOutputDirectory {
-        path: PathBuf,
-        #[source]
-        source: std::io::Error,
-    },
-    #[error("failed to prepare CODEX_HOME at `{path}`: {source}")]
-    PrepareCodexHome {
-        path: PathBuf,
-        #[source]
-        source: std::io::Error,
-    },
-    #[error("codex stdout unavailable")]
-    StdoutUnavailable,
-    #[error("codex stderr unavailable")]
-    StderrUnavailable,
-    #[error("codex stdin unavailable")]
-    StdinUnavailable,
-    #[error("failed to capture codex output: {0}")]
-    CaptureIo(#[from] std::io::Error),
-    #[error("failed to write prompt to codex stdin: {0}")]
-    StdinWrite(#[source] std::io::Error),
-    #[error("failed to join codex output task: {0}")]
-    Join(#[from] tokio::task::JoinError),
-}
-
-/// Single JSONL event emitted by `codex exec --json`.
-///
-/// Each line on stdout maps to a [`ThreadEvent`] with lifecycle edges:
-/// - `thread.started` is emitted once per invocation.
-/// - `turn.started` begins the turn associated with the provided prompt.
-/// - one or more `item.*` events stream output and tool activity.
-/// - `turn.completed` or `turn.failed` closes the stream; `error` captures transport-level failures.
-///
-/// Item variants mirror the upstream `item_type` field: `agent_message`, `reasoning`,
-/// `command_execution`, `file_change`, `mcp_tool_call`, `web_search`, `todo_list`, and `error`.
-/// Unknown or future fields are preserved in `extra` maps to keep the parser forward-compatible.
-#[derive(Clone, Debug, Deserialize, Serialize)]
-#[serde(tag = "type")]
-pub enum ThreadEvent {
-    #[serde(rename = "thread.started", alias = "thread.resumed")]
-    ThreadStarted(ThreadStarted),
-    #[serde(rename = "turn.started")]
-    TurnStarted(TurnStarted),
-    #[serde(rename = "turn.completed")]
-    TurnCompleted(TurnCompleted),
-    #[serde(rename = "turn.failed")]
-    TurnFailed(TurnFailed),
-    #[serde(rename = "item.started", alias = "item.created")]
-    ItemStarted(ItemEnvelope<ItemSnapshot>),
-    #[serde(rename = "item.delta", alias = "item.updated")]
-    ItemDelta(ItemDelta),
-    #[serde(rename = "item.completed")]
-    ItemCompleted(ItemEnvelope<ItemSnapshot>),
-    #[serde(rename = "item.failed")]
-    ItemFailed(ItemEnvelope<ItemFailure>),
-    #[serde(rename = "error")]
-    Error(EventError),
-}
-
-/// Marks the start of a new thread.
-#[derive(Clone, Debug, Deserialize, Serialize)]
-pub struct ThreadStarted {
-    pub thread_id: String,
-    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
-    pub extra: BTreeMap<String, Value>,
-}
-
-/// Indicates the CLI accepted a new turn within a thread.
-#[derive(Clone, Debug, Deserialize, Serialize)]
-pub struct TurnStarted {
-    pub thread_id: String,
-    pub turn_id: String,
-    /// Original input text when upstream echoes it; may be omitted for security reasons.
-    #[serde(default, skip_serializing_if = "Option::is_none")]
-    pub input_text: Option<String>,
-    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
-    pub extra: BTreeMap<String, Value>,
-}
-
-/// Reports a completed turn.
-#[derive(Clone, Debug, Deserialize, Serialize)]
-pub struct TurnCompleted {
-    pub thread_id: String,
-    pub turn_id: String,
-    /// Identifier of the last output item when provided by the CLI.
-    #[serde(default, skip_serializing_if = "Option::is_none")]
-    pub last_item_id: Option<String>,
-    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
-    pub extra: BTreeMap<String, Value>,
-}
-
-/// Indicates a turn-level failure.
-#[derive(Clone, Debug, Deserialize, Serialize)]
-pub struct TurnFailed {
-    pub thread_id: String,
-    pub turn_id: String,
-    pub error: EventError,
-    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
-    pub extra: BTreeMap<String, Value>,
-}
-
-/// Shared wrapper for item events that always include thread/turn context.
-#[derive(Clone, Debug, Deserialize, Serialize)]
-pub struct ItemEnvelope<T> {
-    pub thread_id: String,
-    pub turn_id: String,
-    #[serde(flatten)]
-    pub item: T,
-}
-
-/// Snapshot of an item at start/completion time.
-#[derive(Clone, Debug, Deserialize, Serialize)]
-pub struct ItemSnapshot {
-    #[serde(rename = "item_id", alias = "id")]
-    pub item_id: String,
-    #[serde(default, skip_serializing_if = "Option::is_none")]
-    pub index: Option<u32>,
-    #[serde(default)]
-    pub status: ItemStatus,
-    #[serde(flatten)]
-    pub payload: ItemPayload,
-    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
-    pub extra: BTreeMap<String, Value>,
-}
-
-/// Streaming delta describing the next piece of an item.
-#[derive(Clone, Debug, Deserialize, Serialize)]
-pub struct ItemDelta {
-    pub thread_id: String,
-    pub turn_id: String,
-    #[serde(rename = "item_id", alias = "id")]
-    pub item_id: String,
-    #[serde(default, skip_serializing_if = "Option::is_none")]
-    pub index: Option<u32>,
-    #[serde(flatten)]
-    pub delta: ItemDeltaPayload,
-    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
-    pub extra: BTreeMap<String, Value>,
-}
-
-/// Terminal item failure event.
-#[derive(Clone, Debug, Deserialize, Serialize)]
-pub struct ItemFailure {
-    #[serde(rename = "item_id", alias = "id")]
-    pub item_id: String,
-    #[serde(default, skip_serializing_if = "Option::is_none")]
-    pub index: Option<u32>,
-    pub error: EventError,
-    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
-    pub extra: BTreeMap<String, Value>,
-}
-
-/// Fully-typed item payload for start/completed events.
-#[derive(Clone, Debug, Deserialize, Serialize)]
-#[serde(tag = "item_type", content = "content", rename_all = "snake_case")]
-pub enum ItemPayload {
-    AgentMessage(TextContent),
-    Reasoning(TextContent),
-    CommandExecution(CommandExecutionState),
-    FileChange(FileChangeState),
-    McpToolCall(McpToolCallState),
-    WebSearch(WebSearchState),
-    TodoList(TodoListState),
-    Error(EventError),
-}
-
-/// Delta form of an item payload. Each delta should be applied in order to reconstruct the item.
-#[derive(Clone, Debug, Deserialize, Serialize)]
-#[serde(tag = "item_type", content = "delta", rename_all = "snake_case")]
-pub enum ItemDeltaPayload {
-    AgentMessage(TextDelta),
-    Reasoning(TextDelta),
-    CommandExecution(CommandExecutionDelta),
-    FileChange(FileChangeDelta),
-    McpToolCall(McpToolCallDelta),
-    WebSearch(WebSearchDelta),
-    TodoList(TodoListDelta),
-    Error(EventError),
-}
-
-/// Item status supplied by the CLI for bookkeeping.
-#[derive(Clone, Debug, Default, Deserialize, Serialize, Eq, PartialEq)]
-#[serde(rename_all = "snake_case")]
-pub enum ItemStatus {
-    #[default]
-    InProgress,
-    Completed,
-    Failed,
-    #[serde(other)]
-    Unknown,
-}
-
-/// Human-readable content emitted by the agent.
-#[derive(Clone, Debug, Deserialize, Serialize)]
-pub struct TextContent {
-    pub text: String,
-    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
-    pub extra: BTreeMap<String, Value>,
-}
-
-/// Incremental content fragment for streaming items.
-#[derive(Clone, Debug, Deserialize, Serialize)]
-pub struct TextDelta {
-    #[serde(rename = "text_delta", alias = "text")]
-    pub text_delta: String,
-    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
-    pub extra: BTreeMap<String, Value>,
-}
-
-/// Snapshot of a command execution, including accumulated stdout/stderr.
-#[derive(Clone, Debug, Deserialize, Serialize)]
-pub struct CommandExecutionState {
-    pub command: String,
-    #[serde(default, skip_serializing_if = "Option::is_none")]
-    pub exit_code: Option<i32>,
-    #[serde(
-        default,
-        skip_serializing_if = "String::is_empty",
-        alias = "aggregated_output",
-        alias = "output"
-    )]
-    pub stdout: String,
-    #[serde(
-        default,
-        skip_serializing_if = "String::is_empty",
-        alias = "error_output",
-        alias = "err"
-    )]
-    pub stderr: String,
-    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
-    pub extra: BTreeMap<String, Value>,
-}
-
-/// Streaming delta for command execution.
-#[derive(Clone, Debug, Deserialize, Serialize)]
-pub struct CommandExecutionDelta {
-    #[serde(
-        default,
-        skip_serializing_if = "String::is_empty",
-        alias = "aggregated_output",
-        alias = "output"
-    )]
-    pub stdout: String,
-    #[serde(
-        default,
-        skip_serializing_if = "String::is_empty",
-        alias = "error_output",
-        alias = "err"
-    )]
-    pub stderr: String,
-    #[serde(default, skip_serializing_if = "Option::is_none")]
-    pub exit_code: Option<i32>,
-    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
-    pub extra: BTreeMap<String, Value>,
-}
-
-/// File change or diff applied by the agent.
-#[derive(Clone, Debug, Deserialize, Serialize)]
-pub struct FileChangeState {
-    #[serde(alias = "file_path")]
-    pub path: PathBuf,
-    #[serde(default, skip_serializing_if = "Option::is_none")]
-    pub change: Option<FileChangeKind>,
-    #[serde(default, skip_serializing_if = "Option::is_none", alias = "patch")]
-    pub diff: Option<String>,
-    #[serde(default, skip_serializing_if = "Option::is_none")]
-    pub exit_code: Option<i32>,
-    #[serde(
-        default,
-        skip_serializing_if = "String::is_empty",
-        alias = "aggregated_output",
-        alias = "output"
-    )]
-    pub stdout: String,
-    #[serde(
-        default,
-        skip_serializing_if = "String::is_empty",
-        alias = "error_output",
-        alias = "err"
-    )]
-    pub stderr: String,
-    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
-    pub extra: BTreeMap<String, Value>,
-}
-
-/// Streaming delta describing a file change.
-#[derive(Clone, Debug, Deserialize, Serialize)]
-pub struct FileChangeDelta {
-    #[serde(default, skip_serializing_if = "Option::is_none", alias = "patch")]
-    pub diff: Option<String>,
-    #[serde(
-        default,
-        skip_serializing_if = "String::is_empty",
-        alias = "aggregated_output",
-        alias = "output"
-    )]
-    pub stdout: String,
-    #[serde(
-        default,
-        skip_serializing_if = "String::is_empty",
-        alias = "error_output",
-        alias = "err"
-    )]
-    pub stderr: String,
-    #[serde(default, skip_serializing_if = "Option::is_none")]
-    pub exit_code: Option<i32>,
-    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
-    pub extra: BTreeMap<String, Value>,
-}
-
-/// Type of file operation being reported.
-#[derive(Clone, Copy, Debug, Deserialize, Serialize, Eq, PartialEq)]
-#[serde(rename_all = "snake_case")]
-pub enum FileChangeKind {
-    Apply,
-    Diff,
-    #[serde(other)]
-    Unknown,
-}
-
-/// State of an MCP tool call.
-#[derive(Clone, Debug, Deserialize, Serialize)]
-pub struct McpToolCallState {
-    #[serde(alias = "server")]
-    pub server_name: String,
-    #[serde(alias = "tool")]
-    pub tool_name: String,
-    #[serde(default, skip_serializing_if = "Option::is_none")]
-    pub arguments: Option<Value>,
-    #[serde(default, skip_serializing_if = "Option::is_none")]
-    pub result: Option<Value>,
-    #[serde(default)]
-    pub status: ToolCallStatus,
-    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
-    pub extra: BTreeMap<String, Value>,
-}
-
-/// Streaming delta for MCP tool call output.
-#[derive(Clone, Debug, Deserialize, Serialize)]
-pub struct McpToolCallDelta {
-    #[serde(default, skip_serializing_if = "Option::is_none")]
-    pub result: Option<Value>,
-    #[serde(default)]
-    pub status: ToolCallStatus,
-    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
-    pub extra: BTreeMap<String, Value>,
-}
-
-/// Lifecycle state for a tool call.
-#[derive(Clone, Debug, Default, Deserialize, Serialize, Eq, PartialEq)]
-#[serde(rename_all = "snake_case")]
-pub enum ToolCallStatus {
-    #[default]
-    Pending,
-    Running,
-    Completed,
-    Failed,
-    #[serde(other)]
-    Unknown,
-}
-
-/// Details of a web search step.
-#[derive(Clone, Debug, Deserialize, Serialize)]
-pub struct WebSearchState {
-    pub query: String,
-    #[serde(default, skip_serializing_if = "Option::is_none")]
-    pub results: Option<Value>,
-    #[serde(default)]
-    pub status: WebSearchStatus,
-    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
-    pub extra: BTreeMap<String, Value>,
-}
-
-/// Streaming delta for search results.
-#[derive(Clone, Debug, Deserialize, Serialize)]
-pub struct WebSearchDelta {
-    #[serde(default, skip_serializing_if = "Option::is_none")]
-    pub results: Option<Value>,
-    #[serde(default)]
-    pub status: WebSearchStatus,
-    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
-    pub extra: BTreeMap<String, Value>,
-}
-
-/// Search progress indicator.
-#[derive(Clone, Debug, Default, Deserialize, Serialize, Eq, PartialEq)]
-#[serde(rename_all = "snake_case")]
-pub enum WebSearchStatus {
-    #[default]
-    Pending,
-    Running,
-    Completed,
-    Failed,
-    #[serde(other)]
-    Unknown,
-}
-
-/// Checklist maintained by the agent.
-#[derive(Clone, Debug, Deserialize, Serialize)]
-pub struct TodoListState {
-    #[serde(default, skip_serializing_if = "Vec::is_empty")]
-    pub items: Vec<TodoItem>,
-    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
-    pub extra: BTreeMap<String, Value>,
-}
-
-/// Streaming delta for todo list mutations.
-#[derive(Clone, Debug, Deserialize, Serialize)]
-pub struct TodoListDelta {
-    #[serde(default, skip_serializing_if = "Vec::is_empty")]
-    pub items: Vec<TodoItem>,
-    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
-    pub extra: BTreeMap<String, Value>,
-}
-
-/// Single todo item.
-#[derive(Clone, Debug, Deserialize, Serialize)]
-pub struct TodoItem {
-    pub title: String,
-    #[serde(default)]
-    pub completed: bool,
-    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
-    pub extra: BTreeMap<String, Value>,
-}
-
-/// Error payload shared by turn/item failures.
-#[derive(Clone, Debug, Deserialize, Serialize)]
-pub struct EventError {
-    pub message: String,
-    #[serde(default, skip_serializing_if = "Option::is_none")]
-    pub code: Option<String>,
-    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
-    pub extra: BTreeMap<String, Value>,
-}
-
-/// Options configuring a single exec request.
-#[derive(Clone, Debug)]
-pub struct ExecRequest {
-    pub prompt: String,
-    pub overrides: CliOverridesPatch,
-}
-
-impl ExecRequest {
-    pub fn new(prompt: impl Into<String>) -> Self {
-        Self {
-            prompt: prompt.into(),
-            overrides: CliOverridesPatch::default(),
-        }
-    }
-
-    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
-        self.overrides = overrides;
-        self
-    }
-
-    pub fn config_override(mut self, key: impl Into<String>, value: impl Into<String>) -> Self {
-        self.overrides
-            .config_overrides
-            .push(ConfigOverride::new(key, value));
-        self
-    }
-
-    pub fn config_override_raw(mut self, raw: impl Into<String>) -> Self {
-        self.overrides
-            .config_overrides
-            .push(ConfigOverride::from_raw(raw));
-        self
-    }
-
-    pub fn profile(mut self, profile: impl Into<String>) -> Self {
-        let profile = profile.into();
-        self.overrides.profile = (!profile.trim().is_empty()).then_some(profile);
-        self
-    }
-
-    pub fn oss(mut self, enable: bool) -> Self {
-        self.overrides.oss = if enable {
-            FlagState::Enable
-        } else {
-            FlagState::Disable
-        };
-        self
-    }
-
-    pub fn enable_feature(mut self, name: impl Into<String>) -> Self {
-        self.overrides.feature_toggles.enable.push(name.into());
-        self
-    }
-
-    pub fn disable_feature(mut self, name: impl Into<String>) -> Self {
-        self.overrides.feature_toggles.disable.push(name.into());
-        self
-    }
-
-    pub fn search(mut self, enable: bool) -> Self {
-        self.overrides.search = if enable {
-            FlagState::Enable
-        } else {
-            FlagState::Disable
-        };
-        self
-    }
-}
-
-/// Options configuring a streaming exec invocation.
-#[derive(Clone, Debug)]
-pub struct ExecStreamRequest {
-    /// User prompt that will be forwarded to `codex exec`.
-    pub prompt: String,
-    /// Per-event idle timeout. If no JSON lines arrive before the duration elapses,
-    /// [`ExecStreamError::IdleTimeout`] is returned.
-    pub idle_timeout: Option<Duration>,
-    /// Optional file path passed through to `--output-last-message`. When unset, the wrapper
-    /// will request a temporary path and return it in [`ExecCompletion::last_message_path`].
-    pub output_last_message: Option<PathBuf>,
-    /// Optional file path passed through to `--output-schema` so clients can persist the schema
-    /// describing the item envelope structure seen during the run.
-    pub output_schema: Option<PathBuf>,
-    /// Optional file path that receives a tee of every raw JSONL event line as it streams in.
-    /// Appends to existing files, flushes each line, and creates parent directories. Overrides
-    /// [`CodexClientBuilder::json_event_log`] for this request when provided.
-    pub json_event_log: Option<PathBuf>,
-}
-
-/// Selector for `codex resume` targets.
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub enum ResumeSelector {
-    Id(String),
-    Last,
-    All,
-}
-
-/// Options configuring a streaming resume invocation.
-#[derive(Clone, Debug)]
-pub struct ResumeRequest {
-    pub selector: ResumeSelector,
-    pub prompt: Option<String>,
-    pub idle_timeout: Option<Duration>,
-    pub output_last_message: Option<PathBuf>,
-    pub output_schema: Option<PathBuf>,
-    pub json_event_log: Option<PathBuf>,
-    pub overrides: CliOverridesPatch,
-}
-
-impl ResumeRequest {
-    pub fn new(selector: ResumeSelector) -> Self {
-        Self {
-            selector,
-            prompt: None,
-            idle_timeout: None,
-            output_last_message: None,
-            output_schema: None,
-            json_event_log: None,
-            overrides: CliOverridesPatch::default(),
-        }
-    }
-
-    pub fn with_id(id: impl Into<String>) -> Self {
-        Self::new(ResumeSelector::Id(id.into()))
-    }
-
-    pub fn last() -> Self {
-        Self::new(ResumeSelector::Last)
-    }
-
-    pub fn all() -> Self {
-        Self::new(ResumeSelector::All)
-    }
-
-    pub fn prompt(mut self, prompt: impl Into<String>) -> Self {
-        self.prompt = Some(prompt.into());
-        self
-    }
-
-    pub fn idle_timeout(mut self, idle_timeout: Duration) -> Self {
-        self.idle_timeout = Some(idle_timeout);
-        self
-    }
-
-    pub fn config_override(mut self, key: impl Into<String>, value: impl Into<String>) -> Self {
-        self.overrides
-            .config_overrides
-            .push(ConfigOverride::new(key, value));
-        self
-    }
-
-    pub fn config_override_raw(mut self, raw: impl Into<String>) -> Self {
-        self.overrides
-            .config_overrides
-            .push(ConfigOverride::from_raw(raw));
-        self
-    }
-
-    pub fn profile(mut self, profile: impl Into<String>) -> Self {
-        let profile = profile.into();
-        self.overrides.profile = (!profile.trim().is_empty()).then_some(profile);
-        self
-    }
-
-    pub fn oss(mut self, enable: bool) -> Self {
-        self.overrides.oss = if enable {
-            FlagState::Enable
-        } else {
-            FlagState::Disable
-        };
-        self
-    }
-
-    pub fn enable_feature(mut self, name: impl Into<String>) -> Self {
-        self.overrides.feature_toggles.enable.push(name.into());
-        self
-    }
-
-    pub fn disable_feature(mut self, name: impl Into<String>) -> Self {
-        self.overrides.feature_toggles.disable.push(name.into());
-        self
-    }
-
-    pub fn search(mut self, enable: bool) -> Self {
-        self.overrides.search = if enable {
-            FlagState::Enable
-        } else {
-            FlagState::Disable
-        };
-        self
-    }
-}
-
-/// Sandbox platform variant; maps to platform subcommands of `codex sandbox`.
-#[derive(Clone, Copy, Debug, Eq, PartialEq)]
-pub enum SandboxPlatform {
-    Macos,
-    Linux,
-    Windows,
-}
-
-impl SandboxPlatform {
-    fn subcommand(self) -> &'static str {
-        match self {
-            SandboxPlatform::Macos => "macos",
-            SandboxPlatform::Linux => "linux",
-            SandboxPlatform::Windows => "windows",
-        }
-    }
-}
-
-/// Request to run an arbitrary command inside a Codex-provided sandbox.
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub struct SandboxCommandRequest {
-    /// Target platform subcommand; maps to `macos` (alias `seatbelt`), `linux` (alias `landlock`), or `windows`.
-    pub platform: SandboxPlatform,
-    /// Trailing command arguments to execute. Must be non-empty to avoid the upstream CLI panic.
-    pub command: Vec<OsString>,
-    /// Request the workspace-write sandbox preset (`--full-auto`).
-    pub full_auto: bool,
-    /// Stream macOS sandbox denials after the child process exits (no-op on other platforms).
-    pub log_denials: bool,
-    /// Additional `--config key=value` overrides to pass through.
-    pub config_overrides: Vec<ConfigOverride>,
-    /// Feature toggles forwarded to `--enable`/`--disable`.
-    pub feature_toggles: FeatureToggles,
-    /// Working directory for the spawned command; falls back to the builder value, then the current process directory.
-    pub working_dir: Option<PathBuf>,
-}
-
-impl SandboxCommandRequest {
-    pub fn new<I, S>(platform: SandboxPlatform, command: I) -> Self
-    where
-        I: IntoIterator<Item = S>,
-        S: Into<OsString>,
-    {
-        Self {
-            platform,
-            command: command.into_iter().map(Into::into).collect(),
-            full_auto: false,
-            log_denials: false,
-            config_overrides: Vec::new(),
-            feature_toggles: FeatureToggles::default(),
-            working_dir: None,
-        }
-    }
-
-    pub fn full_auto(mut self, enable: bool) -> Self {
-        self.full_auto = enable;
-        self
-    }
-
-    pub fn log_denials(mut self, enable: bool) -> Self {
-        self.log_denials = enable;
-        self
-    }
-
-    pub fn config_override(mut self, key: impl Into<String>, value: impl Into<String>) -> Self {
-        self.config_overrides.push(ConfigOverride::new(key, value));
-        self
-    }
-
-    pub fn config_override_raw(mut self, raw: impl Into<String>) -> Self {
-        self.config_overrides.push(ConfigOverride::from_raw(raw));
-        self
-    }
-
-    pub fn enable_feature(mut self, name: impl Into<String>) -> Self {
-        self.feature_toggles.enable.push(name.into());
-        self
-    }
-
-    pub fn disable_feature(mut self, name: impl Into<String>) -> Self {
-        self.feature_toggles.disable.push(name.into());
-        self
-    }
-
-    pub fn working_dir(mut self, dir: impl Into<PathBuf>) -> Self {
-        self.working_dir = Some(dir.into());
-        self
-    }
-}
-
-/// Captured output from `codex sandbox <platform>`.
-#[derive(Clone, Debug)]
-pub struct SandboxRun {
-    /// Exit status returned by the inner command (mirrors the sandbox helper).
-    pub status: ExitStatus,
-    /// Captured stdout (mirrored to the console when `mirror_stdout` is true).
-    pub stdout: String,
-    /// Captured stderr (mirrored unless `quiet` is set).
-    pub stderr: String,
-}
-
-/// Request for `codex responses-api-proxy`.
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub struct ResponsesApiProxyRequest {
-    /// API key to write to stdin on startup.
-    pub api_key: String,
-    /// Optional port to bind; falls back to an OS-assigned ephemeral port when omitted.
-    pub port: Option<u16>,
-    /// Optional path passed to `--server-info` for `{port,pid}` JSON output.
-    pub server_info_path: Option<PathBuf>,
-    /// Enables the HTTP shutdown endpoint (`GET /shutdown`).
-    pub http_shutdown: bool,
-    /// Optional upstream URL passed to `--upstream-url` (defaults to `https://api.openai.com/v1/responses`).
-    pub upstream_url: Option<String>,
-}
-
-impl ResponsesApiProxyRequest {
-    /// Creates a request with the API key provided via stdin.
-    pub fn new(api_key: impl Into<String>) -> Self {
-        Self {
-            api_key: api_key.into(),
-            port: None,
-            server_info_path: None,
-            http_shutdown: false,
-            upstream_url: None,
-        }
-    }
-
-    /// Sets the listening port (`--port`).
-    pub fn port(mut self, port: u16) -> Self {
-        self.port = Some(port);
-        self
-    }
-
-    /// Writes `{port,pid}` JSON to the provided path via `--server-info`.
-    pub fn server_info(mut self, path: impl Into<PathBuf>) -> Self {
-        self.server_info_path = Some(path.into());
-        self
-    }
-
-    /// Enables the `--http-shutdown` flag (GET /shutdown).
-    pub fn http_shutdown(mut self, enable: bool) -> Self {
-        self.http_shutdown = enable;
-        self
-    }
-
-    /// Overrides the upstream responses endpoint URL.
-    pub fn upstream_url(mut self, url: impl Into<String>) -> Self {
-        let url = url.into();
-        self.upstream_url = (!url.trim().is_empty()).then_some(url);
-        self
-    }
-}
-
-/// Running responses proxy process and metadata.
-#[derive(Debug)]
-pub struct ResponsesApiProxyHandle {
-    /// Spawned `codex responses-api-proxy` child (inherits kill-on-drop).
-    pub child: tokio::process::Child,
-    /// Optional `--server-info` path that may contain `{port,pid}` JSON.
-    pub server_info_path: Option<PathBuf>,
-}
-
-impl ResponsesApiProxyHandle {
-    /// Reads and parses the `{port,pid}` JSON written by `--server-info`.
-    ///
-    /// Returns `Ok(None)` when no server info path was configured.
-    pub async fn read_server_info(&self) -> Result<Option<ResponsesApiProxyInfo>, CodexError> {
-        let Some(path) = &self.server_info_path else {
-            return Ok(None);
-        };
-
-        const MAX_ATTEMPTS: usize = 10;
-        const BACKOFF_MS: u64 = 25;
-
-        for attempt in 0..MAX_ATTEMPTS {
-            match fs::read_to_string(path).await {
-                Ok(contents) => match serde_json::from_str::<ResponsesApiProxyInfo>(&contents) {
-                    Ok(info) => return Ok(Some(info)),
-                    Err(source) => {
-                        if attempt + 1 == MAX_ATTEMPTS {
-                            return Err(CodexError::ResponsesApiProxyInfoParse {
-                                path: path.clone(),
-                                source,
-                            });
-                        }
-                    }
-                },
-                Err(source) => {
-                    let is_missing = source.kind() == std::io::ErrorKind::NotFound;
-                    if !is_missing || attempt + 1 == MAX_ATTEMPTS {
-                        return Err(CodexError::ResponsesApiProxyInfoRead {
-                            path: path.clone(),
-                            source,
-                        });
-                    }
-                }
-            }
-
-            tokio::time::sleep(std::time::Duration::from_millis(BACKOFF_MS)).await;
-        }
-
-        unreachable!("read_server_info loop must return by MAX_ATTEMPTS")
-    }
-}
-
-/// Parsed `{port,pid}` emitted by `codex responses-api-proxy --server-info`.
-#[derive(Clone, Debug, Eq, PartialEq, Serialize, Deserialize)]
-pub struct ResponsesApiProxyInfo {
-    pub port: u16,
-    pub pid: u32,
-    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
-    pub extra: BTreeMap<String, Value>,
-}
-
-/// Request for `codex stdio-to-uds <SOCKET_PATH>`.
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub struct StdioToUdsRequest {
-    /// Path to the Unix domain socket to connect to.
-    pub socket_path: PathBuf,
-    /// Optional working directory override for the spawned process.
-    pub working_dir: Option<PathBuf>,
-}
-
-impl StdioToUdsRequest {
-    pub fn new(socket_path: impl Into<PathBuf>) -> Self {
-        Self {
-            socket_path: socket_path.into(),
-            working_dir: None,
-        }
-    }
-
-    /// Sets the working directory used to resolve the socket path.
-    pub fn working_dir(mut self, dir: impl Into<PathBuf>) -> Self {
-        self.working_dir = Some(dir.into());
-        self
-    }
-}
-
-/// Stage labels reported by `codex features list`.
-#[derive(Clone, Debug, Eq, PartialEq, Serialize, Deserialize)]
-#[serde(from = "String", into = "String")]
-pub enum CodexFeatureStage {
-    Experimental,
-    Beta,
-    Stable,
-    Deprecated,
-    Removed,
-    Unknown(String),
-}
-
-impl CodexFeatureStage {
-    fn parse(raw: &str) -> Self {
-        let normalized = raw.trim();
-        match normalized.to_ascii_lowercase().as_str() {
-            "experimental" => CodexFeatureStage::Experimental,
-            "beta" => CodexFeatureStage::Beta,
-            "stable" => CodexFeatureStage::Stable,
-            "deprecated" => CodexFeatureStage::Deprecated,
-            "removed" => CodexFeatureStage::Removed,
-            _ => CodexFeatureStage::Unknown(normalized.to_string()),
-        }
-    }
-
-    /// Returns the normalized label for this stage.
-    pub fn as_str(&self) -> &str {
-        match self {
-            CodexFeatureStage::Experimental => "experimental",
-            CodexFeatureStage::Beta => "beta",
-            CodexFeatureStage::Stable => "stable",
-            CodexFeatureStage::Deprecated => "deprecated",
-            CodexFeatureStage::Removed => "removed",
-            CodexFeatureStage::Unknown(label) => label.as_str(),
-        }
-    }
-}
-
-impl From<String> for CodexFeatureStage {
-    fn from(value: String) -> Self {
-        CodexFeatureStage::parse(&value)
-    }
-}
-
-impl From<CodexFeatureStage> for String {
-    fn from(stage: CodexFeatureStage) -> Self {
-        String::from(&stage)
-    }
-}
-
-impl From<&CodexFeatureStage> for String {
-    fn from(stage: &CodexFeatureStage) -> Self {
-        stage.as_str().to_string()
-    }
-}
-
-/// Single feature entry reported by `codex features list`.
-#[derive(Clone, Debug, Eq, PartialEq, Serialize, Deserialize)]
-pub struct CodexFeature {
-    /// Feature name as reported by the CLI.
-    pub name: String,
-    /// Feature stage (experimental/beta/stable/deprecated/removed) when provided.
-    #[serde(default, skip_serializing_if = "Option::is_none")]
-    pub stage: Option<CodexFeatureStage>,
-    /// Whether the feature is enabled for the current config/profile.
-    pub enabled: bool,
-    /// Unrecognized fields from JSON output are preserved here.
-    #[serde(flatten, default, skip_serializing_if = "BTreeMap::is_empty")]
-    pub extra: BTreeMap<String, Value>,
-}
-
-impl CodexFeature {
-    /// Convenience helper mirroring the `enabled` flag.
-    pub const fn is_enabled(&self) -> bool {
-        self.enabled
-    }
-}
-
-/// Format used to parse `codex features list` output.
-#[derive(Clone, Copy, Debug, Eq, PartialEq)]
-pub enum FeaturesListFormat {
-    Json,
-    Text,
-}
-
-/// Parsed output from `codex features list`.
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub struct FeaturesListOutput {
-    /// Exit status returned by the subcommand.
-    pub status: ExitStatus,
-    /// Captured stdout (mirrored to the console when `mirror_stdout` is true).
-    pub stdout: String,
-    /// Captured stderr (mirrored unless `quiet` is set).
-    pub stderr: String,
-    /// Parsed feature entries.
-    pub features: Vec<CodexFeature>,
-    /// Indicates whether JSON or text parsing was used.
-    pub format: FeaturesListFormat,
-}
-
-/// Request for `codex features list`.
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub struct FeaturesListRequest {
-    /// Request JSON output via `--json` (falls back to text parsing when JSON is absent).
-    pub json: bool,
-    /// Per-call CLI overrides layered on top of the builder.
-    pub overrides: CliOverridesPatch,
-}
-
-impl FeaturesListRequest {
-    /// Creates a request with JSON disabled by default for compatibility with older binaries.
-    pub fn new() -> Self {
-        Self {
-            json: false,
-            overrides: CliOverridesPatch::default(),
-        }
-    }
-
-    /// Controls whether `--json` is passed to `codex features list`.
-    pub fn json(mut self, enable: bool) -> Self {
-        self.json = enable;
-        self
-    }
-
-    /// Replaces the default CLI overrides for this request.
-    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
-        self.overrides = overrides;
-        self
-    }
-
-    /// Adds a `--config key=value` override for this request.
-    pub fn config_override(mut self, key: impl Into<String>, value: impl Into<String>) -> Self {
-        self.overrides
-            .config_overrides
-            .push(ConfigOverride::new(key, value));
-        self
-    }
-
-    /// Adds a raw `--config key=value` override without validation.
-    pub fn config_override_raw(mut self, raw: impl Into<String>) -> Self {
-        self.overrides
-            .config_overrides
-            .push(ConfigOverride::from_raw(raw));
-        self
-    }
-
-    /// Sets the config profile (`--profile`) for this request.
-    pub fn profile(mut self, profile: impl Into<String>) -> Self {
-        let profile = profile.into();
-        self.overrides.profile = (!profile.trim().is_empty()).then_some(profile);
-        self
-    }
-
-    /// Requests the CLI `--oss` flag for this call.
-    pub fn oss(mut self, enable: bool) -> Self {
-        self.overrides.oss = if enable {
-            FlagState::Enable
-        } else {
-            FlagState::Disable
-        };
-        self
-    }
-
-    /// Adds a `--enable <feature>` toggle for this call.
-    pub fn enable_feature(mut self, name: impl Into<String>) -> Self {
-        self.overrides.feature_toggles.enable.push(name.into());
-        self
-    }
-
-    /// Adds a `--disable <feature>` toggle for this call.
-    pub fn disable_feature(mut self, name: impl Into<String>) -> Self {
-        self.overrides.feature_toggles.disable.push(name.into());
-        self
-    }
-
-    /// Controls whether `--search` is passed through to Codex.
-    pub fn search(mut self, enable: bool) -> Self {
-        self.overrides.search = if enable {
-            FlagState::Enable
-        } else {
-            FlagState::Disable
-        };
-        self
-    }
-}
-
-impl Default for FeaturesListRequest {
-    fn default() -> Self {
-        Self::new()
-    }
-}
-
-/// Request for `codex features`.
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub struct FeaturesCommandRequest {
-    /// Per-call CLI overrides layered on top of the builder.
-    pub overrides: CliOverridesPatch,
-}
-
-impl FeaturesCommandRequest {
-    pub fn new() -> Self {
-        Self {
-            overrides: CliOverridesPatch::default(),
-        }
-    }
-
-    /// Replaces the default CLI overrides for this request.
-    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
-        self.overrides = overrides;
-        self
-    }
-}
-
-impl Default for FeaturesCommandRequest {
-    fn default() -> Self {
-        Self::new()
-    }
-}
-
-/// Selector for `codex help`-style command families.
-#[derive(Clone, Copy, Debug, Eq, PartialEq)]
-pub enum HelpScope {
-    Root,
-    Exec,
-    Features,
-    Login,
-    AppServer,
-    Sandbox,
-    Cloud,
-    Mcp,
-}
-
-impl HelpScope {
-    fn argv_prefix(&self) -> &'static [&'static str] {
-        match self {
-            HelpScope::Root => &["help"],
-            HelpScope::Exec => &["exec", "help"],
-            HelpScope::Features => &["features", "help"],
-            HelpScope::Login => &["login", "help"],
-            HelpScope::AppServer => &["app-server", "help"],
-            HelpScope::Sandbox => &["sandbox", "help"],
-            HelpScope::Cloud => &["cloud", "help"],
-            HelpScope::Mcp => &["mcp", "help"],
-        }
-    }
-}
-
-/// Request for `codex <scope> help [COMMAND]...`.
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub struct HelpCommandRequest {
-    pub scope: HelpScope,
-    /// Optional command path components appended after `help` (variadic upstream).
-    pub command: Vec<String>,
-    /// Per-call CLI overrides layered on top of the builder.
-    pub overrides: CliOverridesPatch,
-}
-
-impl HelpCommandRequest {
-    pub fn new(scope: HelpScope) -> Self {
-        Self {
-            scope,
-            command: Vec::new(),
-            overrides: CliOverridesPatch::default(),
-        }
-    }
-
-    /// Appends one or more command tokens to the help invocation.
-    pub fn command<I, S>(mut self, tokens: I) -> Self
-    where
-        I: IntoIterator<Item = S>,
-        S: Into<String>,
-    {
-        self.command.extend(tokens.into_iter().map(Into::into));
-        self
-    }
-
-    /// Replaces the default CLI overrides for this request.
-    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
-        self.overrides = overrides;
-        self
-    }
-}
-
-/// Request for `codex review [OPTIONS] [PROMPT]`.
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub struct ReviewCommandRequest {
-    pub prompt: Option<String>,
-    pub base: Option<String>,
-    pub commit: Option<String>,
-    pub title: Option<String>,
-    pub uncommitted: bool,
-    /// Per-call CLI overrides layered on top of the builder.
-    pub overrides: CliOverridesPatch,
-}
-
-impl ReviewCommandRequest {
-    pub fn new() -> Self {
-        Self {
-            prompt: None,
-            base: None,
-            commit: None,
-            title: None,
-            uncommitted: false,
-            overrides: CliOverridesPatch::default(),
-        }
-    }
-
-    pub fn prompt(mut self, prompt: impl Into<String>) -> Self {
-        let prompt = prompt.into();
-        self.prompt = (!prompt.trim().is_empty()).then_some(prompt);
-        self
-    }
-
-    pub fn base(mut self, branch: impl Into<String>) -> Self {
-        let branch = branch.into();
-        self.base = (!branch.trim().is_empty()).then_some(branch);
-        self
-    }
-
-    pub fn commit(mut self, sha: impl Into<String>) -> Self {
-        let sha = sha.into();
-        self.commit = (!sha.trim().is_empty()).then_some(sha);
-        self
-    }
-
-    pub fn title(mut self, title: impl Into<String>) -> Self {
-        let title = title.into();
-        self.title = (!title.trim().is_empty()).then_some(title);
-        self
-    }
-
-    pub fn uncommitted(mut self, enable: bool) -> Self {
-        self.uncommitted = enable;
-        self
-    }
-
-    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
-        self.overrides = overrides;
-        self
-    }
-}
-
-impl Default for ReviewCommandRequest {
-    fn default() -> Self {
-        Self::new()
-    }
-}
-
-/// Request for `codex exec review [OPTIONS] [PROMPT]`.
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub struct ExecReviewCommandRequest {
-    pub prompt: Option<String>,
-    pub base: Option<String>,
-    pub commit: Option<String>,
-    pub title: Option<String>,
-    pub uncommitted: bool,
-    pub json: bool,
-    pub skip_git_repo_check: bool,
-    /// Per-call CLI overrides layered on top of the builder.
-    pub overrides: CliOverridesPatch,
-}
-
-impl ExecReviewCommandRequest {
-    pub fn new() -> Self {
-        Self {
-            prompt: None,
-            base: None,
-            commit: None,
-            title: None,
-            uncommitted: false,
-            json: false,
-            skip_git_repo_check: true,
-            overrides: CliOverridesPatch::default(),
-        }
-    }
-
-    pub fn prompt(mut self, prompt: impl Into<String>) -> Self {
-        let prompt = prompt.into();
-        self.prompt = (!prompt.trim().is_empty()).then_some(prompt);
-        self
-    }
-
-    pub fn base(mut self, branch: impl Into<String>) -> Self {
-        let branch = branch.into();
-        self.base = (!branch.trim().is_empty()).then_some(branch);
-        self
-    }
-
-    pub fn commit(mut self, sha: impl Into<String>) -> Self {
-        let sha = sha.into();
-        self.commit = (!sha.trim().is_empty()).then_some(sha);
-        self
-    }
-
-    pub fn title(mut self, title: impl Into<String>) -> Self {
-        let title = title.into();
-        self.title = (!title.trim().is_empty()).then_some(title);
-        self
-    }
-
-    pub fn uncommitted(mut self, enable: bool) -> Self {
-        self.uncommitted = enable;
-        self
-    }
-
-    pub fn json(mut self, enable: bool) -> Self {
-        self.json = enable;
-        self
-    }
-
-    pub fn skip_git_repo_check(mut self, enable: bool) -> Self {
-        self.skip_git_repo_check = enable;
-        self
-    }
-
-    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
-        self.overrides = overrides;
-        self
-    }
-}
-
-impl Default for ExecReviewCommandRequest {
-    fn default() -> Self {
-        Self::new()
-    }
-}
-
-/// Request for `codex resume [OPTIONS] [SESSION_ID] [PROMPT]`.
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub struct ResumeSessionRequest {
-    pub session_id: Option<String>,
-    pub prompt: Option<String>,
-    pub all: bool,
-    pub last: bool,
-    /// Per-call CLI overrides layered on top of the builder.
-    pub overrides: CliOverridesPatch,
-}
-
-impl ResumeSessionRequest {
-    pub fn new() -> Self {
-        Self {
-            session_id: None,
-            prompt: None,
-            all: false,
-            last: false,
-            overrides: CliOverridesPatch::default(),
-        }
-    }
-
-    pub fn session_id(mut self, session_id: impl Into<String>) -> Self {
-        let session_id = session_id.into();
-        self.session_id = (!session_id.trim().is_empty()).then_some(session_id);
-        self
-    }
-
-    pub fn prompt(mut self, prompt: impl Into<String>) -> Self {
-        let prompt = prompt.into();
-        self.prompt = (!prompt.trim().is_empty()).then_some(prompt);
-        self
-    }
-
-    pub fn all(mut self, enable: bool) -> Self {
-        self.all = enable;
-        self
-    }
-
-    pub fn last(mut self, enable: bool) -> Self {
-        self.last = enable;
-        self
-    }
-
-    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
-        self.overrides = overrides;
-        self
-    }
-}
-
-impl Default for ResumeSessionRequest {
-    fn default() -> Self {
-        Self::new()
-    }
-}
-
-/// Request for `codex fork [OPTIONS] [SESSION_ID] [PROMPT]`.
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub struct ForkSessionRequest {
-    pub session_id: Option<String>,
-    pub prompt: Option<String>,
-    pub all: bool,
-    pub last: bool,
-    /// Per-call CLI overrides layered on top of the builder.
-    pub overrides: CliOverridesPatch,
-}
-
-impl ForkSessionRequest {
-    pub fn new() -> Self {
-        Self {
-            session_id: None,
-            prompt: None,
-            all: false,
-            last: false,
-            overrides: CliOverridesPatch::default(),
-        }
-    }
-
-    pub fn session_id(mut self, session_id: impl Into<String>) -> Self {
-        let session_id = session_id.into();
-        self.session_id = (!session_id.trim().is_empty()).then_some(session_id);
-        self
-    }
-
-    pub fn prompt(mut self, prompt: impl Into<String>) -> Self {
-        let prompt = prompt.into();
-        self.prompt = (!prompt.trim().is_empty()).then_some(prompt);
-        self
-    }
-
-    pub fn all(mut self, enable: bool) -> Self {
-        self.all = enable;
-        self
-    }
-
-    pub fn last(mut self, enable: bool) -> Self {
-        self.last = enable;
-        self
-    }
-
-    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
-        self.overrides = overrides;
-        self
-    }
-}
-
-impl Default for ForkSessionRequest {
-    fn default() -> Self {
-        Self::new()
-    }
-}
-
-/// Request for `codex cloud` (overview/help).
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub struct CloudOverviewRequest {
-    pub overrides: CliOverridesPatch,
-}
-
-impl CloudOverviewRequest {
-    pub fn new() -> Self {
-        Self {
-            overrides: CliOverridesPatch::default(),
-        }
-    }
-
-    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
-        self.overrides = overrides;
-        self
-    }
-}
-
-impl Default for CloudOverviewRequest {
-    fn default() -> Self {
-        Self::new()
-    }
-}
-
-/// Request for `codex cloud list`.
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub struct CloudListRequest {
-    pub json: bool,
-    pub env_id: Option<String>,
-    pub limit: Option<u32>,
-    pub cursor: Option<String>,
-    pub overrides: CliOverridesPatch,
-}
-
-impl CloudListRequest {
-    pub fn new() -> Self {
-        Self {
-            json: false,
-            env_id: None,
-            limit: None,
-            cursor: None,
-            overrides: CliOverridesPatch::default(),
-        }
-    }
-
-    pub fn json(mut self, enable: bool) -> Self {
-        self.json = enable;
-        self
-    }
-
-    pub fn env_id(mut self, env_id: impl Into<String>) -> Self {
-        let env_id = env_id.into();
-        self.env_id = (!env_id.trim().is_empty()).then_some(env_id);
-        self
-    }
-
-    pub fn limit(mut self, limit: u32) -> Self {
-        self.limit = Some(limit);
-        self
-    }
-
-    pub fn cursor(mut self, cursor: impl Into<String>) -> Self {
-        let cursor = cursor.into();
-        self.cursor = (!cursor.trim().is_empty()).then_some(cursor);
-        self
-    }
-
-    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
-        self.overrides = overrides;
-        self
-    }
-}
-
-impl Default for CloudListRequest {
-    fn default() -> Self {
-        Self::new()
-    }
-}
-
-/// Output from `codex cloud list`.
-#[derive(Clone, Debug, PartialEq)]
-pub struct CloudListOutput {
-    pub status: ExitStatus,
-    pub stdout: String,
-    pub stderr: String,
-    /// Parsed JSON output when `--json` was requested.
-    pub json: Option<Value>,
-}
-
-/// Request for `codex cloud status <TASK_ID>`.
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub struct CloudStatusRequest {
-    pub task_id: String,
-    pub overrides: CliOverridesPatch,
-}
-
-impl CloudStatusRequest {
-    pub fn new(task_id: impl Into<String>) -> Self {
-        Self {
-            task_id: task_id.into(),
-            overrides: CliOverridesPatch::default(),
-        }
-    }
-
-    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
-        self.overrides = overrides;
-        self
-    }
-}
-
-/// Request for `codex cloud exec`.
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub struct CloudExecRequest {
-    pub env_id: String,
-    pub query: Option<String>,
-    pub attempts: Option<u32>,
-    pub branch: Option<String>,
-    pub overrides: CliOverridesPatch,
-}
-
-impl CloudExecRequest {
-    pub fn new(env_id: impl Into<String>) -> Self {
-        Self {
-            env_id: env_id.into(),
-            query: None,
-            attempts: None,
-            branch: None,
-            overrides: CliOverridesPatch::default(),
-        }
-    }
-
-    pub fn query(mut self, query: impl Into<String>) -> Self {
-        let query = query.into();
-        self.query = (!query.trim().is_empty()).then_some(query);
-        self
-    }
-
-    pub fn attempts(mut self, attempts: u32) -> Self {
-        self.attempts = Some(attempts);
-        self
-    }
-
-    pub fn branch(mut self, branch: impl Into<String>) -> Self {
-        let branch = branch.into();
-        self.branch = (!branch.trim().is_empty()).then_some(branch);
-        self
-    }
-
-    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
-        self.overrides = overrides;
-        self
-    }
-}
-
-/// Request for `codex mcp` (overview/help).
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub struct McpOverviewRequest {
-    pub overrides: CliOverridesPatch,
-}
-
-impl McpOverviewRequest {
-    pub fn new() -> Self {
-        Self {
-            overrides: CliOverridesPatch::default(),
-        }
-    }
-
-    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
-        self.overrides = overrides;
-        self
-    }
-}
-
-impl Default for McpOverviewRequest {
-    fn default() -> Self {
-        Self::new()
-    }
-}
-
-/// Request for `codex mcp list`.
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub struct McpListRequest {
-    pub json: bool,
-    pub overrides: CliOverridesPatch,
-}
-
-impl McpListRequest {
-    pub fn new() -> Self {
-        Self {
-            json: false,
-            overrides: CliOverridesPatch::default(),
-        }
-    }
-
-    pub fn json(mut self, enable: bool) -> Self {
-        self.json = enable;
-        self
-    }
-
-    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
-        self.overrides = overrides;
-        self
-    }
-}
-
-impl Default for McpListRequest {
-    fn default() -> Self {
-        Self::new()
-    }
-}
-
-/// Output from `codex mcp list`.
-#[derive(Clone, Debug, PartialEq)]
-pub struct McpListOutput {
-    pub status: ExitStatus,
-    pub stdout: String,
-    pub stderr: String,
-    pub json: Option<Value>,
-}
-
-/// Request for `codex mcp get <NAME>`.
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub struct McpGetRequest {
-    pub name: String,
-    pub json: bool,
-    pub overrides: CliOverridesPatch,
-}
-
-impl McpGetRequest {
-    pub fn new(name: impl Into<String>) -> Self {
-        Self {
-            name: name.into(),
-            json: false,
-            overrides: CliOverridesPatch::default(),
-        }
-    }
-
-    pub fn json(mut self, enable: bool) -> Self {
-        self.json = enable;
-        self
-    }
-
-    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
-        self.overrides = overrides;
-        self
-    }
-}
-
-/// Transport for `codex mcp add`.
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub enum McpAddTransport {
-    Stdio {
-        env: Vec<(String, String)>,
-        command: Vec<OsString>,
-    },
-    StreamableHttp {
-        url: String,
-        bearer_token_env_var: Option<String>,
-    },
-}
-
-/// Request for `codex mcp add`.
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub struct McpAddRequest {
-    pub name: String,
-    pub transport: McpAddTransport,
-    pub overrides: CliOverridesPatch,
-}
-
-impl McpAddRequest {
-    pub fn stdio(name: impl Into<String>, command: Vec<OsString>) -> Self {
-        Self {
-            name: name.into(),
-            transport: McpAddTransport::Stdio {
-                env: Vec::new(),
-                command,
-            },
-            overrides: CliOverridesPatch::default(),
-        }
-    }
-
-    pub fn streamable_http(name: impl Into<String>, url: impl Into<String>) -> Self {
-        Self {
-            name: name.into(),
-            transport: McpAddTransport::StreamableHttp {
-                url: url.into(),
-                bearer_token_env_var: None,
-            },
-            overrides: CliOverridesPatch::default(),
-        }
-    }
-
-    pub fn env(mut self, key: impl Into<String>, value: impl Into<String>) -> Self {
-        if let McpAddTransport::Stdio { env, .. } = &mut self.transport {
-            env.push((key.into(), value.into()));
-        }
-        self
-    }
-
-    pub fn bearer_token_env_var(mut self, env_var: impl Into<String>) -> Self {
-        if let McpAddTransport::StreamableHttp {
-            bearer_token_env_var,
-            ..
-        } = &mut self.transport
-        {
-            let env_var = env_var.into();
-            *bearer_token_env_var = (!env_var.trim().is_empty()).then_some(env_var);
-        }
-        self
-    }
-
-    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
-        self.overrides = overrides;
-        self
-    }
-}
-
-/// Request for `codex mcp remove <NAME>`.
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub struct McpRemoveRequest {
-    pub name: String,
-    pub overrides: CliOverridesPatch,
-}
-
-impl McpRemoveRequest {
-    pub fn new(name: impl Into<String>) -> Self {
-        Self {
-            name: name.into(),
-            overrides: CliOverridesPatch::default(),
-        }
-    }
-
-    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
-        self.overrides = overrides;
-        self
-    }
-}
-
-/// Request for `codex mcp logout <NAME>`.
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub struct McpLogoutRequest {
-    pub name: String,
-    pub overrides: CliOverridesPatch,
-}
-
-impl McpLogoutRequest {
-    pub fn new(name: impl Into<String>) -> Self {
-        Self {
-            name: name.into(),
-            overrides: CliOverridesPatch::default(),
-        }
-    }
-
-    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
-        self.overrides = overrides;
-        self
-    }
-}
-
-/// Request for `codex mcp login <NAME>` (OAuth).
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub struct McpOauthLoginRequest {
-    pub name: String,
-    pub scopes: Vec<String>,
-    pub overrides: CliOverridesPatch,
-}
-
-impl McpOauthLoginRequest {
-    pub fn new(name: impl Into<String>) -> Self {
-        Self {
-            name: name.into(),
-            scopes: Vec::new(),
-            overrides: CliOverridesPatch::default(),
-        }
-    }
-
-    pub fn scopes<I, S>(mut self, scopes: I) -> Self
-    where
-        I: IntoIterator<Item = S>,
-        S: Into<String>,
-    {
-        self.scopes.extend(
-            scopes
-                .into_iter()
-                .map(|s| s.into())
-                .filter(|s| !s.trim().is_empty()),
-        );
-        self
-    }
-
-    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
-        self.overrides = overrides;
-        self
-    }
-}
-
-/// Target for app-server code generation.
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub enum AppServerCodegenTarget {
-    /// Emits TypeScript bindings for the app-server protocol. Optionally formats the output with Prettier.
-    TypeScript { prettier: Option<PathBuf> },
-    /// Emits a JSON schema bundle for the app-server protocol.
-    JsonSchema,
-}
-
-impl AppServerCodegenTarget {
-    fn subcommand(&self) -> &'static str {
-        match self {
-            AppServerCodegenTarget::TypeScript { .. } => "generate-ts",
-            AppServerCodegenTarget::JsonSchema => "generate-json-schema",
-        }
-    }
-
-    fn prettier(&self) -> Option<&PathBuf> {
-        match self {
-            AppServerCodegenTarget::TypeScript { prettier } => prettier.as_ref(),
-            AppServerCodegenTarget::JsonSchema => None,
-        }
-    }
-}
-
-/// Request for `codex app-server generate-ts` or `generate-json-schema`.
-#[derive(Clone, Debug, Eq, PartialEq)]
-pub struct AppServerCodegenRequest {
-    /// Codegen target and optional Prettier path (TypeScript only).
-    pub target: AppServerCodegenTarget,
-    /// Output directory passed to `--out`; created if missing.
-    pub out_dir: PathBuf,
-    /// Per-call CLI overrides layered on top of the builder.
-    pub overrides: CliOverridesPatch,
-}
-
-impl AppServerCodegenRequest {
-    /// Generates TypeScript bindings into `out_dir`.
-    pub fn typescript(out_dir: impl Into<PathBuf>) -> Self {
-        Self {
-            target: AppServerCodegenTarget::TypeScript { prettier: None },
-            out_dir: out_dir.into(),
-            overrides: CliOverridesPatch::default(),
-        }
-    }
-
-    /// Generates a JSON schema bundle into `out_dir`.
-    pub fn json_schema(out_dir: impl Into<PathBuf>) -> Self {
-        Self {
-            target: AppServerCodegenTarget::JsonSchema,
-            out_dir: out_dir.into(),
-            overrides: CliOverridesPatch::default(),
-        }
-    }
-
-    /// Formats TypeScript output with the provided Prettier executable (no-op for JSON schema).
-    pub fn prettier(mut self, prettier: impl Into<PathBuf>) -> Self {
-        if let AppServerCodegenTarget::TypeScript { prettier: slot } = &mut self.target {
-            *slot = Some(prettier.into());
-        }
-        self
-    }
-
-    /// Replaces the default CLI overrides for this request.
-    pub fn with_overrides(mut self, overrides: CliOverridesPatch) -> Self {
-        self.overrides = overrides;
-        self
-    }
-
-    /// Adds a `--config key=value` override for this request.
-    pub fn config_override(mut self, key: impl Into<String>, value: impl Into<String>) -> Self {
-        self.overrides
-            .config_overrides
-            .push(ConfigOverride::new(key, value));
-        self
-    }
-
-    /// Adds a raw `--config key=value` override without validation.
-    pub fn config_override_raw(mut self, raw: impl Into<String>) -> Self {
-        self.overrides
-            .config_overrides
-            .push(ConfigOverride::from_raw(raw));
-        self
-    }
-
-    /// Sets the config profile (`--profile`) for this request.
-    pub fn profile(mut self, profile: impl Into<String>) -> Self {
-        let profile = profile.into();
-        self.overrides.profile = (!profile.trim().is_empty()).then_some(profile);
-        self
-    }
-
-    /// Requests the CLI `--oss` flag for this codegen call.
-    pub fn oss(mut self, enable: bool) -> Self {
-        self.overrides.oss = if enable {
-            FlagState::Enable
-        } else {
-            FlagState::Disable
-        };
-        self
-    }
-
-    /// Adds a `--enable <feature>` toggle for this codegen call.
-    pub fn enable_feature(mut self, name: impl Into<String>) -> Self {
-        self.overrides.feature_toggles.enable.push(name.into());
-        self
-    }
-
-    /// Adds a `--disable <feature>` toggle for this codegen call.
-    pub fn disable_feature(mut self, name: impl Into<String>) -> Self {
-        self.overrides.feature_toggles.disable.push(name.into());
-        self
-    }
-
-    /// Controls whether `--search` is passed through to Codex.
-    pub fn search(mut self, enable: bool) -> Self {
-        self.overrides.search = if enable {
-            FlagState::Enable
-        } else {
-            FlagState::Disable
-        };
-        self
-    }
-}
-
-/// Captured output from app-server codegen commands.
-#[derive(Clone, Debug)]
-pub struct AppServerCodegenOutput {
-    /// Exit status returned by the subcommand.
-    pub status: ExitStatus,
-    /// Captured stdout (mirrored to the console when `mirror_stdout` is true).
-    pub stdout: String,
-    /// Captured stderr (mirrored unless `quiet` is set).
-    pub stderr: String,
-    /// Output directory passed to `--out`.
-    pub out_dir: PathBuf,
-}
-
-/// Ergonomic container for the streaming surface; produced by `stream_exec` (implemented in D2).
-///
-/// `events` yields parsed [`ThreadEvent`] values as soon as each JSONL line arrives from the CLI.
-/// `completion` resolves once the Codex process exits and is the place to surface `--output-last-message`
-/// and `--output-schema` paths after streaming finishes.
-pub struct ExecStream {
-    pub events: DynThreadEventStream,
-    pub completion: DynExecCompletion,
-}
-
-/// Type-erased stream of events from the Codex CLI.
-pub type DynThreadEventStream =
-    Pin<Box<dyn Stream<Item = Result<ThreadEvent, ExecStreamError>> + Send>>;
-
-/// Type-erased completion future that resolves when streaming stops.
-pub type DynExecCompletion =
-    Pin<Box<dyn Future<Output = Result<ExecCompletion, ExecStreamError>> + Send>>;
-
-/// Summary returned when the codex child process exits.
-#[derive(Clone, Debug)]
-pub struct ExecCompletion {
-    pub status: ExitStatus,
-    /// Path that codex wrote when `--output-last-message` was enabled. The wrapper may eagerly
-    /// read the file and populate `last_message` when feasible.
-    pub last_message_path: Option<PathBuf>,
-    pub last_message: Option<String>,
-    /// Path to the JSON schema requested via `--output-schema`, if provided by the caller.
-    pub schema_path: Option<PathBuf>,
-}
-
-/// Errors that may occur while consuming the JSONL stream.
-#[derive(Debug, Error)]
-pub enum ExecStreamError {
-    #[error(transparent)]
-    Codex(#[from] CodexError),
-    #[error("failed to parse codex JSONL event: {source}: `{line}`")]
-    Parse {
-        line: String,
+    #[error("failed to resolve working directory: {source}")]
+    WorkingDirectory {
         #[source]
-        source: serde_json::Error,
+        source: std::io::Error,
     },
-    #[error("codex JSONL event missing required context: {message}: `{line}`")]
-    Normalize { line: String, message: String },
-    #[error("codex JSON stream idle for {idle_for:?}")]
-    IdleTimeout { idle_for: Duration },
-    #[error("codex JSON stream closed unexpectedly")]
-    ChannelClosed,
-}
-
-async fn read_last_message(path: &Path) -> Option<String> {
-    (fs::read_to_string(path).await).ok()
-}
-
-fn unique_temp_path(prefix: &str, extension: &str) -> PathBuf {
-    let mut path = env::temp_dir();
-    let timestamp = SystemTime::now()
-        .duration_since(UNIX_EPOCH)
-        .unwrap_or_else(|_| Duration::from_secs(0))
-        .as_nanos();
-    path.push(format!(
-        "{prefix}{timestamp}_{}.{}",
-        std::process::id(),
-        extension
-    ));
-    path
+    #[error("failed to prepare app-server output directory `{path}`: {source}")]
+    PrepareOutputDirectory {
+        path: PathBuf,
+        #[source]
+        source: std::io::Error,
+    },
+    #[error("failed to prepare CODEX_HOME at `{path}`: {source}")]
+    PrepareCodexHome {
+        path: PathBuf,
+        #[source]
+        source: std::io::Error,
+    },
+    #[error("codex stdout unavailable")]
+    StdoutUnavailable,
+    #[error("codex stderr unavailable")]
+    StderrUnavailable,
+    #[error("codex stdin unavailable")]
+    StdinUnavailable,
+    #[error("failed to capture codex output: {0}")]
+    CaptureIo(#[from] std::io::Error),
+    #[error("failed to write prompt to codex stdin: {0}")]
+    StdinWrite(#[source] std::io::Error),
+    #[error("failed to join codex output task: {0}")]
+    Join(#[from] tokio::task::JoinError),
 }
 
 enum DirectoryContext {
@@ -4824,586 +2021,43 @@ impl DirectoryContext {
     }
 }
 
-fn command_output_text(output: &CommandOutput) -> String {
-    let stdout = String::from_utf8_lossy(&output.stdout).into_owned();
-    let stderr = String::from_utf8_lossy(&output.stderr).into_owned();
-    let stdout = stdout.trim_end();
-    let stderr = stderr.trim_end();
-    if stdout.is_empty() {
-        stderr.to_string()
-    } else if stderr.is_empty() {
-        stdout.to_string()
-    } else {
-        format!("{stdout}\n{stderr}")
-    }
-}
-
-fn parse_semver_from_raw(raw: &str) -> Option<Version> {
-    for token in raw.split_whitespace() {
-        let candidate = token
-            .trim_matches(|c: char| matches!(c, '(' | ')' | ',' | ';'))
-            .trim_start_matches('v');
-        if let Ok(version) = Version::parse(candidate) {
-            return Some(version);
-        }
-    }
-    None
-}
-
-fn parse_version_output(output: &str) -> CodexVersionInfo {
-    let raw = output.trim().to_string();
-    let parsed_version = parse_semver_from_raw(&raw);
-    let semantic = parsed_version
-        .as_ref()
-        .map(|version| (version.major, version.minor, version.patch));
-    let mut commit = extract_commit_hash(&raw);
-    if commit.is_none() {
-        for token in raw.split_whitespace() {
-            let candidate = token
-                .trim_matches(|c: char| matches!(c, '(' | ')' | ',' | ';'))
-                .trim_start_matches('v');
-            if let Some(cleaned) = cleaned_hex(candidate) {
-                commit = Some(cleaned);
-                break;
-            }
-        }
-    }
-    let channel = parsed_version
-        .as_ref()
-        .map(release_channel_for_version)
-        .unwrap_or_else(|| infer_release_channel(&raw));
-
-    CodexVersionInfo {
-        raw,
-        semantic,
-        commit,
-        channel,
-    }
-}
-
-fn release_channel_for_version(version: &Version) -> CodexReleaseChannel {
-    if version.pre.is_empty() {
-        CodexReleaseChannel::Stable
-    } else {
-        let prerelease = version.pre.as_str().to_ascii_lowercase();
-        if prerelease.contains("beta") {
-            CodexReleaseChannel::Beta
-        } else if prerelease.contains("nightly") {
-            CodexReleaseChannel::Nightly
-        } else {
-            CodexReleaseChannel::Custom
-        }
-    }
-}
-
-fn infer_release_channel(raw: &str) -> CodexReleaseChannel {
-    let lower = raw.to_ascii_lowercase();
-    if lower.contains("beta") {
-        CodexReleaseChannel::Beta
-    } else if lower.contains("nightly") {
-        CodexReleaseChannel::Nightly
-    } else {
-        CodexReleaseChannel::Custom
-    }
-}
-
-fn codex_semver(info: &CodexVersionInfo) -> Option<Version> {
-    if let Some(parsed) = parse_semver_from_raw(&info.raw) {
-        return Some(parsed);
-    }
-    let (major, minor, patch) = info.semantic?;
-    let mut version = Version::new(major, minor, patch);
-    if version.pre.is_empty() {
-        match info.channel {
-            CodexReleaseChannel::Beta => {
-                version.pre = Prerelease::new("beta").ok()?;
-            }
-            CodexReleaseChannel::Nightly => {
-                version.pre = Prerelease::new("nightly").ok()?;
-            }
-            CodexReleaseChannel::Stable | CodexReleaseChannel::Custom => {}
-        }
-    }
-    Some(version)
+fn default_rust_log_value() -> Option<&'static str> {
+    env::var_os(RUST_LOG_ENV)
+        .is_none()
+        .then_some(DEFAULT_RUST_LOG)
 }
 
-fn codex_release_from_info(info: &CodexVersionInfo) -> Option<CodexRelease> {
-    let version = codex_semver(info)?;
-    Some(CodexRelease {
-        channel: info.channel,
-        version,
-    })
+fn default_binary_path() -> PathBuf {
+    env::var_os(CODEX_BINARY_ENV)
+        .map(PathBuf::from)
+        .unwrap_or_else(|| PathBuf::from("codex"))
 }
 
-fn extract_commit_hash(raw: &str) -> Option<String> {
-    let tokens: Vec<&str> = raw.split_whitespace().collect();
-    for window in tokens.windows(2) {
-        if window[0].eq_ignore_ascii_case("commit") {
-            if let Some(cleaned) = cleaned_hex(window[1]) {
-                return Some(cleaned);
-            }
-        }
+fn parse_login_success(output: &str) -> Option<CodexAuthStatus> {
+    let lower = output.to_lowercase();
+    if lower.contains("chatgpt") {
+        return Some(CodexAuthStatus::LoggedIn(CodexAuthMethod::ChatGpt));
     }
-
-    for token in tokens {
-        if let Some(cleaned) = cleaned_hex(token) {
-            return Some(cleaned);
-        }
+    if lower.contains("api key") || lower.contains("apikey") {
+        // Prefer everything after the first " - " so we do not chop the key itself.
+        let masked = output
+            .split_once(" - ")
+            .map(|(_, value)| value.trim().to_string())
+            .filter(|value| !value.is_empty())
+            .or_else(|| output.split_whitespace().last().map(|v| v.to_string()));
+        return Some(CodexAuthStatus::LoggedIn(CodexAuthMethod::ApiKey {
+            masked_key: masked,
+        }));
     }
     None
 }
 
-fn cleaned_hex(token: &str) -> Option<String> {
-    let trimmed = token
-        .trim_matches(|c: char| matches!(c, '(' | ')' | ',' | ';'))
-        .trim_start_matches("commit")
-        .trim_start_matches(':')
-        .trim_start_matches('g');
-    if trimmed.len() >= 7 && trimmed.chars().all(|c| c.is_ascii_hexdigit()) {
-        Some(trimmed.to_string())
-    } else {
-        None
-    }
-}
-
-fn parse_features_from_json(output: &str) -> Option<CodexFeatureFlags> {
-    let parsed: Value = serde_json::from_str(output).ok()?;
-    let mut tokens = HashSet::new();
-    collect_feature_tokens(&parsed, &mut tokens);
-    if tokens.is_empty() {
-        return None;
-    }
-
-    let mut flags = CodexFeatureFlags::default();
-    for token in tokens {
-        apply_feature_token(&mut flags, &token);
-    }
-    Some(flags)
-}
-
-fn collect_feature_tokens(value: &Value, tokens: &mut HashSet<String>) {
-    match value {
-        Value::String(value) => {
-            if !value.trim().is_empty() {
-                tokens.insert(value.clone());
-            }
-        }
-        Value::Array(items) => {
-            for item in items {
-                collect_feature_tokens(item, tokens);
-            }
-        }
-        Value::Object(map) => {
-            for (key, value) in map {
-                if let Value::Bool(true) = value {
-                    tokens.insert(key.clone());
-                }
-                collect_feature_tokens(value, tokens);
-            }
-        }
-        _ => {}
-    }
-}
-
-fn parse_features_from_text(output: &str) -> CodexFeatureFlags {
-    let mut flags = CodexFeatureFlags::default();
-    let lower = output.to_ascii_lowercase();
-    if lower.contains("features list") {
-        flags.supports_features_list = true;
-    }
-    if lower.contains("--output-schema") || lower.contains("output schema") {
-        flags.supports_output_schema = true;
-    }
-    if lower.contains("add-dir") || lower.contains("add dir") {
-        flags.supports_add_dir = true;
-    }
-    if lower.contains("login --mcp") || lower.contains("mcp login") {
-        flags.supports_mcp_login = true;
-    }
-    if lower.contains("login") && lower.contains("mcp") {
-        flags.supports_mcp_login = true;
-    }
-
-    for token in lower
-        .split(|c: char| c.is_ascii_whitespace() || c == ',' || c == ';' || c == '|')
-        .filter(|token| !token.is_empty())
-    {
-        apply_feature_token(&mut flags, token);
-    }
-    flags
-}
-
-fn parse_help_output(output: &str) -> CodexFeatureFlags {
-    let mut flags = parse_features_from_text(output);
-    let lower = output.to_ascii_lowercase();
-    if lower.contains("features list") {
-        flags.supports_features_list = true;
-    }
-    flags
-}
-
-fn merge_feature_flags(target: &mut CodexFeatureFlags, update: CodexFeatureFlags) {
-    target.supports_features_list |= update.supports_features_list;
-    target.supports_output_schema |= update.supports_output_schema;
-    target.supports_add_dir |= update.supports_add_dir;
-    target.supports_mcp_login |= update.supports_mcp_login;
-}
-
-fn detected_feature_flags(flags: &CodexFeatureFlags) -> bool {
-    flags.supports_output_schema || flags.supports_add_dir || flags.supports_mcp_login
-}
-
-fn should_run_help_fallback(flags: &CodexFeatureFlags) -> bool {
-    !flags.supports_features_list
-        || !flags.supports_output_schema
-        || !flags.supports_add_dir
-        || !flags.supports_mcp_login
-}
-
-fn normalize_feature_token(token: &str) -> String {
-    token
-        .chars()
-        .map(|c| {
-            if c.is_ascii_alphanumeric() {
-                c.to_ascii_lowercase()
-            } else {
-                '_'
-            }
-        })
-        .collect()
-}
-
-fn apply_feature_token(flags: &mut CodexFeatureFlags, token: &str) {
-    let normalized = normalize_feature_token(token);
-    let compact = normalized.replace('_', "");
-    if normalized.contains("features_list") || compact.contains("featureslist") {
-        flags.supports_features_list = true;
-    }
-    if normalized.contains("output_schema") || compact.contains("outputschema") {
-        flags.supports_output_schema = true;
-    }
-    if normalized.contains("add_dir") || compact.contains("adddir") {
-        flags.supports_add_dir = true;
-    }
-    if normalized.contains("mcp_login")
-        || (normalized.contains("login") && normalized.contains("mcp"))
-    {
-        flags.supports_mcp_login = true;
-    }
-}
-
-fn parse_feature_list_output(
-    stdout: &str,
-    prefer_json: bool,
-) -> Result<(Vec<CodexFeature>, FeaturesListFormat), String> {
-    let trimmed = stdout.trim();
-    if trimmed.is_empty() {
-        return Err("features list output was empty".to_string());
-    }
-
-    if prefer_json {
-        if let Some(features) = parse_feature_list_json(trimmed) {
-            if !features.is_empty() {
-                return Ok((features, FeaturesListFormat::Json));
-            }
-        }
-        if let Some(features) = parse_feature_list_text(trimmed) {
-            if !features.is_empty() {
-                return Ok((features, FeaturesListFormat::Text));
-            }
-        }
-    } else {
-        if let Some(features) = parse_feature_list_text(trimmed) {
-            if !features.is_empty() {
-                return Ok((features, FeaturesListFormat::Text));
-            }
-        }
-        if let Some(features) = parse_feature_list_json(trimmed) {
-            if !features.is_empty() {
-                return Ok((features, FeaturesListFormat::Json));
-            }
-        }
-    }
-
-    Err("could not parse JSON or text feature rows".to_string())
-}
-
-fn parse_feature_list_json(output: &str) -> Option<Vec<CodexFeature>> {
-    let parsed: Value = serde_json::from_str(output).ok()?;
-    parse_feature_list_json_value(&parsed)
-}
-
-fn parse_feature_list_json_value(value: &Value) -> Option<Vec<CodexFeature>> {
-    match value {
-        Value::Array(items) => Some(
-            items
-                .iter()
-                .filter_map(|item| match item {
-                    Value::Object(map) => feature_from_json_fields(None, map),
-                    Value::String(name) => Some(CodexFeature {
-                        name: name.clone(),
-                        stage: None,
-                        enabled: true,
-                        extra: BTreeMap::new(),
-                    }),
-                    _ => None,
-                })
-                .collect(),
-        ),
-        Value::Object(map) => {
-            if let Some(features) = map.get("features") {
-                return parse_feature_list_json_value(features);
-            }
-            if map.contains_key("name") || map.contains_key("enabled") || map.contains_key("stage")
-            {
-                return feature_from_json_fields(None, map).map(|feature| vec![feature]);
-            }
-            Some(
-                map.iter()
-                    .filter_map(|(name, value)| match value {
-                        Value::Object(inner) => {
-                            feature_from_json_fields(Some(name.as_str()), inner)
-                        }
-                        Value::Bool(flag) => Some(CodexFeature {
-                            name: name.clone(),
-                            stage: None,
-                            enabled: *flag,
-                            extra: BTreeMap::new(),
-                        }),
-                        Value::String(flag) => parse_feature_enabled_str(flag)
-                            .map(|enabled| CodexFeature {
-                                name: name.clone(),
-                                stage: None,
-                                enabled,
-                                extra: BTreeMap::new(),
-                            })
-                            .or_else(|| {
-                                Some(CodexFeature {
-                                    name: name.clone(),
-                                    stage: Some(CodexFeatureStage::parse(flag)),
-                                    enabled: true,
-                                    extra: BTreeMap::new(),
-                                })
-                            }),
-                        _ => None,
-                    })
-                    .collect(),
-            )
-        }
-        _ => None,
-    }
-}
-
-fn parse_feature_list_text(output: &str) -> Option<Vec<CodexFeature>> {
-    let mut features = Vec::new();
-    for line in output.lines() {
-        let trimmed = line.trim();
-        if trimmed.is_empty() {
-            continue;
-        }
-        if trimmed
-            .chars()
-            .all(|c| matches!(c, '-' | '=' | '+' | '*' | '|'))
-        {
-            continue;
-        }
-
-        let tokens: Vec<&str> = trimmed.split_whitespace().collect();
-        if tokens.len() < 3 {
-            continue;
-        }
-        if tokens[0].eq_ignore_ascii_case("feature")
-            && tokens[1].eq_ignore_ascii_case("stage")
-            && tokens[2].eq_ignore_ascii_case("enabled")
-        {
-            continue;
-        }
-
-        let enabled_token = tokens.last().copied().unwrap_or_default();
-        let enabled = match parse_feature_enabled_str(enabled_token) {
-            Some(value) => value,
-            None => continue,
-        };
-        let stage_token = tokens.get(tokens.len() - 2).copied().unwrap_or_default();
-        let name = tokens[..tokens.len() - 2].join(" ");
-        if name.is_empty() {
-            continue;
-        }
-        let stage = (!stage_token.is_empty()).then(|| CodexFeatureStage::parse(stage_token));
-        features.push(CodexFeature {
-            name,
-            stage,
-            enabled,
-            extra: BTreeMap::new(),
-        });
-    }
-
-    if features.is_empty() {
-        None
-    } else {
-        Some(features)
-    }
-}
-
-fn parse_feature_enabled_value(value: &Value) -> Option<bool> {
-    match value {
-        Value::Bool(flag) => Some(*flag),
-        Value::String(raw) => parse_feature_enabled_str(raw),
-        _ => None,
-    }
-}
-
-fn parse_feature_enabled_str(raw: &str) -> Option<bool> {
-    match raw.trim().to_ascii_lowercase().as_str() {
-        "true" | "yes" | "y" | "on" | "1" | "enabled" => Some(true),
-        "false" | "no" | "n" | "off" | "0" | "disabled" => Some(false),
-        _ => None,
-    }
-}
-
-fn feature_from_json_fields(
-    name_hint: Option<&str>,
-    map: &serde_json::Map<String, Value>,
-) -> Option<CodexFeature> {
-    let name = map
-        .get("name")
-        .and_then(Value::as_str)
-        .map(str::to_string)
-        .or_else(|| name_hint.map(str::to_string))?;
-    let enabled = map
-        .get("enabled")
-        .and_then(parse_feature_enabled_value)
-        .or_else(|| map.get("value").and_then(parse_feature_enabled_value))?;
-    let stage = map
-        .get("stage")
-        .or_else(|| map.get("status"))
-        .and_then(Value::as_str)
-        .map(CodexFeatureStage::parse);
-
-    let mut extra = BTreeMap::new();
-    for (key, value) in map {
-        if matches!(
-            key.as_str(),
-            "name" | "stage" | "status" | "enabled" | "value"
-        ) {
-            continue;
-        }
-        extra.insert(key.clone(), value.clone());
-    }
-
-    Some(CodexFeature {
-        name,
-        stage,
-        enabled,
-        extra,
-    })
-}
-
-/// Computes an update advisory for a previously probed binary.
-///
-/// Callers that already have a [`CodexCapabilities`] snapshot can use this
-/// helper to avoid re-running `codex --version`. Provide a [`CodexLatestReleases`]
-/// table sourced from your preferred distribution channel.
-pub fn update_advisory_from_capabilities(
-    capabilities: &CodexCapabilities,
-    latest_releases: &CodexLatestReleases,
-) -> CodexUpdateAdvisory {
-    let local_release = capabilities
-        .version
-        .as_ref()
-        .and_then(codex_release_from_info);
-    let preferred_channel = local_release
-        .as_ref()
-        .map(|release| release.channel)
-        .unwrap_or(CodexReleaseChannel::Stable);
-    let (latest_release, comparison_channel, fell_back) =
-        latest_releases.select_for_channel(preferred_channel);
-    let mut notes = Vec::new();
-
-    if fell_back {
-        notes.push(format!(
-            "No latest {preferred_channel} release provided; comparing against {comparison_channel}."
-        ));
-    }
-
-    let status = match (local_release.as_ref(), latest_release.as_ref()) {
-        (None, None) => CodexUpdateStatus::UnknownLatestVersion,
-        (None, Some(_)) => CodexUpdateStatus::UnknownLocalVersion,
-        (Some(_), None) => CodexUpdateStatus::UnknownLatestVersion,
-        (Some(local), Some(latest)) => {
-            if local.version < latest.version {
-                CodexUpdateStatus::UpdateRecommended
-            } else if local.version > latest.version {
-                CodexUpdateStatus::LocalNewerThanKnown
-            } else {
-                CodexUpdateStatus::UpToDate
-            }
-        }
-    };
-
-    match status {
-        CodexUpdateStatus::UpdateRecommended => {
-            if let (Some(local), Some(latest)) = (local_release.as_ref(), latest_release.as_ref()) {
-                notes.push(format!(
-                    "Local codex {local_version} is behind latest {comparison_channel} {latest_version}.",
-                    local_version = local.version,
-                    latest_version = latest.version
-                ));
-            }
-        }
-        CodexUpdateStatus::LocalNewerThanKnown => {
-            if let Some(local) = local_release.as_ref() {
-                let known = latest_release
-                    .as_ref()
-                    .map(|release| release.version.to_string())
-                    .unwrap_or_else(|| "unknown".to_string());
-                notes.push(format!(
-                    "Local codex {local_version} is newer than provided {comparison_channel} metadata (latest table: {known}).",
-                    local_version = local.version
-                ));
-            }
-        }
-        CodexUpdateStatus::UnknownLocalVersion => {
-            if let Some(latest) = latest_release.as_ref() {
-                notes.push(format!(
-                    "Latest known {comparison_channel} release is {latest_version}; local version could not be parsed.",
-                    latest_version = latest.version
-                ));
-            } else {
-                notes.push(
-                    "Local version could not be parsed and no latest release was provided."
-                        .to_string(),
-                );
-            }
-        }
-        CodexUpdateStatus::UnknownLatestVersion => notes.push(
-            "No latest Codex release information provided; update advisory unavailable."
-                .to_string(),
-        ),
-        CodexUpdateStatus::UpToDate => {
-            if let Some(latest) = latest_release.as_ref() {
-                notes.push(format!(
-                    "Local codex matches latest {comparison_channel} release {latest_version}.",
-                    latest_version = latest.version
-                ));
-            }
-        }
-    }
-
-    CodexUpdateAdvisory {
-        local_release,
-        latest_release,
-        comparison_channel,
-        status,
-        notes,
-    }
-}
-
 #[cfg(test)]
 mod tests {
     use super::*;
     use crate::builder::ResolvedCliOverrides;
     use futures_util::{pin_mut, StreamExt};
+    use semver::Version;
     use serde_json::json;
     use std::collections::HashMap;
     use std::fs as std_fs;
@@ -6772,7 +3426,7 @@ done
                 binary_path: PathBuf::from("codex"),
             },
             fingerprint: None,
-            version: Some(parse_version_output(raw_version)),
+            version: Some(version::parse_version_output(raw_version)),
             features: CodexFeatureFlags::default(),
             probe_plan: CapabilityProbePlan::default(),
             collected_at: SystemTime::now(),
@@ -6841,7 +3495,7 @@ done
     fn sample_capability_overrides() -> CapabilityOverrides {
         CapabilityOverrides {
             snapshot: Some(sample_capabilities_snapshot()),
-            version: Some(parse_version_output("codex 9.9.9-nightly")),
+            version: Some(version::parse_version_output("codex 9.9.9-nightly")),
             features: CapabilityFeatureOverrides {
                 supports_features_list: Some(true),
                 supports_output_schema: Some(true),
@@ -7348,7 +4002,7 @@ exit 0
 
     #[test]
     fn parses_version_output_fields() {
-        let parsed = parse_version_output("codex v3.4.5-nightly (commit abc1234)");
+        let parsed = version::parse_version_output("codex v3.4.5-nightly (commit abc1234)");
         assert_eq!(parsed.semantic, Some((3, 4, 5)));
         assert_eq!(parsed.channel, CodexReleaseChannel::Nightly);
         assert_eq!(parsed.commit.as_deref(), Some("abc1234"));
@@ -7575,7 +4229,7 @@ exit 0
         let snapshot = CodexCapabilities {
             cache_key: cache_key.clone(),
             fingerprint: fingerprint.clone(),
-            version: Some(parse_version_output("codex 0.0.1")),
+            version: Some(version::parse_version_output("codex 0.0.1")),
             features: CodexFeatureFlags {
                 supports_features_list: true,
                 supports_output_schema: true,
@@ -7673,7 +4327,7 @@ exit 0
                 CodexCapabilities {
                     cache_key: cache_key.clone(),
                     fingerprint: None,
-                    version: Some(parse_version_output("codex 9.9.9")),
+                    version: Some(version::parse_version_output("codex 9.9.9")),
                     features: CodexFeatureFlags {
                         supports_features_list: true,
                         supports_output_schema: true,
@@ -7777,13 +4431,13 @@ fi
     #[test]
     fn parses_features_from_json_and_text() {
         let json = r#"{"features":["output_schema","add_dir"],"mcp_login":true}"#;
-        let parsed_json = parse_features_from_json(json).unwrap();
+        let parsed_json = version::parse_features_from_json(json).unwrap();
         assert!(parsed_json.supports_output_schema);
         assert!(parsed_json.supports_add_dir);
         assert!(parsed_json.supports_mcp_login);
 
         let text = "Features: output-schema add-dir login --mcp";
-        let parsed_text = parse_features_from_text(text);
+        let parsed_text = version::parse_features_from_text(text);
         assert!(parsed_text.supports_output_schema);
         assert!(parsed_text.supports_add_dir);
         assert!(parsed_text.supports_mcp_login);
@@ -7792,7 +4446,7 @@ fi
     #[test]
     fn parses_feature_list_json_and_text_tables() {
         let json = r#"{"features":[{"name":"json-stream","stage":"stable","enabled":true,"notes":"keep"},{"name":"cloud-exec","stage":"experimental","enabled":false}]}"#;
-        let (json_features, json_format) = parse_feature_list_output(json, true).unwrap();
+        let (json_features, json_format) = version::parse_feature_list_output(json, true).unwrap();
         assert_eq!(json_format, FeaturesListFormat::Json);
         assert_eq!(json_features.len(), 2);
         assert_eq!(json_features[0].name, "json-stream");
@@ -7808,9 +4462,9 @@ fi
         let text = r#"
 Feature   Stage         Enabled
 json-stream stable      true
-cloud-exec experimental false
-"#;
-        let (text_features, text_format) = parse_feature_list_output(text, false).unwrap();
+	cloud-exec experimental false
+	"#;
+        let (text_features, text_format) = version::parse_feature_list_output(text, false).unwrap();
         assert_eq!(text_format, FeaturesListFormat::Text);
         assert_eq!(text_features.len(), 2);
         assert_eq!(
@@ -7819,7 +4473,8 @@ cloud-exec experimental false
         );
         assert!(!text_features[1].enabled);
 
-        let (fallback_features, fallback_format) = parse_feature_list_output(text, true).unwrap();
+        let (fallback_features, fallback_format) =
+            version::parse_feature_list_output(text, true).unwrap();
         assert_eq!(fallback_format, FeaturesListFormat::Text);
         assert_eq!(fallback_features.len(), 2);
     }
@@ -7828,7 +4483,7 @@ cloud-exec experimental false
     fn parses_help_output_flags() {
         let help =
             "Usage: codex --output-schema ... add-dir ... login --mcp. See `codex features list`.";
-        let parsed = parse_help_output(help);
+        let parsed = version::parse_help_output(help);
         assert!(parsed.supports_output_schema);
         assert!(parsed.supports_add_dir);
         assert!(parsed.supports_mcp_login);
@@ -7919,7 +4574,7 @@ exit 99
                 binary_path: PathBuf::from("codex"),
             },
             fingerprint: None,
-            version: Some(parse_version_output("codex 9.9.9-custom")),
+            version: Some(version::parse_version_output("codex 9.9.9-custom")),
             features: CodexFeatureFlags {
                 supports_features_list: true,
                 supports_output_schema: true,
@@ -8024,9 +4679,10 @@ elif [[ "$1" == "features" && "$2" == "list" ]]; then
 elif [[ "$1" == "--help" ]]; then
   echo "Usage: codex add-dir"
 fi
-"#;
+	"#;
         let binary = write_fake_codex(temp.path(), script);
-        let version_override = parse_version_output("codex 9.9.9-nightly (commit beefcafe)");
+        let version_override =
+            version::parse_version_output("codex 9.9.9-nightly (commit beefcafe)");
 
         let client = CodexClient::builder()
             .binary(&binary)
@@ -8957,90 +5613,3 @@ exit 2
         ));
     }
 }
-
-fn default_rust_log_value() -> Option<&'static str> {
-    env::var_os(RUST_LOG_ENV)
-        .is_none()
-        .then_some(DEFAULT_RUST_LOG)
-}
-
-fn default_binary_path() -> PathBuf {
-    env::var_os(CODEX_BINARY_ENV)
-        .map(PathBuf::from)
-        .unwrap_or_else(|| PathBuf::from("codex"))
-}
-
-#[derive(Clone, Copy)]
-enum ConsoleTarget {
-    Stdout,
-    Stderr,
-}
-
-async fn tee_stream<R>(
-    mut reader: R,
-    target: ConsoleTarget,
-    mirror_console: bool,
-) -> Result<Vec<u8>, std::io::Error>
-where
-    R: AsyncRead + Unpin,
-{
-    let mut buffer = Vec::new();
-    let mut chunk = [0u8; 4096];
-    loop {
-        let n = reader.read(&mut chunk).await?;
-        if n == 0 {
-            break;
-        }
-        if mirror_console {
-            task::block_in_place(|| match target {
-                ConsoleTarget::Stdout => {
-                    let mut out = stdio::stdout();
-                    out.write_all(&chunk[..n])?;
-                    out.flush()
-                }
-                ConsoleTarget::Stderr => {
-                    let mut out = stdio::stderr();
-                    out.write_all(&chunk[..n])?;
-                    out.flush()
-                }
-            })?;
-        }
-        buffer.extend_from_slice(&chunk[..n]);
-    }
-    Ok(buffer)
-}
-
-fn parse_login_success(output: &str) -> Option<CodexAuthStatus> {
-    let lower = output.to_lowercase();
-    if lower.contains("chatgpt") {
-        return Some(CodexAuthStatus::LoggedIn(CodexAuthMethod::ChatGpt));
-    }
-    if lower.contains("api key") || lower.contains("apikey") {
-        // Prefer everything after the first " - " so we do not chop the key itself.
-        let masked = output
-            .split_once(" - ")
-            .map(|(_, value)| value.trim().to_string())
-            .filter(|value| !value.is_empty())
-            .or_else(|| output.split_whitespace().last().map(|v| v.to_string()));
-        return Some(CodexAuthStatus::LoggedIn(CodexAuthMethod::ApiKey {
-            masked_key: masked,
-        }));
-    }
-    None
-}
-
-fn preferred_output_channel(output: &CommandOutput) -> String {
-    let stderr = String::from_utf8(output.stderr.clone()).unwrap_or_default();
-    let stdout = String::from_utf8(output.stdout.clone()).unwrap_or_default();
-    if stderr.trim().is_empty() {
-        stdout
-    } else {
-        stderr
-    }
-}
-
-struct CommandOutput {
-    status: ExitStatus,
-    stdout: Vec<u8>,
-    stderr: Vec<u8>,
-}
diff --git a/crates/codex/src/mcp.rs b/crates/codex/src/mcp.rs
index 8b94464..1329087 100644
--- a/crates/codex/src/mcp.rs
+++ b/crates/codex/src/mcp.rs
@@ -16,11 +16,6 @@
 //! requests. Runtime and pool helpers keep resume hints/metadata intact while starting,
 //! reusing, and stopping app-server instances.
 
-use std::{io, sync::Arc, time::Duration};
-
-use serde_json::{json, Value};
-use thiserror::Error;
-
 mod protocol;
 pub use protocol::*;
 
@@ -33,2471 +28,12 @@ mod app;
 pub use app::*;
 mod jsonrpc;
 
-use jsonrpc::{map_response, JsonRpcTransport};
-
-/// Errors surfaced while managing MCP/app-server transports.
-#[derive(Debug, Error)]
-pub enum McpError {
-    #[error("failed to spawn `{command}`: {source}")]
-    Spawn {
-        command: String,
-        #[source]
-        source: io::Error,
-    },
-    #[error("server did not respond to initialize: {0}")]
-    Handshake(String),
-    #[error("transport task failed: {0}")]
-    Transport(String),
-    #[error("server returned JSON-RPC error {code}: {message}")]
-    Rpc {
-        code: i64,
-        message: String,
-        data: Option<Value>,
-    },
-    #[error("server reported an error: {0}")]
-    Server(String),
-    #[error("request was cancelled")]
-    Cancelled,
-    #[error("timed out after {0:?}")]
-    Timeout(Duration),
-    #[error("serialization failed: {0}")]
-    Serialization(#[from] serde_json::Error),
-    #[error("transport channel closed unexpectedly")]
-    ChannelClosed,
-}
-
-/// Client wrapper around the stdio MCP server.
-pub struct CodexMcpServer {
-    transport: Arc<JsonRpcTransport>,
-}
-
-impl CodexMcpServer {
-    /// Launch `codex mcp-server`, issue `initialize`, and return a connected handle.
-    pub async fn start(config: StdioServerConfig, client: ClientInfo) -> Result<Self, McpError> {
-        Self::with_capabilities(config, client, Value::Object(Default::default())).await
-    }
-
-    /// Launch with explicit capabilities to send during `initialize`.
-    pub async fn with_capabilities(
-        config: StdioServerConfig,
-        client: ClientInfo,
-        capabilities: Value,
-    ) -> Result<Self, McpError> {
-        let capabilities = match capabilities {
-            Value::Null => Value::Object(Default::default()),
-            other => other,
-        };
-        let transport = JsonRpcTransport::spawn_mcp(config).await?;
-        let params = InitializeParams {
-            client,
-            protocol_version: "2024-11-05".to_string(),
-            capabilities,
-        };
-
-        transport
-            .initialize(params, transport.startup_timeout())
-            .await
-            .map_err(|err| McpError::Handshake(err.to_string()))?;
-
-        Ok(Self {
-            transport: Arc::new(transport),
-        })
-    }
-
-    /// Send a new Codex prompt via `codex/codex`.
-    pub async fn codex(&self, params: CodexCallParams) -> Result<CodexCallHandle, McpError> {
-        self.invoke_tool_call("codex", serde_json::to_value(params)?)
-            .await
-    }
-
-    /// Continue an existing conversation via `codex/codex-reply`.
-    pub async fn codex_reply(&self, params: CodexReplyParams) -> Result<CodexCallHandle, McpError> {
-        self.invoke_tool_call("codex-reply", serde_json::to_value(params)?)
-            .await
-    }
-
-    /// Send an approval decision back to the MCP server.
-    pub async fn send_approval(&self, decision: ApprovalDecision) -> Result<(), McpError> {
-        let (_, rx) = self
-            .transport
-            .request(METHOD_CODEX_APPROVAL, serde_json::to_value(decision)?)
-            .await?;
-
-        match rx.await {
-            Ok(Ok(_)) => Ok(()),
-            Ok(Err(err)) => Err(err),
-            Err(_) => Err(McpError::ChannelClosed),
-        }
-    }
-
-    /// Request cancellation for a pending call.
-    pub fn cancel(&self, request_id: RequestId) -> Result<(), McpError> {
-        self.transport.cancel(request_id)
-    }
-
-    /// Gracefully shut down the MCP server.
-    pub async fn shutdown(&self) -> Result<(), McpError> {
-        self.transport.shutdown().await
-    }
-
-    async fn invoke_tool_call(
-        &self,
-        tool_name: &str,
-        arguments: Value,
-    ) -> Result<CodexCallHandle, McpError> {
-        let events = self.transport.register_codex_listener().await;
-        let request = json!({
-            "name": tool_name,
-            "arguments": arguments,
-        });
-        let (request_id, raw_response) = self.transport.request(METHOD_CODEX, request).await?;
-        let response = map_response::<CodexCallResult>(raw_response);
-
-        Ok(CodexCallHandle {
-            request_id,
-            events,
-            response,
-        })
-    }
-}
-
-/// Client wrapper around the stdio app-server.
-pub struct CodexAppServer {
-    transport: Arc<JsonRpcTransport>,
-}
-
-impl CodexAppServer {
-    /// Launch `codex app-server`, issue `initialize`, and return a connected handle.
-    pub async fn start(config: StdioServerConfig, client: ClientInfo) -> Result<Self, McpError> {
-        Self::with_capabilities(config, client, Value::Object(Default::default())).await
-    }
-
-    /// Launch with explicit capabilities to send during `initialize`.
-    pub async fn with_capabilities(
-        config: StdioServerConfig,
-        client: ClientInfo,
-        capabilities: Value,
-    ) -> Result<Self, McpError> {
-        let capabilities = match capabilities {
-            Value::Null => Value::Object(Default::default()),
-            other => other,
-        };
-        let transport = JsonRpcTransport::spawn_app(config).await?;
-        let params = InitializeParams {
-            client,
-            protocol_version: "2024-11-05".to_string(),
-            capabilities,
-        };
-
-        transport
-            .initialize(params, transport.startup_timeout())
-            .await
-            .map_err(|err| McpError::Handshake(err.to_string()))?;
-
-        Ok(Self {
-            transport: Arc::new(transport),
-        })
-    }
-
-    /// Start a new thread (or use a provided ID) via `thread/start`.
-    pub async fn thread_start(&self, params: ThreadStartParams) -> Result<AppCallHandle, McpError> {
-        self.invoke_app_call(METHOD_THREAD_START, serde_json::to_value(params)?)
-            .await
-    }
-
-    /// Resume an existing thread via `thread/resume`.
-    pub async fn thread_resume(
-        &self,
-        params: ThreadResumeParams,
-    ) -> Result<AppCallHandle, McpError> {
-        self.invoke_app_call(METHOD_THREAD_RESUME, serde_json::to_value(params)?)
-            .await
-    }
-
-    /// Start a new turn on a thread via `turn/start`.
-    pub async fn turn_start(&self, params: TurnStartParams) -> Result<AppCallHandle, McpError> {
-        self.invoke_app_call(METHOD_TURN_START, serde_json::to_value(params)?)
-            .await
-    }
-
-    /// Interrupt an active turn via `turn/interrupt`.
-    pub async fn turn_interrupt(
-        &self,
-        params: TurnInterruptParams,
-    ) -> Result<AppCallHandle, McpError> {
-        self.invoke_app_call(METHOD_TURN_INTERRUPT, serde_json::to_value(params)?)
-            .await
-    }
-
-    /// Request cancellation for a pending call.
-    pub fn cancel(&self, request_id: RequestId) -> Result<(), McpError> {
-        self.transport.cancel(request_id)
-    }
-
-    /// Gracefully shut down the app-server.
-    pub async fn shutdown(&self) -> Result<(), McpError> {
-        self.transport.shutdown().await
-    }
-
-    async fn invoke_app_call(
-        &self,
-        method: &str,
-        params: Value,
-    ) -> Result<AppCallHandle, McpError> {
-        let events = self.transport.register_app_listener().await;
-        let (request_id, raw_response) = self.transport.request(method, params).await?;
-        let response = map_response::<Value>(raw_response);
-
-        Ok(AppCallHandle {
-            request_id,
-            events,
-            response,
-        })
-    }
-}
+mod client;
+pub use client::*;
 
 #[cfg(test)]
-mod tests {
-    use super::*;
-    use std::{
-        collections::{BTreeMap, HashMap},
-        env,
-        ffi::OsString,
-        fs,
-        os::unix::fs::PermissionsExt,
-        path::PathBuf,
-    };
-    use tokio::{
-        io::{AsyncBufReadExt, BufReader},
-        time,
-    };
-    use toml::Value as TomlValue;
-
-    fn temp_config_manager() -> (tempfile::TempDir, McpConfigManager) {
-        let dir = tempfile::tempdir().expect("tempdir");
-        let manager = McpConfigManager::from_code_home(dir.path());
-        (dir, manager)
-    }
-
-    fn stdio_definition(command: &str) -> McpServerDefinition {
-        McpServerDefinition {
-            transport: McpTransport::Stdio(StdioServerDefinition {
-                command: command.to_string(),
-                args: Vec::new(),
-                env: BTreeMap::new(),
-                timeout_ms: Some(1500),
-            }),
-            description: None,
-            tags: Vec::new(),
-            tools: None,
-        }
-    }
-
-    fn streamable_definition(url: &str, bearer_var: &str) -> McpServerDefinition {
-        McpServerDefinition {
-            transport: McpTransport::StreamableHttp(StreamableHttpDefinition {
-                url: url.to_string(),
-                headers: BTreeMap::new(),
-                bearer_env_var: Some(bearer_var.to_string()),
-                connect_timeout_ms: Some(5000),
-                request_timeout_ms: Some(5000),
-            }),
-            description: None,
-            tags: Vec::new(),
-            tools: Some(McpToolConfig {
-                enabled: vec![],
-                disabled: vec![],
-            }),
-        }
-    }
-
-    fn write_fake_mcp_server() -> (tempfile::TempDir, PathBuf) {
-        let dir = tempfile::tempdir().expect("tempdir");
-        let script_path = dir.path().join("fake-codex");
-        let script = r#"#!/usr/bin/env python3
-import json
-import sys
-import threading
-import time
-
-pending = {}
-
-def send(payload):
-    sys.stdout.write(json.dumps(payload) + "\n")
-    sys.stdout.flush()
-
-def mark_cancelled(target, reason="cancelled"):
-    if target is None:
-        return
-    state = pending.get(str(target)) or {}
-    conv_id = state.get("conversation_id")
-    pending[str(target)] = {"status": "cancelled", "conversation_id": conv_id}
-    if conv_id:
-        send({"jsonrpc": "2.0", "method": "codex/event", "params": {"type": "cancelled", "conversation_id": conv_id, "reason": reason}})
-    send({"jsonrpc": "2.0", "id": target, "error": {"code": -32800, "message": reason}})
-
-def handle_codex(req_id, params):
-    conversation_id = params.get("conversation_id") or params.get("conversationId") or f"conv-{req_id}"
-    pending[str(req_id)] = {"status": "pending", "conversation_id": conversation_id}
-    def worker():
-        time.sleep(0.05)
-        state = pending.get(str(req_id))
-        if not state or state.get("status") == "cancelled":
-            return
-        send({"jsonrpc": "2.0", "method": "codex/event", "params": {"type": "approval_required", "approval_id": f"ap-{req_id}", "kind": "exec"}})
-        time.sleep(0.05)
-        state = pending.get(str(req_id))
-        if not state or state.get("status") == "cancelled":
-            return
-        send({"jsonrpc": "2.0", "method": "codex/event", "params": {"type": "task_complete", "conversation_id": conversation_id, "result": {"ok": True}}})
-        send({"jsonrpc": "2.0", "id": req_id, "result": {"conversation_id": conversation_id, "output": {"ok": True}}})
-        pending.pop(str(req_id), None)
-    threading.Thread(target=worker, daemon=True).start()
-
-for line in sys.stdin:
-    if not line.strip():
-        continue
-    msg = json.loads(line)
-    method = msg.get("method")
-    if method == "initialize":
-        send({"jsonrpc": "2.0", "id": msg.get("id"), "result": {"ready": True}})
-    elif method == "tools/call":
-        params = msg.get("params", {})
-        tool = params.get("name")
-        args = params.get("arguments", {})
-        if tool in ["codex", "codex-reply"]:
-            handle_codex(msg.get("id"), args)
-    elif method == "$/cancelRequest":
-        target = msg.get("params", {}).get("id")
-        mark_cancelled(target, reason="client_cancel")
-    elif method == "shutdown":
-        send({"jsonrpc": "2.0", "id": msg.get("id"), "result": {"ok": True}})
-        break
-    elif method == "exit":
-        break
-"#;
-
-        fs::write(&script_path, script).expect("write script");
-        let mut perms = fs::metadata(&script_path).expect("metadata").permissions();
-        perms.set_mode(0o755);
-        fs::set_permissions(&script_path, perms).expect("chmod");
-        (dir, script_path)
-    }
-
-    fn write_fake_app_server() -> (tempfile::TempDir, PathBuf) {
-        let dir = tempfile::tempdir().expect("tempdir");
-        let script_path = dir.path().join("fake-codex-app");
-        let script = r#"#!/usr/bin/env python3
-import json
-import os
-import sys
-import threading
-import time
-
-pending = {}
-turn_lookup = {}
-
-log_path = os.environ.get("ARGV_LOG")
-if log_path:
-    with open(log_path, "w", encoding="utf-8") as fh:
-        fh.write(json.dumps(sys.argv[1:]) + "\n")
-
-def send(payload):
-    sys.stdout.write(json.dumps(payload) + "\n")
-    sys.stdout.flush()
-
-def mark_cancelled(req_id, reason="cancelled"):
-    if req_id is None:
-        return
-    state = pending.get(str(req_id)) or {}
-    thread_id = state.get("thread_id") or "thread-unknown"
-    turn_id = state.get("turn_id")
-    pending[str(req_id)] = {"status": "cancelled", "thread_id": thread_id, "turn_id": turn_id}
-    if turn_id:
-        send({"jsonrpc": "2.0", "method": "task/notification", "params": {"type": "task_complete", "thread_id": thread_id, "turn_id": turn_id, "result": {"cancelled": True, "reason": reason}}})
-    send({"jsonrpc": "2.0", "id": req_id, "error": {"code": -32800, "message": reason}})
-
-def handle_turn(req_id, params):
-    thread_id = params.get("threadId") or params.get("thread_id") or "thread-unknown"
-    turn_id = params.get("turnId") or params.get("turn_id") or f"turn-{req_id}"
-    pending[str(req_id)] = {"status": "pending", "thread_id": thread_id, "turn_id": turn_id}
-    turn_lookup[turn_id] = req_id
-
-    def worker():
-        time.sleep(0.05)
-        state = pending.get(str(req_id))
-        if not state or state.get("status") == "cancelled":
-            return
-        send({"jsonrpc": "2.0", "method": "task/notification", "params": {"type": "item", "thread_id": thread_id, "turn_id": turn_id, "item": {"message": "processing"}}})
-        time.sleep(0.05)
-        state = pending.get(str(req_id))
-        if not state or state.get("status") == "cancelled":
-            return
-        send({"jsonrpc": "2.0", "method": "task/notification", "params": {"type": "task_complete", "thread_id": thread_id, "turn_id": turn_id, "result": {"ok": True}}})
-        send({"jsonrpc": "2.0", "id": req_id, "result": {"turn_id": turn_id, "accepted": True}})
-        pending.pop(str(req_id), None)
-        turn_lookup.pop(turn_id, None)
-
-    threading.Thread(target=worker, daemon=True).start()
-
-for line in sys.stdin:
-    if not line.strip():
-        continue
-    msg = json.loads(line)
-    method = msg.get("method")
-    if method == "initialize":
-        send({"jsonrpc": "2.0", "id": msg.get("id"), "result": {"ready": True}})
-    elif method == "thread/start":
-        params = msg.get("params", {})
-        thread_id = params.get("thread_id") or f"thread-{msg.get('id')}"
-        send({"jsonrpc": "2.0", "id": msg.get("id"), "result": {"thread_id": thread_id}})
-    elif method == "thread/resume":
-        params = msg.get("params", {})
-        thread_id = params.get("threadId") or params.get("thread_id")
-        send({"jsonrpc": "2.0", "id": msg.get("id"), "result": {"thread_id": thread_id, "resumed": True}})
-    elif method == "turn/start":
-        handle_turn(msg.get("id"), msg.get("params", {}))
-    elif method == "turn/interrupt":
-        params = msg.get("params", {})
-        turn_id = params.get("turnId") or params.get("turn_id")
-        req_id = turn_lookup.get(turn_id)
-        if req_id:
-            mark_cancelled(req_id, reason="interrupted")
-            turn_lookup.pop(turn_id, None)
-            pending.pop(str(req_id), None)
-        send({"jsonrpc": "2.0", "id": msg.get("id"), "result": {"interrupted": True}})
-    elif method == "$/cancelRequest":
-        target = msg.get("params", {}).get("id")
-        mark_cancelled(target, reason="client_cancel")
-    elif method == "shutdown":
-        send({"jsonrpc": "2.0", "id": msg.get("id"), "result": {"ok": True}})
-        break
-    elif method == "exit":
-        break
-"#;
-
-        fs::write(&script_path, script).expect("write script");
-        let mut perms = fs::metadata(&script_path).expect("metadata").permissions();
-        perms.set_mode(0o755);
-        fs::set_permissions(&script_path, perms).expect("chmod");
-        (dir, script_path)
-    }
-
-    fn write_env_probe_server(var: &str) -> (tempfile::TempDir, PathBuf) {
-        let dir = tempfile::tempdir().expect("tempdir");
-        let script_path = dir.path().join("env-probe-server");
-        let script = format!(
-            r#"#!/usr/bin/env python3
-import os
-import sys
-import time
-
-sys.stdout.write(os.environ.get("{var}", "") + "\n")
-sys.stdout.flush()
-time.sleep(30)
-"#
-        );
-
-        fs::write(&script_path, script).expect("write script");
-        let mut perms = fs::metadata(&script_path).expect("metadata").permissions();
-        perms.set_mode(0o755);
-        fs::set_permissions(&script_path, perms).expect("chmod");
-        (dir, script_path)
-    }
-
-    fn test_config(binary: PathBuf) -> StdioServerConfig {
-        StdioServerConfig {
-            binary,
-            code_home: None,
-            current_dir: None,
-            env: Vec::new(),
-            app_server_analytics_default_enabled: false,
-            mirror_stdio: false,
-            startup_timeout: Duration::from_secs(5),
-        }
-    }
-
-    fn test_client() -> ClientInfo {
-        ClientInfo {
-            name: "tests".to_string(),
-            version: "0.0.0".to_string(),
-        }
-    }
-
-    async fn start_fake_mcp_server() -> (tempfile::TempDir, CodexMcpServer) {
-        let (dir, script) = write_fake_mcp_server();
-        let config = test_config(script);
-        let client = test_client();
-        let server = CodexMcpServer::start(config, client)
-            .await
-            .expect("spawn mcp server");
-        (dir, server)
-    }
-
-    async fn start_fake_app_server() -> (tempfile::TempDir, CodexAppServer) {
-        let (dir, script) = write_fake_app_server();
-        let config = test_config(script);
-        let client = test_client();
-        let server = CodexAppServer::start(config, client)
-            .await
-            .expect("spawn app server");
-        (dir, server)
-    }
-
-    #[tokio::test]
-    async fn app_server_launch_can_enable_analytics_flag() {
-        let (dir, script) = write_fake_app_server();
-        let log_path = dir.path().join("argv.json");
-
-        let mut config = test_config(script);
-        config.app_server_analytics_default_enabled = true;
-        config.env.push((
-            OsString::from("ARGV_LOG"),
-            OsString::from(log_path.as_os_str()),
-        ));
-
-        let client = test_client();
-        let server = CodexAppServer::start(config, client)
-            .await
-            .expect("spawn app server");
-
-        let mut argv_line = None;
-        for _ in 0..50 {
-            if let Ok(contents) = fs::read_to_string(&log_path) {
-                argv_line = contents.lines().next().map(str::to_string);
-                break;
-            }
-            tokio::time::sleep(Duration::from_millis(5)).await;
-        }
-
-        let argv_line = argv_line.expect("argv log should be written");
-        let argv: Vec<String> = serde_json::from_str(&argv_line).expect("argv json");
-        assert_eq!(argv, vec!["app-server", "--analytics-default-enabled"]);
-
-        server.shutdown().await.expect("shutdown server");
-    }
-
-    #[test]
-    fn add_stdio_server_injects_env_and_persists() {
-        let (dir, manager) = temp_config_manager();
-        let env_key = "MCP_STDIO_TEST_KEY";
-        env::remove_var(env_key);
-
-        let mut env_map = BTreeMap::new();
-        env_map.insert(env_key.to_string(), "secret".to_string());
-
-        let added = manager
-            .add_server(AddServerRequest {
-                name: "local".into(),
-                definition: stdio_definition("my-mcp"),
-                overwrite: false,
-                env: env_map,
-                bearer_token: None,
-            })
-            .expect("add server");
-
-        match added.definition.transport {
-            McpTransport::Stdio(def) => {
-                assert_eq!(def.command, "my-mcp");
-                assert_eq!(def.env.get(env_key), Some(&"secret".to_string()));
-            }
-            _ => panic!("expected stdio transport"),
-        }
-
-        let listed = manager.list_servers().expect("list servers");
-        assert_eq!(listed.len(), 1);
-        assert_eq!(listed[0].name, "local");
-
-        let fetched = manager.get_server("local").expect("get server");
-        match fetched.definition.transport {
-            McpTransport::Stdio(def) => {
-                assert_eq!(def.env.get(env_key), Some(&"secret".to_string()))
-            }
-            _ => panic!("expected stdio transport"),
-        }
-
-        let config_path = dir.path().join(DEFAULT_CONFIG_FILE);
-        let serialized = fs::read_to_string(config_path).expect("read config");
-        let value: TomlValue = serialized.parse().expect("parse toml");
-        let table = value.as_table().expect("table root");
-        let servers_table = table.get("mcp_servers").expect("mcp_servers");
-        let decoded: BTreeMap<String, McpServerDefinition> = servers_table
-            .clone()
-            .try_into()
-            .expect("decode mcp_servers");
-        let stored = decoded.get("local").expect("stored server");
-        match &stored.transport {
-            McpTransport::Stdio(def) => {
-                assert_eq!(def.env.get(env_key), Some(&"secret".to_string()))
-            }
-            _ => panic!("expected stdio transport"),
-        }
-
-        assert_eq!(env::var(env_key).unwrap(), "secret");
-        env::remove_var(env_key);
-    }
-
-    #[test]
-    fn add_streamable_http_sets_token_and_allows_login_logout() {
-        let (_dir, manager) = temp_config_manager();
-        let env_var = "MCP_HTTP_TOKEN_E5";
-        env::remove_var(env_var);
-
-        let mut definition = streamable_definition("https://example.test/mcp", env_var);
-        if let McpTransport::StreamableHttp(ref mut http) = definition.transport {
-            http.headers.insert("X-Test".into(), "true".into());
-        }
-
-        let _added = manager
-            .add_server(AddServerRequest {
-                name: "remote".into(),
-                definition,
-                overwrite: false,
-                env: BTreeMap::new(),
-                bearer_token: Some("token-a".into()),
-            })
-            .expect("add server");
-
-        assert_eq!(env::var(env_var).unwrap(), "token-a");
-
-        let logout = manager.logout("remote").expect("logout");
-        assert_eq!(logout.env_var.as_deref(), Some(env_var));
-        assert!(logout.cleared);
-        assert!(env::var(env_var).is_err());
-
-        let login = manager.login("remote", "token-b").expect("login");
-        assert_eq!(login.env_var.as_deref(), Some(env_var));
-        assert_eq!(env::var(env_var).unwrap(), "token-b");
-
-        env::remove_var(env_var);
-    }
-
-    #[test]
-    fn remove_server_prunes_config() {
-        let (_dir, manager) = temp_config_manager();
-
-        manager
-            .add_server(AddServerRequest {
-                name: "one".into(),
-                definition: stdio_definition("one"),
-                overwrite: false,
-                env: BTreeMap::new(),
-                bearer_token: None,
-            })
-            .expect("add first");
-
-        manager
-            .add_server(AddServerRequest {
-                name: "two".into(),
-                definition: stdio_definition("two"),
-                overwrite: false,
-                env: BTreeMap::new(),
-                bearer_token: None,
-            })
-            .expect("add second");
-
-        let removed = manager.remove_server("one").expect("remove");
-        assert!(removed.is_some());
-
-        let listed = manager.list_servers().expect("list");
-        assert_eq!(listed.len(), 1);
-        assert_eq!(listed[0].name, "two");
-
-        let config = fs::read_to_string(manager.config_path()).expect("read config");
-        let value: TomlValue = config.parse().expect("parse config");
-        let table = value.as_table().expect("table root");
-        let servers_value = table.get("mcp_servers").cloned().expect("servers");
-        let servers: BTreeMap<String, McpServerDefinition> =
-            servers_value.try_into().expect("decode servers");
-        assert!(!servers.contains_key("one"));
-        assert!(servers.contains_key("two"));
-    }
-
-    #[test]
-    fn runtime_stdio_server_resolves_env_and_tools() {
-        let (_dir, manager) = temp_config_manager();
-        let mut definition = stdio_definition("my-mcp");
-        definition.description = Some("local mcp".into());
-        definition.tags = vec!["dev".into(), "local".into()];
-        definition.tools = Some(McpToolConfig {
-            enabled: vec!["tool-a".into()],
-            disabled: vec!["tool-b".into()],
-        });
-
-        if let McpTransport::Stdio(ref mut stdio) = definition.transport {
-            stdio.args = vec!["--flag".into()];
-            stdio.env.insert("EXAMPLE".into(), "value".into());
-            stdio.timeout_ms = Some(2500);
-        }
-
-        let mut injected = BTreeMap::new();
-        injected.insert("MCP_STDIO_INJECT_E6".into(), "yes".into());
-
-        manager
-            .add_server(AddServerRequest {
-                name: "local".into(),
-                definition,
-                overwrite: false,
-                env: injected,
-                bearer_token: None,
-            })
-            .expect("add server");
-
-        let runtime = manager.runtime_server("local").expect("runtime server");
-        assert_eq!(runtime.name, "local");
-        assert_eq!(runtime.description.as_deref(), Some("local mcp"));
-        assert_eq!(runtime.tags, vec!["dev".to_string(), "local".to_string()]);
-
-        let tools = runtime.tools.as_ref().expect("tool hints");
-        assert_eq!(tools.enabled, vec!["tool-a".to_string()]);
-        assert_eq!(tools.disabled, vec!["tool-b".to_string()]);
-
-        match &runtime.transport {
-            McpRuntimeTransport::Stdio(def) => {
-                assert_eq!(def.command, "my-mcp");
-                assert_eq!(def.args, vec!["--flag".to_string()]);
-                assert_eq!(def.timeout_ms, Some(2500));
-                assert_eq!(def.env.get("EXAMPLE").map(String::as_str), Some("value"));
-                assert_eq!(
-                    def.env.get("MCP_STDIO_INJECT_E6").map(String::as_str),
-                    Some("yes")
-                );
-            }
-            other => panic!("expected stdio transport, got {other:?}"),
-        }
-
-        serde_json::to_string(&runtime).expect("serialize runtime");
-        env::remove_var("MCP_STDIO_INJECT_E6");
-    }
-
-    #[test]
-    fn runtime_http_resolves_bearer_and_sets_header() {
-        let (_dir, manager) = temp_config_manager();
-        let env_var = "MCP_HTTP_TOKEN_E6";
-        env::set_var(env_var, "token-123");
-
-        let mut definition = streamable_definition("https://example.test/mcp", env_var);
-        if let McpTransport::StreamableHttp(ref mut http) = definition.transport {
-            http.headers.insert("X-Test".into(), "true".into());
-            http.connect_timeout_ms = Some(1200);
-            http.request_timeout_ms = Some(3400);
-        }
-
-        manager
-            .add_server(AddServerRequest {
-                name: "remote".into(),
-                definition,
-                overwrite: false,
-                env: BTreeMap::new(),
-                bearer_token: None,
-            })
-            .expect("add server");
-
-        let runtime = manager.runtime_server("remote").expect("runtime server");
-        match &runtime.transport {
-            McpRuntimeTransport::StreamableHttp(def) => {
-                assert_eq!(def.url, "https://example.test/mcp");
-                assert_eq!(def.bearer_env_var.as_deref(), Some(env_var));
-                assert_eq!(def.bearer_token.as_deref(), Some("token-123"));
-                assert_eq!(def.headers.get("X-Test").map(String::as_str), Some("true"));
-                assert_eq!(
-                    def.headers.get("Authorization").map(String::as_str),
-                    Some("Bearer token-123")
-                );
-                assert_eq!(def.connect_timeout_ms, Some(1200));
-                assert_eq!(def.request_timeout_ms, Some(3400));
-            }
-            other => panic!("expected streamable_http transport, got {other:?}"),
-        }
-
-        let serialized = serde_json::to_value(&runtime).expect("serialize runtime");
-        assert!(serialized.get("transport").is_some());
-
-        env::remove_var(env_var);
-    }
-
-    #[test]
-    fn runtime_http_preserves_existing_auth_header() {
-        let (_dir, manager) = temp_config_manager();
-        let env_var = "MCP_HTTP_TOKEN_E6B";
-        env::set_var(env_var, "token-override");
-
-        let mut definition = streamable_definition("https://example.test/custom", env_var);
-        if let McpTransport::StreamableHttp(ref mut http) = definition.transport {
-            http.headers
-                .insert("Authorization".into(), "Custom 123".into());
-        }
-
-        manager
-            .add_server(AddServerRequest {
-                name: "remote-custom".into(),
-                definition,
-                overwrite: false,
-                env: BTreeMap::new(),
-                bearer_token: None,
-            })
-            .expect("add server");
-
-        let runtime = manager
-            .runtime_server("remote-custom")
-            .expect("runtime server");
-        match &runtime.transport {
-            McpRuntimeTransport::StreamableHttp(def) => {
-                assert_eq!(def.bearer_token.as_deref(), Some("token-override"));
-                assert_eq!(
-                    def.headers.get("Authorization").map(String::as_str),
-                    Some("Custom 123")
-                );
-            }
-            other => panic!("expected streamable_http transport, got {other:?}"),
-        }
-
-        env::remove_var(env_var);
-    }
-
-    #[test]
-    fn runtime_stdio_launcher_merges_env_timeout_and_tools() {
-        let base_dir = tempfile::tempdir().expect("tempdir");
-        let code_home = base_dir.path().join("code_home");
-
-        let defaults = StdioServerConfig {
-            binary: PathBuf::from("codex"),
-            code_home: Some(code_home.clone()),
-            current_dir: Some(base_dir.path().to_path_buf()),
-            env: vec![
-                (OsString::from("BASE_ONLY"), OsString::from("base")),
-                (OsString::from("OVERRIDE_ME"), OsString::from("base")),
-            ],
-            app_server_analytics_default_enabled: false,
-            mirror_stdio: true,
-            startup_timeout: Duration::from_secs(5),
-        };
-
-        let mut definition = StdioServerDefinition {
-            command: "my-mcp".into(),
-            args: vec!["--flag".into()],
-            env: BTreeMap::new(),
-            timeout_ms: Some(1500),
-        };
-        definition
-            .env
-            .insert("OVERRIDE_ME".into(), "runtime".into());
-        definition
-            .env
-            .insert("RUNTIME_ONLY".into(), "runtime-env".into());
-
-        let runtime = McpRuntimeServer {
-            name: "local".into(),
-            transport: McpRuntimeTransport::Stdio(definition),
-            description: Some("example".into()),
-            tags: vec!["dev".into()],
-            tools: Some(McpToolConfig {
-                enabled: vec!["tool-1".into()],
-                disabled: vec!["tool-2".into()],
-            }),
-        };
-
-        let launcher = runtime.into_launcher(&defaults);
-        assert_eq!(launcher.name, "local");
-        assert_eq!(launcher.description.as_deref(), Some("example"));
-        assert_eq!(launcher.tags, vec!["dev".to_string()]);
-
-        let tools = launcher.tools.clone().expect("tool hints");
-        assert_eq!(tools.enabled, vec!["tool-1".to_string()]);
-        assert_eq!(tools.disabled, vec!["tool-2".to_string()]);
-
-        match launcher.transport {
-            McpServerLauncherTransport::Stdio(launch) => {
-                assert_eq!(launch.command, PathBuf::from("my-mcp"));
-                assert_eq!(launch.args, vec!["--flag".to_string()]);
-                assert_eq!(launch.current_dir.as_ref(), defaults.current_dir.as_ref());
-                assert_eq!(launch.timeout, Duration::from_millis(1500));
-                assert!(launch.mirror_stdio);
-
-                let env_map: HashMap<OsString, OsString> = launch.env.into_iter().collect();
-                assert_eq!(
-                    env_map.get(&OsString::from("BASE_ONLY")),
-                    Some(&OsString::from("base"))
-                );
-                assert_eq!(
-                    env_map.get(&OsString::from("OVERRIDE_ME")),
-                    Some(&OsString::from("runtime"))
-                );
-                assert_eq!(
-                    env_map.get(&OsString::from("RUNTIME_ONLY")),
-                    Some(&OsString::from("runtime-env"))
-                );
-                assert_eq!(
-                    env_map.get(&OsString::from("CODEX_HOME")),
-                    Some(&code_home.as_os_str().to_os_string())
-                );
-            }
-            other => panic!("expected stdio launcher, got {other:?}"),
-        }
-    }
-
-    #[test]
-    fn streamable_http_connector_converts_timeouts_and_headers() {
-        let env_var = "MCP_HTTP_TOKEN_E7";
-        env::set_var(env_var, "token-launcher");
-
-        let mut definition = StreamableHttpDefinition {
-            url: "https://example.test/stream".into(),
-            headers: BTreeMap::new(),
-            bearer_env_var: Some(env_var.to_string()),
-            connect_timeout_ms: Some(1200),
-            request_timeout_ms: Some(3400),
-        };
-        definition.headers.insert("X-Test".into(), "true".into());
-
-        let runtime = McpRuntimeServer::from_definition(
-            "remote",
-            McpServerDefinition {
-                transport: McpTransport::StreamableHttp(definition),
-                description: None,
-                tags: vec!["http".into()],
-                tools: Some(McpToolConfig {
-                    enabled: vec!["tool-a".into()],
-                    disabled: vec![],
-                }),
-            },
-        );
-
-        let defaults = StdioServerConfig {
-            binary: PathBuf::from("codex"),
-            code_home: None,
-            current_dir: None,
-            env: Vec::new(),
-            app_server_analytics_default_enabled: false,
-            mirror_stdio: false,
-            startup_timeout: Duration::from_secs(2),
-        };
-
-        let launcher = runtime.into_launcher(&defaults);
-        match launcher.transport {
-            McpServerLauncherTransport::StreamableHttp(connector) => {
-                assert_eq!(connector.url, "https://example.test/stream");
-                assert_eq!(
-                    connector.headers.get("X-Test").map(String::as_str),
-                    Some("true")
-                );
-                assert_eq!(
-                    connector.headers.get("Authorization").map(String::as_str),
-                    Some("Bearer token-launcher")
-                );
-                assert_eq!(connector.connect_timeout, Some(Duration::from_millis(1200)));
-                assert_eq!(connector.request_timeout, Some(Duration::from_millis(3400)));
-                assert_eq!(connector.bearer_env_var.as_deref(), Some(env_var));
-                assert_eq!(connector.bearer_token.as_deref(), Some("token-launcher"));
-
-                let tools = launcher.tools.as_ref().expect("tool hints present");
-                assert_eq!(tools.enabled, vec!["tool-a".to_string()]);
-                assert!(tools.disabled.is_empty());
-            }
-            other => panic!("expected http connector, got {other:?}"),
-        }
-
-        env::remove_var(env_var);
-    }
-
-    #[tokio::test]
-    async fn codex_flow_streams_events_and_response() {
-        let (_dir, server) = start_fake_mcp_server().await;
-
-        let params = CodexCallParams {
-            prompt: "hello".into(),
-            model: None,
-            cwd: None,
-            sandbox: None,
-            approval_policy: None,
-            profile: None,
-            config: BTreeMap::new(),
-        };
-
-        let mut handle = server.codex(params).await.expect("codex call");
-
-        let first_event = time::timeout(Duration::from_secs(2), handle.events.recv())
-            .await
-            .expect("event timeout")
-            .expect("event value");
-        match first_event {
-            CodexEvent::ApprovalRequired(req) => {
-                assert!(req.approval_id.starts_with("ap-"));
-                assert_eq!(req.kind, ApprovalKind::Exec);
-            }
-            other => panic!("unexpected event: {other:?}"),
-        }
-
-        let second_event = time::timeout(Duration::from_secs(2), handle.events.recv())
-            .await
-            .expect("event timeout")
-            .expect("event value");
-        let event_conversation = match second_event {
-            CodexEvent::TaskComplete {
-                conversation_id, ..
-            } => {
-                assert!(!conversation_id.is_empty());
-                conversation_id
-            }
-            other => panic!("unexpected event: {other:?}"),
-        };
-
-        let response = time::timeout(Duration::from_secs(2), handle.response)
-            .await
-            .expect("response timeout")
-            .expect("response recv");
-        let response = response.expect("response ok");
-        assert_eq!(
-            response.conversation_id.as_deref(),
-            Some(event_conversation.as_str())
-        );
-        assert_eq!(response.output, serde_json::json!({ "ok": true }));
-
-        let _ = server.shutdown().await;
-    }
-
-    #[tokio::test]
-    async fn canceling_request_returns_cancelled_error() {
-        let (_dir, server) = start_fake_mcp_server().await;
-
-        let params = CodexCallParams {
-            prompt: "cancel me".into(),
-            model: None,
-            cwd: None,
-            sandbox: None,
-            approval_policy: None,
-            profile: None,
-            config: BTreeMap::new(),
-        };
-
-        let mut handle = server.codex(params).await.expect("codex call");
-        server.cancel(handle.request_id).expect("cancel send");
-
-        let expected_conversation = format!("conv-{}", handle.request_id);
-        let cancel_event = time::timeout(Duration::from_secs(2), handle.events.recv())
-            .await
-            .expect("event timeout")
-            .expect("cancel notification");
-        match cancel_event {
-            CodexEvent::Cancelled {
-                conversation_id,
-                reason,
-            } => {
-                assert_eq!(
-                    conversation_id.as_deref(),
-                    Some(expected_conversation.as_str())
-                );
-                assert_eq!(reason.as_deref(), Some("client_cancel"));
-            }
-            other => panic!("expected cancellation event, got {other:?}"),
-        }
-
-        let response = time::timeout(Duration::from_secs(2), handle.response)
-            .await
-            .expect("response timeout")
-            .expect("recv");
-        assert!(matches!(response, Err(McpError::Cancelled)));
-
-        let _ = server.shutdown().await;
-    }
-
-    #[tokio::test]
-    async fn codex_reply_streams_follow_up_notifications() {
-        let (_dir, server) = start_fake_mcp_server().await;
-
-        let params = CodexCallParams {
-            prompt: "hello".into(),
-            model: None,
-            cwd: None,
-            sandbox: None,
-            approval_policy: None,
-            profile: None,
-            config: BTreeMap::new(),
-        };
-        let first = server.codex(params).await.expect("start codex");
-        let first_response = time::timeout(Duration::from_secs(2), first.response)
-            .await
-            .expect("response timeout")
-            .expect("recv")
-            .expect("ok");
-        let conversation_id = first_response.conversation_id.expect("conversation id set");
-        assert!(!conversation_id.is_empty());
-
-        let reply_params = CodexReplyParams {
-            conversation_id: conversation_id.clone(),
-            prompt: "follow up".into(),
-        };
-        let mut reply = server.codex_reply(reply_params).await.expect("codex reply");
-
-        let expected_approval = format!("ap-{}", reply.request_id);
-        let approval = time::timeout(Duration::from_secs(2), reply.events.recv())
-            .await
-            .expect("event timeout")
-            .expect("approval");
-        match approval {
-            CodexEvent::ApprovalRequired(req) => {
-                assert_eq!(req.approval_id, expected_approval);
-                assert_eq!(req.kind, ApprovalKind::Exec);
-            }
-            other => panic!("unexpected event: {other:?}"),
-        }
-
-        let complete = time::timeout(Duration::from_secs(2), reply.events.recv())
-            .await
-            .expect("event timeout")
-            .expect("task completion");
-        match complete {
-            CodexEvent::TaskComplete {
-                conversation_id: event_conv,
-                ..
-            } => assert_eq!(event_conv, conversation_id),
-            other => panic!("unexpected event: {other:?}"),
-        }
-
-        let reply_response = time::timeout(Duration::from_secs(2), reply.response)
-            .await
-            .expect("response timeout")
-            .expect("recv")
-            .expect("ok");
-        assert_eq!(
-            reply_response.conversation_id.as_deref(),
-            Some(conversation_id.as_str())
-        );
-        assert_eq!(reply_response.output, serde_json::json!({ "ok": true }));
-
-        let _ = server.shutdown().await;
-    }
-
-    #[tokio::test]
-    async fn app_flow_streams_notifications_and_response() {
-        let (_dir, server) = start_fake_app_server().await;
-
-        let thread_params = ThreadStartParams {
-            thread_id: None,
-            metadata: Value::Null,
-        };
-        let thread_handle = server
-            .thread_start(thread_params)
-            .await
-            .expect("thread start");
-        let thread_response = time::timeout(Duration::from_secs(2), thread_handle.response)
-            .await
-            .expect("thread response timeout")
-            .expect("thread response recv")
-            .expect("thread response ok");
-        let thread_id = thread_response
-            .get("thread_id")
-            .and_then(Value::as_str)
-            .unwrap_or_default()
-            .to_string();
-        assert!(!thread_id.is_empty());
-
-        let params = TurnStartParams {
-            thread_id: thread_id.clone(),
-            input: vec![TurnInput {
-                kind: "text".to_string(),
-                text: Some("hi".to_string()),
-            }],
-            model: None,
-            config: BTreeMap::new(),
-        };
-        let mut handle = server.turn_start(params).await.expect("turn start");
-
-        let first_event = time::timeout(Duration::from_secs(2), handle.events.recv())
-            .await
-            .expect("event timeout")
-            .expect("event value");
-        let turn_id = match first_event {
-            AppNotification::Item {
-                thread_id: tid,
-                turn_id: Some(turn),
-                item,
-            } => {
-                assert_eq!(tid, thread_id);
-                assert!(item.get("message").is_some());
-                turn
-            }
-            other => panic!("unexpected event: {other:?}"),
-        };
-
-        let second_event = time::timeout(Duration::from_secs(2), handle.events.recv())
-            .await
-            .expect("event timeout")
-            .expect("event value");
-        match second_event {
-            AppNotification::TaskComplete {
-                thread_id: tid,
-                turn_id: event_turn,
-                result,
-            } => {
-                assert_eq!(tid, thread_id);
-                assert_eq!(event_turn.as_deref(), Some(turn_id.as_str()));
-                assert_eq!(result, serde_json::json!({ "ok": true }));
-            }
-            other => panic!("unexpected event: {other:?}"),
-        }
-
-        let response = time::timeout(Duration::from_secs(2), handle.response)
-            .await
-            .expect("response timeout")
-            .expect("response recv");
-        let response = response.expect("response ok");
-        assert_eq!(
-            response
-                .get("turn_id")
-                .and_then(Value::as_str)
-                .unwrap_or_default(),
-            turn_id
-        );
-
-        let _ = server.shutdown().await;
-    }
-
-    #[tokio::test]
-    async fn canceling_app_request_returns_cancelled_error() {
-        let (_dir, server) = start_fake_app_server().await;
-
-        let thread_params = ThreadStartParams {
-            thread_id: None,
-            metadata: Value::Null,
-        };
-        let thread_handle = server
-            .thread_start(thread_params)
-            .await
-            .expect("thread start");
-        let thread_response = time::timeout(Duration::from_secs(2), thread_handle.response)
-            .await
-            .expect("thread response timeout")
-            .expect("thread response recv")
-            .expect("thread response ok");
-        let thread_id = thread_response
-            .get("thread_id")
-            .and_then(Value::as_str)
-            .unwrap_or_default()
-            .to_string();
-
-        let params = TurnStartParams {
-            thread_id: thread_id.clone(),
-            input: vec![TurnInput {
-                kind: "text".to_string(),
-                text: Some("cancel me".to_string()),
-            }],
-            model: None,
-            config: BTreeMap::new(),
-        };
-
-        let mut handle = server.turn_start(params).await.expect("turn start");
-        server.cancel(handle.request_id).expect("send cancel");
-
-        let cancel_event = time::timeout(Duration::from_secs(2), handle.events.recv())
-            .await
-            .expect("event timeout")
-            .expect("cancel event");
-        match cancel_event {
-            AppNotification::TaskComplete {
-                thread_id: tid,
-                turn_id,
-                result,
-            } => {
-                assert_eq!(tid, thread_id);
-                assert!(turn_id.is_some());
-                assert_eq!(result.get("cancelled"), Some(&Value::Bool(true)));
-                assert_eq!(
-                    result.get("reason"),
-                    Some(&Value::String("client_cancel".into()))
-                );
-            }
-            other => panic!("unexpected cancellation notification: {other:?}"),
-        }
-
-        let response = time::timeout(Duration::from_secs(2), handle.response)
-            .await
-            .expect("response timeout")
-            .expect("recv");
-        assert!(matches!(response, Err(McpError::Cancelled)));
-
-        let _ = server.shutdown().await;
-    }
-
-    #[tokio::test]
-    async fn thread_resume_allows_follow_up_turns() {
-        let (_dir, server) = start_fake_app_server().await;
-
-        let thread_params = ThreadStartParams {
-            thread_id: None,
-            metadata: Value::Null,
-        };
-        let thread_handle = server
-            .thread_start(thread_params)
-            .await
-            .expect("thread start");
-        let thread_response = time::timeout(Duration::from_secs(2), thread_handle.response)
-            .await
-            .expect("thread response timeout")
-            .expect("recv")
-            .expect("ok");
-        let thread_id = thread_response
-            .get("thread_id")
-            .and_then(Value::as_str)
-            .unwrap_or_default()
-            .to_string();
-
-        let resume_params = ThreadResumeParams {
-            thread_id: thread_id.clone(),
-        };
-        let resume_handle = server
-            .thread_resume(resume_params)
-            .await
-            .expect("thread resume");
-        let resume_response = time::timeout(Duration::from_secs(2), resume_handle.response)
-            .await
-            .expect("resume response timeout")
-            .expect("recv")
-            .expect("ok");
-        assert_eq!(
-            resume_response
-                .get("thread_id")
-                .and_then(Value::as_str)
-                .unwrap_or_default(),
-            thread_id
-        );
-        assert!(resume_response
-            .get("resumed")
-            .and_then(Value::as_bool)
-            .unwrap_or(false));
-
-        let params = TurnStartParams {
-            thread_id: thread_id.clone(),
-            input: vec![TurnInput {
-                kind: "text".to_string(),
-                text: Some("resume flow".to_string()),
-            }],
-            model: None,
-            config: BTreeMap::new(),
-        };
-        let mut turn = server.turn_start(params).await.expect("turn start");
-
-        let item = time::timeout(Duration::from_secs(2), turn.events.recv())
-            .await
-            .expect("event timeout")
-            .expect("item event");
-        let turn_id = match item {
-            AppNotification::Item {
-                thread_id: tid,
-                turn_id: Some(turn_id),
-                ..
-            } => {
-                assert_eq!(tid, thread_id);
-                turn_id
-            }
-            other => panic!("unexpected event: {other:?}"),
-        };
-
-        let complete = time::timeout(Duration::from_secs(2), turn.events.recv())
-            .await
-            .expect("event timeout")
-            .expect("completion event");
-        match complete {
-            AppNotification::TaskComplete {
-                thread_id: tid,
-                turn_id: event_turn,
-                result,
-            } => {
-                assert_eq!(tid, thread_id);
-                assert_eq!(event_turn.as_deref(), Some(turn_id.as_str()));
-                assert_eq!(result, serde_json::json!({ "ok": true }));
-            }
-            other => panic!("unexpected event: {other:?}"),
-        }
-
-        let turn_response = time::timeout(Duration::from_secs(2), turn.response)
-            .await
-            .expect("response timeout")
-            .expect("recv")
-            .expect("ok");
-        assert_eq!(
-            turn_response
-                .get("turn_id")
-                .and_then(Value::as_str)
-                .unwrap_or_default(),
-            turn_id
-        );
-
-        let _ = server.shutdown().await;
-    }
-
-    #[tokio::test]
-    async fn turn_interrupt_sends_cancel_notification() {
-        let (_dir, server) = start_fake_app_server().await;
-
-        let thread_params = ThreadStartParams {
-            thread_id: None,
-            metadata: Value::Null,
-        };
-        let thread_handle = server
-            .thread_start(thread_params)
-            .await
-            .expect("thread start");
-        let thread_response = time::timeout(Duration::from_secs(2), thread_handle.response)
-            .await
-            .expect("thread response timeout")
-            .expect("recv")
-            .expect("ok");
-        let thread_id = thread_response
-            .get("thread_id")
-            .and_then(Value::as_str)
-            .unwrap_or_default()
-            .to_string();
-
-        let params = TurnStartParams {
-            thread_id: thread_id.clone(),
-            input: vec![TurnInput {
-                kind: "text".to_string(),
-                text: Some("please interrupt".to_string()),
-            }],
-            model: None,
-            config: BTreeMap::new(),
-        };
-        let mut turn = server.turn_start(params).await.expect("turn start");
-
-        let first_event = time::timeout(Duration::from_secs(2), turn.events.recv())
-            .await
-            .expect("event timeout")
-            .expect("event value");
-        let turn_id = match first_event {
-            AppNotification::Item {
-                thread_id: tid,
-                turn_id: Some(turn),
-                ..
-            } => {
-                assert_eq!(tid, thread_id);
-                turn
-            }
-            other => panic!("unexpected event: {other:?}"),
-        };
-
-        let interrupt = server
-            .turn_interrupt(TurnInterruptParams {
-                thread_id: Some(thread_id.clone()),
-                turn_id: turn_id.clone(),
-            })
-            .await
-            .expect("send interrupt");
-
-        let cancel_event = time::timeout(Duration::from_secs(2), turn.events.recv())
-            .await
-            .expect("event timeout")
-            .expect("cancel event");
-        match cancel_event {
-            AppNotification::TaskComplete {
-                thread_id: tid,
-                turn_id: event_turn,
-                result,
-            } => {
-                assert_eq!(tid, thread_id);
-                assert_eq!(event_turn.as_deref(), Some(turn_id.as_str()));
-                assert_eq!(result.get("cancelled"), Some(&Value::Bool(true)));
-                assert_eq!(
-                    result.get("reason"),
-                    Some(&Value::String("interrupted".into()))
-                );
-            }
-            other => panic!("unexpected cancel notification: {other:?}"),
-        }
-
-        let turn_response = time::timeout(Duration::from_secs(2), turn.response)
-            .await
-            .expect("response timeout")
-            .expect("recv");
-        assert!(matches!(turn_response, Err(McpError::Cancelled)));
-
-        let interrupt_response = time::timeout(Duration::from_secs(2), interrupt.response)
-            .await
-            .expect("interrupt response timeout")
-            .expect("recv")
-            .expect("ok");
-        assert!(interrupt_response
-            .get("interrupted")
-            .and_then(Value::as_bool)
-            .unwrap_or(false));
-
-        let _ = server.shutdown().await;
-    }
-
-    #[test]
-    fn runtime_api_lists_launchers_without_changing_config() {
-        let (dir, manager) = temp_config_manager();
-        let stdio_env_key = "MCP_RUNTIME_API_STDIO_ENV";
-        let request_env_key = "MCP_RUNTIME_API_REQUEST_ENV";
-        let http_env_key = "MCP_RUNTIME_API_HTTP_ENV";
-        env::set_var(http_env_key, "token-api");
-
-        let mut stdio = stdio_definition("runtime-api-stdio");
-        stdio.description = Some("stdio runtime".into());
-        stdio.tags = vec!["local".into()];
-        stdio.tools = Some(McpToolConfig {
-            enabled: vec!["fmt".into()],
-            disabled: vec!["lint".into()],
-        });
-        if let McpTransport::Stdio(ref mut stdio_def) = stdio.transport {
-            stdio_def.args.push("--flag".into());
-            stdio_def
-                .env
-                .insert(stdio_env_key.into(), "runtime-env".into());
-            stdio_def.timeout_ms = Some(2400);
-        }
-
-        let mut env_map = BTreeMap::new();
-        env_map.insert(request_env_key.to_string(), "injected".to_string());
-
-        manager
-            .add_server(AddServerRequest {
-                name: "local-api".into(),
-                definition: stdio,
-                overwrite: false,
-                env: env_map,
-                bearer_token: None,
-            })
-            .expect("add stdio server");
-
-        let mut http = streamable_definition("https://example.test/runtime-api", http_env_key);
-        http.description = Some("http runtime".into());
-        http.tags = vec!["remote".into()];
-        http.tools = Some(McpToolConfig {
-            enabled: vec!["alpha".into()],
-            disabled: vec!["beta".into()],
-        });
-        if let McpTransport::StreamableHttp(ref mut http_def) = http.transport {
-            http_def.headers.insert("X-Req".into(), "true".into());
-            http_def.request_timeout_ms = Some(2200);
-        }
-
-        manager
-            .add_server(AddServerRequest {
-                name: "remote-api".into(),
-                definition: http,
-                overwrite: false,
-                env: BTreeMap::new(),
-                bearer_token: None,
-            })
-            .expect("add http server");
-
-        let before = fs::read_to_string(manager.config_path()).expect("read config before");
-        let cwd = dir.path().join("cwd");
-
-        let defaults = StdioServerConfig {
-            binary: PathBuf::from("codex"),
-            code_home: Some(dir.path().to_path_buf()),
-            current_dir: Some(cwd.clone()),
-            env: vec![
-                (OsString::from("DEFAULT_ONLY"), OsString::from("default")),
-                (
-                    OsString::from(request_env_key),
-                    OsString::from("base-default"),
-                ),
-            ],
-            app_server_analytics_default_enabled: false,
-            mirror_stdio: true,
-            startup_timeout: Duration::from_secs(3),
-        };
-
-        let api = McpRuntimeApi::from_config(&manager, &defaults).expect("runtime api");
-
-        let available = api.available();
-        assert_eq!(available.len(), 2);
-
-        let stdio_summary = available
-            .iter()
-            .find(|entry| entry.name == "local-api")
-            .expect("stdio summary");
-        assert_eq!(stdio_summary.transport, McpRuntimeSummaryTransport::Stdio);
-        let stdio_tools = stdio_summary.tools.as_ref().expect("stdio tools");
-        assert_eq!(stdio_tools.enabled, vec!["fmt".to_string()]);
-        assert_eq!(stdio_tools.disabled, vec!["lint".to_string()]);
-
-        let stdio_launcher = api.stdio_launcher("local-api").expect("stdio launcher");
-        assert_eq!(stdio_launcher.args, vec!["--flag".to_string()]);
-        assert_eq!(stdio_launcher.timeout, Duration::from_millis(2400));
-        assert!(stdio_launcher.mirror_stdio);
-        assert_eq!(stdio_launcher.current_dir.as_deref(), Some(cwd.as_path()));
-
-        let env_map: HashMap<OsString, OsString> = stdio_launcher.env.into_iter().collect();
-        assert_eq!(
-            env_map.get(&OsString::from("CODEX_HOME")),
-            Some(&dir.path().as_os_str().to_os_string())
-        );
-        assert_eq!(
-            env_map.get(&OsString::from("DEFAULT_ONLY")),
-            Some(&OsString::from("default"))
-        );
-        assert_eq!(
-            env_map.get(&OsString::from(request_env_key)),
-            Some(&OsString::from("injected"))
-        );
-        assert_eq!(
-            env_map.get(&OsString::from(stdio_env_key)),
-            Some(&OsString::from("runtime-env"))
-        );
-
-        let http_connector = api.http_connector("remote-api").expect("http connector");
-        assert_eq!(http_connector.bearer_token.as_deref(), Some("token-api"));
-        assert_eq!(
-            http_connector
-                .headers
-                .get("Authorization")
-                .map(String::as_str),
-            Some("Bearer token-api")
-        );
-        assert_eq!(
-            http_connector.headers.get("X-Req").map(String::as_str),
-            Some("true")
-        );
-        assert_eq!(
-            http_connector.request_timeout,
-            Some(Duration::from_millis(2200))
-        );
-
-        let http_tools = available
-            .iter()
-            .find(|entry| entry.name == "remote-api")
-            .and_then(|entry| entry.tools.as_ref())
-            .expect("http tools");
-        assert_eq!(http_tools.enabled, vec!["alpha".to_string()]);
-        assert_eq!(http_tools.disabled, vec!["beta".to_string()]);
-
-        match api.stdio_launcher("remote-api") {
-            Err(McpRuntimeError::UnsupportedTransport {
-                name,
-                expected,
-                actual,
-            }) => {
-                assert_eq!(name, "remote-api");
-                assert_eq!(expected, "stdio");
-                assert_eq!(actual, "streamable_http");
-            }
-            other => panic!("unexpected result: {other:?}"),
-        }
-
-        match api.http_connector("local-api") {
-            Err(McpRuntimeError::UnsupportedTransport {
-                name,
-                expected,
-                actual,
-            }) => {
-                assert_eq!(name, "local-api");
-                assert_eq!(expected, "streamable_http");
-                assert_eq!(actual, "stdio");
-            }
-            other => panic!("unexpected http result: {other:?}"),
-        }
-
-        let after = fs::read_to_string(manager.config_path()).expect("read config after");
-        assert_eq!(before, after);
-
-        env::remove_var(http_env_key);
-        env::remove_var(request_env_key);
-    }
-
-    #[test]
-    fn runtime_api_prepare_http_is_non_destructive() {
-        let (dir, manager) = temp_config_manager();
-        let env_var = "MCP_RUNTIME_API_PREPARE";
-        env::set_var(env_var, "prepare-token");
-
-        let mut http = streamable_definition("https://example.test/prepare", env_var);
-        http.tags = vec!["prepare".into()];
-        http.tools = Some(McpToolConfig {
-            enabled: vec!["delta".into()],
-            disabled: vec![],
-        });
-
-        manager
-            .add_server(AddServerRequest {
-                name: "prepare-http".into(),
-                definition: http,
-                overwrite: false,
-                env: BTreeMap::new(),
-                bearer_token: None,
-            })
-            .expect("add http server");
-
-        let before = fs::read_to_string(manager.config_path()).expect("read config before");
-
-        let defaults = StdioServerConfig {
-            binary: PathBuf::from("codex"),
-            code_home: Some(dir.path().to_path_buf()),
-            current_dir: None,
-            env: Vec::new(),
-            app_server_analytics_default_enabled: false,
-            mirror_stdio: false,
-            startup_timeout: Duration::from_secs(2),
-        };
-
-        let api = McpRuntimeApi::from_config(&manager, &defaults).expect("runtime api");
-        let handle = api.prepare("prepare-http").expect("prepare http");
-
-        match handle {
-            McpRuntimeHandle::StreamableHttp(http_handle) => {
-                assert_eq!(http_handle.name, "prepare-http");
-                assert_eq!(
-                    http_handle.connector.bearer_token.as_deref(),
-                    Some("prepare-token")
-                );
-                assert_eq!(
-                    http_handle
-                        .connector
-                        .headers
-                        .get("Authorization")
-                        .map(String::as_str),
-                    Some("Bearer prepare-token")
-                );
-                let tools = http_handle.tools.expect("tool hints");
-                assert_eq!(tools.enabled, vec!["delta".to_string()]);
-            }
-            other => panic!("expected http handle, got {other:?}"),
-        }
-
-        let after = fs::read_to_string(manager.config_path()).expect("read config after");
-        assert_eq!(before, after);
-
-        env::remove_var(env_var);
-    }
-
-    #[test]
-    fn app_runtime_api_lists_and_merges_without_writes() {
-        let (dir, manager) = temp_config_manager();
-
-        let alpha_home = dir.path().join("app-home-a");
-        let alpha_cwd = dir.path().join("app-cwd-a");
-        let mut alpha_env = BTreeMap::new();
-        alpha_env.insert("APP_RUNTIME_ENV".into(), "alpha".into());
-        alpha_env.insert("OVERRIDE_ME".into(), "runtime".into());
-
-        manager
-            .add_app_runtime(AddAppRuntimeRequest {
-                name: "alpha".into(),
-                definition: AppRuntimeDefinition {
-                    description: Some("local app".into()),
-                    tags: vec!["local".into()],
-                    env: alpha_env,
-                    code_home: Some(alpha_home.clone()),
-                    current_dir: Some(alpha_cwd.clone()),
-                    mirror_stdio: Some(true),
-                    startup_timeout_ms: Some(4200),
-                    binary: Some(PathBuf::from("/bin/app-alpha")),
-                    metadata: serde_json::json!({"thread": "t-alpha"}),
-                },
-                overwrite: false,
-            })
-            .expect("add alpha app runtime");
-
-        let mut beta_env = BTreeMap::new();
-        beta_env.insert("APP_RUNTIME_ENV".into(), "beta".into());
-
-        manager
-            .add_app_runtime(AddAppRuntimeRequest {
-                name: "beta".into(),
-                definition: AppRuntimeDefinition {
-                    description: None,
-                    tags: vec!["default".into()],
-                    env: beta_env,
-                    code_home: None,
-                    current_dir: None,
-                    mirror_stdio: None,
-                    startup_timeout_ms: None,
-                    binary: None,
-                    metadata: serde_json::json!({"resume": true}),
-                },
-                overwrite: false,
-            })
-            .expect("add beta app runtime");
-
-        let before = fs::read_to_string(manager.config_path()).expect("read config before");
-
-        let default_home = dir.path().join("default-home");
-        let default_cwd = dir.path().join("default-cwd");
-        let defaults = StdioServerConfig {
-            binary: PathBuf::from("codex"),
-            code_home: Some(default_home.clone()),
-            current_dir: Some(default_cwd.clone()),
-            env: vec![
-                (OsString::from("DEFAULT_ONLY"), OsString::from("base")),
-                (OsString::from("OVERRIDE_ME"), OsString::from("base")),
-            ],
-            app_server_analytics_default_enabled: false,
-            mirror_stdio: false,
-            startup_timeout: Duration::from_secs(3),
-        };
-
-        let api = AppRuntimeApi::from_config(&manager, &defaults).expect("app runtime api");
-
-        let available = api.available();
-        assert_eq!(available.len(), 2);
-
-        let alpha_summary = available
-            .iter()
-            .find(|entry| entry.name == "alpha")
-            .expect("alpha summary");
-        assert_eq!(alpha_summary.description.as_deref(), Some("local app"));
-        assert_eq!(alpha_summary.tags, vec!["local".to_string()]);
-        assert_eq!(
-            alpha_summary.metadata,
-            serde_json::json!({"thread": "t-alpha"})
-        );
-
-        let alpha = api.prepare("alpha").expect("prepare alpha");
-        assert_eq!(alpha.name, "alpha");
-        assert_eq!(alpha.metadata, serde_json::json!({"thread": "t-alpha"}));
-        assert_eq!(alpha.config.binary, PathBuf::from("/bin/app-alpha"));
-        assert_eq!(
-            alpha.config.code_home.as_deref(),
-            Some(alpha_home.as_path())
-        );
-        assert_eq!(
-            alpha.config.current_dir.as_deref(),
-            Some(alpha_cwd.as_path())
-        );
-        assert!(alpha.config.mirror_stdio);
-        assert_eq!(alpha.config.startup_timeout, Duration::from_millis(4200));
-
-        let alpha_env: HashMap<OsString, OsString> = alpha.config.env.into_iter().collect();
-        assert_eq!(
-            alpha_env.get(&OsString::from("CODEX_HOME")),
-            Some(&alpha_home.as_os_str().to_os_string())
-        );
-        assert_eq!(
-            alpha_env.get(&OsString::from("DEFAULT_ONLY")),
-            Some(&OsString::from("base"))
-        );
-        assert_eq!(
-            alpha_env.get(&OsString::from("OVERRIDE_ME")),
-            Some(&OsString::from("runtime"))
-        );
-        assert_eq!(
-            alpha_env.get(&OsString::from("APP_RUNTIME_ENV")),
-            Some(&OsString::from("alpha"))
-        );
-
-        let beta = api.stdio_config("beta").expect("beta config");
-        assert_eq!(beta.binary, PathBuf::from("codex"));
-        assert_eq!(beta.code_home.as_deref(), Some(default_home.as_path()));
-        assert_eq!(beta.current_dir.as_deref(), Some(default_cwd.as_path()));
-        assert!(!beta.mirror_stdio);
-        assert_eq!(beta.startup_timeout, Duration::from_secs(3));
-
-        let beta_env: HashMap<OsString, OsString> = beta.env.into_iter().collect();
-        assert_eq!(
-            beta_env.get(&OsString::from("CODEX_HOME")),
-            Some(&default_home.as_os_str().to_os_string())
-        );
-        assert_eq!(
-            beta_env.get(&OsString::from("DEFAULT_ONLY")),
-            Some(&OsString::from("base"))
-        );
-        assert_eq!(
-            beta_env.get(&OsString::from("OVERRIDE_ME")),
-            Some(&OsString::from("base"))
-        );
-        assert_eq!(
-            beta_env.get(&OsString::from("APP_RUNTIME_ENV")),
-            Some(&OsString::from("beta"))
-        );
-
-        let beta_summary = available
-            .iter()
-            .find(|entry| entry.name == "beta")
-            .expect("beta summary");
-        assert_eq!(beta_summary.metadata, serde_json::json!({"resume": true}));
-
-        let after = fs::read_to_string(manager.config_path()).expect("read config after");
-        assert_eq!(before, after);
-    }
-
-    #[tokio::test]
-    async fn app_runtime_lifecycle_starts_and_stops_without_mutation() {
-        let (config_dir, manager) = temp_config_manager();
-        let (_server_dir, server_path) = write_fake_app_server();
-        let code_home = config_dir.path().join("app-lifecycle-home");
-
-        let mut env_map = BTreeMap::new();
-        env_map.insert("APP_RUNTIME_LIFECYCLE".into(), "runtime-env".into());
-
-        let metadata = serde_json::json!({"resume_thread": "thread-lifecycle"});
-        manager
-            .add_app_runtime(AddAppRuntimeRequest {
-                name: "lifecycle".into(),
-                definition: AppRuntimeDefinition {
-                    description: Some("app lifecycle".into()),
-                    tags: vec!["app".into()],
-                    env: env_map,
-                    code_home: None,
-                    current_dir: None,
-                    mirror_stdio: Some(true),
-                    startup_timeout_ms: Some(1500),
-                    binary: None,
-                    metadata: metadata.clone(),
-                },
-                overwrite: false,
-            })
-            .expect("add app runtime");
-
-        let defaults = StdioServerConfig {
-            binary: server_path.clone(),
-            code_home: Some(code_home.clone()),
-            current_dir: None,
-            env: vec![(
-                OsString::from("APP_RUNTIME_LIFECYCLE"),
-                OsString::from("default"),
-            )],
-            app_server_analytics_default_enabled: false,
-            mirror_stdio: false,
-            startup_timeout: Duration::from_secs(3),
-        };
-
-        let before = fs::read_to_string(manager.config_path()).expect("read config before");
-        let api = AppRuntimeApi::from_config(&manager, &defaults).expect("build api");
-        let client = test_client();
-
-        let runtime = api
-            .start("lifecycle", client.clone())
-            .await
-            .expect("start runtime");
-        assert_eq!(runtime.name, "lifecycle");
-        assert_eq!(runtime.metadata, metadata);
-
-        let env_values: HashMap<OsString, OsString> = runtime.config.env.iter().cloned().collect();
-        assert_eq!(
-            env_values.get(&OsString::from("CODEX_HOME")),
-            Some(&code_home.as_os_str().to_os_string())
-        );
-        assert_eq!(
-            env_values.get(&OsString::from("APP_RUNTIME_LIFECYCLE")),
-            Some(&OsString::from("runtime-env"))
-        );
-
-        let thread = runtime
-            .server
-            .thread_start(ThreadStartParams {
-                thread_id: None,
-                metadata: serde_json::json!({"from": "lifecycle"}),
-            })
-            .await
-            .expect("thread start");
-        let thread_response = time::timeout(Duration::from_secs(2), thread.response)
-            .await
-            .expect("thread response timeout")
-            .expect("recv thread response")
-            .expect("thread response ok");
-        let thread_id = thread_response
-            .get("thread_id")
-            .and_then(Value::as_str)
-            .unwrap_or_default()
-            .to_string();
-        assert!(!thread_id.is_empty());
-
-        runtime.stop().await.expect("shutdown runtime");
-
-        let after = fs::read_to_string(manager.config_path()).expect("read config after");
-        assert_eq!(before, after);
-
-        let prepared = api.prepare("lifecycle").expect("prepare after stop");
-        assert_eq!(prepared.metadata, metadata);
-    }
-
-    #[tokio::test]
-    async fn app_runtime_api_not_found_errors() {
-        let api = AppRuntimeApi::new(Vec::new());
-        match api.prepare("missing") {
-            Err(AppRuntimeError::NotFound(name)) => assert_eq!(name, "missing"),
-            other => panic!("unexpected result: {other:?}"),
-        }
-
-        let client = test_client();
-        match api.start("missing", client).await {
-            Err(AppRuntimeError::NotFound(name)) => assert_eq!(name, "missing"),
-            other => panic!("unexpected start result: {other:?}"),
-        }
-    }
-
-    #[tokio::test]
-    async fn app_runtime_pool_api_reuses_and_restarts_stdio() {
-        let (config_dir, manager) = temp_config_manager();
-        let (_server_dir, server_path) = write_fake_app_server();
-        let code_home = config_dir.path().join("app-pool-home");
-
-        let mut env_map = BTreeMap::new();
-        env_map.insert("APP_POOL_ENV".into(), "runtime".into());
-
-        let metadata = serde_json::json!({"resume_thread": "thread-pool"});
-        manager
-            .add_app_runtime(AddAppRuntimeRequest {
-                name: "pooled".into(),
-                definition: AppRuntimeDefinition {
-                    description: Some("pooled app".into()),
-                    tags: vec!["pool".into()],
-                    env: env_map,
-                    code_home: None,
-                    current_dir: None,
-                    mirror_stdio: Some(true),
-                    startup_timeout_ms: Some(2000),
-                    binary: None,
-                    metadata: metadata.clone(),
-                },
-                overwrite: false,
-            })
-            .expect("add app runtime");
-
-        let defaults = StdioServerConfig {
-            binary: server_path.clone(),
-            code_home: Some(code_home.clone()),
-            current_dir: None,
-            env: vec![
-                (OsString::from("APP_POOL_ENV"), OsString::from("default")),
-                (OsString::from("POOL_ONLY"), OsString::from("base")),
-            ],
-            app_server_analytics_default_enabled: false,
-            mirror_stdio: false,
-            startup_timeout: Duration::from_secs(3),
-        };
-
-        let before = fs::read_to_string(manager.config_path()).expect("read config before");
-        let api = AppRuntimePoolApi::from_config(&manager, &defaults).expect("build pool api");
-        let client = test_client();
-
-        let available = api.available();
-        assert_eq!(available.len(), 1);
-        let pooled_summary = &available[0];
-        assert_eq!(pooled_summary.name, "pooled");
-        assert_eq!(pooled_summary.metadata, metadata);
-
-        let launcher = api.launcher("pooled").expect("pooled launcher");
-        assert_eq!(launcher.description.as_deref(), Some("pooled app"));
-        assert_eq!(launcher.metadata, metadata);
-
-        let launcher_config = launcher.config.clone();
-        assert_eq!(launcher_config.binary, server_path);
-        assert_eq!(
-            launcher_config.code_home.as_deref(),
-            Some(code_home.as_path())
-        );
-        assert_eq!(launcher_config.startup_timeout, Duration::from_secs(2));
-
-        let launcher_env: HashMap<OsString, OsString> = launcher_config.env.into_iter().collect();
-        assert_eq!(
-            launcher_env.get(&OsString::from("CODEX_HOME")),
-            Some(&code_home.as_os_str().to_os_string())
-        );
-        assert_eq!(
-            launcher_env.get(&OsString::from("POOL_ONLY")),
-            Some(&OsString::from("base"))
-        );
-        assert_eq!(
-            launcher_env.get(&OsString::from("APP_POOL_ENV")),
-            Some(&OsString::from("runtime"))
-        );
-
-        let stdio_config = api
-            .stdio_config("pooled")
-            .expect("pooled stdio config without starting");
-        assert_eq!(stdio_config.binary, server_path);
-        assert_eq!(stdio_config.code_home.as_deref(), Some(code_home.as_path()));
-        let stdio_env: HashMap<OsString, OsString> = stdio_config.env.into_iter().collect();
-        assert_eq!(
-            stdio_env.get(&OsString::from("POOL_ONLY")),
-            Some(&OsString::from("base"))
-        );
-        assert_eq!(
-            stdio_env.get(&OsString::from("CODEX_HOME")),
-            Some(&code_home.as_os_str().to_os_string())
-        );
-        assert_eq!(
-            stdio_env.get(&OsString::from("APP_POOL_ENV")),
-            Some(&OsString::from("runtime"))
-        );
-
-        assert!(api.running().await.is_empty());
-
-        let runtime = api
-            .start("pooled", client.clone())
-            .await
-            .expect("start pooled runtime");
-        assert_eq!(runtime.name, "pooled");
-        assert_eq!(runtime.metadata, metadata);
-
-        let env_values: HashMap<OsString, OsString> = runtime.config.env.iter().cloned().collect();
-        assert_eq!(
-            env_values.get(&OsString::from("CODEX_HOME")),
-            Some(&code_home.as_os_str().to_os_string())
-        );
-        assert_eq!(
-            env_values.get(&OsString::from("POOL_ONLY")),
-            Some(&OsString::from("base"))
-        );
-        assert_eq!(
-            env_values.get(&OsString::from("APP_POOL_ENV")),
-            Some(&OsString::from("runtime"))
-        );
-
-        let thread = runtime
-            .server
-            .thread_start(ThreadStartParams {
-                thread_id: None,
-                metadata: serde_json::json!({"from": "pool"}),
-            })
-            .await
-            .expect("thread start");
-        let response = time::timeout(Duration::from_secs(2), thread.response)
-            .await
-            .expect("thread response timeout")
-            .expect("recv thread response")
-            .expect("thread response ok");
-        let thread_id = response
-            .get("thread_id")
-            .and_then(Value::as_str)
-            .unwrap_or_default()
-            .to_string();
-        assert!(!thread_id.is_empty());
-
-        let running = api.running().await;
-        let running_summary = running
-            .iter()
-            .find(|summary| summary.name == "pooled")
-            .expect("running summary present");
-        assert_eq!(running_summary.metadata, metadata);
-
-        let reused = api
-            .start("pooled", client.clone())
-            .await
-            .expect("reuse pooled runtime");
-        assert!(Arc::ptr_eq(&runtime, &reused));
-
-        api.stop("pooled").await.expect("stop pooled runtime");
-        match api.stop("pooled").await {
-            Err(AppRuntimeError::NotFound(name)) => assert_eq!(name, "pooled"),
-            other => panic!("expected not found on second stop, got {other:?}"),
-        }
-
-        assert!(api.running().await.is_empty());
-
-        let restarted = api
-            .start("pooled", client)
-            .await
-            .expect("restart pooled runtime");
-        assert!(!Arc::ptr_eq(&runtime, &restarted));
-        assert_eq!(restarted.metadata, metadata);
-
-        let prepared = api.prepare("pooled").expect("prepare after restart");
-        assert_eq!(prepared.metadata, metadata);
-
-        let after = fs::read_to_string(manager.config_path()).expect("read config after");
-        assert_eq!(before, after);
-    }
-
-    #[tokio::test]
-    async fn app_runtime_pool_api_stop_all_shuts_down_runtimes() {
-        let (config_dir, manager) = temp_config_manager();
-        let (_server_dir, server_path) = write_fake_app_server();
-        let code_home = config_dir.path().join("app-pool-stop-home");
-
-        let alpha_metadata = serde_json::json!({"resume_thread": "alpha"});
-        manager
-            .add_app_runtime(AddAppRuntimeRequest {
-                name: "alpha".into(),
-                definition: AppRuntimeDefinition {
-                    description: Some("alpha runtime".into()),
-                    tags: vec!["pool".into()],
-                    env: BTreeMap::new(),
-                    code_home: None,
-                    current_dir: None,
-                    mirror_stdio: Some(false),
-                    startup_timeout_ms: Some(2000),
-                    binary: None,
-                    metadata: alpha_metadata.clone(),
-                },
-                overwrite: false,
-            })
-            .expect("add alpha runtime");
-
-        let beta_metadata = serde_json::json!({"resume_thread": "beta"});
-        manager
-            .add_app_runtime(AddAppRuntimeRequest {
-                name: "beta".into(),
-                definition: AppRuntimeDefinition {
-                    description: Some("beta runtime".into()),
-                    tags: vec!["pool".into()],
-                    env: BTreeMap::new(),
-                    code_home: None,
-                    current_dir: None,
-                    mirror_stdio: Some(false),
-                    startup_timeout_ms: Some(2000),
-                    binary: None,
-                    metadata: beta_metadata.clone(),
-                },
-                overwrite: false,
-            })
-            .expect("add beta runtime");
-
-        let defaults = StdioServerConfig {
-            binary: server_path.clone(),
-            code_home: Some(code_home.clone()),
-            current_dir: None,
-            env: Vec::new(),
-            app_server_analytics_default_enabled: false,
-            mirror_stdio: false,
-            startup_timeout: Duration::from_secs(3),
-        };
-
-        let before = fs::read_to_string(manager.config_path()).expect("read config before");
-        let api = AppRuntimePoolApi::from_config(&manager, &defaults).expect("build pool api");
-        let client = test_client();
-
-        assert!(api.running().await.is_empty());
-
-        let alpha = api
-            .start("alpha", client.clone())
-            .await
-            .expect("start alpha runtime");
-        let beta = api
-            .start("beta", client.clone())
-            .await
-            .expect("start beta runtime");
-
-        assert_eq!(alpha.metadata, alpha_metadata);
-        assert_eq!(beta.metadata, beta_metadata);
-
-        let mut running = api.running().await;
-        running.sort_by(|a, b| a.name.cmp(&b.name));
-        assert_eq!(running.len(), 2);
-        assert_eq!(running[0].name, "alpha");
-        assert_eq!(running[0].metadata, alpha_metadata);
-        assert_eq!(running[1].name, "beta");
-        assert_eq!(running[1].metadata, beta_metadata);
-
-        let alpha_thread = alpha
-            .server
-            .thread_start(ThreadStartParams {
-                thread_id: None,
-                metadata: serde_json::json!({"from": "alpha"}),
-            })
-            .await
-            .expect("alpha thread start");
-        let _ = time::timeout(Duration::from_secs(2), alpha_thread.response)
-            .await
-            .expect("alpha thread response timeout")
-            .expect("alpha response recv")
-            .expect("alpha ok");
-
-        api.stop_all().await.expect("stop all runtimes");
-        assert!(api.running().await.is_empty());
-
-        let restarted_alpha = api
-            .start("alpha", client.clone())
-            .await
-            .expect("restart alpha");
-        assert!(!Arc::ptr_eq(&alpha, &restarted_alpha));
-        assert_eq!(restarted_alpha.metadata, alpha_metadata);
-
-        let restarted_beta = api.start("beta", client).await.expect("restart beta");
-        assert!(!Arc::ptr_eq(&beta, &restarted_beta));
-        assert_eq!(restarted_beta.metadata, beta_metadata);
-
-        let prepared_alpha = api.prepare("alpha").expect("prepare alpha");
-        assert_eq!(prepared_alpha.metadata, alpha_metadata);
-        let prepared_beta = api.prepare("beta").expect("prepare beta");
-        assert_eq!(prepared_beta.metadata, beta_metadata);
-
-        let after = fs::read_to_string(manager.config_path()).expect("read config after");
-        assert_eq!(before, after);
-    }
-
-    #[tokio::test]
-    async fn runtime_manager_starts_and_stops_stdio() {
-        let (_dir, script) = write_env_probe_server("MCP_RUNTIME_ENV_E8");
-        let code_home = tempfile::tempdir().expect("code_home");
-
-        let defaults = StdioServerConfig {
-            binary: PathBuf::from("codex"),
-            code_home: Some(code_home.path().to_path_buf()),
-            current_dir: None,
-            env: vec![(
-                OsString::from("MCP_RUNTIME_ENV_E8"),
-                OsString::from("manager-ok"),
-            )],
-            app_server_analytics_default_enabled: false,
-            mirror_stdio: false,
-            startup_timeout: Duration::from_secs(5),
-        };
-
-        let runtime = McpRuntimeServer {
-            name: "env-probe".into(),
-            transport: McpRuntimeTransport::Stdio(StdioServerDefinition {
-                command: script.to_string_lossy().to_string(),
-                args: Vec::new(),
-                env: BTreeMap::new(),
-                timeout_ms: Some(1500),
-            }),
-            description: None,
-            tags: vec!["local".into()],
-            tools: Some(McpToolConfig {
-                enabled: vec!["tool-x".into()],
-                disabled: vec![],
-            }),
-        };
-
-        let launcher = runtime.into_launcher(&defaults);
-        let manager = McpRuntimeManager::new(vec![launcher]);
-
-        let mut handle = match manager.prepare("env-probe").expect("prepare stdio") {
-            McpRuntimeHandle::Stdio(handle) => handle,
-            other => panic!("expected stdio handle, got {other:?}"),
-        };
-
-        let mut reader = BufReader::new(handle.stdout_mut());
-        let mut line = String::new();
-        let _ = time::timeout(Duration::from_secs(2), reader.read_line(&mut line))
-            .await
-            .expect("read timeout")
-            .expect("read env line");
-        assert_eq!(line.trim(), "manager-ok");
-
-        let tools = handle.tools().expect("tool hints");
-        assert_eq!(tools.enabled, vec!["tool-x".to_string()]);
-
-        handle.stop().await.expect("stop server");
-    }
-
-    #[test]
-    fn runtime_manager_propagates_tool_hints_for_http() {
-        let env_var = "MCP_HTTP_TOKEN_E8_HINTS";
-        env::set_var(env_var, "token-hints");
-
-        let mut http = StreamableHttpDefinition {
-            url: "https://example.test/hints".into(),
-            headers: BTreeMap::new(),
-            bearer_env_var: Some(env_var.to_string()),
-            connect_timeout_ms: Some(1200),
-            request_timeout_ms: Some(2400),
-        };
-        http.headers.insert("X-Test".into(), "true".into());
-
-        let runtime = McpRuntimeServer::from_definition(
-            "remote-http",
-            McpServerDefinition {
-                transport: McpTransport::StreamableHttp(http),
-                description: Some("http runtime".into()),
-                tags: vec!["http".into()],
-                tools: Some(McpToolConfig {
-                    enabled: vec!["alpha".into()],
-                    disabled: vec!["beta".into()],
-                }),
-            },
-        );
-
-        let defaults = StdioServerConfig {
-            binary: PathBuf::from("codex"),
-            code_home: None,
-            current_dir: None,
-            env: Vec::new(),
-            app_server_analytics_default_enabled: false,
-            mirror_stdio: false,
-            startup_timeout: Duration::from_secs(2),
-        };
-
-        let launcher = runtime.into_launcher(&defaults);
-        let manager = McpRuntimeManager::new(vec![launcher]);
-
-        let available = manager.available();
-        assert_eq!(available.len(), 1);
-        let summary = &available[0];
-        assert_eq!(summary.name, "remote-http");
-        assert_eq!(
-            summary.transport,
-            McpRuntimeSummaryTransport::StreamableHttp
-        );
-        let summary_tools = summary.tools.as_ref().expect("tool hints present");
-        assert_eq!(summary_tools.enabled, vec!["alpha".to_string()]);
-        assert_eq!(summary_tools.disabled, vec!["beta".to_string()]);
-
-        match manager.prepare("remote-http").expect("prepare http") {
-            McpRuntimeHandle::StreamableHttp(http_handle) => {
-                let tools = http_handle.tools.as_ref().expect("tool hints on handle");
-                assert_eq!(tools.enabled, vec!["alpha".to_string()]);
-                assert_eq!(tools.disabled, vec!["beta".to_string()]);
-                assert_eq!(
-                    http_handle.connector.bearer_token.as_deref(),
-                    Some("token-hints")
-                );
-            }
-            other => panic!("expected http handle, got {other:?}"),
-        }
-
-        env::remove_var(env_var);
-    }
-
-    #[test]
-    fn http_connector_retrieval_is_non_destructive() {
-        let env_var = "MCP_HTTP_TOKEN_E8_REUSE";
-        env::set_var(env_var, "token-reuse");
-
-        let runtime = McpRuntimeServer::from_definition(
-            "remote-reuse",
-            McpServerDefinition {
-                transport: McpTransport::StreamableHttp(StreamableHttpDefinition {
-                    url: "https://example.test/reuse".into(),
-                    headers: BTreeMap::new(),
-                    bearer_env_var: Some(env_var.to_string()),
-                    connect_timeout_ms: Some(1500),
-                    request_timeout_ms: Some(3200),
-                }),
-                description: None,
-                tags: vec!["http".into()],
-                tools: Some(McpToolConfig {
-                    enabled: vec!["one".into()],
-                    disabled: vec![],
-                }),
-            },
-        );
-
-        let defaults = StdioServerConfig {
-            binary: PathBuf::from("codex"),
-            code_home: None,
-            current_dir: None,
-            env: Vec::new(),
-            app_server_analytics_default_enabled: false,
-            mirror_stdio: false,
-            startup_timeout: Duration::from_secs(2),
-        };
-
-        let launcher = runtime.into_launcher(&defaults);
-        let manager = McpRuntimeManager::new(vec![launcher]);
-
-        let first = manager.prepare("remote-reuse").expect("first prepare");
-        let second = manager.prepare("remote-reuse").expect("second prepare");
-
-        let first_token = match first {
-            McpRuntimeHandle::StreamableHttp(handle) => handle.connector.bearer_token,
-            other => panic!("expected http handle, got {other:?}"),
-        };
-        let second_token = match second {
-            McpRuntimeHandle::StreamableHttp(handle) => handle.connector.bearer_token,
-            other => panic!("expected http handle, got {other:?}"),
-        };
-
-        assert_eq!(first_token.as_deref(), Some("token-reuse"));
-        assert_eq!(second_token.as_deref(), Some("token-reuse"));
-
-        let summary = manager
-            .available()
-            .into_iter()
-            .find(|s| s.name == "remote-reuse")
-            .expect("summary present");
-        assert_eq!(
-            summary.transport,
-            McpRuntimeSummaryTransport::StreamableHttp
-        );
-        let tools = summary.tools.as_ref().expect("tool hints preserved");
-        assert_eq!(tools.enabled, vec!["one".to_string()]);
-
-        env::remove_var(env_var);
-    }
-}
+mod test_support;
+#[cfg(test)]
+mod tests_core;
+#[cfg(test)]
+mod tests_runtime_app;
diff --git a/crates/codex/src/mcp/client.rs b/crates/codex/src/mcp/client.rs
new file mode 100644
index 0000000..6118e6e
--- /dev/null
+++ b/crates/codex/src/mcp/client.rs
@@ -0,0 +1,240 @@
+use std::{io, sync::Arc, time::Duration};
+
+use serde_json::{json, Value};
+use thiserror::Error;
+
+use super::{
+    AppCallHandle, ApprovalDecision, ClientInfo, CodexCallHandle, CodexCallParams, CodexCallResult,
+    CodexReplyParams, InitializeParams, RequestId, StdioServerConfig, METHOD_CODEX,
+    METHOD_CODEX_APPROVAL, METHOD_THREAD_RESUME, METHOD_THREAD_START, METHOD_TURN_INTERRUPT,
+    METHOD_TURN_START,
+};
+
+use super::jsonrpc::{map_response, JsonRpcTransport};
+
+/// Errors surfaced while managing MCP/app-server transports.
+#[derive(Debug, Error)]
+pub enum McpError {
+    #[error("failed to spawn `{command}`: {source}")]
+    Spawn {
+        command: String,
+        #[source]
+        source: io::Error,
+    },
+    #[error("server did not respond to initialize: {0}")]
+    Handshake(String),
+    #[error("transport task failed: {0}")]
+    Transport(String),
+    #[error("server returned JSON-RPC error {code}: {message}")]
+    Rpc {
+        code: i64,
+        message: String,
+        data: Option<Value>,
+    },
+    #[error("server reported an error: {0}")]
+    Server(String),
+    #[error("request was cancelled")]
+    Cancelled,
+    #[error("timed out after {0:?}")]
+    Timeout(Duration),
+    #[error("serialization failed: {0}")]
+    Serialization(#[from] serde_json::Error),
+    #[error("transport channel closed unexpectedly")]
+    ChannelClosed,
+}
+
+/// Client wrapper around the stdio MCP server.
+pub struct CodexMcpServer {
+    transport: Arc<JsonRpcTransport>,
+}
+
+impl CodexMcpServer {
+    /// Launch `codex mcp-server`, issue `initialize`, and return a connected handle.
+    pub async fn start(config: StdioServerConfig, client: ClientInfo) -> Result<Self, McpError> {
+        Self::with_capabilities(config, client, Value::Object(Default::default())).await
+    }
+
+    /// Launch with explicit capabilities to send during `initialize`.
+    pub async fn with_capabilities(
+        config: StdioServerConfig,
+        client: ClientInfo,
+        capabilities: Value,
+    ) -> Result<Self, McpError> {
+        let capabilities = match capabilities {
+            Value::Null => Value::Object(Default::default()),
+            other => other,
+        };
+        let transport = JsonRpcTransport::spawn_mcp(config).await?;
+        let params = InitializeParams {
+            client,
+            protocol_version: "2024-11-05".to_string(),
+            capabilities,
+        };
+
+        transport
+            .initialize(params, transport.startup_timeout())
+            .await
+            .map_err(|err| McpError::Handshake(err.to_string()))?;
+
+        Ok(Self {
+            transport: Arc::new(transport),
+        })
+    }
+
+    /// Send a new Codex prompt via `codex/codex`.
+    pub async fn codex(&self, params: CodexCallParams) -> Result<CodexCallHandle, McpError> {
+        self.invoke_tool_call("codex", serde_json::to_value(params)?)
+            .await
+    }
+
+    /// Continue an existing conversation via `codex/codex-reply`.
+    pub async fn codex_reply(&self, params: CodexReplyParams) -> Result<CodexCallHandle, McpError> {
+        self.invoke_tool_call("codex-reply", serde_json::to_value(params)?)
+            .await
+    }
+
+    /// Send an approval decision back to the MCP server.
+    pub async fn send_approval(&self, decision: ApprovalDecision) -> Result<(), McpError> {
+        let (_, rx) = self
+            .transport
+            .request(METHOD_CODEX_APPROVAL, serde_json::to_value(decision)?)
+            .await?;
+
+        match rx.await {
+            Ok(Ok(_)) => Ok(()),
+            Ok(Err(err)) => Err(err),
+            Err(_) => Err(McpError::ChannelClosed),
+        }
+    }
+
+    /// Request cancellation for a pending call.
+    pub fn cancel(&self, request_id: RequestId) -> Result<(), McpError> {
+        self.transport.cancel(request_id)
+    }
+
+    /// Gracefully shut down the MCP server.
+    pub async fn shutdown(&self) -> Result<(), McpError> {
+        self.transport.shutdown().await
+    }
+
+    async fn invoke_tool_call(
+        &self,
+        tool_name: &str,
+        arguments: Value,
+    ) -> Result<CodexCallHandle, McpError> {
+        let events = self.transport.register_codex_listener().await;
+        let request = json!({
+            "name": tool_name,
+            "arguments": arguments,
+        });
+        let (request_id, raw_response) = self.transport.request(METHOD_CODEX, request).await?;
+        let response = map_response::<CodexCallResult>(raw_response);
+
+        Ok(CodexCallHandle {
+            request_id,
+            events,
+            response,
+        })
+    }
+}
+
+/// Client wrapper around the stdio app-server.
+pub struct CodexAppServer {
+    transport: Arc<JsonRpcTransport>,
+}
+
+impl CodexAppServer {
+    /// Launch `codex app-server`, issue `initialize`, and return a connected handle.
+    pub async fn start(config: StdioServerConfig, client: ClientInfo) -> Result<Self, McpError> {
+        Self::with_capabilities(config, client, Value::Object(Default::default())).await
+    }
+
+    /// Launch with explicit capabilities to send during `initialize`.
+    pub async fn with_capabilities(
+        config: StdioServerConfig,
+        client: ClientInfo,
+        capabilities: Value,
+    ) -> Result<Self, McpError> {
+        let capabilities = match capabilities {
+            Value::Null => Value::Object(Default::default()),
+            other => other,
+        };
+        let transport = JsonRpcTransport::spawn_app(config).await?;
+        let params = InitializeParams {
+            client,
+            protocol_version: "2024-11-05".to_string(),
+            capabilities,
+        };
+
+        transport
+            .initialize(params, transport.startup_timeout())
+            .await
+            .map_err(|err| McpError::Handshake(err.to_string()))?;
+
+        Ok(Self {
+            transport: Arc::new(transport),
+        })
+    }
+
+    /// Start a new thread (or use a provided ID) via `thread/start`.
+    pub async fn thread_start(
+        &self,
+        params: super::ThreadStartParams,
+    ) -> Result<AppCallHandle, McpError> {
+        self.invoke_app_call(METHOD_THREAD_START, serde_json::to_value(params)?)
+            .await
+    }
+
+    /// Resume an existing thread via `thread/resume`.
+    pub async fn thread_resume(
+        &self,
+        params: super::ThreadResumeParams,
+    ) -> Result<AppCallHandle, McpError> {
+        self.invoke_app_call(METHOD_THREAD_RESUME, serde_json::to_value(params)?)
+            .await
+    }
+
+    /// Start a new turn on a thread via `turn/start`.
+    pub async fn turn_start(
+        &self,
+        params: super::TurnStartParams,
+    ) -> Result<AppCallHandle, McpError> {
+        self.invoke_app_call(METHOD_TURN_START, serde_json::to_value(params)?)
+            .await
+    }
+
+    /// Interrupt an active turn via `turn/interrupt`.
+    pub async fn turn_interrupt(
+        &self,
+        params: super::TurnInterruptParams,
+    ) -> Result<AppCallHandle, McpError> {
+        self.invoke_app_call(METHOD_TURN_INTERRUPT, serde_json::to_value(params)?)
+            .await
+    }
+
+    /// Request cancellation for a pending call.
+    pub fn cancel(&self, request_id: RequestId) -> Result<(), McpError> {
+        self.transport.cancel(request_id)
+    }
+
+    /// Gracefully shut down the app-server.
+    pub async fn shutdown(&self) -> Result<(), McpError> {
+        self.transport.shutdown().await
+    }
+
+    async fn invoke_app_call(
+        &self,
+        method: &str,
+        params: Value,
+    ) -> Result<AppCallHandle, McpError> {
+        let events = self.transport.register_app_listener().await;
+        let (request_id, raw_response) = self.transport.request(method, params).await?;
+        let response = map_response::<Value>(raw_response);
+
+        Ok(AppCallHandle {
+            request_id,
+            events,
+            response,
+        })
+    }
+}
diff --git a/crates/codex/src/mcp/test_support.rs b/crates/codex/src/mcp/test_support.rs
new file mode 100644
index 0000000..f45ee44
--- /dev/null
+++ b/crates/codex/src/mcp/test_support.rs
@@ -0,0 +1,293 @@
+use super::*;
+
+pub(super) mod prelude {
+    pub(crate) use serde_json::Value;
+    pub(crate) use std::{
+        collections::{BTreeMap, HashMap},
+        env,
+        ffi::OsString,
+        fs,
+        os::unix::fs::PermissionsExt,
+        path::PathBuf,
+        sync::Arc,
+        time::Duration,
+    };
+    pub(crate) use tokio::{
+        io::{AsyncBufReadExt, BufReader},
+        time,
+    };
+    pub(crate) use toml::Value as TomlValue;
+}
+
+use prelude::*;
+
+pub(super) fn temp_config_manager() -> (tempfile::TempDir, McpConfigManager) {
+    let dir = tempfile::tempdir().expect("tempdir");
+    let manager = McpConfigManager::from_code_home(dir.path());
+    (dir, manager)
+}
+
+pub(super) fn stdio_definition(command: &str) -> McpServerDefinition {
+    McpServerDefinition {
+        transport: McpTransport::Stdio(StdioServerDefinition {
+            command: command.to_string(),
+            args: Vec::new(),
+            env: BTreeMap::new(),
+            timeout_ms: Some(1500),
+        }),
+        description: None,
+        tags: Vec::new(),
+        tools: None,
+    }
+}
+
+pub(super) fn streamable_definition(url: &str, bearer_var: &str) -> McpServerDefinition {
+    McpServerDefinition {
+        transport: McpTransport::StreamableHttp(StreamableHttpDefinition {
+            url: url.to_string(),
+            headers: BTreeMap::new(),
+            bearer_env_var: Some(bearer_var.to_string()),
+            connect_timeout_ms: Some(5000),
+            request_timeout_ms: Some(5000),
+        }),
+        description: None,
+        tags: Vec::new(),
+        tools: Some(McpToolConfig {
+            enabled: vec![],
+            disabled: vec![],
+        }),
+    }
+}
+
+pub(super) fn write_fake_mcp_server() -> (tempfile::TempDir, PathBuf) {
+    let dir = tempfile::tempdir().expect("tempdir");
+    let script_path = dir.path().join("fake-codex");
+    let script = r#"#!/usr/bin/env python3
+import json
+import sys
+import threading
+import time
+
+pending = {}
+
+def send(payload):
+    sys.stdout.write(json.dumps(payload) + "\n")
+    sys.stdout.flush()
+
+def mark_cancelled(target, reason="cancelled"):
+    if target is None:
+        return
+    state = pending.get(str(target)) or {}
+    conv_id = state.get("conversation_id")
+    pending[str(target)] = {"status": "cancelled", "conversation_id": conv_id}
+    if conv_id:
+        send({"jsonrpc": "2.0", "method": "codex/event", "params": {"type": "cancelled", "conversation_id": conv_id, "reason": reason}})
+    send({"jsonrpc": "2.0", "id": target, "error": {"code": -32800, "message": reason}})
+
+def handle_codex(req_id, params):
+    conversation_id = params.get("conversation_id") or params.get("conversationId") or f"conv-{req_id}"
+    pending[str(req_id)] = {"status": "pending", "conversation_id": conversation_id}
+    def worker():
+        time.sleep(0.05)
+        state = pending.get(str(req_id))
+        if not state or state.get("status") == "cancelled":
+            return
+        send({"jsonrpc": "2.0", "method": "codex/event", "params": {"type": "approval_required", "approval_id": f"ap-{req_id}", "kind": "exec"}})
+        time.sleep(0.05)
+        state = pending.get(str(req_id))
+        if not state or state.get("status") == "cancelled":
+            return
+        send({"jsonrpc": "2.0", "method": "codex/event", "params": {"type": "task_complete", "conversation_id": conversation_id, "result": {"ok": True}}})
+        send({"jsonrpc": "2.0", "id": req_id, "result": {"conversation_id": conversation_id, "output": {"ok": True}}})
+        pending.pop(str(req_id), None)
+    threading.Thread(target=worker, daemon=True).start()
+
+for line in sys.stdin:
+    if not line.strip():
+        continue
+    msg = json.loads(line)
+    method = msg.get("method")
+    if method == "initialize":
+        send({"jsonrpc": "2.0", "id": msg.get("id"), "result": {"ready": True}})
+    elif method == "tools/call":
+        params = msg.get("params", {})
+        tool = params.get("name")
+        args = params.get("arguments", {})
+        if tool in ["codex", "codex-reply"]:
+            handle_codex(msg.get("id"), args)
+    elif method == "$/cancelRequest":
+        target = msg.get("params", {}).get("id")
+        mark_cancelled(target, reason="client_cancel")
+    elif method == "shutdown":
+        send({"jsonrpc": "2.0", "id": msg.get("id"), "result": {"ok": True}})
+        break
+    elif method == "exit":
+        break
+"#;
+
+    fs::write(&script_path, script).expect("write script");
+    let mut perms = fs::metadata(&script_path).expect("metadata").permissions();
+    perms.set_mode(0o755);
+    fs::set_permissions(&script_path, perms).expect("chmod");
+    (dir, script_path)
+}
+
+pub(super) fn write_fake_app_server() -> (tempfile::TempDir, PathBuf) {
+    let dir = tempfile::tempdir().expect("tempdir");
+    let script_path = dir.path().join("fake-codex-app");
+    let script = r#"#!/usr/bin/env python3
+import json
+import os
+import sys
+import threading
+import time
+
+pending = {}
+turn_lookup = {}
+
+log_path = os.environ.get("ARGV_LOG")
+if log_path:
+    with open(log_path, "w", encoding="utf-8") as fh:
+        fh.write(json.dumps(sys.argv[1:]) + "\n")
+
+def send(payload):
+    sys.stdout.write(json.dumps(payload) + "\n")
+    sys.stdout.flush()
+
+def mark_cancelled(req_id, reason="cancelled"):
+    if req_id is None:
+        return
+    state = pending.get(str(req_id)) or {}
+    thread_id = state.get("thread_id") or "thread-unknown"
+    turn_id = state.get("turn_id")
+    pending[str(req_id)] = {"status": "cancelled", "thread_id": thread_id, "turn_id": turn_id}
+    if turn_id:
+        send({"jsonrpc": "2.0", "method": "task/notification", "params": {"type": "task_complete", "thread_id": thread_id, "turn_id": turn_id, "result": {"cancelled": True, "reason": reason}}})
+    send({"jsonrpc": "2.0", "id": req_id, "error": {"code": -32800, "message": reason}})
+
+def handle_turn(req_id, params):
+    thread_id = params.get("threadId") or params.get("thread_id") or "thread-unknown"
+    turn_id = params.get("turnId") or params.get("turn_id") or f"turn-{req_id}"
+    pending[str(req_id)] = {"status": "pending", "thread_id": thread_id, "turn_id": turn_id}
+    turn_lookup[turn_id] = req_id
+
+    def worker():
+        time.sleep(0.05)
+        state = pending.get(str(req_id))
+        if not state or state.get("status") == "cancelled":
+            return
+        send({"jsonrpc": "2.0", "method": "task/notification", "params": {"type": "item", "thread_id": thread_id, "turn_id": turn_id, "item": {"message": "processing"}}})
+        time.sleep(0.05)
+        state = pending.get(str(req_id))
+        if not state or state.get("status") == "cancelled":
+            return
+        send({"jsonrpc": "2.0", "method": "task/notification", "params": {"type": "task_complete", "thread_id": thread_id, "turn_id": turn_id, "result": {"ok": True}}})
+        send({"jsonrpc": "2.0", "id": req_id, "result": {"turn_id": turn_id, "accepted": True}})
+        pending.pop(str(req_id), None)
+        turn_lookup.pop(turn_id, None)
+
+    threading.Thread(target=worker, daemon=True).start()
+
+for line in sys.stdin:
+    if not line.strip():
+        continue
+    msg = json.loads(line)
+    method = msg.get("method")
+    if method == "initialize":
+        send({"jsonrpc": "2.0", "id": msg.get("id"), "result": {"ready": True}})
+    elif method == "thread/start":
+        params = msg.get("params", {})
+        thread_id = params.get("thread_id") or f"thread-{msg.get('id')}"
+        send({"jsonrpc": "2.0", "id": msg.get("id"), "result": {"thread_id": thread_id}})
+    elif method == "thread/resume":
+        params = msg.get("params", {})
+        thread_id = params.get("threadId") or params.get("thread_id")
+        send({"jsonrpc": "2.0", "id": msg.get("id"), "result": {"thread_id": thread_id, "resumed": True}})
+    elif method == "turn/start":
+        handle_turn(msg.get("id"), msg.get("params", {}))
+    elif method == "turn/interrupt":
+        params = msg.get("params", {})
+        turn_id = params.get("turnId") or params.get("turn_id")
+        req_id = turn_lookup.get(turn_id)
+        if req_id:
+            mark_cancelled(req_id, reason="interrupted")
+            turn_lookup.pop(turn_id, None)
+            pending.pop(str(req_id), None)
+        send({"jsonrpc": "2.0", "id": msg.get("id"), "result": {"interrupted": True}})
+    elif method == "$/cancelRequest":
+        target = msg.get("params", {}).get("id")
+        mark_cancelled(target, reason="client_cancel")
+    elif method == "shutdown":
+        send({"jsonrpc": "2.0", "id": msg.get("id"), "result": {"ok": True}})
+        break
+    elif method == "exit":
+        break
+"#;
+
+    fs::write(&script_path, script).expect("write script");
+    let mut perms = fs::metadata(&script_path).expect("metadata").permissions();
+    perms.set_mode(0o755);
+    fs::set_permissions(&script_path, perms).expect("chmod");
+    (dir, script_path)
+}
+
+pub(super) fn write_env_probe_server(var: &str) -> (tempfile::TempDir, PathBuf) {
+    let dir = tempfile::tempdir().expect("tempdir");
+    let script_path = dir.path().join("env-probe-server");
+    let script = format!(
+        r#"#!/usr/bin/env python3
+import os
+import sys
+import time
+
+sys.stdout.write(os.environ.get("{var}", "") + "\n")
+sys.stdout.flush()
+time.sleep(30)
+"#
+    );
+
+    fs::write(&script_path, script).expect("write script");
+    let mut perms = fs::metadata(&script_path).expect("metadata").permissions();
+    perms.set_mode(0o755);
+    fs::set_permissions(&script_path, perms).expect("chmod");
+    (dir, script_path)
+}
+
+pub(super) fn test_config(binary: PathBuf) -> StdioServerConfig {
+    StdioServerConfig {
+        binary,
+        code_home: None,
+        current_dir: None,
+        env: Vec::new(),
+        app_server_analytics_default_enabled: false,
+        mirror_stdio: false,
+        startup_timeout: Duration::from_secs(5),
+    }
+}
+
+pub(super) fn test_client() -> ClientInfo {
+    ClientInfo {
+        name: "tests".to_string(),
+        version: "0.0.0".to_string(),
+    }
+}
+
+pub(super) async fn start_fake_mcp_server() -> (tempfile::TempDir, CodexMcpServer) {
+    let (dir, script) = write_fake_mcp_server();
+    let config = test_config(script);
+    let client = test_client();
+    let server = CodexMcpServer::start(config, client)
+        .await
+        .expect("spawn mcp server");
+    (dir, server)
+}
+
+pub(super) async fn start_fake_app_server() -> (tempfile::TempDir, CodexAppServer) {
+    let (dir, script) = write_fake_app_server();
+    let config = test_config(script);
+    let client = test_client();
+    let server = CodexAppServer::start(config, client)
+        .await
+        .expect("spawn app server");
+    (dir, server)
+}
diff --git a/crates/codex/src/mcp/tests_core.rs b/crates/codex/src/mcp/tests_core.rs
new file mode 100644
index 0000000..f73a948
--- /dev/null
+++ b/crates/codex/src/mcp/tests_core.rs
@@ -0,0 +1,982 @@
+use super::test_support::{prelude::*, *};
+use super::*;
+
+#[tokio::test]
+async fn app_server_launch_can_enable_analytics_flag() {
+    let (dir, script) = write_fake_app_server();
+    let log_path = dir.path().join("argv.json");
+
+    let mut config = test_config(script);
+    config.app_server_analytics_default_enabled = true;
+    config.env.push((
+        OsString::from("ARGV_LOG"),
+        OsString::from(log_path.as_os_str()),
+    ));
+
+    let client = test_client();
+    let server = CodexAppServer::start(config, client)
+        .await
+        .expect("spawn app server");
+
+    let mut argv_line = None;
+    for _ in 0..50 {
+        if let Ok(contents) = fs::read_to_string(&log_path) {
+            argv_line = contents.lines().next().map(str::to_string);
+            break;
+        }
+        tokio::time::sleep(Duration::from_millis(5)).await;
+    }
+
+    let argv_line = argv_line.expect("argv log should be written");
+    let argv: Vec<String> = serde_json::from_str(&argv_line).expect("argv json");
+    assert_eq!(argv, vec!["app-server", "--analytics-default-enabled"]);
+
+    server.shutdown().await.expect("shutdown server");
+}
+
+#[test]
+fn add_stdio_server_injects_env_and_persists() {
+    let (dir, manager) = temp_config_manager();
+    let env_key = "MCP_STDIO_TEST_KEY";
+    env::remove_var(env_key);
+
+    let mut env_map = BTreeMap::new();
+    env_map.insert(env_key.to_string(), "secret".to_string());
+
+    let added = manager
+        .add_server(AddServerRequest {
+            name: "local".into(),
+            definition: stdio_definition("my-mcp"),
+            overwrite: false,
+            env: env_map,
+            bearer_token: None,
+        })
+        .expect("add server");
+
+    match added.definition.transport {
+        McpTransport::Stdio(def) => {
+            assert_eq!(def.command, "my-mcp");
+            assert_eq!(def.env.get(env_key), Some(&"secret".to_string()));
+        }
+        _ => panic!("expected stdio transport"),
+    }
+
+    let listed = manager.list_servers().expect("list servers");
+    assert_eq!(listed.len(), 1);
+    assert_eq!(listed[0].name, "local");
+
+    let fetched = manager.get_server("local").expect("get server");
+    match fetched.definition.transport {
+        McpTransport::Stdio(def) => {
+            assert_eq!(def.env.get(env_key), Some(&"secret".to_string()))
+        }
+        _ => panic!("expected stdio transport"),
+    }
+
+    let config_path = dir.path().join(DEFAULT_CONFIG_FILE);
+    let serialized = fs::read_to_string(config_path).expect("read config");
+    let value: TomlValue = serialized.parse().expect("parse toml");
+    let table = value.as_table().expect("table root");
+    let servers_table = table.get("mcp_servers").expect("mcp_servers");
+    let decoded: BTreeMap<String, McpServerDefinition> = servers_table
+        .clone()
+        .try_into()
+        .expect("decode mcp_servers");
+    let stored = decoded.get("local").expect("stored server");
+    match &stored.transport {
+        McpTransport::Stdio(def) => {
+            assert_eq!(def.env.get(env_key), Some(&"secret".to_string()))
+        }
+        _ => panic!("expected stdio transport"),
+    }
+
+    assert_eq!(env::var(env_key).unwrap(), "secret");
+    env::remove_var(env_key);
+}
+
+#[test]
+fn add_streamable_http_sets_token_and_allows_login_logout() {
+    let (_dir, manager) = temp_config_manager();
+    let env_var = "MCP_HTTP_TOKEN_E5";
+    env::remove_var(env_var);
+
+    let mut definition = streamable_definition("https://example.test/mcp", env_var);
+    if let McpTransport::StreamableHttp(ref mut http) = definition.transport {
+        http.headers.insert("X-Test".into(), "true".into());
+    }
+
+    let _added = manager
+        .add_server(AddServerRequest {
+            name: "remote".into(),
+            definition,
+            overwrite: false,
+            env: BTreeMap::new(),
+            bearer_token: Some("token-a".into()),
+        })
+        .expect("add server");
+
+    assert_eq!(env::var(env_var).unwrap(), "token-a");
+
+    let logout = manager.logout("remote").expect("logout");
+    assert_eq!(logout.env_var.as_deref(), Some(env_var));
+    assert!(logout.cleared);
+    assert!(env::var(env_var).is_err());
+
+    let login = manager.login("remote", "token-b").expect("login");
+    assert_eq!(login.env_var.as_deref(), Some(env_var));
+    assert_eq!(env::var(env_var).unwrap(), "token-b");
+
+    env::remove_var(env_var);
+}
+
+#[test]
+fn remove_server_prunes_config() {
+    let (_dir, manager) = temp_config_manager();
+
+    manager
+        .add_server(AddServerRequest {
+            name: "one".into(),
+            definition: stdio_definition("one"),
+            overwrite: false,
+            env: BTreeMap::new(),
+            bearer_token: None,
+        })
+        .expect("add first");
+
+    manager
+        .add_server(AddServerRequest {
+            name: "two".into(),
+            definition: stdio_definition("two"),
+            overwrite: false,
+            env: BTreeMap::new(),
+            bearer_token: None,
+        })
+        .expect("add second");
+
+    let removed = manager.remove_server("one").expect("remove");
+    assert!(removed.is_some());
+
+    let listed = manager.list_servers().expect("list");
+    assert_eq!(listed.len(), 1);
+    assert_eq!(listed[0].name, "two");
+
+    let config = fs::read_to_string(manager.config_path()).expect("read config");
+    let value: TomlValue = config.parse().expect("parse config");
+    let table = value.as_table().expect("table root");
+    let servers_value = table.get("mcp_servers").cloned().expect("servers");
+    let servers: BTreeMap<String, McpServerDefinition> =
+        servers_value.try_into().expect("decode servers");
+    assert!(!servers.contains_key("one"));
+    assert!(servers.contains_key("two"));
+}
+
+#[test]
+fn runtime_stdio_server_resolves_env_and_tools() {
+    let (_dir, manager) = temp_config_manager();
+    let mut definition = stdio_definition("my-mcp");
+    definition.description = Some("local mcp".into());
+    definition.tags = vec!["dev".into(), "local".into()];
+    definition.tools = Some(McpToolConfig {
+        enabled: vec!["tool-a".into()],
+        disabled: vec!["tool-b".into()],
+    });
+
+    if let McpTransport::Stdio(ref mut stdio) = definition.transport {
+        stdio.args = vec!["--flag".into()];
+        stdio.env.insert("EXAMPLE".into(), "value".into());
+        stdio.timeout_ms = Some(2500);
+    }
+
+    let mut injected = BTreeMap::new();
+    injected.insert("MCP_STDIO_INJECT_E6".into(), "yes".into());
+
+    manager
+        .add_server(AddServerRequest {
+            name: "local".into(),
+            definition,
+            overwrite: false,
+            env: injected,
+            bearer_token: None,
+        })
+        .expect("add server");
+
+    let runtime = manager.runtime_server("local").expect("runtime server");
+    assert_eq!(runtime.name, "local");
+    assert_eq!(runtime.description.as_deref(), Some("local mcp"));
+    assert_eq!(runtime.tags, vec!["dev".to_string(), "local".to_string()]);
+
+    let tools = runtime.tools.as_ref().expect("tool hints");
+    assert_eq!(tools.enabled, vec!["tool-a".to_string()]);
+    assert_eq!(tools.disabled, vec!["tool-b".to_string()]);
+
+    match &runtime.transport {
+        McpRuntimeTransport::Stdio(def) => {
+            assert_eq!(def.command, "my-mcp");
+            assert_eq!(def.args, vec!["--flag".to_string()]);
+            assert_eq!(def.timeout_ms, Some(2500));
+            assert_eq!(def.env.get("EXAMPLE").map(String::as_str), Some("value"));
+            assert_eq!(
+                def.env.get("MCP_STDIO_INJECT_E6").map(String::as_str),
+                Some("yes")
+            );
+        }
+        other => panic!("expected stdio transport, got {other:?}"),
+    }
+
+    serde_json::to_string(&runtime).expect("serialize runtime");
+    env::remove_var("MCP_STDIO_INJECT_E6");
+}
+
+#[test]
+fn runtime_http_resolves_bearer_and_sets_header() {
+    let (_dir, manager) = temp_config_manager();
+    let env_var = "MCP_HTTP_TOKEN_E6";
+    env::set_var(env_var, "token-123");
+
+    let mut definition = streamable_definition("https://example.test/mcp", env_var);
+    if let McpTransport::StreamableHttp(ref mut http) = definition.transport {
+        http.headers.insert("X-Test".into(), "true".into());
+        http.connect_timeout_ms = Some(1200);
+        http.request_timeout_ms = Some(3400);
+    }
+
+    manager
+        .add_server(AddServerRequest {
+            name: "remote".into(),
+            definition,
+            overwrite: false,
+            env: BTreeMap::new(),
+            bearer_token: None,
+        })
+        .expect("add server");
+
+    let runtime = manager.runtime_server("remote").expect("runtime server");
+    match &runtime.transport {
+        McpRuntimeTransport::StreamableHttp(def) => {
+            assert_eq!(def.url, "https://example.test/mcp");
+            assert_eq!(def.bearer_env_var.as_deref(), Some(env_var));
+            assert_eq!(def.bearer_token.as_deref(), Some("token-123"));
+            assert_eq!(def.headers.get("X-Test").map(String::as_str), Some("true"));
+            assert_eq!(
+                def.headers.get("Authorization").map(String::as_str),
+                Some("Bearer token-123")
+            );
+            assert_eq!(def.connect_timeout_ms, Some(1200));
+            assert_eq!(def.request_timeout_ms, Some(3400));
+        }
+        other => panic!("expected streamable_http transport, got {other:?}"),
+    }
+
+    let serialized = serde_json::to_value(&runtime).expect("serialize runtime");
+    assert!(serialized.get("transport").is_some());
+
+    env::remove_var(env_var);
+}
+
+#[test]
+fn runtime_http_preserves_existing_auth_header() {
+    let (_dir, manager) = temp_config_manager();
+    let env_var = "MCP_HTTP_TOKEN_E6B";
+    env::set_var(env_var, "token-override");
+
+    let mut definition = streamable_definition("https://example.test/custom", env_var);
+    if let McpTransport::StreamableHttp(ref mut http) = definition.transport {
+        http.headers
+            .insert("Authorization".into(), "Custom 123".into());
+    }
+
+    manager
+        .add_server(AddServerRequest {
+            name: "remote-custom".into(),
+            definition,
+            overwrite: false,
+            env: BTreeMap::new(),
+            bearer_token: None,
+        })
+        .expect("add server");
+
+    let runtime = manager
+        .runtime_server("remote-custom")
+        .expect("runtime server");
+    match &runtime.transport {
+        McpRuntimeTransport::StreamableHttp(def) => {
+            assert_eq!(def.bearer_token.as_deref(), Some("token-override"));
+            assert_eq!(
+                def.headers.get("Authorization").map(String::as_str),
+                Some("Custom 123")
+            );
+        }
+        other => panic!("expected streamable_http transport, got {other:?}"),
+    }
+
+    env::remove_var(env_var);
+}
+
+#[test]
+fn runtime_stdio_launcher_merges_env_timeout_and_tools() {
+    let base_dir = tempfile::tempdir().expect("tempdir");
+    let code_home = base_dir.path().join("code_home");
+
+    let defaults = StdioServerConfig {
+        binary: PathBuf::from("codex"),
+        code_home: Some(code_home.clone()),
+        current_dir: Some(base_dir.path().to_path_buf()),
+        env: vec![
+            (OsString::from("BASE_ONLY"), OsString::from("base")),
+            (OsString::from("OVERRIDE_ME"), OsString::from("base")),
+        ],
+        app_server_analytics_default_enabled: false,
+        mirror_stdio: true,
+        startup_timeout: Duration::from_secs(5),
+    };
+
+    let mut definition = StdioServerDefinition {
+        command: "my-mcp".into(),
+        args: vec!["--flag".into()],
+        env: BTreeMap::new(),
+        timeout_ms: Some(1500),
+    };
+    definition
+        .env
+        .insert("OVERRIDE_ME".into(), "runtime".into());
+    definition
+        .env
+        .insert("RUNTIME_ONLY".into(), "runtime-env".into());
+
+    let runtime = McpRuntimeServer {
+        name: "local".into(),
+        transport: McpRuntimeTransport::Stdio(definition),
+        description: Some("example".into()),
+        tags: vec!["dev".into()],
+        tools: Some(McpToolConfig {
+            enabled: vec!["tool-1".into()],
+            disabled: vec!["tool-2".into()],
+        }),
+    };
+
+    let launcher = runtime.into_launcher(&defaults);
+    assert_eq!(launcher.name, "local");
+    assert_eq!(launcher.description.as_deref(), Some("example"));
+    assert_eq!(launcher.tags, vec!["dev".to_string()]);
+
+    let tools = launcher.tools.clone().expect("tool hints");
+    assert_eq!(tools.enabled, vec!["tool-1".to_string()]);
+    assert_eq!(tools.disabled, vec!["tool-2".to_string()]);
+
+    match launcher.transport {
+        McpServerLauncherTransport::Stdio(launch) => {
+            assert_eq!(launch.command, PathBuf::from("my-mcp"));
+            assert_eq!(launch.args, vec!["--flag".to_string()]);
+            assert_eq!(launch.current_dir.as_ref(), defaults.current_dir.as_ref());
+            assert_eq!(launch.timeout, Duration::from_millis(1500));
+            assert!(launch.mirror_stdio);
+
+            let env_map: HashMap<OsString, OsString> = launch.env.into_iter().collect();
+            assert_eq!(
+                env_map.get(&OsString::from("BASE_ONLY")),
+                Some(&OsString::from("base"))
+            );
+            assert_eq!(
+                env_map.get(&OsString::from("OVERRIDE_ME")),
+                Some(&OsString::from("runtime"))
+            );
+            assert_eq!(
+                env_map.get(&OsString::from("RUNTIME_ONLY")),
+                Some(&OsString::from("runtime-env"))
+            );
+            assert_eq!(
+                env_map.get(&OsString::from("CODEX_HOME")),
+                Some(&code_home.as_os_str().to_os_string())
+            );
+        }
+        other => panic!("expected stdio launcher, got {other:?}"),
+    }
+}
+
+#[test]
+fn streamable_http_connector_converts_timeouts_and_headers() {
+    let env_var = "MCP_HTTP_TOKEN_E7";
+    env::set_var(env_var, "token-launcher");
+
+    let mut definition = StreamableHttpDefinition {
+        url: "https://example.test/stream".into(),
+        headers: BTreeMap::new(),
+        bearer_env_var: Some(env_var.to_string()),
+        connect_timeout_ms: Some(1200),
+        request_timeout_ms: Some(3400),
+    };
+    definition.headers.insert("X-Test".into(), "true".into());
+
+    let runtime = McpRuntimeServer::from_definition(
+        "remote",
+        McpServerDefinition {
+            transport: McpTransport::StreamableHttp(definition),
+            description: None,
+            tags: vec!["http".into()],
+            tools: Some(McpToolConfig {
+                enabled: vec!["tool-a".into()],
+                disabled: vec![],
+            }),
+        },
+    );
+
+    let defaults = StdioServerConfig {
+        binary: PathBuf::from("codex"),
+        code_home: None,
+        current_dir: None,
+        env: Vec::new(),
+        app_server_analytics_default_enabled: false,
+        mirror_stdio: false,
+        startup_timeout: Duration::from_secs(2),
+    };
+
+    let launcher = runtime.into_launcher(&defaults);
+    match launcher.transport {
+        McpServerLauncherTransport::StreamableHttp(connector) => {
+            assert_eq!(connector.url, "https://example.test/stream");
+            assert_eq!(
+                connector.headers.get("X-Test").map(String::as_str),
+                Some("true")
+            );
+            assert_eq!(
+                connector.headers.get("Authorization").map(String::as_str),
+                Some("Bearer token-launcher")
+            );
+            assert_eq!(connector.connect_timeout, Some(Duration::from_millis(1200)));
+            assert_eq!(connector.request_timeout, Some(Duration::from_millis(3400)));
+            assert_eq!(connector.bearer_env_var.as_deref(), Some(env_var));
+            assert_eq!(connector.bearer_token.as_deref(), Some("token-launcher"));
+
+            let tools = launcher.tools.as_ref().expect("tool hints present");
+            assert_eq!(tools.enabled, vec!["tool-a".to_string()]);
+            assert!(tools.disabled.is_empty());
+        }
+        other => panic!("expected http connector, got {other:?}"),
+    }
+
+    env::remove_var(env_var);
+}
+
+#[tokio::test]
+async fn codex_flow_streams_events_and_response() {
+    let (_dir, server) = start_fake_mcp_server().await;
+
+    let params = CodexCallParams {
+        prompt: "hello".into(),
+        model: None,
+        cwd: None,
+        sandbox: None,
+        approval_policy: None,
+        profile: None,
+        config: BTreeMap::new(),
+    };
+
+    let mut handle = server.codex(params).await.expect("codex call");
+
+    let first_event = time::timeout(Duration::from_secs(2), handle.events.recv())
+        .await
+        .expect("event timeout")
+        .expect("event value");
+    match first_event {
+        CodexEvent::ApprovalRequired(req) => {
+            assert!(req.approval_id.starts_with("ap-"));
+            assert_eq!(req.kind, ApprovalKind::Exec);
+        }
+        other => panic!("unexpected event: {other:?}"),
+    }
+
+    let second_event = time::timeout(Duration::from_secs(2), handle.events.recv())
+        .await
+        .expect("event timeout")
+        .expect("event value");
+    let event_conversation = match second_event {
+        CodexEvent::TaskComplete {
+            conversation_id, ..
+        } => {
+            assert!(!conversation_id.is_empty());
+            conversation_id
+        }
+        other => panic!("unexpected event: {other:?}"),
+    };
+
+    let response = time::timeout(Duration::from_secs(2), handle.response)
+        .await
+        .expect("response timeout")
+        .expect("response recv");
+    let response = response.expect("response ok");
+    assert_eq!(
+        response.conversation_id.as_deref(),
+        Some(event_conversation.as_str())
+    );
+    assert_eq!(response.output, serde_json::json!({ "ok": true }));
+
+    let _ = server.shutdown().await;
+}
+
+#[tokio::test]
+async fn canceling_request_returns_cancelled_error() {
+    let (_dir, server) = start_fake_mcp_server().await;
+
+    let params = CodexCallParams {
+        prompt: "cancel me".into(),
+        model: None,
+        cwd: None,
+        sandbox: None,
+        approval_policy: None,
+        profile: None,
+        config: BTreeMap::new(),
+    };
+
+    let mut handle = server.codex(params).await.expect("codex call");
+    server.cancel(handle.request_id).expect("cancel send");
+
+    let expected_conversation = format!("conv-{}", handle.request_id);
+    let cancel_event = time::timeout(Duration::from_secs(2), handle.events.recv())
+        .await
+        .expect("event timeout")
+        .expect("cancel notification");
+    match cancel_event {
+        CodexEvent::Cancelled {
+            conversation_id,
+            reason,
+        } => {
+            assert_eq!(
+                conversation_id.as_deref(),
+                Some(expected_conversation.as_str())
+            );
+            assert_eq!(reason.as_deref(), Some("client_cancel"));
+        }
+        other => panic!("expected cancellation event, got {other:?}"),
+    }
+
+    let response = time::timeout(Duration::from_secs(2), handle.response)
+        .await
+        .expect("response timeout")
+        .expect("recv");
+    assert!(matches!(response, Err(McpError::Cancelled)));
+
+    let _ = server.shutdown().await;
+}
+
+#[tokio::test]
+async fn codex_reply_streams_follow_up_notifications() {
+    let (_dir, server) = start_fake_mcp_server().await;
+
+    let params = CodexCallParams {
+        prompt: "hello".into(),
+        model: None,
+        cwd: None,
+        sandbox: None,
+        approval_policy: None,
+        profile: None,
+        config: BTreeMap::new(),
+    };
+    let first = server.codex(params).await.expect("start codex");
+    let first_response = time::timeout(Duration::from_secs(2), first.response)
+        .await
+        .expect("response timeout")
+        .expect("recv")
+        .expect("ok");
+    let conversation_id = first_response.conversation_id.expect("conversation id set");
+    assert!(!conversation_id.is_empty());
+
+    let reply_params = CodexReplyParams {
+        conversation_id: conversation_id.clone(),
+        prompt: "follow up".into(),
+    };
+    let mut reply = server.codex_reply(reply_params).await.expect("codex reply");
+
+    let expected_approval = format!("ap-{}", reply.request_id);
+    let approval = time::timeout(Duration::from_secs(2), reply.events.recv())
+        .await
+        .expect("event timeout")
+        .expect("approval");
+    match approval {
+        CodexEvent::ApprovalRequired(req) => {
+            assert_eq!(req.approval_id, expected_approval);
+            assert_eq!(req.kind, ApprovalKind::Exec);
+        }
+        other => panic!("unexpected event: {other:?}"),
+    }
+
+    let complete = time::timeout(Duration::from_secs(2), reply.events.recv())
+        .await
+        .expect("event timeout")
+        .expect("task completion");
+    match complete {
+        CodexEvent::TaskComplete {
+            conversation_id: event_conv,
+            ..
+        } => assert_eq!(event_conv, conversation_id),
+        other => panic!("unexpected event: {other:?}"),
+    }
+
+    let reply_response = time::timeout(Duration::from_secs(2), reply.response)
+        .await
+        .expect("response timeout")
+        .expect("recv")
+        .expect("ok");
+    assert_eq!(
+        reply_response.conversation_id.as_deref(),
+        Some(conversation_id.as_str())
+    );
+    assert_eq!(reply_response.output, serde_json::json!({ "ok": true }));
+
+    let _ = server.shutdown().await;
+}
+
+#[tokio::test]
+async fn app_flow_streams_notifications_and_response() {
+    let (_dir, server) = start_fake_app_server().await;
+
+    let thread_params = ThreadStartParams {
+        thread_id: None,
+        metadata: Value::Null,
+    };
+    let thread_handle = server
+        .thread_start(thread_params)
+        .await
+        .expect("thread start");
+    let thread_response = time::timeout(Duration::from_secs(2), thread_handle.response)
+        .await
+        .expect("thread response timeout")
+        .expect("thread response recv")
+        .expect("thread response ok");
+    let thread_id = thread_response
+        .get("thread_id")
+        .and_then(Value::as_str)
+        .unwrap_or_default()
+        .to_string();
+    assert!(!thread_id.is_empty());
+
+    let params = TurnStartParams {
+        thread_id: thread_id.clone(),
+        input: vec![TurnInput {
+            kind: "text".to_string(),
+            text: Some("hi".to_string()),
+        }],
+        model: None,
+        config: BTreeMap::new(),
+    };
+    let mut handle = server.turn_start(params).await.expect("turn start");
+
+    let first_event = time::timeout(Duration::from_secs(2), handle.events.recv())
+        .await
+        .expect("event timeout")
+        .expect("event value");
+    let turn_id = match first_event {
+        AppNotification::Item {
+            thread_id: tid,
+            turn_id: Some(turn),
+            item,
+        } => {
+            assert_eq!(tid, thread_id);
+            assert!(item.get("message").is_some());
+            turn
+        }
+        other => panic!("unexpected event: {other:?}"),
+    };
+
+    let second_event = time::timeout(Duration::from_secs(2), handle.events.recv())
+        .await
+        .expect("event timeout")
+        .expect("event value");
+    match second_event {
+        AppNotification::TaskComplete {
+            thread_id: tid,
+            turn_id: event_turn,
+            result,
+        } => {
+            assert_eq!(tid, thread_id);
+            assert_eq!(event_turn.as_deref(), Some(turn_id.as_str()));
+            assert_eq!(result, serde_json::json!({ "ok": true }));
+        }
+        other => panic!("unexpected event: {other:?}"),
+    }
+
+    let response = time::timeout(Duration::from_secs(2), handle.response)
+        .await
+        .expect("response timeout")
+        .expect("response recv");
+    let response = response.expect("response ok");
+    assert_eq!(
+        response
+            .get("turn_id")
+            .and_then(Value::as_str)
+            .unwrap_or_default(),
+        turn_id
+    );
+
+    let _ = server.shutdown().await;
+}
+
+#[tokio::test]
+async fn canceling_app_request_returns_cancelled_error() {
+    let (_dir, server) = start_fake_app_server().await;
+
+    let thread_params = ThreadStartParams {
+        thread_id: None,
+        metadata: Value::Null,
+    };
+    let thread_handle = server
+        .thread_start(thread_params)
+        .await
+        .expect("thread start");
+    let thread_response = time::timeout(Duration::from_secs(2), thread_handle.response)
+        .await
+        .expect("thread response timeout")
+        .expect("thread response recv")
+        .expect("thread response ok");
+    let thread_id = thread_response
+        .get("thread_id")
+        .and_then(Value::as_str)
+        .unwrap_or_default()
+        .to_string();
+
+    let params = TurnStartParams {
+        thread_id: thread_id.clone(),
+        input: vec![TurnInput {
+            kind: "text".to_string(),
+            text: Some("cancel me".to_string()),
+        }],
+        model: None,
+        config: BTreeMap::new(),
+    };
+
+    let mut handle = server.turn_start(params).await.expect("turn start");
+    server.cancel(handle.request_id).expect("send cancel");
+
+    let cancel_event = time::timeout(Duration::from_secs(2), handle.events.recv())
+        .await
+        .expect("event timeout")
+        .expect("cancel event");
+    match cancel_event {
+        AppNotification::TaskComplete {
+            thread_id: tid,
+            turn_id,
+            result,
+        } => {
+            assert_eq!(tid, thread_id);
+            assert!(turn_id.is_some());
+            assert_eq!(result.get("cancelled"), Some(&Value::Bool(true)));
+            assert_eq!(
+                result.get("reason"),
+                Some(&Value::String("client_cancel".into()))
+            );
+        }
+        other => panic!("unexpected cancellation notification: {other:?}"),
+    }
+
+    let response = time::timeout(Duration::from_secs(2), handle.response)
+        .await
+        .expect("response timeout")
+        .expect("recv");
+    assert!(matches!(response, Err(McpError::Cancelled)));
+
+    let _ = server.shutdown().await;
+}
+
+#[tokio::test]
+async fn thread_resume_allows_follow_up_turns() {
+    let (_dir, server) = start_fake_app_server().await;
+
+    let thread_params = ThreadStartParams {
+        thread_id: None,
+        metadata: Value::Null,
+    };
+    let thread_handle = server
+        .thread_start(thread_params)
+        .await
+        .expect("thread start");
+    let thread_response = time::timeout(Duration::from_secs(2), thread_handle.response)
+        .await
+        .expect("thread response timeout")
+        .expect("recv")
+        .expect("ok");
+    let thread_id = thread_response
+        .get("thread_id")
+        .and_then(Value::as_str)
+        .unwrap_or_default()
+        .to_string();
+
+    let resume_params = ThreadResumeParams {
+        thread_id: thread_id.clone(),
+    };
+    let resume_handle = server
+        .thread_resume(resume_params)
+        .await
+        .expect("thread resume");
+    let resume_response = time::timeout(Duration::from_secs(2), resume_handle.response)
+        .await
+        .expect("resume response timeout")
+        .expect("recv")
+        .expect("ok");
+    assert_eq!(
+        resume_response
+            .get("thread_id")
+            .and_then(Value::as_str)
+            .unwrap_or_default(),
+        thread_id
+    );
+    assert!(resume_response
+        .get("resumed")
+        .and_then(Value::as_bool)
+        .unwrap_or(false));
+
+    let params = TurnStartParams {
+        thread_id: thread_id.clone(),
+        input: vec![TurnInput {
+            kind: "text".to_string(),
+            text: Some("resume flow".to_string()),
+        }],
+        model: None,
+        config: BTreeMap::new(),
+    };
+    let mut turn = server.turn_start(params).await.expect("turn start");
+
+    let item = time::timeout(Duration::from_secs(2), turn.events.recv())
+        .await
+        .expect("event timeout")
+        .expect("item event");
+    let turn_id = match item {
+        AppNotification::Item {
+            thread_id: tid,
+            turn_id: Some(turn_id),
+            ..
+        } => {
+            assert_eq!(tid, thread_id);
+            turn_id
+        }
+        other => panic!("unexpected event: {other:?}"),
+    };
+
+    let complete = time::timeout(Duration::from_secs(2), turn.events.recv())
+        .await
+        .expect("event timeout")
+        .expect("completion event");
+    match complete {
+        AppNotification::TaskComplete {
+            thread_id: tid,
+            turn_id: event_turn,
+            result,
+        } => {
+            assert_eq!(tid, thread_id);
+            assert_eq!(event_turn.as_deref(), Some(turn_id.as_str()));
+            assert_eq!(result, serde_json::json!({ "ok": true }));
+        }
+        other => panic!("unexpected event: {other:?}"),
+    }
+
+    let turn_response = time::timeout(Duration::from_secs(2), turn.response)
+        .await
+        .expect("response timeout")
+        .expect("recv")
+        .expect("ok");
+    assert_eq!(
+        turn_response
+            .get("turn_id")
+            .and_then(Value::as_str)
+            .unwrap_or_default(),
+        turn_id
+    );
+
+    let _ = server.shutdown().await;
+}
+
+#[tokio::test]
+async fn turn_interrupt_sends_cancel_notification() {
+    let (_dir, server) = start_fake_app_server().await;
+
+    let thread_params = ThreadStartParams {
+        thread_id: None,
+        metadata: Value::Null,
+    };
+    let thread_handle = server
+        .thread_start(thread_params)
+        .await
+        .expect("thread start");
+    let thread_response = time::timeout(Duration::from_secs(2), thread_handle.response)
+        .await
+        .expect("thread response timeout")
+        .expect("recv")
+        .expect("ok");
+    let thread_id = thread_response
+        .get("thread_id")
+        .and_then(Value::as_str)
+        .unwrap_or_default()
+        .to_string();
+
+    let params = TurnStartParams {
+        thread_id: thread_id.clone(),
+        input: vec![TurnInput {
+            kind: "text".to_string(),
+            text: Some("please interrupt".to_string()),
+        }],
+        model: None,
+        config: BTreeMap::new(),
+    };
+    let mut turn = server.turn_start(params).await.expect("turn start");
+
+    let first_event = time::timeout(Duration::from_secs(2), turn.events.recv())
+        .await
+        .expect("event timeout")
+        .expect("event value");
+    let turn_id = match first_event {
+        AppNotification::Item {
+            thread_id: tid,
+            turn_id: Some(turn),
+            ..
+        } => {
+            assert_eq!(tid, thread_id);
+            turn
+        }
+        other => panic!("unexpected event: {other:?}"),
+    };
+
+    let interrupt = server
+        .turn_interrupt(TurnInterruptParams {
+            thread_id: Some(thread_id.clone()),
+            turn_id: turn_id.clone(),
+        })
+        .await
+        .expect("send interrupt");
+
+    let cancel_event = time::timeout(Duration::from_secs(2), turn.events.recv())
+        .await
+        .expect("event timeout")
+        .expect("cancel event");
+    match cancel_event {
+        AppNotification::TaskComplete {
+            thread_id: tid,
+            turn_id: event_turn,
+            result,
+        } => {
+            assert_eq!(tid, thread_id);
+            assert_eq!(event_turn.as_deref(), Some(turn_id.as_str()));
+            assert_eq!(result.get("cancelled"), Some(&Value::Bool(true)));
+            assert_eq!(
+                result.get("reason"),
+                Some(&Value::String("interrupted".into()))
+            );
+        }
+        other => panic!("unexpected cancel notification: {other:?}"),
+    }
+
+    let turn_response = time::timeout(Duration::from_secs(2), turn.response)
+        .await
+        .expect("response timeout")
+        .expect("recv");
+    assert!(matches!(turn_response, Err(McpError::Cancelled)));
+
+    let interrupt_response = time::timeout(Duration::from_secs(2), interrupt.response)
+        .await
+        .expect("interrupt response timeout")
+        .expect("recv")
+        .expect("ok");
+    assert!(interrupt_response
+        .get("interrupted")
+        .and_then(Value::as_bool)
+        .unwrap_or(false));
+
+    let _ = server.shutdown().await;
+}
diff --git a/crates/codex/src/mcp/tests_runtime_app.rs b/crates/codex/src/mcp/tests_runtime_app.rs
new file mode 100644
index 0000000..490143a
--- /dev/null
+++ b/crates/codex/src/mcp/tests_runtime_app.rs
@@ -0,0 +1,979 @@
+use super::test_support::{prelude::*, *};
+use super::*;
+
+#[test]
+fn runtime_api_lists_launchers_without_changing_config() {
+    let (dir, manager) = temp_config_manager();
+    let stdio_env_key = "MCP_RUNTIME_API_STDIO_ENV";
+    let request_env_key = "MCP_RUNTIME_API_REQUEST_ENV";
+    let http_env_key = "MCP_RUNTIME_API_HTTP_ENV";
+    env::set_var(http_env_key, "token-api");
+
+    let mut stdio = stdio_definition("runtime-api-stdio");
+    stdio.description = Some("stdio runtime".into());
+    stdio.tags = vec!["local".into()];
+    stdio.tools = Some(McpToolConfig {
+        enabled: vec!["fmt".into()],
+        disabled: vec!["lint".into()],
+    });
+    if let McpTransport::Stdio(ref mut stdio_def) = stdio.transport {
+        stdio_def.args.push("--flag".into());
+        stdio_def
+            .env
+            .insert(stdio_env_key.into(), "runtime-env".into());
+        stdio_def.timeout_ms = Some(2400);
+    }
+
+    let mut env_map = BTreeMap::new();
+    env_map.insert(request_env_key.to_string(), "injected".to_string());
+
+    manager
+        .add_server(AddServerRequest {
+            name: "local-api".into(),
+            definition: stdio,
+            overwrite: false,
+            env: env_map,
+            bearer_token: None,
+        })
+        .expect("add stdio server");
+
+    let mut http = streamable_definition("https://example.test/runtime-api", http_env_key);
+    http.description = Some("http runtime".into());
+    http.tags = vec!["remote".into()];
+    http.tools = Some(McpToolConfig {
+        enabled: vec!["alpha".into()],
+        disabled: vec!["beta".into()],
+    });
+    if let McpTransport::StreamableHttp(ref mut http_def) = http.transport {
+        http_def.headers.insert("X-Req".into(), "true".into());
+        http_def.request_timeout_ms = Some(2200);
+    }
+
+    manager
+        .add_server(AddServerRequest {
+            name: "remote-api".into(),
+            definition: http,
+            overwrite: false,
+            env: BTreeMap::new(),
+            bearer_token: None,
+        })
+        .expect("add http server");
+
+    let before = fs::read_to_string(manager.config_path()).expect("read config before");
+    let cwd = dir.path().join("cwd");
+
+    let defaults = StdioServerConfig {
+        binary: PathBuf::from("codex"),
+        code_home: Some(dir.path().to_path_buf()),
+        current_dir: Some(cwd.clone()),
+        env: vec![
+            (OsString::from("DEFAULT_ONLY"), OsString::from("default")),
+            (
+                OsString::from(request_env_key),
+                OsString::from("base-default"),
+            ),
+        ],
+        app_server_analytics_default_enabled: false,
+        mirror_stdio: true,
+        startup_timeout: Duration::from_secs(3),
+    };
+
+    let api = McpRuntimeApi::from_config(&manager, &defaults).expect("runtime api");
+
+    let available = api.available();
+    assert_eq!(available.len(), 2);
+
+    let stdio_summary = available
+        .iter()
+        .find(|entry| entry.name == "local-api")
+        .expect("stdio summary");
+    assert_eq!(stdio_summary.transport, McpRuntimeSummaryTransport::Stdio);
+    let stdio_tools = stdio_summary.tools.as_ref().expect("stdio tools");
+    assert_eq!(stdio_tools.enabled, vec!["fmt".to_string()]);
+    assert_eq!(stdio_tools.disabled, vec!["lint".to_string()]);
+
+    let stdio_launcher = api.stdio_launcher("local-api").expect("stdio launcher");
+    assert_eq!(stdio_launcher.args, vec!["--flag".to_string()]);
+    assert_eq!(stdio_launcher.timeout, Duration::from_millis(2400));
+    assert!(stdio_launcher.mirror_stdio);
+    assert_eq!(stdio_launcher.current_dir.as_deref(), Some(cwd.as_path()));
+
+    let env_map: HashMap<OsString, OsString> = stdio_launcher.env.into_iter().collect();
+    assert_eq!(
+        env_map.get(&OsString::from("CODEX_HOME")),
+        Some(&dir.path().as_os_str().to_os_string())
+    );
+    assert_eq!(
+        env_map.get(&OsString::from("DEFAULT_ONLY")),
+        Some(&OsString::from("default"))
+    );
+    assert_eq!(
+        env_map.get(&OsString::from(request_env_key)),
+        Some(&OsString::from("injected"))
+    );
+    assert_eq!(
+        env_map.get(&OsString::from(stdio_env_key)),
+        Some(&OsString::from("runtime-env"))
+    );
+
+    let http_connector = api.http_connector("remote-api").expect("http connector");
+    assert_eq!(http_connector.bearer_token.as_deref(), Some("token-api"));
+    assert_eq!(
+        http_connector
+            .headers
+            .get("Authorization")
+            .map(String::as_str),
+        Some("Bearer token-api")
+    );
+    assert_eq!(
+        http_connector.headers.get("X-Req").map(String::as_str),
+        Some("true")
+    );
+    assert_eq!(
+        http_connector.request_timeout,
+        Some(Duration::from_millis(2200))
+    );
+
+    let http_tools = available
+        .iter()
+        .find(|entry| entry.name == "remote-api")
+        .and_then(|entry| entry.tools.as_ref())
+        .expect("http tools");
+    assert_eq!(http_tools.enabled, vec!["alpha".to_string()]);
+    assert_eq!(http_tools.disabled, vec!["beta".to_string()]);
+
+    match api.stdio_launcher("remote-api") {
+        Err(McpRuntimeError::UnsupportedTransport {
+            name,
+            expected,
+            actual,
+        }) => {
+            assert_eq!(name, "remote-api");
+            assert_eq!(expected, "stdio");
+            assert_eq!(actual, "streamable_http");
+        }
+        other => panic!("unexpected result: {other:?}"),
+    }
+
+    match api.http_connector("local-api") {
+        Err(McpRuntimeError::UnsupportedTransport {
+            name,
+            expected,
+            actual,
+        }) => {
+            assert_eq!(name, "local-api");
+            assert_eq!(expected, "streamable_http");
+            assert_eq!(actual, "stdio");
+        }
+        other => panic!("unexpected http result: {other:?}"),
+    }
+
+    let after = fs::read_to_string(manager.config_path()).expect("read config after");
+    assert_eq!(before, after);
+
+    env::remove_var(http_env_key);
+    env::remove_var(request_env_key);
+}
+
+#[test]
+fn runtime_api_prepare_http_is_non_destructive() {
+    let (dir, manager) = temp_config_manager();
+    let env_var = "MCP_RUNTIME_API_PREPARE";
+    env::set_var(env_var, "prepare-token");
+
+    let mut http = streamable_definition("https://example.test/prepare", env_var);
+    http.tags = vec!["prepare".into()];
+    http.tools = Some(McpToolConfig {
+        enabled: vec!["delta".into()],
+        disabled: vec![],
+    });
+
+    manager
+        .add_server(AddServerRequest {
+            name: "prepare-http".into(),
+            definition: http,
+            overwrite: false,
+            env: BTreeMap::new(),
+            bearer_token: None,
+        })
+        .expect("add http server");
+
+    let before = fs::read_to_string(manager.config_path()).expect("read config before");
+
+    let defaults = StdioServerConfig {
+        binary: PathBuf::from("codex"),
+        code_home: Some(dir.path().to_path_buf()),
+        current_dir: None,
+        env: Vec::new(),
+        app_server_analytics_default_enabled: false,
+        mirror_stdio: false,
+        startup_timeout: Duration::from_secs(2),
+    };
+
+    let api = McpRuntimeApi::from_config(&manager, &defaults).expect("runtime api");
+    let handle = api.prepare("prepare-http").expect("prepare http");
+
+    match handle {
+        McpRuntimeHandle::StreamableHttp(http_handle) => {
+            assert_eq!(http_handle.name, "prepare-http");
+            assert_eq!(
+                http_handle.connector.bearer_token.as_deref(),
+                Some("prepare-token")
+            );
+            assert_eq!(
+                http_handle
+                    .connector
+                    .headers
+                    .get("Authorization")
+                    .map(String::as_str),
+                Some("Bearer prepare-token")
+            );
+            let tools = http_handle.tools.expect("tool hints");
+            assert_eq!(tools.enabled, vec!["delta".to_string()]);
+        }
+        other => panic!("expected http handle, got {other:?}"),
+    }
+
+    let after = fs::read_to_string(manager.config_path()).expect("read config after");
+    assert_eq!(before, after);
+
+    env::remove_var(env_var);
+}
+
+#[test]
+fn app_runtime_api_lists_and_merges_without_writes() {
+    let (dir, manager) = temp_config_manager();
+
+    let alpha_home = dir.path().join("app-home-a");
+    let alpha_cwd = dir.path().join("app-cwd-a");
+    let mut alpha_env = BTreeMap::new();
+    alpha_env.insert("APP_RUNTIME_ENV".into(), "alpha".into());
+    alpha_env.insert("OVERRIDE_ME".into(), "runtime".into());
+
+    manager
+        .add_app_runtime(AddAppRuntimeRequest {
+            name: "alpha".into(),
+            definition: AppRuntimeDefinition {
+                description: Some("local app".into()),
+                tags: vec!["local".into()],
+                env: alpha_env,
+                code_home: Some(alpha_home.clone()),
+                current_dir: Some(alpha_cwd.clone()),
+                mirror_stdio: Some(true),
+                startup_timeout_ms: Some(4200),
+                binary: Some(PathBuf::from("/bin/app-alpha")),
+                metadata: serde_json::json!({"thread": "t-alpha"}),
+            },
+            overwrite: false,
+        })
+        .expect("add alpha app runtime");
+
+    let mut beta_env = BTreeMap::new();
+    beta_env.insert("APP_RUNTIME_ENV".into(), "beta".into());
+
+    manager
+        .add_app_runtime(AddAppRuntimeRequest {
+            name: "beta".into(),
+            definition: AppRuntimeDefinition {
+                description: None,
+                tags: vec!["default".into()],
+                env: beta_env,
+                code_home: None,
+                current_dir: None,
+                mirror_stdio: None,
+                startup_timeout_ms: None,
+                binary: None,
+                metadata: serde_json::json!({"resume": true}),
+            },
+            overwrite: false,
+        })
+        .expect("add beta app runtime");
+
+    let before = fs::read_to_string(manager.config_path()).expect("read config before");
+
+    let default_home = dir.path().join("default-home");
+    let default_cwd = dir.path().join("default-cwd");
+    let defaults = StdioServerConfig {
+        binary: PathBuf::from("codex"),
+        code_home: Some(default_home.clone()),
+        current_dir: Some(default_cwd.clone()),
+        env: vec![
+            (OsString::from("DEFAULT_ONLY"), OsString::from("base")),
+            (OsString::from("OVERRIDE_ME"), OsString::from("base")),
+        ],
+        app_server_analytics_default_enabled: false,
+        mirror_stdio: false,
+        startup_timeout: Duration::from_secs(3),
+    };
+
+    let api = AppRuntimeApi::from_config(&manager, &defaults).expect("app runtime api");
+
+    let available = api.available();
+    assert_eq!(available.len(), 2);
+
+    let alpha_summary = available
+        .iter()
+        .find(|entry| entry.name == "alpha")
+        .expect("alpha summary");
+    assert_eq!(alpha_summary.description.as_deref(), Some("local app"));
+    assert_eq!(alpha_summary.tags, vec!["local".to_string()]);
+    assert_eq!(
+        alpha_summary.metadata,
+        serde_json::json!({"thread": "t-alpha"})
+    );
+
+    let alpha = api.prepare("alpha").expect("prepare alpha");
+    assert_eq!(alpha.name, "alpha");
+    assert_eq!(alpha.metadata, serde_json::json!({"thread": "t-alpha"}));
+    assert_eq!(alpha.config.binary, PathBuf::from("/bin/app-alpha"));
+    assert_eq!(
+        alpha.config.code_home.as_deref(),
+        Some(alpha_home.as_path())
+    );
+    assert_eq!(
+        alpha.config.current_dir.as_deref(),
+        Some(alpha_cwd.as_path())
+    );
+    assert!(alpha.config.mirror_stdio);
+    assert_eq!(alpha.config.startup_timeout, Duration::from_millis(4200));
+
+    let alpha_env: HashMap<OsString, OsString> = alpha.config.env.into_iter().collect();
+    assert_eq!(
+        alpha_env.get(&OsString::from("CODEX_HOME")),
+        Some(&alpha_home.as_os_str().to_os_string())
+    );
+    assert_eq!(
+        alpha_env.get(&OsString::from("DEFAULT_ONLY")),
+        Some(&OsString::from("base"))
+    );
+    assert_eq!(
+        alpha_env.get(&OsString::from("OVERRIDE_ME")),
+        Some(&OsString::from("runtime"))
+    );
+    assert_eq!(
+        alpha_env.get(&OsString::from("APP_RUNTIME_ENV")),
+        Some(&OsString::from("alpha"))
+    );
+
+    let beta = api.stdio_config("beta").expect("beta config");
+    assert_eq!(beta.binary, PathBuf::from("codex"));
+    assert_eq!(beta.code_home.as_deref(), Some(default_home.as_path()));
+    assert_eq!(beta.current_dir.as_deref(), Some(default_cwd.as_path()));
+    assert!(!beta.mirror_stdio);
+    assert_eq!(beta.startup_timeout, Duration::from_secs(3));
+
+    let beta_env: HashMap<OsString, OsString> = beta.env.into_iter().collect();
+    assert_eq!(
+        beta_env.get(&OsString::from("CODEX_HOME")),
+        Some(&default_home.as_os_str().to_os_string())
+    );
+    assert_eq!(
+        beta_env.get(&OsString::from("DEFAULT_ONLY")),
+        Some(&OsString::from("base"))
+    );
+    assert_eq!(
+        beta_env.get(&OsString::from("OVERRIDE_ME")),
+        Some(&OsString::from("base"))
+    );
+    assert_eq!(
+        beta_env.get(&OsString::from("APP_RUNTIME_ENV")),
+        Some(&OsString::from("beta"))
+    );
+
+    let beta_summary = available
+        .iter()
+        .find(|entry| entry.name == "beta")
+        .expect("beta summary");
+    assert_eq!(beta_summary.metadata, serde_json::json!({"resume": true}));
+
+    let after = fs::read_to_string(manager.config_path()).expect("read config after");
+    assert_eq!(before, after);
+}
+
+#[tokio::test]
+async fn app_runtime_lifecycle_starts_and_stops_without_mutation() {
+    let (config_dir, manager) = temp_config_manager();
+    let (_server_dir, server_path) = write_fake_app_server();
+    let code_home = config_dir.path().join("app-lifecycle-home");
+
+    let mut env_map = BTreeMap::new();
+    env_map.insert("APP_RUNTIME_LIFECYCLE".into(), "runtime-env".into());
+
+    let metadata = serde_json::json!({"resume_thread": "thread-lifecycle"});
+    manager
+        .add_app_runtime(AddAppRuntimeRequest {
+            name: "lifecycle".into(),
+            definition: AppRuntimeDefinition {
+                description: Some("app lifecycle".into()),
+                tags: vec!["app".into()],
+                env: env_map,
+                code_home: None,
+                current_dir: None,
+                mirror_stdio: Some(true),
+                startup_timeout_ms: Some(1500),
+                binary: None,
+                metadata: metadata.clone(),
+            },
+            overwrite: false,
+        })
+        .expect("add app runtime");
+
+    let defaults = StdioServerConfig {
+        binary: server_path.clone(),
+        code_home: Some(code_home.clone()),
+        current_dir: None,
+        env: vec![(
+            OsString::from("APP_RUNTIME_LIFECYCLE"),
+            OsString::from("default"),
+        )],
+        app_server_analytics_default_enabled: false,
+        mirror_stdio: false,
+        startup_timeout: Duration::from_secs(3),
+    };
+
+    let before = fs::read_to_string(manager.config_path()).expect("read config before");
+    let api = AppRuntimeApi::from_config(&manager, &defaults).expect("build api");
+    let client = test_client();
+
+    let runtime = api
+        .start("lifecycle", client.clone())
+        .await
+        .expect("start runtime");
+    assert_eq!(runtime.name, "lifecycle");
+    assert_eq!(runtime.metadata, metadata);
+
+    let env_values: HashMap<OsString, OsString> = runtime.config.env.iter().cloned().collect();
+    assert_eq!(
+        env_values.get(&OsString::from("CODEX_HOME")),
+        Some(&code_home.as_os_str().to_os_string())
+    );
+    assert_eq!(
+        env_values.get(&OsString::from("APP_RUNTIME_LIFECYCLE")),
+        Some(&OsString::from("runtime-env"))
+    );
+
+    let thread = runtime
+        .server
+        .thread_start(ThreadStartParams {
+            thread_id: None,
+            metadata: serde_json::json!({"from": "lifecycle"}),
+        })
+        .await
+        .expect("thread start");
+    let thread_response = time::timeout(Duration::from_secs(2), thread.response)
+        .await
+        .expect("thread response timeout")
+        .expect("recv thread response")
+        .expect("thread response ok");
+    let thread_id = thread_response
+        .get("thread_id")
+        .and_then(Value::as_str)
+        .unwrap_or_default()
+        .to_string();
+    assert!(!thread_id.is_empty());
+
+    runtime.stop().await.expect("shutdown runtime");
+
+    let after = fs::read_to_string(manager.config_path()).expect("read config after");
+    assert_eq!(before, after);
+
+    let prepared = api.prepare("lifecycle").expect("prepare after stop");
+    assert_eq!(prepared.metadata, metadata);
+}
+
+#[tokio::test]
+async fn app_runtime_api_not_found_errors() {
+    let api = AppRuntimeApi::new(Vec::new());
+    match api.prepare("missing") {
+        Err(AppRuntimeError::NotFound(name)) => assert_eq!(name, "missing"),
+        other => panic!("unexpected result: {other:?}"),
+    }
+
+    let client = test_client();
+    match api.start("missing", client).await {
+        Err(AppRuntimeError::NotFound(name)) => assert_eq!(name, "missing"),
+        other => panic!("unexpected start result: {other:?}"),
+    }
+}
+
+#[tokio::test]
+async fn app_runtime_pool_api_reuses_and_restarts_stdio() {
+    let (config_dir, manager) = temp_config_manager();
+    let (_server_dir, server_path) = write_fake_app_server();
+    let code_home = config_dir.path().join("app-pool-home");
+
+    let mut env_map = BTreeMap::new();
+    env_map.insert("APP_POOL_ENV".into(), "runtime".into());
+
+    let metadata = serde_json::json!({"resume_thread": "thread-pool"});
+    manager
+        .add_app_runtime(AddAppRuntimeRequest {
+            name: "pooled".into(),
+            definition: AppRuntimeDefinition {
+                description: Some("pooled app".into()),
+                tags: vec!["pool".into()],
+                env: env_map,
+                code_home: None,
+                current_dir: None,
+                mirror_stdio: Some(true),
+                startup_timeout_ms: Some(2000),
+                binary: None,
+                metadata: metadata.clone(),
+            },
+            overwrite: false,
+        })
+        .expect("add app runtime");
+
+    let defaults = StdioServerConfig {
+        binary: server_path.clone(),
+        code_home: Some(code_home.clone()),
+        current_dir: None,
+        env: vec![
+            (OsString::from("APP_POOL_ENV"), OsString::from("default")),
+            (OsString::from("POOL_ONLY"), OsString::from("base")),
+        ],
+        app_server_analytics_default_enabled: false,
+        mirror_stdio: false,
+        startup_timeout: Duration::from_secs(3),
+    };
+
+    let before = fs::read_to_string(manager.config_path()).expect("read config before");
+    let api = AppRuntimePoolApi::from_config(&manager, &defaults).expect("build pool api");
+    let client = test_client();
+
+    let available = api.available();
+    assert_eq!(available.len(), 1);
+    let pooled_summary = &available[0];
+    assert_eq!(pooled_summary.name, "pooled");
+    assert_eq!(pooled_summary.metadata, metadata);
+
+    let launcher = api.launcher("pooled").expect("pooled launcher");
+    assert_eq!(launcher.description.as_deref(), Some("pooled app"));
+    assert_eq!(launcher.metadata, metadata);
+
+    let launcher_config = launcher.config.clone();
+    assert_eq!(launcher_config.binary, server_path);
+    assert_eq!(
+        launcher_config.code_home.as_deref(),
+        Some(code_home.as_path())
+    );
+    assert_eq!(launcher_config.startup_timeout, Duration::from_secs(2));
+
+    let launcher_env: HashMap<OsString, OsString> = launcher_config.env.into_iter().collect();
+    assert_eq!(
+        launcher_env.get(&OsString::from("CODEX_HOME")),
+        Some(&code_home.as_os_str().to_os_string())
+    );
+    assert_eq!(
+        launcher_env.get(&OsString::from("POOL_ONLY")),
+        Some(&OsString::from("base"))
+    );
+    assert_eq!(
+        launcher_env.get(&OsString::from("APP_POOL_ENV")),
+        Some(&OsString::from("runtime"))
+    );
+
+    let stdio_config = api
+        .stdio_config("pooled")
+        .expect("pooled stdio config without starting");
+    assert_eq!(stdio_config.binary, server_path);
+    assert_eq!(stdio_config.code_home.as_deref(), Some(code_home.as_path()));
+    let stdio_env: HashMap<OsString, OsString> = stdio_config.env.into_iter().collect();
+    assert_eq!(
+        stdio_env.get(&OsString::from("POOL_ONLY")),
+        Some(&OsString::from("base"))
+    );
+    assert_eq!(
+        stdio_env.get(&OsString::from("CODEX_HOME")),
+        Some(&code_home.as_os_str().to_os_string())
+    );
+    assert_eq!(
+        stdio_env.get(&OsString::from("APP_POOL_ENV")),
+        Some(&OsString::from("runtime"))
+    );
+
+    assert!(api.running().await.is_empty());
+
+    let runtime = api
+        .start("pooled", client.clone())
+        .await
+        .expect("start pooled runtime");
+    assert_eq!(runtime.name, "pooled");
+    assert_eq!(runtime.metadata, metadata);
+
+    let env_values: HashMap<OsString, OsString> = runtime.config.env.iter().cloned().collect();
+    assert_eq!(
+        env_values.get(&OsString::from("CODEX_HOME")),
+        Some(&code_home.as_os_str().to_os_string())
+    );
+    assert_eq!(
+        env_values.get(&OsString::from("POOL_ONLY")),
+        Some(&OsString::from("base"))
+    );
+    assert_eq!(
+        env_values.get(&OsString::from("APP_POOL_ENV")),
+        Some(&OsString::from("runtime"))
+    );
+
+    let thread = runtime
+        .server
+        .thread_start(ThreadStartParams {
+            thread_id: None,
+            metadata: serde_json::json!({"from": "pool"}),
+        })
+        .await
+        .expect("thread start");
+    let response = time::timeout(Duration::from_secs(2), thread.response)
+        .await
+        .expect("thread response timeout")
+        .expect("recv thread response")
+        .expect("thread response ok");
+    let thread_id = response
+        .get("thread_id")
+        .and_then(Value::as_str)
+        .unwrap_or_default()
+        .to_string();
+    assert!(!thread_id.is_empty());
+
+    let running = api.running().await;
+    let running_summary = running
+        .iter()
+        .find(|summary| summary.name == "pooled")
+        .expect("running summary present");
+    assert_eq!(running_summary.metadata, metadata);
+
+    let reused = api
+        .start("pooled", client.clone())
+        .await
+        .expect("reuse pooled runtime");
+    assert!(Arc::ptr_eq(&runtime, &reused));
+
+    api.stop("pooled").await.expect("stop pooled runtime");
+    match api.stop("pooled").await {
+        Err(AppRuntimeError::NotFound(name)) => assert_eq!(name, "pooled"),
+        other => panic!("expected not found on second stop, got {other:?}"),
+    }
+
+    assert!(api.running().await.is_empty());
+
+    let restarted = api
+        .start("pooled", client)
+        .await
+        .expect("restart pooled runtime");
+    assert!(!Arc::ptr_eq(&runtime, &restarted));
+    assert_eq!(restarted.metadata, metadata);
+
+    let prepared = api.prepare("pooled").expect("prepare after restart");
+    assert_eq!(prepared.metadata, metadata);
+
+    let after = fs::read_to_string(manager.config_path()).expect("read config after");
+    assert_eq!(before, after);
+}
+
+#[tokio::test]
+async fn app_runtime_pool_api_stop_all_shuts_down_runtimes() {
+    let (config_dir, manager) = temp_config_manager();
+    let (_server_dir, server_path) = write_fake_app_server();
+    let code_home = config_dir.path().join("app-pool-stop-home");
+
+    let alpha_metadata = serde_json::json!({"resume_thread": "alpha"});
+    manager
+        .add_app_runtime(AddAppRuntimeRequest {
+            name: "alpha".into(),
+            definition: AppRuntimeDefinition {
+                description: Some("alpha runtime".into()),
+                tags: vec!["pool".into()],
+                env: BTreeMap::new(),
+                code_home: None,
+                current_dir: None,
+                mirror_stdio: Some(false),
+                startup_timeout_ms: Some(2000),
+                binary: None,
+                metadata: alpha_metadata.clone(),
+            },
+            overwrite: false,
+        })
+        .expect("add alpha runtime");
+
+    let beta_metadata = serde_json::json!({"resume_thread": "beta"});
+    manager
+        .add_app_runtime(AddAppRuntimeRequest {
+            name: "beta".into(),
+            definition: AppRuntimeDefinition {
+                description: Some("beta runtime".into()),
+                tags: vec!["pool".into()],
+                env: BTreeMap::new(),
+                code_home: None,
+                current_dir: None,
+                mirror_stdio: Some(false),
+                startup_timeout_ms: Some(2000),
+                binary: None,
+                metadata: beta_metadata.clone(),
+            },
+            overwrite: false,
+        })
+        .expect("add beta runtime");
+
+    let defaults = StdioServerConfig {
+        binary: server_path.clone(),
+        code_home: Some(code_home.clone()),
+        current_dir: None,
+        env: Vec::new(),
+        app_server_analytics_default_enabled: false,
+        mirror_stdio: false,
+        startup_timeout: Duration::from_secs(3),
+    };
+
+    let before = fs::read_to_string(manager.config_path()).expect("read config before");
+    let api = AppRuntimePoolApi::from_config(&manager, &defaults).expect("build pool api");
+    let client = test_client();
+
+    assert!(api.running().await.is_empty());
+
+    let alpha = api
+        .start("alpha", client.clone())
+        .await
+        .expect("start alpha runtime");
+    let beta = api
+        .start("beta", client.clone())
+        .await
+        .expect("start beta runtime");
+
+    assert_eq!(alpha.metadata, alpha_metadata);
+    assert_eq!(beta.metadata, beta_metadata);
+
+    let mut running = api.running().await;
+    running.sort_by(|a, b| a.name.cmp(&b.name));
+    assert_eq!(running.len(), 2);
+    assert_eq!(running[0].name, "alpha");
+    assert_eq!(running[0].metadata, alpha_metadata);
+    assert_eq!(running[1].name, "beta");
+    assert_eq!(running[1].metadata, beta_metadata);
+
+    let alpha_thread = alpha
+        .server
+        .thread_start(ThreadStartParams {
+            thread_id: None,
+            metadata: serde_json::json!({"from": "alpha"}),
+        })
+        .await
+        .expect("alpha thread start");
+    let _ = time::timeout(Duration::from_secs(2), alpha_thread.response)
+        .await
+        .expect("alpha thread response timeout")
+        .expect("alpha response recv")
+        .expect("alpha ok");
+
+    api.stop_all().await.expect("stop all runtimes");
+    assert!(api.running().await.is_empty());
+
+    let restarted_alpha = api
+        .start("alpha", client.clone())
+        .await
+        .expect("restart alpha");
+    assert!(!Arc::ptr_eq(&alpha, &restarted_alpha));
+    assert_eq!(restarted_alpha.metadata, alpha_metadata);
+
+    let restarted_beta = api.start("beta", client).await.expect("restart beta");
+    assert!(!Arc::ptr_eq(&beta, &restarted_beta));
+    assert_eq!(restarted_beta.metadata, beta_metadata);
+
+    let prepared_alpha = api.prepare("alpha").expect("prepare alpha");
+    assert_eq!(prepared_alpha.metadata, alpha_metadata);
+    let prepared_beta = api.prepare("beta").expect("prepare beta");
+    assert_eq!(prepared_beta.metadata, beta_metadata);
+
+    let after = fs::read_to_string(manager.config_path()).expect("read config after");
+    assert_eq!(before, after);
+}
+
+#[tokio::test]
+async fn runtime_manager_starts_and_stops_stdio() {
+    let (_dir, script) = write_env_probe_server("MCP_RUNTIME_ENV_E8");
+    let code_home = tempfile::tempdir().expect("code_home");
+
+    let defaults = StdioServerConfig {
+        binary: PathBuf::from("codex"),
+        code_home: Some(code_home.path().to_path_buf()),
+        current_dir: None,
+        env: vec![(
+            OsString::from("MCP_RUNTIME_ENV_E8"),
+            OsString::from("manager-ok"),
+        )],
+        app_server_analytics_default_enabled: false,
+        mirror_stdio: false,
+        startup_timeout: Duration::from_secs(5),
+    };
+
+    let runtime = McpRuntimeServer {
+        name: "env-probe".into(),
+        transport: McpRuntimeTransport::Stdio(StdioServerDefinition {
+            command: script.to_string_lossy().to_string(),
+            args: Vec::new(),
+            env: BTreeMap::new(),
+            timeout_ms: Some(1500),
+        }),
+        description: None,
+        tags: vec!["local".into()],
+        tools: Some(McpToolConfig {
+            enabled: vec!["tool-x".into()],
+            disabled: vec![],
+        }),
+    };
+
+    let launcher = runtime.into_launcher(&defaults);
+    let manager = McpRuntimeManager::new(vec![launcher]);
+
+    let mut handle = match manager.prepare("env-probe").expect("prepare stdio") {
+        McpRuntimeHandle::Stdio(handle) => handle,
+        other => panic!("expected stdio handle, got {other:?}"),
+    };
+
+    let mut reader = BufReader::new(handle.stdout_mut());
+    let mut line = String::new();
+    let _ = time::timeout(Duration::from_secs(2), reader.read_line(&mut line))
+        .await
+        .expect("read timeout")
+        .expect("read env line");
+    assert_eq!(line.trim(), "manager-ok");
+
+    let tools = handle.tools().expect("tool hints");
+    assert_eq!(tools.enabled, vec!["tool-x".to_string()]);
+
+    handle.stop().await.expect("stop server");
+}
+
+#[test]
+fn runtime_manager_propagates_tool_hints_for_http() {
+    let env_var = "MCP_HTTP_TOKEN_E8_HINTS";
+    env::set_var(env_var, "token-hints");
+
+    let mut http = StreamableHttpDefinition {
+        url: "https://example.test/hints".into(),
+        headers: BTreeMap::new(),
+        bearer_env_var: Some(env_var.to_string()),
+        connect_timeout_ms: Some(1200),
+        request_timeout_ms: Some(2400),
+    };
+    http.headers.insert("X-Test".into(), "true".into());
+
+    let runtime = McpRuntimeServer::from_definition(
+        "remote-http",
+        McpServerDefinition {
+            transport: McpTransport::StreamableHttp(http),
+            description: Some("http runtime".into()),
+            tags: vec!["http".into()],
+            tools: Some(McpToolConfig {
+                enabled: vec!["alpha".into()],
+                disabled: vec!["beta".into()],
+            }),
+        },
+    );
+
+    let defaults = StdioServerConfig {
+        binary: PathBuf::from("codex"),
+        code_home: None,
+        current_dir: None,
+        env: Vec::new(),
+        app_server_analytics_default_enabled: false,
+        mirror_stdio: false,
+        startup_timeout: Duration::from_secs(2),
+    };
+
+    let launcher = runtime.into_launcher(&defaults);
+    let manager = McpRuntimeManager::new(vec![launcher]);
+
+    let available = manager.available();
+    assert_eq!(available.len(), 1);
+    let summary = &available[0];
+    assert_eq!(summary.name, "remote-http");
+    assert_eq!(
+        summary.transport,
+        McpRuntimeSummaryTransport::StreamableHttp
+    );
+    let summary_tools = summary.tools.as_ref().expect("tool hints present");
+    assert_eq!(summary_tools.enabled, vec!["alpha".to_string()]);
+    assert_eq!(summary_tools.disabled, vec!["beta".to_string()]);
+
+    match manager.prepare("remote-http").expect("prepare http") {
+        McpRuntimeHandle::StreamableHttp(http_handle) => {
+            let tools = http_handle.tools.as_ref().expect("tool hints on handle");
+            assert_eq!(tools.enabled, vec!["alpha".to_string()]);
+            assert_eq!(tools.disabled, vec!["beta".to_string()]);
+            assert_eq!(
+                http_handle.connector.bearer_token.as_deref(),
+                Some("token-hints")
+            );
+        }
+        other => panic!("expected http handle, got {other:?}"),
+    }
+
+    env::remove_var(env_var);
+}
+
+#[test]
+fn http_connector_retrieval_is_non_destructive() {
+    let env_var = "MCP_HTTP_TOKEN_E8_REUSE";
+    env::set_var(env_var, "token-reuse");
+
+    let runtime = McpRuntimeServer::from_definition(
+        "remote-reuse",
+        McpServerDefinition {
+            transport: McpTransport::StreamableHttp(StreamableHttpDefinition {
+                url: "https://example.test/reuse".into(),
+                headers: BTreeMap::new(),
+                bearer_env_var: Some(env_var.to_string()),
+                connect_timeout_ms: Some(1500),
+                request_timeout_ms: Some(3200),
+            }),
+            description: None,
+            tags: vec!["http".into()],
+            tools: Some(McpToolConfig {
+                enabled: vec!["one".into()],
+                disabled: vec![],
+            }),
+        },
+    );
+
+    let defaults = StdioServerConfig {
+        binary: PathBuf::from("codex"),
+        code_home: None,
+        current_dir: None,
+        env: Vec::new(),
+        app_server_analytics_default_enabled: false,
+        mirror_stdio: false,
+        startup_timeout: Duration::from_secs(2),
+    };
+
+    let launcher = runtime.into_launcher(&defaults);
+    let manager = McpRuntimeManager::new(vec![launcher]);
+
+    let first = manager.prepare("remote-reuse").expect("first prepare");
+    let second = manager.prepare("remote-reuse").expect("second prepare");
+
+    let first_token = match first {
+        McpRuntimeHandle::StreamableHttp(handle) => handle.connector.bearer_token,
+        other => panic!("expected http handle, got {other:?}"),
+    };
+    let second_token = match second {
+        McpRuntimeHandle::StreamableHttp(handle) => handle.connector.bearer_token,
+        other => panic!("expected http handle, got {other:?}"),
+    };
+
+    assert_eq!(first_token.as_deref(), Some("token-reuse"));
+    assert_eq!(second_token.as_deref(), Some("token-reuse"));
+
+    let summary = manager
+        .available()
+        .into_iter()
+        .find(|s| s.name == "remote-reuse")
+        .expect("summary present");
+    assert_eq!(
+        summary.transport,
+        McpRuntimeSummaryTransport::StreamableHttp
+    );
+    let tools = summary.tools.as_ref().expect("tool hints preserved");
+    assert_eq!(tools.enabled, vec!["one".to_string()]);
+
+    env::remove_var(env_var);
+}
diff --git a/crates/codex/src/process.rs b/crates/codex/src/process.rs
new file mode 100644
index 0000000..b9b7975
--- /dev/null
+++ b/crates/codex/src/process.rs
@@ -0,0 +1,111 @@
+use std::{
+    io::{self, Write},
+    path::Path,
+    process::ExitStatus,
+    time::Duration,
+};
+
+use tokio::{
+    io::{AsyncRead, AsyncReadExt},
+    process::Command,
+    task,
+};
+
+use crate::CodexError;
+
+#[derive(Clone, Copy)]
+pub(crate) enum ConsoleTarget {
+    Stdout,
+    Stderr,
+}
+
+pub(crate) async fn tee_stream<R>(
+    mut reader: R,
+    target: ConsoleTarget,
+    mirror_console: bool,
+) -> Result<Vec<u8>, io::Error>
+where
+    R: AsyncRead + Unpin,
+{
+    let mut buffer = Vec::new();
+    let mut chunk = [0u8; 4096];
+    loop {
+        let n = reader.read(&mut chunk).await?;
+        if n == 0 {
+            break;
+        }
+        if mirror_console {
+            task::block_in_place(|| match target {
+                ConsoleTarget::Stdout => {
+                    let mut out = io::stdout();
+                    out.write_all(&chunk[..n])?;
+                    out.flush()
+                }
+                ConsoleTarget::Stderr => {
+                    let mut out = io::stderr();
+                    out.write_all(&chunk[..n])?;
+                    out.flush()
+                }
+            })?;
+        }
+        buffer.extend_from_slice(&chunk[..n]);
+    }
+    Ok(buffer)
+}
+
+pub(crate) fn spawn_with_retry(
+    command: &mut Command,
+    binary: &Path,
+) -> Result<tokio::process::Child, CodexError> {
+    let mut backoff = Duration::from_millis(2);
+    for attempt in 0..5 {
+        match command.spawn() {
+            Ok(child) => return Ok(child),
+            Err(source) => {
+                let is_busy = matches!(source.kind(), std::io::ErrorKind::ExecutableFileBusy)
+                    || source.raw_os_error() == Some(26);
+                if is_busy && attempt < 4 {
+                    std::thread::sleep(backoff);
+                    backoff = std::cmp::min(backoff * 2, Duration::from_millis(50));
+                    continue;
+                }
+                return Err(CodexError::Spawn {
+                    binary: binary.to_path_buf(),
+                    source,
+                });
+            }
+        }
+    }
+
+    unreachable!("spawn_with_retry should return before exhausting retries")
+}
+
+pub(crate) fn command_output_text(output: &CommandOutput) -> String {
+    let stdout = String::from_utf8_lossy(&output.stdout).into_owned();
+    let stderr = String::from_utf8_lossy(&output.stderr).into_owned();
+    let stdout = stdout.trim_end();
+    let stderr = stderr.trim_end();
+    if stdout.is_empty() {
+        stderr.to_string()
+    } else if stderr.is_empty() {
+        stdout.to_string()
+    } else {
+        format!("{stdout}\n{stderr}")
+    }
+}
+
+pub(crate) fn preferred_output_channel(output: &CommandOutput) -> String {
+    let stderr = String::from_utf8(output.stderr.clone()).unwrap_or_default();
+    let stdout = String::from_utf8(output.stdout.clone()).unwrap_or_default();
+    if stderr.trim().is_empty() {
+        stdout
+    } else {
+        stderr
+    }
+}
+
+pub(crate) struct CommandOutput {
+    pub(crate) status: ExitStatus,
+    pub(crate) stdout: Vec<u8>,
+    pub(crate) stderr: Vec<u8>,
+}
diff --git a/crates/codex/src/version.rs b/crates/codex/src/version.rs
new file mode 100644
index 0000000..134c1d3
--- /dev/null
+++ b/crates/codex/src/version.rs
@@ -0,0 +1,571 @@
+use std::collections::{BTreeMap, HashSet};
+
+use semver::{Prerelease, Version};
+use serde_json::Value;
+
+use crate::{
+    CodexCapabilities, CodexFeature, CodexFeatureFlags, CodexFeatureStage, CodexLatestReleases,
+    CodexRelease, CodexReleaseChannel, CodexUpdateAdvisory, CodexUpdateStatus, CodexVersionInfo,
+    FeaturesListFormat,
+};
+
+fn parse_semver_from_raw(raw: &str) -> Option<Version> {
+    for token in raw.split_whitespace() {
+        let candidate = token
+            .trim_matches(|c: char| matches!(c, '(' | ')' | ',' | ';'))
+            .trim_start_matches('v');
+        if let Ok(version) = Version::parse(candidate) {
+            return Some(version);
+        }
+    }
+    None
+}
+
+pub(super) fn parse_version_output(output: &str) -> CodexVersionInfo {
+    let raw = output.trim().to_string();
+    let parsed_version = parse_semver_from_raw(&raw);
+    let semantic = parsed_version
+        .as_ref()
+        .map(|version| (version.major, version.minor, version.patch));
+    let mut commit = extract_commit_hash(&raw);
+    if commit.is_none() {
+        for token in raw.split_whitespace() {
+            let candidate = token
+                .trim_matches(|c: char| matches!(c, '(' | ')' | ',' | ';'))
+                .trim_start_matches('v');
+            if let Some(cleaned) = cleaned_hex(candidate) {
+                commit = Some(cleaned);
+                break;
+            }
+        }
+    }
+    let channel = parsed_version
+        .as_ref()
+        .map(release_channel_for_version)
+        .unwrap_or_else(|| infer_release_channel(&raw));
+
+    CodexVersionInfo {
+        raw,
+        semantic,
+        commit,
+        channel,
+    }
+}
+
+fn release_channel_for_version(version: &Version) -> CodexReleaseChannel {
+    if version.pre.is_empty() {
+        CodexReleaseChannel::Stable
+    } else {
+        let prerelease = version.pre.as_str().to_ascii_lowercase();
+        if prerelease.contains("beta") {
+            CodexReleaseChannel::Beta
+        } else if prerelease.contains("nightly") {
+            CodexReleaseChannel::Nightly
+        } else {
+            CodexReleaseChannel::Custom
+        }
+    }
+}
+
+fn infer_release_channel(raw: &str) -> CodexReleaseChannel {
+    let lower = raw.to_ascii_lowercase();
+    if lower.contains("beta") {
+        CodexReleaseChannel::Beta
+    } else if lower.contains("nightly") {
+        CodexReleaseChannel::Nightly
+    } else {
+        CodexReleaseChannel::Custom
+    }
+}
+
+fn codex_semver(info: &CodexVersionInfo) -> Option<Version> {
+    if let Some(parsed) = parse_semver_from_raw(&info.raw) {
+        return Some(parsed);
+    }
+    let (major, minor, patch) = info.semantic?;
+    let mut version = Version::new(major, minor, patch);
+    if version.pre.is_empty() {
+        match info.channel {
+            CodexReleaseChannel::Beta => {
+                version.pre = Prerelease::new("beta").ok()?;
+            }
+            CodexReleaseChannel::Nightly => {
+                version.pre = Prerelease::new("nightly").ok()?;
+            }
+            CodexReleaseChannel::Stable | CodexReleaseChannel::Custom => {}
+        }
+    }
+    Some(version)
+}
+
+fn codex_release_from_info(info: &CodexVersionInfo) -> Option<CodexRelease> {
+    let version = codex_semver(info)?;
+    Some(CodexRelease {
+        channel: info.channel,
+        version,
+    })
+}
+
+fn extract_commit_hash(raw: &str) -> Option<String> {
+    let tokens: Vec<&str> = raw.split_whitespace().collect();
+    for window in tokens.windows(2) {
+        if window[0].eq_ignore_ascii_case("commit") {
+            if let Some(cleaned) = cleaned_hex(window[1]) {
+                return Some(cleaned);
+            }
+        }
+    }
+
+    for token in tokens {
+        if let Some(cleaned) = cleaned_hex(token) {
+            return Some(cleaned);
+        }
+    }
+    None
+}
+
+fn cleaned_hex(token: &str) -> Option<String> {
+    let trimmed = token
+        .trim_matches(|c: char| matches!(c, '(' | ')' | ',' | ';'))
+        .trim_start_matches("commit")
+        .trim_start_matches(':')
+        .trim_start_matches('g');
+    if trimmed.len() >= 7 && trimmed.chars().all(|c| c.is_ascii_hexdigit()) {
+        Some(trimmed.to_string())
+    } else {
+        None
+    }
+}
+
+pub(super) fn parse_features_from_json(output: &str) -> Option<CodexFeatureFlags> {
+    let parsed: Value = serde_json::from_str(output).ok()?;
+    let mut tokens = HashSet::new();
+    collect_feature_tokens(&parsed, &mut tokens);
+    if tokens.is_empty() {
+        return None;
+    }
+
+    let mut flags = CodexFeatureFlags::default();
+    for token in tokens {
+        apply_feature_token(&mut flags, &token);
+    }
+    Some(flags)
+}
+
+fn collect_feature_tokens(value: &Value, tokens: &mut HashSet<String>) {
+    match value {
+        Value::String(value) => {
+            if !value.trim().is_empty() {
+                tokens.insert(value.clone());
+            }
+        }
+        Value::Array(items) => {
+            for item in items {
+                collect_feature_tokens(item, tokens);
+            }
+        }
+        Value::Object(map) => {
+            for (key, value) in map {
+                if let Value::Bool(true) = value {
+                    tokens.insert(key.clone());
+                }
+                collect_feature_tokens(value, tokens);
+            }
+        }
+        _ => {}
+    }
+}
+
+pub(super) fn parse_features_from_text(output: &str) -> CodexFeatureFlags {
+    let mut flags = CodexFeatureFlags::default();
+    let lower = output.to_ascii_lowercase();
+    if lower.contains("features list") {
+        flags.supports_features_list = true;
+    }
+    if lower.contains("--output-schema") || lower.contains("output schema") {
+        flags.supports_output_schema = true;
+    }
+    if lower.contains("add-dir") || lower.contains("add dir") {
+        flags.supports_add_dir = true;
+    }
+    if lower.contains("login --mcp") || lower.contains("mcp login") {
+        flags.supports_mcp_login = true;
+    }
+    if lower.contains("login") && lower.contains("mcp") {
+        flags.supports_mcp_login = true;
+    }
+
+    for token in lower
+        .split(|c: char| c.is_ascii_whitespace() || c == ',' || c == ';' || c == '|')
+        .filter(|token| !token.is_empty())
+    {
+        apply_feature_token(&mut flags, token);
+    }
+    flags
+}
+
+pub(super) fn parse_help_output(output: &str) -> CodexFeatureFlags {
+    let mut flags = parse_features_from_text(output);
+    let lower = output.to_ascii_lowercase();
+    if lower.contains("features list") {
+        flags.supports_features_list = true;
+    }
+    flags
+}
+
+pub(super) fn merge_feature_flags(target: &mut CodexFeatureFlags, update: CodexFeatureFlags) {
+    target.supports_features_list |= update.supports_features_list;
+    target.supports_output_schema |= update.supports_output_schema;
+    target.supports_add_dir |= update.supports_add_dir;
+    target.supports_mcp_login |= update.supports_mcp_login;
+}
+
+pub(super) fn detected_feature_flags(flags: &CodexFeatureFlags) -> bool {
+    flags.supports_output_schema || flags.supports_add_dir || flags.supports_mcp_login
+}
+
+pub(super) fn should_run_help_fallback(flags: &CodexFeatureFlags) -> bool {
+    !flags.supports_features_list
+        || !flags.supports_output_schema
+        || !flags.supports_add_dir
+        || !flags.supports_mcp_login
+}
+
+fn normalize_feature_token(token: &str) -> String {
+    token
+        .chars()
+        .map(|c| {
+            if c.is_ascii_alphanumeric() {
+                c.to_ascii_lowercase()
+            } else {
+                '_'
+            }
+        })
+        .collect()
+}
+
+fn apply_feature_token(flags: &mut CodexFeatureFlags, token: &str) {
+    let normalized = normalize_feature_token(token);
+    let compact = normalized.replace('_', "");
+    if normalized.contains("features_list") || compact.contains("featureslist") {
+        flags.supports_features_list = true;
+    }
+    if normalized.contains("output_schema") || compact.contains("outputschema") {
+        flags.supports_output_schema = true;
+    }
+    if normalized.contains("add_dir") || compact.contains("adddir") {
+        flags.supports_add_dir = true;
+    }
+    if normalized.contains("mcp_login")
+        || (normalized.contains("login") && normalized.contains("mcp"))
+    {
+        flags.supports_mcp_login = true;
+    }
+}
+
+pub(super) fn parse_feature_list_output(
+    stdout: &str,
+    prefer_json: bool,
+) -> Result<(Vec<CodexFeature>, FeaturesListFormat), String> {
+    let trimmed = stdout.trim();
+    if trimmed.is_empty() {
+        return Err("features list output was empty".to_string());
+    }
+
+    if prefer_json {
+        if let Some(features) = parse_feature_list_json(trimmed) {
+            if !features.is_empty() {
+                return Ok((features, FeaturesListFormat::Json));
+            }
+        }
+        if let Some(features) = parse_feature_list_text(trimmed) {
+            if !features.is_empty() {
+                return Ok((features, FeaturesListFormat::Text));
+            }
+        }
+    } else {
+        if let Some(features) = parse_feature_list_text(trimmed) {
+            if !features.is_empty() {
+                return Ok((features, FeaturesListFormat::Text));
+            }
+        }
+        if let Some(features) = parse_feature_list_json(trimmed) {
+            if !features.is_empty() {
+                return Ok((features, FeaturesListFormat::Json));
+            }
+        }
+    }
+
+    Err("could not parse JSON or text feature rows".to_string())
+}
+
+fn parse_feature_list_json(output: &str) -> Option<Vec<CodexFeature>> {
+    let parsed: Value = serde_json::from_str(output).ok()?;
+    parse_feature_list_json_value(&parsed)
+}
+
+fn parse_feature_list_json_value(value: &Value) -> Option<Vec<CodexFeature>> {
+    match value {
+        Value::Array(items) => Some(
+            items
+                .iter()
+                .filter_map(|item| match item {
+                    Value::Object(map) => feature_from_json_fields(None, map),
+                    Value::String(name) => Some(CodexFeature {
+                        name: name.clone(),
+                        stage: None,
+                        enabled: true,
+                        extra: BTreeMap::new(),
+                    }),
+                    _ => None,
+                })
+                .collect(),
+        ),
+        Value::Object(map) => {
+            if let Some(features) = map.get("features") {
+                return parse_feature_list_json_value(features);
+            }
+            if map.contains_key("name") || map.contains_key("enabled") || map.contains_key("stage")
+            {
+                return feature_from_json_fields(None, map).map(|feature| vec![feature]);
+            }
+            Some(
+                map.iter()
+                    .filter_map(|(name, value)| match value {
+                        Value::Object(inner) => {
+                            feature_from_json_fields(Some(name.as_str()), inner)
+                        }
+                        Value::Bool(flag) => Some(CodexFeature {
+                            name: name.clone(),
+                            stage: None,
+                            enabled: *flag,
+                            extra: BTreeMap::new(),
+                        }),
+                        Value::String(flag) => parse_feature_enabled_str(flag)
+                            .map(|enabled| CodexFeature {
+                                name: name.clone(),
+                                stage: None,
+                                enabled,
+                                extra: BTreeMap::new(),
+                            })
+                            .or_else(|| {
+                                Some(CodexFeature {
+                                    name: name.clone(),
+                                    stage: Some(CodexFeatureStage::parse(flag)),
+                                    enabled: true,
+                                    extra: BTreeMap::new(),
+                                })
+                            }),
+                        _ => None,
+                    })
+                    .collect(),
+            )
+        }
+        _ => None,
+    }
+}
+
+fn parse_feature_list_text(output: &str) -> Option<Vec<CodexFeature>> {
+    let mut features = Vec::new();
+    for line in output.lines() {
+        let trimmed = line.trim();
+        if trimmed.is_empty() {
+            continue;
+        }
+        if trimmed
+            .chars()
+            .all(|c| matches!(c, '-' | '=' | '+' | '*' | '|'))
+        {
+            continue;
+        }
+
+        let tokens: Vec<&str> = trimmed.split_whitespace().collect();
+        if tokens.len() < 3 {
+            continue;
+        }
+        if tokens[0].eq_ignore_ascii_case("feature")
+            && tokens[1].eq_ignore_ascii_case("stage")
+            && tokens[2].eq_ignore_ascii_case("enabled")
+        {
+            continue;
+        }
+
+        let enabled_token = tokens.last().copied().unwrap_or_default();
+        let enabled = match parse_feature_enabled_str(enabled_token) {
+            Some(value) => value,
+            None => continue,
+        };
+        let stage_token = tokens.get(tokens.len() - 2).copied().unwrap_or_default();
+        let name = tokens[..tokens.len() - 2].join(" ");
+        if name.is_empty() {
+            continue;
+        }
+        let stage = (!stage_token.is_empty()).then(|| CodexFeatureStage::parse(stage_token));
+        features.push(CodexFeature {
+            name,
+            stage,
+            enabled,
+            extra: BTreeMap::new(),
+        });
+    }
+
+    if features.is_empty() {
+        None
+    } else {
+        Some(features)
+    }
+}
+
+fn parse_feature_enabled_value(value: &Value) -> Option<bool> {
+    match value {
+        Value::Bool(flag) => Some(*flag),
+        Value::String(raw) => parse_feature_enabled_str(raw),
+        _ => None,
+    }
+}
+
+fn parse_feature_enabled_str(raw: &str) -> Option<bool> {
+    match raw.trim().to_ascii_lowercase().as_str() {
+        "true" | "yes" | "y" | "on" | "1" | "enabled" => Some(true),
+        "false" | "no" | "n" | "off" | "0" | "disabled" => Some(false),
+        _ => None,
+    }
+}
+
+fn feature_from_json_fields(
+    name_hint: Option<&str>,
+    map: &serde_json::Map<String, Value>,
+) -> Option<CodexFeature> {
+    let name = map
+        .get("name")
+        .and_then(Value::as_str)
+        .map(str::to_string)
+        .or_else(|| name_hint.map(str::to_string))?;
+    let enabled = map
+        .get("enabled")
+        .and_then(parse_feature_enabled_value)
+        .or_else(|| map.get("value").and_then(parse_feature_enabled_value))?;
+    let stage = map
+        .get("stage")
+        .or_else(|| map.get("status"))
+        .and_then(Value::as_str)
+        .map(CodexFeatureStage::parse);
+
+    let mut extra = BTreeMap::new();
+    for (key, value) in map {
+        if matches!(
+            key.as_str(),
+            "name" | "stage" | "status" | "enabled" | "value"
+        ) {
+            continue;
+        }
+        extra.insert(key.clone(), value.clone());
+    }
+
+    Some(CodexFeature {
+        name,
+        stage,
+        enabled,
+        extra,
+    })
+}
+
+/// Computes an update advisory for a previously probed binary.
+///
+/// Callers that already have a [`CodexCapabilities`] snapshot can use this
+/// helper to avoid re-running `codex --version`. Provide a [`CodexLatestReleases`]
+/// table sourced from your preferred distribution channel.
+pub fn update_advisory_from_capabilities(
+    capabilities: &CodexCapabilities,
+    latest_releases: &CodexLatestReleases,
+) -> CodexUpdateAdvisory {
+    let local_release = capabilities
+        .version
+        .as_ref()
+        .and_then(codex_release_from_info);
+    let preferred_channel = local_release
+        .as_ref()
+        .map(|release| release.channel)
+        .unwrap_or(CodexReleaseChannel::Stable);
+    let (latest_release, comparison_channel, fell_back) =
+        latest_releases.select_for_channel(preferred_channel);
+    let mut notes = Vec::new();
+
+    if fell_back {
+        notes.push(format!(
+            "No latest {preferred_channel} release provided; comparing against {comparison_channel}."
+        ));
+    }
+
+    let status = match (local_release.as_ref(), latest_release.as_ref()) {
+        (None, None) => CodexUpdateStatus::UnknownLatestVersion,
+        (None, Some(_)) => CodexUpdateStatus::UnknownLocalVersion,
+        (Some(_), None) => CodexUpdateStatus::UnknownLatestVersion,
+        (Some(local), Some(latest)) => {
+            if local.version < latest.version {
+                CodexUpdateStatus::UpdateRecommended
+            } else if local.version > latest.version {
+                CodexUpdateStatus::LocalNewerThanKnown
+            } else {
+                CodexUpdateStatus::UpToDate
+            }
+        }
+    };
+
+    match status {
+        CodexUpdateStatus::UpdateRecommended => {
+            if let (Some(local), Some(latest)) = (local_release.as_ref(), latest_release.as_ref()) {
+                notes.push(format!(
+                    "Local codex {local_version} is behind latest {comparison_channel} {latest_version}.",
+                    local_version = local.version,
+                    latest_version = latest.version
+                ));
+            }
+        }
+        CodexUpdateStatus::LocalNewerThanKnown => {
+            if let Some(local) = local_release.as_ref() {
+                let known = latest_release
+                    .as_ref()
+                    .map(|release| release.version.to_string())
+                    .unwrap_or_else(|| "unknown".to_string());
+                notes.push(format!(
+                    "Local codex {local_version} is newer than provided {comparison_channel} metadata (latest table: {known}).",
+                    local_version = local.version
+                ));
+            }
+        }
+        CodexUpdateStatus::UnknownLocalVersion => {
+            if let Some(latest) = latest_release.as_ref() {
+                notes.push(format!(
+                    "Latest known {comparison_channel} release is {latest_version}; local version could not be parsed.",
+                    latest_version = latest.version
+                ));
+            } else {
+                notes.push(
+                    "Local version could not be parsed and no latest release was provided."
+                        .to_string(),
+                );
+            }
+        }
+        CodexUpdateStatus::UnknownLatestVersion => notes.push(
+            "No latest Codex release information provided; update advisory unavailable."
+                .to_string(),
+        ),
+        CodexUpdateStatus::UpToDate => {
+            if let Some(latest) = latest_release.as_ref() {
+                notes.push(format!(
+                    "Local codex matches latest {comparison_channel} release {latest_version}.",
+                    latest_version = latest.version
+                ));
+            }
+        }
+    }
+
+    CodexUpdateAdvisory {
+        local_release,
+        latest_release,
+        comparison_channel,
+        status,
+        notes,
+    }
+}
diff --git a/crates/xtask/src/codex_validate.rs b/crates/xtask/src/codex_validate.rs
index f54656c..6da3ab3 100644
--- a/crates/xtask/src/codex_validate.rs
+++ b/crates/xtask/src/codex_validate.rs
@@ -11,10 +11,14 @@ use semver::Version;
 use serde_json::{json, Value};
 use thiserror::Error;
 
+mod current;
+mod fix_mode;
 mod models;
+mod pointer_consistency;
 mod pointers;
 mod report_invariants;
 mod schema;
+mod versions;
 mod wrapper_coverage;
 use models::{
     IuSortKey, ParityExclusionUnit, ParityExclusionsIndex, PointerRead, PointerValue,
@@ -213,7 +217,7 @@ fn run_inner(args: Args) -> Result<Vec<Violation>, FatalError> {
     };
 
     if matches!(args.mode, Mode::Fix) {
-        apply_fix_mode(&ctx)?;
+        fix_mode::apply_fix_mode(&ctx)?;
     }
 
     let mut violations = Vec::<Violation>::new();
@@ -225,16 +229,21 @@ fn run_inner(args: Args) -> Result<Vec<Violation>, FatalError> {
 
     // 2) Version set to validate.
     let versions_to_validate =
-        compute_versions_to_validate(&mut ctx, &mut violations, &pointer_values);
+        versions::compute_versions_to_validate(&mut ctx, &mut violations, &pointer_values);
 
     // 3) Per-version required files (+ schemas).
     let mut version_metadata = BTreeMap::<String, Value>::new();
     for version in &versions_to_validate {
-        validate_version_bundle(&mut ctx, &mut violations, version, &mut version_metadata);
+        versions::validate_version_bundle(
+            &mut ctx,
+            &mut violations,
+            version,
+            &mut version_metadata,
+        );
     }
 
     // 4) current.json invariants.
-    validate_current_json(
+    current::validate_current_json(
         &mut ctx,
         &mut violations,
         pointer_values.latest_validated.as_deref(),
@@ -244,7 +253,12 @@ fn run_inner(args: Args) -> Result<Vec<Violation>, FatalError> {
     wrapper_coverage::validate_wrapper_coverage(&mut ctx, &mut violations);
 
     // 6) Pointer  version metadata consistency (requires parsed metadata).
-    validate_pointer_consistency(&ctx, &mut violations, &pointer_values, &version_metadata);
+    pointer_consistency::validate_pointer_consistency(
+        &ctx,
+        &mut violations,
+        &pointer_values,
+        &version_metadata,
+    );
 
     violations.sort_by(|a, b| {
         a.sort_key()
@@ -258,729 +272,6 @@ fn run_inner(args: Args) -> Result<Vec<Violation>, FatalError> {
     Ok(violations)
 }
 
-fn apply_fix_mode(ctx: &ValidateCtx) -> Result<(), FatalError> {
-    // 1) Create missing pointer files under pointers/ for every expected target.
-    for target in &ctx.expected_targets {
-        for dir in ["pointers/latest_supported", "pointers/latest_validated"] {
-            let path = ctx.root.join(dir).join(format!("{target}.txt"));
-            if path.exists() {
-                continue;
-            }
-            fs::create_dir_all(path.parent().unwrap_or(&ctx.root))?;
-            fs::write(&path, b"none\n")?;
-        }
-    }
-
-    // 2) Normalize pointer formatting (single line + trailing newline).
-    for target in &ctx.expected_targets {
-        for dir in ["pointers/latest_supported", "pointers/latest_validated"] {
-            let path = ctx.root.join(dir).join(format!("{target}.txt"));
-            pointers::normalize_single_line_file(&path)?;
-        }
-    }
-    pointers::normalize_single_line_file(&ctx.root.join("latest_validated.txt"))?;
-    pointers::normalize_single_line_file(&ctx.root.join("min_supported.txt"))?;
-
-    // 3) Normalize current.json to match snapshots/<latest_validated>/union.json (if possible).
-    let latest_validated = match pointers::read_pointer_file(
-        &ctx.root.join("latest_validated.txt"),
-        &ctx.stable_semver_re,
-        false,
-    ) {
-        Ok(PointerRead::Value(PointerValue::Version(ver))) => Some(ver.to_string()),
-        _ => None,
-    };
-
-    if let Some(version) = latest_validated {
-        let union_path = ctx.root.join("snapshots").join(&version).join("union.json");
-        if union_path.is_file() {
-            let bytes = fs::read(&union_path)?;
-            fs::write(ctx.root.join("current.json"), bytes)?;
-        }
-    }
-
-    Ok(())
-}
-
-fn compute_versions_to_validate(
-    ctx: &mut ValidateCtx,
-    violations: &mut Vec<Violation>,
-    pointers: &PointerValues,
-) -> Vec<String> {
-    let mut versions = BTreeSet::<Version>::new();
-
-    for v in pointers
-        .min_supported
-        .iter()
-        .chain(pointers.latest_validated.iter())
-    {
-        if let Some(ver) = parse_stable_version(v, &ctx.stable_semver_re) {
-            versions.insert(ver);
-        }
-    }
-    for (_target, v) in pointers
-        .by_target_latest_supported
-        .iter()
-        .chain(pointers.by_target_latest_validated.iter())
-    {
-        if let Some(v) = v {
-            if let Some(ver) = parse_stable_version(v, &ctx.stable_semver_re) {
-                versions.insert(ver);
-            }
-        }
-    }
-
-    let versions_dir = ctx.root.join("versions");
-    match fs::read_dir(&versions_dir) {
-        Ok(read_dir) => {
-            let mut entries = read_dir
-                .filter_map(|e| e.ok())
-                .filter_map(|e| {
-                    let path = e.path();
-                    if path.extension().and_then(|x| x.to_str()) != Some("json") {
-                        return None;
-                    }
-                    let stem = path.file_stem()?.to_str()?.to_string();
-                    Some((stem, path))
-                })
-                .collect::<Vec<_>>();
-            entries.sort_by(|a, b| a.0.cmp(&b.0));
-            for (stem, path) in entries {
-                match parse_stable_version(&stem, &ctx.stable_semver_re) {
-                    Some(ver) => {
-                        versions.insert(ver);
-                    }
-                    None => violations.push(Violation {
-                        code: "VERSION_FILE_INVALID_NAME",
-                        path: rel_path(&ctx.root, &path),
-                        json_pointer: None,
-                        message: format!(
-                            "versions/<version>.json filename must be a strict stable semver (got {stem})"
-                        ),
-                        unit: Some("versions"),
-                        command_path: None,
-                        key_or_name: Some(stem),
-                        field: Some("filename"),
-                        target_triple: None,
-                        details: None,
-                    }),
-                }
-            }
-        }
-        Err(e) if e.kind() == io::ErrorKind::NotFound => {}
-        Err(e) => {
-            violations.push(Violation {
-                code: "VERSIONS_DIR_UNREADABLE",
-                path: rel_path(&ctx.root, &versions_dir),
-                json_pointer: None,
-                message: format!("failed to read versions directory: {e}"),
-                unit: Some("versions"),
-                command_path: None,
-                key_or_name: None,
-                field: None,
-                target_triple: None,
-                details: None,
-            });
-        }
-    }
-
-    versions.into_iter().map(|v| v.to_string()).collect()
-}
-
-fn validate_version_bundle(
-    ctx: &mut ValidateCtx,
-    violations: &mut Vec<Violation>,
-    version: &str,
-    version_metadata: &mut BTreeMap<String, Value>,
-) {
-    let version_path = ctx.root.join("versions").join(format!("{version}.json"));
-    match schema::read_json_file(
-        &ctx.root,
-        &version_path,
-        violations,
-        "VERSION_METADATA_INVALID_JSON",
-    ) {
-        Some(value) => {
-            schema::schema_validate(
-                ctx,
-                violations,
-                &ctx.version_schema,
-                &value,
-                &version_path,
-                "VERSION_METADATA_SCHEMA_INVALID",
-            );
-            validate_version_metadata_validation_sets(
-                ctx,
-                violations,
-                version,
-                &value,
-                &version_path,
-            );
-            version_metadata.insert(version.to_string(), value);
-        }
-        None => {
-            if !version_path.exists() {
-                violations.push(Violation {
-                    code: "VERSION_METADATA_MISSING",
-                    path: rel_path(&ctx.root, &version_path),
-                    json_pointer: None,
-                    message: format!("missing required file: versions/{version}.json"),
-                    unit: Some("versions"),
-                    command_path: None,
-                    key_or_name: Some(version.to_string()),
-                    field: Some("versions"),
-                    target_triple: None,
-                    details: None,
-                });
-            }
-        }
-    }
-
-    let union_path = ctx.root.join("snapshots").join(version).join("union.json");
-    let union_value = match schema::read_json_file(
-        &ctx.root,
-        &union_path,
-        violations,
-        "UNION_INVALID_JSON",
-    ) {
-        Some(value) => {
-            schema::schema_validate(
-                ctx,
-                violations,
-                &ctx.schema,
-                &value,
-                &union_path,
-                "UNION_SCHEMA_INVALID",
-            );
-            if !is_union_snapshot(&value) {
-                violations.push(Violation {
-                    code: "UNION_WRONG_KIND",
-                    path: rel_path(&ctx.root, &union_path),
-                    json_pointer: Some("/snapshot_schema_version".to_string()),
-                    message: "snapshots/<version>/union.json must be an UpstreamSnapshotUnionV2 (snapshot_schema_version=2, mode=union)".to_string(),
-                    unit: Some("snapshots"),
-                    command_path: None,
-                    key_or_name: Some(version.to_string()),
-                    field: Some("union"),
-                    target_triple: None,
-                    details: None,
-                });
-            }
-            Some(value)
-        }
-        None => {
-            if !union_path.exists() {
-                violations.push(Violation {
-                    code: "UNION_MISSING",
-                    path: rel_path(&ctx.root, &union_path),
-                    json_pointer: None,
-                    message: format!("missing required file: snapshots/{version}/union.json"),
-                    unit: Some("snapshots"),
-                    command_path: None,
-                    key_or_name: Some(version.to_string()),
-                    field: Some("union"),
-                    target_triple: None,
-                    details: None,
-                });
-            }
-            None
-        }
-    };
-
-    let inputs = union_value
-        .as_ref()
-        .and_then(|u| u.get("inputs"))
-        .and_then(Value::as_array)
-        .cloned()
-        .unwrap_or_default();
-
-    let mut input_targets = Vec::<String>::new();
-    for input in &inputs {
-        if let Some(t) = input.get("target_triple").and_then(Value::as_str) {
-            input_targets.push(t.to_string());
-        }
-    }
-
-    for target in &input_targets {
-        let per_target_path = ctx
-            .root
-            .join("snapshots")
-            .join(version)
-            .join(format!("{target}.json"));
-        match schema::read_json_file(
-            &ctx.root,
-            &per_target_path,
-            violations,
-            "SNAPSHOT_INVALID_JSON",
-        ) {
-            Some(value) => {
-                schema::schema_validate(
-                    ctx,
-                    violations,
-                    &ctx.schema,
-                    &value,
-                    &per_target_path,
-                    "SNAPSHOT_SCHEMA_INVALID",
-                );
-                if !is_per_target_snapshot(&value) {
-                    violations.push(Violation {
-                        code: "SNAPSHOT_WRONG_KIND",
-                        path: rel_path(&ctx.root, &per_target_path),
-                        json_pointer: Some("/snapshot_schema_version".to_string()),
-                        message: "snapshots/<version>/<target_triple>.json must be an UpstreamSnapshotV1 (snapshot_schema_version=1)".to_string(),
-                        unit: Some("snapshots"),
-                        command_path: None,
-                        key_or_name: Some(target.to_string()),
-                        field: Some("per_target"),
-                        target_triple: Some(target.to_string()),
-                        details: None,
-                    });
-                }
-            }
-            None => {
-                if per_target_path.exists() {
-                    continue;
-                }
-                violations.push(Violation {
-                    code: "SNAPSHOT_MISSING",
-                    path: rel_path(&ctx.root, &per_target_path),
-                    json_pointer: None,
-                    message: format!(
-                        "missing required file: snapshots/{version}/{target}.json (referenced by union.inputs[])"
-                    ),
-                    unit: Some("snapshots"),
-                    command_path: None,
-                    key_or_name: Some(target.to_string()),
-                    field: Some("per_target"),
-                    target_triple: Some(target.to_string()),
-                    details: None,
-                });
-            }
-        }
-    }
-
-    // Reports are required depending on version status.
-    let status = version_metadata
-        .get(version)
-        .and_then(|v| v.get("status"))
-        .and_then(Value::as_str)
-        .unwrap_or("unknown");
-
-    let require_reports = matches!(status, "reported" | "validated" | "supported");
-    let reports_dir = ctx.root.join("reports").join(version);
-    let any_report = reports_dir.join("coverage.any.json");
-    if require_reports {
-        report_invariants::require_report(ctx, violations, version, "any", None, &any_report);
-    } else {
-        report_invariants::validate_report_if_present(ctx, violations, &any_report);
-    }
-
-    for target in &input_targets {
-        let per_target = reports_dir.join(format!("coverage.{target}.json"));
-        if require_reports {
-            report_invariants::require_report(
-                ctx,
-                violations,
-                version,
-                "per_target",
-                Some(target.as_str()),
-                &per_target,
-            );
-        } else {
-            report_invariants::validate_report_if_present(ctx, violations, &per_target);
-        }
-    }
-
-    let complete = union_value
-        .as_ref()
-        .and_then(|u| u.get("complete"))
-        .and_then(Value::as_bool)
-        .unwrap_or(false);
-    if complete {
-        let all_report = reports_dir.join("coverage.all.json");
-        if require_reports {
-            report_invariants::require_report(ctx, violations, version, "all", None, &all_report);
-        } else {
-            report_invariants::validate_report_if_present(ctx, violations, &all_report);
-        }
-    }
-}
-
-fn validate_current_json(
-    ctx: &mut ValidateCtx,
-    violations: &mut Vec<Violation>,
-    latest_validated: Option<&str>,
-) {
-    let current_path = ctx.root.join("current.json");
-    let current_value = match schema::read_json_file(
-        &ctx.root,
-        &current_path,
-        violations,
-        "CURRENT_INVALID_JSON",
-    ) {
-        Some(v) => {
-            schema::schema_validate(
-                ctx,
-                violations,
-                &ctx.schema,
-                &v,
-                &current_path,
-                "CURRENT_SCHEMA_INVALID",
-            );
-            if !is_union_snapshot(&v) {
-                violations.push(Violation {
-                    code: "CURRENT_WRONG_KIND",
-                    path: rel_path(&ctx.root, &current_path),
-                    json_pointer: Some("/snapshot_schema_version".to_string()),
-                    message: "current.json must be an UpstreamSnapshotUnionV2 (snapshot_schema_version=2, mode=union)".to_string(),
-                    unit: Some("current_json"),
-                    command_path: None,
-                    key_or_name: None,
-                    field: Some("current"),
-                    target_triple: None,
-                    details: None,
-                });
-            }
-            Some(v)
-        }
-        None => {
-            if current_path.exists() {
-                return;
-            }
-            violations.push(Violation {
-                code: "CURRENT_MISSING",
-                path: rel_path(&ctx.root, &current_path),
-                json_pointer: None,
-                message: "missing required file: current.json".to_string(),
-                unit: Some("current_json"),
-                command_path: None,
-                key_or_name: None,
-                field: Some("current"),
-                target_triple: None,
-                details: None,
-            });
-            None
-        }
-    };
-
-    let Some(latest_validated) = latest_validated else {
-        return;
-    };
-    let union_path = ctx
-        .root
-        .join("snapshots")
-        .join(latest_validated)
-        .join("union.json");
-
-    if current_path.is_file() && union_path.is_file() {
-        if let (Ok(a), Ok(b)) = (fs::read(&current_path), fs::read(&union_path)) {
-            if a != b {
-                violations.push(Violation {
-                    code: "CURRENT_JSON_NOT_EQUAL_UNION",
-                    path: rel_path(&ctx.root, &current_path),
-                    json_pointer: None,
-                    message: format!(
-                        "current.json must be byte-for-byte identical to snapshots/{latest_validated}/union.json"
-                    ),
-                    unit: Some("current_json"),
-                    command_path: None,
-                    key_or_name: Some(latest_validated.to_string()),
-                    field: Some("identity"),
-                    target_triple: None,
-                    details: None,
-                });
-            }
-        }
-    }
-
-    // current.json semantic version invariants use the required target's input.binary.semantic_version.
-    let Some(current_value) = current_value else {
-        return;
-    };
-    let required_target = ctx.required_target.clone();
-    let required_input = current_value
-        .get("inputs")
-        .and_then(Value::as_array)
-        .and_then(|inputs| {
-            inputs.iter().find(|i| {
-                i.get("target_triple")
-                    .and_then(Value::as_str)
-                    .is_some_and(|t| t == required_target.as_str())
-            })
-        });
-    let Some(required_input) = required_input else {
-        violations.push(Violation {
-            code: "CURRENT_JSON_MISSING_REQUIRED_TARGET",
-            path: rel_path(&ctx.root, &current_path),
-            json_pointer: Some("/inputs".to_string()),
-            message: format!("current.json.inputs[] missing required_target={required_target}"),
-            unit: Some("current_json"),
-            command_path: None,
-            key_or_name: Some(required_target.clone()),
-            field: Some("inputs"),
-            target_triple: Some(required_target),
-            details: None,
-        });
-        return;
-    };
-    let semantic_version = required_input
-        .get("binary")
-        .and_then(|b| b.get("semantic_version"))
-        .and_then(Value::as_str);
-    if semantic_version != Some(latest_validated) {
-        violations.push(Violation {
-            code: "CURRENT_JSON_SEMVER_MISMATCH",
-            path: rel_path(&ctx.root, &current_path),
-            json_pointer: Some("/inputs/*/binary/semantic_version".to_string()),
-            message: format!(
-                "current.json required_target binary.semantic_version must equal latest_validated.txt (expected {latest_validated}, got {})",
-                semantic_version.unwrap_or("<missing>")
-            ),
-            unit: Some("current_json"),
-            command_path: None,
-            key_or_name: Some(required_target.clone()),
-            field: Some("semantic_version"),
-            target_triple: Some(required_target),
-            details: None,
-        });
-    }
-}
-
-fn intersect(a: &BTreeSet<String>, b: &BTreeSet<String>) -> BTreeSet<String> {
-    a.intersection(b).cloned().collect()
-}
-
-fn validate_version_metadata_validation_sets(
-    ctx: &ValidateCtx,
-    violations: &mut Vec<Violation>,
-    version: &str,
-    meta: &Value,
-    path: &Path,
-) {
-    let Some(validation) = meta.get("validation") else {
-        return;
-    };
-
-    let expected = ctx
-        .expected_targets
-        .iter()
-        .cloned()
-        .collect::<BTreeSet<_>>();
-
-    let passed = validation
-        .get("passed_targets")
-        .and_then(Value::as_array)
-        .map(|arr| {
-            arr.iter()
-                .filter_map(Value::as_str)
-                .map(|s| s.to_string())
-                .collect::<BTreeSet<_>>()
-        })
-        .unwrap_or_default();
-    let failed = validation
-        .get("failed_targets")
-        .and_then(Value::as_array)
-        .map(|arr| {
-            arr.iter()
-                .filter_map(Value::as_str)
-                .map(|s| s.to_string())
-                .collect::<BTreeSet<_>>()
-        })
-        .unwrap_or_default();
-    let skipped = validation
-        .get("skipped_targets")
-        .and_then(Value::as_array)
-        .map(|arr| {
-            arr.iter()
-                .filter_map(Value::as_str)
-                .map(|s| s.to_string())
-                .collect::<BTreeSet<_>>()
-        })
-        .unwrap_or_default();
-
-    let overlaps = [
-        (
-            "passed_targets",
-            "failed_targets",
-            intersect(&passed, &failed),
-        ),
-        (
-            "passed_targets",
-            "skipped_targets",
-            intersect(&passed, &skipped),
-        ),
-        (
-            "failed_targets",
-            "skipped_targets",
-            intersect(&failed, &skipped),
-        ),
-    ];
-    for (a, b, inter) in overlaps {
-        if inter.is_empty() {
-            continue;
-        }
-        violations.push(Violation {
-            code: "VALIDATION_TARGET_SETS_OVERLAP",
-            path: rel_path(&ctx.root, path),
-            json_pointer: Some("/validation".to_string()),
-            message: format!(
-                "versions/{version}.json validation target sets overlap ({a}  {b} = {:?})",
-                inter.iter().collect::<Vec<_>>()
-            ),
-            unit: Some("versions"),
-            command_path: None,
-            key_or_name: Some(version.to_string()),
-            field: Some("validation"),
-            target_triple: None,
-            details: Some(json!({
-                "overlap": inter.into_iter().collect::<Vec<_>>(),
-                "a": a,
-                "b": b,
-            })),
-        });
-    }
-
-    for t in passed.iter().chain(failed.iter()).chain(skipped.iter()) {
-        if expected.contains(t) {
-            continue;
-        }
-        violations.push(Violation {
-            code: "VALIDATION_TARGET_NOT_EXPECTED",
-            path: rel_path(&ctx.root, path),
-            json_pointer: Some("/validation".to_string()),
-            message: format!(
-                "versions/{version}.json validation includes unexpected target_triple={t} (not in RULES.json.union.expected_targets)"
-            ),
-            unit: Some("versions"),
-            command_path: None,
-            key_or_name: Some(version.to_string()),
-            field: Some("validation"),
-            target_triple: Some(t.to_string()),
-            details: None,
-        });
-    }
-
-    let required = ctx.required_target.as_str();
-    let count = (passed.contains(required) as u8)
-        + (failed.contains(required) as u8)
-        + (skipped.contains(required) as u8);
-    if count != 1 {
-        violations.push(Violation {
-            code: "VALIDATION_REQUIRED_TARGET_NOT_EXPLICIT",
-            path: rel_path(&ctx.root, path),
-            json_pointer: Some("/validation".to_string()),
-            message: format!(
-                "versions/{version}.json validation must include required_target={} in exactly one of passed_targets/failed_targets/skipped_targets",
-                ctx.required_target
-            ),
-            unit: Some("versions"),
-            command_path: None,
-            key_or_name: Some(version.to_string()),
-            field: Some("validation"),
-            target_triple: Some(ctx.required_target.clone()),
-            details: Some(json!({
-                "required_target": ctx.required_target,
-                "passed": passed.contains(required),
-                "failed": failed.contains(required),
-                "skipped": skipped.contains(required),
-            })),
-        });
-    }
-}
-
-fn validate_pointer_consistency(
-    ctx: &ValidateCtx,
-    violations: &mut Vec<Violation>,
-    pointers: &PointerValues,
-    version_metadata: &BTreeMap<String, Value>,
-) {
-    for (target, v) in &pointers.by_target_latest_supported {
-        let Some(version) = v.as_deref() else {
-            continue;
-        };
-        let meta = version_metadata.get(version);
-        if meta.is_none() {
-            continue;
-        }
-        let supported_targets = meta
-            .and_then(|m| m.get("coverage"))
-            .and_then(|c| c.get("supported_targets"))
-            .and_then(Value::as_array)
-            .map(|arr| {
-                arr.iter()
-                    .filter_map(Value::as_str)
-                    .map(|s| s.to_string())
-                    .collect::<BTreeSet<_>>()
-            })
-            .unwrap_or_default();
-        if !supported_targets.contains(target) {
-            violations.push(Violation {
-                code: "POINTER_INCONSISTENT_WITH_VERSION_METADATA",
-                path: rel_path(&ctx.root, &ctx.root.join("versions").join(format!("{version}.json"))),
-                json_pointer: Some("/coverage/supported_targets".to_string()),
-                message: format!(
-                    "pointers/latest_supported/{target}.txt={version} requires versions/{version}.json.coverage.supported_targets to include target_triple={target}"
-                ),
-                unit: Some("pointers"),
-                command_path: None,
-                key_or_name: Some(target.clone()),
-                field: Some("latest_supported"),
-                target_triple: Some(target.clone()),
-                details: None,
-            });
-        }
-    }
-
-    for (target, v) in &pointers.by_target_latest_validated {
-        let Some(version) = v.as_deref() else {
-            continue;
-        };
-        let meta = version_metadata.get(version);
-        if meta.is_none() {
-            continue;
-        }
-        let supported_targets = meta
-            .and_then(|m| m.get("coverage"))
-            .and_then(|c| c.get("supported_targets"))
-            .and_then(Value::as_array)
-            .map(|arr| {
-                arr.iter()
-                    .filter_map(Value::as_str)
-                    .map(|s| s.to_string())
-                    .collect::<BTreeSet<_>>()
-            })
-            .unwrap_or_default();
-        let passed_targets = meta
-            .and_then(|m| m.get("validation"))
-            .and_then(|v| v.get("passed_targets"))
-            .and_then(Value::as_array)
-            .map(|arr| {
-                arr.iter()
-                    .filter_map(Value::as_str)
-                    .map(|s| s.to_string())
-                    .collect::<BTreeSet<_>>()
-            })
-            .unwrap_or_default();
-
-        if !supported_targets.contains(target) || !passed_targets.contains(target) {
-            violations.push(Violation {
-                code: "POINTER_INCONSISTENT_WITH_VERSION_METADATA",
-                path: rel_path(&ctx.root, &ctx.root.join("versions").join(format!("{version}.json"))),
-                json_pointer: Some("/validation/passed_targets".to_string()),
-                message: format!(
-                    "pointers/latest_validated/{target}.txt={version} requires versions/{version}.json.coverage.supported_targets and versions/{version}.json.validation.passed_targets to include target_triple={target}"
-                ),
-                unit: Some("pointers"),
-                command_path: None,
-                key_or_name: Some(target.clone()),
-                field: Some("latest_validated"),
-                target_triple: Some(target.clone()),
-                details: None,
-            });
-        }
-    }
-}
-
 fn parse_stable_version(s: &str, stable_semver_re: &Regex) -> Option<Version> {
     models::parse_stable_version(s, stable_semver_re)
 }
diff --git a/crates/xtask/src/codex_validate/current.rs b/crates/xtask/src/codex_validate/current.rs
new file mode 100644
index 0000000..697f12d
--- /dev/null
+++ b/crates/xtask/src/codex_validate/current.rs
@@ -0,0 +1,145 @@
+use std::fs;
+
+use serde_json::Value;
+
+use super::{is_union_snapshot, rel_path, schema, ValidateCtx, Violation};
+
+pub(super) fn validate_current_json(
+    ctx: &mut ValidateCtx,
+    violations: &mut Vec<Violation>,
+    latest_validated: Option<&str>,
+) {
+    let current_path = ctx.root.join("current.json");
+    let current_value = match schema::read_json_file(
+        &ctx.root,
+        &current_path,
+        violations,
+        "CURRENT_INVALID_JSON",
+    ) {
+        Some(v) => {
+            schema::schema_validate(
+                ctx,
+                violations,
+                &ctx.schema,
+                &v,
+                &current_path,
+                "CURRENT_SCHEMA_INVALID",
+            );
+            if !is_union_snapshot(&v) {
+                violations.push(Violation {
+                    code: "CURRENT_WRONG_KIND",
+                    path: rel_path(&ctx.root, &current_path),
+                    json_pointer: Some("/snapshot_schema_version".to_string()),
+                    message: "current.json must be an UpstreamSnapshotUnionV2 (snapshot_schema_version=2, mode=union)".to_string(),
+                    unit: Some("current_json"),
+                    command_path: None,
+                    key_or_name: None,
+                    field: Some("current"),
+                    target_triple: None,
+                    details: None,
+                });
+            }
+            Some(v)
+        }
+        None => {
+            if current_path.exists() {
+                return;
+            }
+            violations.push(Violation {
+                code: "CURRENT_MISSING",
+                path: rel_path(&ctx.root, &current_path),
+                json_pointer: None,
+                message: "missing required file: current.json".to_string(),
+                unit: Some("current_json"),
+                command_path: None,
+                key_or_name: None,
+                field: Some("current"),
+                target_triple: None,
+                details: None,
+            });
+            None
+        }
+    };
+
+    let Some(latest_validated) = latest_validated else {
+        return;
+    };
+    let union_path = ctx
+        .root
+        .join("snapshots")
+        .join(latest_validated)
+        .join("union.json");
+
+    if current_path.is_file() && union_path.is_file() {
+        if let (Ok(a), Ok(b)) = (fs::read(&current_path), fs::read(&union_path)) {
+            if a != b {
+                violations.push(Violation {
+                    code: "CURRENT_JSON_NOT_EQUAL_UNION",
+                    path: rel_path(&ctx.root, &current_path),
+                    json_pointer: None,
+                    message: format!(
+                        "current.json must be byte-for-byte identical to snapshots/{latest_validated}/union.json"
+                    ),
+                    unit: Some("current_json"),
+                    command_path: None,
+                    key_or_name: Some(latest_validated.to_string()),
+                    field: Some("identity"),
+                    target_triple: None,
+                    details: None,
+                });
+            }
+        }
+    }
+
+    // current.json semantic version invariants use the required target's input.binary.semantic_version.
+    let Some(current_value) = current_value else {
+        return;
+    };
+    let required_target = ctx.required_target.clone();
+    let required_input = current_value
+        .get("inputs")
+        .and_then(Value::as_array)
+        .and_then(|inputs| {
+            inputs.iter().find(|i| {
+                i.get("target_triple")
+                    .and_then(Value::as_str)
+                    .is_some_and(|t| t == required_target.as_str())
+            })
+        });
+    let Some(required_input) = required_input else {
+        violations.push(Violation {
+            code: "CURRENT_JSON_MISSING_REQUIRED_TARGET",
+            path: rel_path(&ctx.root, &current_path),
+            json_pointer: Some("/inputs".to_string()),
+            message: format!("current.json.inputs[] missing required_target={required_target}"),
+            unit: Some("current_json"),
+            command_path: None,
+            key_or_name: Some(required_target.clone()),
+            field: Some("inputs"),
+            target_triple: Some(required_target),
+            details: None,
+        });
+        return;
+    };
+    let semantic_version = required_input
+        .get("binary")
+        .and_then(|b| b.get("semantic_version"))
+        .and_then(Value::as_str);
+    if semantic_version != Some(latest_validated) {
+        violations.push(Violation {
+            code: "CURRENT_JSON_SEMVER_MISMATCH",
+            path: rel_path(&ctx.root, &current_path),
+            json_pointer: Some("/inputs/*/binary/semantic_version".to_string()),
+            message: format!(
+                "current.json required_target binary.semantic_version must equal latest_validated.txt (expected {latest_validated}, got {})",
+                semantic_version.unwrap_or("<missing>")
+            ),
+            unit: Some("current_json"),
+            command_path: None,
+            key_or_name: Some(required_target.clone()),
+            field: Some("semantic_version"),
+            target_triple: Some(required_target),
+            details: None,
+        });
+    }
+}
diff --git a/crates/xtask/src/codex_validate/fix_mode.rs b/crates/xtask/src/codex_validate/fix_mode.rs
new file mode 100644
index 0000000..845b6d6
--- /dev/null
+++ b/crates/xtask/src/codex_validate/fix_mode.rs
@@ -0,0 +1,47 @@
+use std::fs;
+
+use super::{pointers, FatalError, PointerRead, PointerValue, ValidateCtx};
+
+pub(super) fn apply_fix_mode(ctx: &ValidateCtx) -> Result<(), FatalError> {
+    // 1) Create missing pointer files under pointers/ for every expected target.
+    for target in &ctx.expected_targets {
+        for dir in ["pointers/latest_supported", "pointers/latest_validated"] {
+            let path = ctx.root.join(dir).join(format!("{target}.txt"));
+            if path.exists() {
+                continue;
+            }
+            fs::create_dir_all(path.parent().unwrap_or(&ctx.root))?;
+            fs::write(&path, b"none\n")?;
+        }
+    }
+
+    // 2) Normalize pointer formatting (single line + trailing newline).
+    for target in &ctx.expected_targets {
+        for dir in ["pointers/latest_supported", "pointers/latest_validated"] {
+            let path = ctx.root.join(dir).join(format!("{target}.txt"));
+            pointers::normalize_single_line_file(&path)?;
+        }
+    }
+    pointers::normalize_single_line_file(&ctx.root.join("latest_validated.txt"))?;
+    pointers::normalize_single_line_file(&ctx.root.join("min_supported.txt"))?;
+
+    // 3) Normalize current.json to match snapshots/<latest_validated>/union.json (if possible).
+    let latest_validated = match pointers::read_pointer_file(
+        &ctx.root.join("latest_validated.txt"),
+        &ctx.stable_semver_re,
+        false,
+    ) {
+        Ok(PointerRead::Value(PointerValue::Version(ver))) => Some(ver.to_string()),
+        _ => None,
+    };
+
+    if let Some(version) = latest_validated {
+        let union_path = ctx.root.join("snapshots").join(&version).join("union.json");
+        if union_path.is_file() {
+            let bytes = fs::read(&union_path)?;
+            fs::write(ctx.root.join("current.json"), bytes)?;
+        }
+    }
+
+    Ok(())
+}
diff --git a/crates/xtask/src/codex_validate/pointer_consistency.rs b/crates/xtask/src/codex_validate/pointer_consistency.rs
new file mode 100644
index 0000000..24b5c8e
--- /dev/null
+++ b/crates/xtask/src/codex_validate/pointer_consistency.rs
@@ -0,0 +1,98 @@
+use std::collections::{BTreeMap, BTreeSet};
+
+use serde_json::Value;
+
+use super::{rel_path, PointerValues, ValidateCtx, Violation};
+
+pub(super) fn validate_pointer_consistency(
+    ctx: &ValidateCtx,
+    violations: &mut Vec<Violation>,
+    pointers: &PointerValues,
+    version_metadata: &BTreeMap<String, Value>,
+) {
+    for (target, v) in &pointers.by_target_latest_supported {
+        let Some(version) = v.as_deref() else {
+            continue;
+        };
+        let meta = version_metadata.get(version);
+        if meta.is_none() {
+            continue;
+        }
+        let supported_targets = meta
+            .and_then(|m| m.get("coverage"))
+            .and_then(|c| c.get("supported_targets"))
+            .and_then(Value::as_array)
+            .map(|arr| {
+                arr.iter()
+                    .filter_map(Value::as_str)
+                    .map(|s| s.to_string())
+                    .collect::<BTreeSet<_>>()
+            })
+            .unwrap_or_default();
+        if !supported_targets.contains(target) {
+            violations.push(Violation {
+                code: "POINTER_INCONSISTENT_WITH_VERSION_METADATA",
+                path: rel_path(&ctx.root, &ctx.root.join("versions").join(format!("{version}.json"))),
+                json_pointer: Some("/coverage/supported_targets".to_string()),
+                message: format!(
+                    "pointers/latest_supported/{target}.txt={version} requires versions/{version}.json.coverage.supported_targets to include target_triple={target}"
+                ),
+                unit: Some("pointers"),
+                command_path: None,
+                key_or_name: Some(target.clone()),
+                field: Some("latest_supported"),
+                target_triple: Some(target.clone()),
+                details: None,
+            });
+        }
+    }
+
+    for (target, v) in &pointers.by_target_latest_validated {
+        let Some(version) = v.as_deref() else {
+            continue;
+        };
+        let meta = version_metadata.get(version);
+        if meta.is_none() {
+            continue;
+        }
+        let supported_targets = meta
+            .and_then(|m| m.get("coverage"))
+            .and_then(|c| c.get("supported_targets"))
+            .and_then(Value::as_array)
+            .map(|arr| {
+                arr.iter()
+                    .filter_map(Value::as_str)
+                    .map(|s| s.to_string())
+                    .collect::<BTreeSet<_>>()
+            })
+            .unwrap_or_default();
+        let passed_targets = meta
+            .and_then(|m| m.get("validation"))
+            .and_then(|v| v.get("passed_targets"))
+            .and_then(Value::as_array)
+            .map(|arr| {
+                arr.iter()
+                    .filter_map(Value::as_str)
+                    .map(|s| s.to_string())
+                    .collect::<BTreeSet<_>>()
+            })
+            .unwrap_or_default();
+
+        if !supported_targets.contains(target) || !passed_targets.contains(target) {
+            violations.push(Violation {
+                code: "POINTER_INCONSISTENT_WITH_VERSION_METADATA",
+                path: rel_path(&ctx.root, &ctx.root.join("versions").join(format!("{version}.json"))),
+                json_pointer: Some("/validation/passed_targets".to_string()),
+                message: format!(
+                    "pointers/latest_validated/{target}.txt={version} requires versions/{version}.json.coverage.supported_targets and versions/{version}.json.validation.passed_targets to include target_triple={target}"
+                ),
+                unit: Some("pointers"),
+                command_path: None,
+                key_or_name: Some(target.clone()),
+                field: Some("latest_validated"),
+                target_triple: Some(target.clone()),
+                details: None,
+            });
+        }
+    }
+}
diff --git a/crates/xtask/src/codex_validate/versions.rs b/crates/xtask/src/codex_validate/versions.rs
new file mode 100644
index 0000000..4933a89
--- /dev/null
+++ b/crates/xtask/src/codex_validate/versions.rs
@@ -0,0 +1,459 @@
+use std::{
+    collections::{BTreeMap, BTreeSet},
+    fs, io,
+    path::Path,
+};
+
+use semver::Version;
+use serde_json::{json, Value};
+
+use super::{
+    is_per_target_snapshot, is_union_snapshot, parse_stable_version, rel_path, report_invariants,
+    schema, PointerValues, ValidateCtx, Violation,
+};
+
+pub(super) fn compute_versions_to_validate(
+    ctx: &mut ValidateCtx,
+    violations: &mut Vec<Violation>,
+    pointers: &PointerValues,
+) -> Vec<String> {
+    let mut versions = BTreeSet::<Version>::new();
+
+    for v in pointers
+        .min_supported
+        .iter()
+        .chain(pointers.latest_validated.iter())
+    {
+        if let Some(ver) = parse_stable_version(v, &ctx.stable_semver_re) {
+            versions.insert(ver);
+        }
+    }
+    for (_target, v) in pointers
+        .by_target_latest_supported
+        .iter()
+        .chain(pointers.by_target_latest_validated.iter())
+    {
+        if let Some(v) = v {
+            if let Some(ver) = parse_stable_version(v, &ctx.stable_semver_re) {
+                versions.insert(ver);
+            }
+        }
+    }
+
+    let versions_dir = ctx.root.join("versions");
+    match fs::read_dir(&versions_dir) {
+        Ok(read_dir) => {
+            let mut entries = read_dir
+                .filter_map(|e| e.ok())
+                .filter_map(|e| {
+                    let path = e.path();
+                    if path.extension().and_then(|x| x.to_str()) != Some("json") {
+                        return None;
+                    }
+                    let stem = path.file_stem()?.to_str()?.to_string();
+                    Some((stem, path))
+                })
+                .collect::<Vec<_>>();
+            entries.sort_by(|a, b| a.0.cmp(&b.0));
+            for (stem, path) in entries {
+                match parse_stable_version(&stem, &ctx.stable_semver_re) {
+                    Some(ver) => {
+                        versions.insert(ver);
+                    }
+                    None => violations.push(Violation {
+                        code: "VERSION_FILE_INVALID_NAME",
+                        path: rel_path(&ctx.root, &path),
+                        json_pointer: None,
+                        message: format!(
+                            "versions/<version>.json filename must be a strict stable semver (got {stem})"
+                        ),
+                        unit: Some("versions"),
+                        command_path: None,
+                        key_or_name: Some(stem),
+                        field: Some("filename"),
+                        target_triple: None,
+                        details: None,
+                    }),
+                }
+            }
+        }
+        Err(e) if e.kind() == io::ErrorKind::NotFound => {}
+        Err(e) => {
+            violations.push(Violation {
+                code: "VERSIONS_DIR_UNREADABLE",
+                path: rel_path(&ctx.root, &versions_dir),
+                json_pointer: None,
+                message: format!("failed to read versions directory: {e}"),
+                unit: Some("versions"),
+                command_path: None,
+                key_or_name: None,
+                field: None,
+                target_triple: None,
+                details: None,
+            });
+        }
+    }
+
+    versions.into_iter().map(|v| v.to_string()).collect()
+}
+
+pub(super) fn validate_version_bundle(
+    ctx: &mut ValidateCtx,
+    violations: &mut Vec<Violation>,
+    version: &str,
+    version_metadata: &mut BTreeMap<String, Value>,
+) {
+    let version_path = ctx.root.join("versions").join(format!("{version}.json"));
+    match schema::read_json_file(
+        &ctx.root,
+        &version_path,
+        violations,
+        "VERSION_METADATA_INVALID_JSON",
+    ) {
+        Some(value) => {
+            schema::schema_validate(
+                ctx,
+                violations,
+                &ctx.version_schema,
+                &value,
+                &version_path,
+                "VERSION_METADATA_SCHEMA_INVALID",
+            );
+            validate_version_metadata_validation_sets(
+                ctx,
+                violations,
+                version,
+                &value,
+                &version_path,
+            );
+            version_metadata.insert(version.to_string(), value);
+        }
+        None => {
+            if !version_path.exists() {
+                violations.push(Violation {
+                    code: "VERSION_METADATA_MISSING",
+                    path: rel_path(&ctx.root, &version_path),
+                    json_pointer: None,
+                    message: format!("missing required file: versions/{version}.json"),
+                    unit: Some("versions"),
+                    command_path: None,
+                    key_or_name: Some(version.to_string()),
+                    field: Some("versions"),
+                    target_triple: None,
+                    details: None,
+                });
+            }
+        }
+    }
+
+    let union_path = ctx.root.join("snapshots").join(version).join("union.json");
+    let union_value = match schema::read_json_file(
+        &ctx.root,
+        &union_path,
+        violations,
+        "UNION_INVALID_JSON",
+    ) {
+        Some(value) => {
+            schema::schema_validate(
+                ctx,
+                violations,
+                &ctx.schema,
+                &value,
+                &union_path,
+                "UNION_SCHEMA_INVALID",
+            );
+            if !is_union_snapshot(&value) {
+                violations.push(Violation {
+                    code: "UNION_WRONG_KIND",
+                    path: rel_path(&ctx.root, &union_path),
+                    json_pointer: Some("/snapshot_schema_version".to_string()),
+                    message: "snapshots/<version>/union.json must be an UpstreamSnapshotUnionV2 (snapshot_schema_version=2, mode=union)".to_string(),
+                    unit: Some("snapshots"),
+                    command_path: None,
+                    key_or_name: Some(version.to_string()),
+                    field: Some("union"),
+                    target_triple: None,
+                    details: None,
+                });
+            }
+            Some(value)
+        }
+        None => {
+            if !union_path.exists() {
+                violations.push(Violation {
+                    code: "UNION_MISSING",
+                    path: rel_path(&ctx.root, &union_path),
+                    json_pointer: None,
+                    message: format!("missing required file: snapshots/{version}/union.json"),
+                    unit: Some("snapshots"),
+                    command_path: None,
+                    key_or_name: Some(version.to_string()),
+                    field: Some("union"),
+                    target_triple: None,
+                    details: None,
+                });
+            }
+            None
+        }
+    };
+
+    let inputs = union_value
+        .as_ref()
+        .and_then(|u| u.get("inputs"))
+        .and_then(Value::as_array)
+        .cloned()
+        .unwrap_or_default();
+
+    let mut input_targets = Vec::<String>::new();
+    for input in &inputs {
+        if let Some(t) = input.get("target_triple").and_then(Value::as_str) {
+            input_targets.push(t.to_string());
+        }
+    }
+
+    for target in &input_targets {
+        let per_target_path = ctx
+            .root
+            .join("snapshots")
+            .join(version)
+            .join(format!("{target}.json"));
+        match schema::read_json_file(
+            &ctx.root,
+            &per_target_path,
+            violations,
+            "SNAPSHOT_INVALID_JSON",
+        ) {
+            Some(value) => {
+                schema::schema_validate(
+                    ctx,
+                    violations,
+                    &ctx.schema,
+                    &value,
+                    &per_target_path,
+                    "SNAPSHOT_SCHEMA_INVALID",
+                );
+                if !is_per_target_snapshot(&value) {
+                    violations.push(Violation {
+                        code: "SNAPSHOT_WRONG_KIND",
+                        path: rel_path(&ctx.root, &per_target_path),
+                        json_pointer: Some("/snapshot_schema_version".to_string()),
+                        message: "snapshots/<version>/<target_triple>.json must be an UpstreamSnapshotV1 (snapshot_schema_version=1)".to_string(),
+                        unit: Some("snapshots"),
+                        command_path: None,
+                        key_or_name: Some(target.to_string()),
+                        field: Some("per_target"),
+                        target_triple: Some(target.to_string()),
+                        details: None,
+                    });
+                }
+            }
+            None => {
+                if per_target_path.exists() {
+                    continue;
+                }
+                violations.push(Violation {
+                    code: "SNAPSHOT_MISSING",
+                    path: rel_path(&ctx.root, &per_target_path),
+                    json_pointer: None,
+                    message: format!(
+                        "missing required file: snapshots/{version}/{target}.json (referenced by union.inputs[])"
+                    ),
+                    unit: Some("snapshots"),
+                    command_path: None,
+                    key_or_name: Some(target.to_string()),
+                    field: Some("per_target"),
+                    target_triple: Some(target.to_string()),
+                    details: None,
+                });
+            }
+        }
+    }
+
+    // Reports are required depending on version status.
+    let status = version_metadata
+        .get(version)
+        .and_then(|v| v.get("status"))
+        .and_then(Value::as_str)
+        .unwrap_or("unknown");
+
+    let require_reports = matches!(status, "reported" | "validated" | "supported");
+    let reports_dir = ctx.root.join("reports").join(version);
+    let any_report = reports_dir.join("coverage.any.json");
+    if require_reports {
+        report_invariants::require_report(ctx, violations, version, "any", None, &any_report);
+    } else {
+        report_invariants::validate_report_if_present(ctx, violations, &any_report);
+    }
+
+    for target in &input_targets {
+        let per_target = reports_dir.join(format!("coverage.{target}.json"));
+        if require_reports {
+            report_invariants::require_report(
+                ctx,
+                violations,
+                version,
+                "per_target",
+                Some(target.as_str()),
+                &per_target,
+            );
+        } else {
+            report_invariants::validate_report_if_present(ctx, violations, &per_target);
+        }
+    }
+
+    let complete = union_value
+        .as_ref()
+        .and_then(|u| u.get("complete"))
+        .and_then(Value::as_bool)
+        .unwrap_or(false);
+    if complete {
+        let all_report = reports_dir.join("coverage.all.json");
+        if require_reports {
+            report_invariants::require_report(ctx, violations, version, "all", None, &all_report);
+        } else {
+            report_invariants::validate_report_if_present(ctx, violations, &all_report);
+        }
+    }
+}
+
+fn intersect(a: &BTreeSet<String>, b: &BTreeSet<String>) -> BTreeSet<String> {
+    a.intersection(b).cloned().collect()
+}
+
+fn validate_version_metadata_validation_sets(
+    ctx: &ValidateCtx,
+    violations: &mut Vec<Violation>,
+    version: &str,
+    meta: &Value,
+    path: &Path,
+) {
+    let Some(validation) = meta.get("validation") else {
+        return;
+    };
+
+    let expected = ctx
+        .expected_targets
+        .iter()
+        .cloned()
+        .collect::<BTreeSet<_>>();
+
+    let passed = validation
+        .get("passed_targets")
+        .and_then(Value::as_array)
+        .map(|arr| {
+            arr.iter()
+                .filter_map(Value::as_str)
+                .map(|s| s.to_string())
+                .collect::<BTreeSet<_>>()
+        })
+        .unwrap_or_default();
+    let failed = validation
+        .get("failed_targets")
+        .and_then(Value::as_array)
+        .map(|arr| {
+            arr.iter()
+                .filter_map(Value::as_str)
+                .map(|s| s.to_string())
+                .collect::<BTreeSet<_>>()
+        })
+        .unwrap_or_default();
+    let skipped = validation
+        .get("skipped_targets")
+        .and_then(Value::as_array)
+        .map(|arr| {
+            arr.iter()
+                .filter_map(Value::as_str)
+                .map(|s| s.to_string())
+                .collect::<BTreeSet<_>>()
+        })
+        .unwrap_or_default();
+
+    let overlaps = [
+        (
+            "passed_targets",
+            "failed_targets",
+            intersect(&passed, &failed),
+        ),
+        (
+            "passed_targets",
+            "skipped_targets",
+            intersect(&passed, &skipped),
+        ),
+        (
+            "failed_targets",
+            "skipped_targets",
+            intersect(&failed, &skipped),
+        ),
+    ];
+    for (a, b, inter) in overlaps {
+        if inter.is_empty() {
+            continue;
+        }
+        violations.push(Violation {
+            code: "VALIDATION_TARGET_SETS_OVERLAP",
+            path: rel_path(&ctx.root, path),
+            json_pointer: Some("/validation".to_string()),
+            message: format!(
+                "versions/{version}.json validation target sets overlap ({a}  {b} = {:?})",
+                inter.iter().collect::<Vec<_>>()
+            ),
+            unit: Some("versions"),
+            command_path: None,
+            key_or_name: Some(version.to_string()),
+            field: Some("validation"),
+            target_triple: None,
+            details: Some(json!({
+                "overlap": inter.into_iter().collect::<Vec<_>>(),
+                "a": a,
+                "b": b,
+            })),
+        });
+    }
+
+    for t in passed.iter().chain(failed.iter()).chain(skipped.iter()) {
+        if expected.contains(t) {
+            continue;
+        }
+        violations.push(Violation {
+            code: "VALIDATION_TARGET_NOT_EXPECTED",
+            path: rel_path(&ctx.root, path),
+            json_pointer: Some("/validation".to_string()),
+            message: format!(
+                "versions/{version}.json validation includes unexpected target_triple={t} (not in RULES.json.union.expected_targets)"
+            ),
+            unit: Some("versions"),
+            command_path: None,
+            key_or_name: Some(version.to_string()),
+            field: Some("validation"),
+            target_triple: Some(t.to_string()),
+            details: None,
+        });
+    }
+
+    let required = ctx.required_target.as_str();
+    let count = (passed.contains(required) as u8)
+        + (failed.contains(required) as u8)
+        + (skipped.contains(required) as u8);
+    if count != 1 {
+        violations.push(Violation {
+            code: "VALIDATION_REQUIRED_TARGET_NOT_EXPLICIT",
+            path: rel_path(&ctx.root, path),
+            json_pointer: Some("/validation".to_string()),
+            message: format!(
+                "versions/{version}.json validation must include required_target={} in exactly one of passed_targets/failed_targets/skipped_targets",
+                ctx.required_target
+            ),
+            unit: Some("versions"),
+            command_path: None,
+            key_or_name: Some(version.to_string()),
+            field: Some("validation"),
+            target_triple: Some(ctx.required_target.clone()),
+            details: Some(json!({
+                "required_target": ctx.required_target,
+                "passed": passed.contains(required),
+                "failed": failed.contains(required),
+                "skipped": skipped.contains(required),
+            })),
+        });
+    }
+}
