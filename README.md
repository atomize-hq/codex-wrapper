# Codex Rust Wrapper

Async helper around the OpenAI Codex CLI for programmatic prompting, streaming, and server flows. The crate shells out to `codex`, applies safe defaults (temp working dirs, timeouts, quiet stderr mirroring), and lets you pick either a packaged binary or an env-provided one.

## Getting Started
- Add the dependency:  
  ```toml
  [dependencies]
  codex = { path = "crates/codex" }
  ```
- Minimal prompt:
  ```rust
  use codex::CodexClient;

  # async fn demo() -> Result<(), Box<dyn std::error::Error>> {
  let client = CodexClient::builder().build();
  let reply = client.send_prompt("List rustfmt defaults").await?;
  println!("{reply}");
  # Ok(()) }
  ```
- Default binary resolution: `CODEX_BINARY` if set, otherwise `codex` on `PATH`. Use `.binary(...)` to point at a bundled binary (see `crates/codex/examples/bundled_binary.rs`).

## Bundled Binary & `CODEX_HOME`
- Ship Codex with your app by setting `CODEX_BINARY` or calling `.binary("/opt/myapp/bin/codex")`. The `bundled_binary` example shows falling back to `CODEX_BUNDLED_PATH` and a local `bin/codex` hint.
- Isolate state with `CODEX_HOME` (config/auth/history/logs live under that directory: `config.toml`, `auth.json`, `.credentials.json`, `history.jsonl`, `conversations/*.jsonl`, `logs/codex-*.log`). The crate uses the current process env for every spawn.
- Quick isolated run (see `crates/codex/examples/codex_home.rs`):
  ```rust
  std::env::set_var("CODEX_HOME", "/tmp/my-app-codex");
  let client = CodexClient::builder().build();
  let _ = client.send_prompt("Health check").await?;
  ```

## Exec API & Safety Defaults
- `send_prompt` shells out to `codex exec --skip-git-repo-check` with:
  - temp working directory per call unless `working_dir` is set
  - 120s timeout (use `.timeout(Duration::ZERO)` to disable)
  - ANSI colors off by default (`ColorMode::Never`)
  - mirrors stdout by default; set `.mirror_stdout(false)` when parsing JSON
  - `RUST_LOG=error` if unset to keep the console quiet
  - model-specific reasoning config for `gpt-5`/`gpt-5-codex`
- Other builder flags: `.model("gpt-5-codex")`, `.image("/path/mock.png")`, `.json(true)` (pipes prompt via stdin), `.quiet(true)`.
- Example `crates/codex/examples/send_prompt.rs` covers the baseline; `working_dir(_json).rs`, `timeout*.rs`, `image_json.rs`, `color_always.rs`, `quiet.rs`, and `no_stdout_mirror.rs` expand on inputs and output handling.

## Streaming Output & Artifacts
- Event schema: JSONL lines carry `type` plus IDs/status. Expect `thread.started`, `turn.started/turn.completed/turn.failed`, and `item.created/item.updated` where `item.type` can be `agent_message`, `reasoning`, `command_execution`, `file_change`, `mcp_tool_call`, `web_search`, or `todo_list` with optional `status`/`content`/`input`. Errors surface as `{"type":"error","message":...}`. Examples ship `--sample` payloads so you can inspect shapes without a binary.
- Enable JSONL streaming with `.json(true)` or by invoking the CLI directly. The crate returns captured output; use the examples to consume the stream yourself:
  - `crates/codex/examples/stream_events.rs`: typed consumer for `thread/turn/item` events (success + failure), uses `--timeout 0` to keep streaming, includes idle timeout handling, and a `--sample` replay path.
  - `crates/codex/examples/stream_last_message.rs`: runs `--output-last-message` + `--output-schema`, reads the emitted files, and ships sample payloads if the binary is missing.
  - `crates/codex/examples/stream_with_log.rs`: mirrors JSON events to stdout and tees them to `CODEX_LOG_PATH` (default `codex-stream.log`); also supports `--sample` and can defer to the binary's built-in log tee feature when advertised via `codex features list`.
  - `crates/codex/examples/json_stream.rs`: simplest `--json` usage when you just want the raw stream buffered.
- Artifacts: Codex can persist the final assistant message and the output schema alongside streaming output; point them at writable locations per the `stream_last_message` example. Apply/diff flows also surface stdout/stderr/exit (see below) so you can log or mirror them alongside the JSON stream.

## Resume, Diff, and Apply
- Resume an existing conversation with `codex resume --json --skip-git-repo-check --last` (or `--id <conversationId>`/`CODEX_CONVERSATION_ID`). The event stream matches `exec` (`thread/turn/item` plus `turn.failed` on idle timeouts); reuse the streaming examples to consume it.
- Preview a patch before applying it: `codex diff --json --skip-git-repo-check` emits the staged diff while preserving JSON-safe output. Pair it with `codex apply --json` to capture stdout, stderr, and the exit code for the apply step.
- Approvals and cancellations surface as events in MCP/app-server flows; see the server examples for approval-required hooks around apply.
- Example `crates/codex/examples/resume_apply.rs` covers the full flow with `--sample` payloads (resume stream, diff preview, apply result) and lets you skip the apply step with `--no-apply`.

## MCP + App-Server Flows
- The CLI ships stdio servers for Model Context Protocol and the app-server APIs. Examples cover the JSON-RPC wiring, approvals, and shutdown:
  - `crates/codex/examples/mcp_codex_tool.rs`: start `codex mcp-server --stdio`, call `tools/codex` with prompt/cwd/model/sandbox, and watch `approval_required`/`task_complete` notifications (includes `turn_id`/`sandbox` and supports `--sample`).
  - `crates/codex/examples/mcp_codex_reply.rs`: resume a session via `tools/codex-reply`, taking `CODEX_CONVERSATION_ID` or a CLI arg; supports `--sample`.
  - `crates/codex/examples/app_server_thread_turn.rs`: launch `codex app-server --stdio`, send `thread/start` then `turn/start`, and stream task notifications (thread/turn IDs echoed; `--sample` supported).
- Pass `CODEX_HOME` for isolated server state and `CODEX_BINARY` (or `.binary(...)`) to pin the binary version used by the servers.

## Feature Detection & Version Hooks
- `crates/codex/examples/feature_detection.rs` shows how to:
  - parse `codex --version`
  - list features via `codex features list` (if supported) and cache them per binary path so repeated probes avoid extra processes
  - gate optional knobs like JSON streaming, log tee, MCP/app-server endpoints, resume/apply/diff flags, and artifact flags
  - emit an upgrade advisory hook when required capabilities are missing
- Use this when deciding whether to enable `--json`, log tee paths, resume/apply helpers, or app-server endpoints in your app UI. Always gate new feature names against `codex features list` so drift in the binary's output is handled gracefully.

## Upgrade Advisories & Gaps
- Sample streams, resume/apply payloads, and feature names reflect the current CLI surface but are not validated against a live binary here; gate risky flags behind capability checks and prefer `--sample` payloads while developing.
- The crate still buffers stdout/stderr from streaming/apply flows instead of exposing a typed stream API; use the examples to consume JSONL incrementally until a typed interface lands.
- Apply/diff flows depend on Codex emitting JSON-friendly stdout/stderr; handle non-JSON output defensively in host apps.

## Examples Index
- The full wrapper vs. native CLI matrix lives in `crates/codex/EXAMPLES.md`.
- Run any example via `cargo run -p codex --example <name> -- <args>`; most support `--sample` so you can read shapes without a binary present.
